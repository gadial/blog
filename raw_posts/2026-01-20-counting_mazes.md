---
title: "מונה מבוכים"
layout: post
categories:
  - משחקים וחידות מתמטיות
tags:
  - חידה מתמטית
  - גרף
  - משפט המטריצה-עץ של קירקהוף
  - לפלסיאן של גרפים
  - ערכים עצמיים
  - פולינומי צ'בישב
  - סכום קרונקר
---

 ## מה אנחנו מנסים לעשות פה בכלל

בפוסט הזה אני רוצה לדבר על משהו שהוא בין חידה לבין תוצאה מתמטית ישירה יחסית, אבל כזו שהיא ממש נחמדה בזכות שילוב של שני דברים: ראשית, זו בעיה מספרית קונקרטית עם פתרון קונקרטי, וכזה שזועק בכל הכוח "אין לכם שום סיכוי למצוא אותי בלי להיות חכמים!" ושנית, זו חידה שנותנת הזדמנות לראות כמה וכמה פיסות יפות של מתמטיקה שמשתלבות נהדר ביחד כדי לפתור אותה. והחידה היא זו: כמה מבוכים מגודל {% equation %}423\times855{% endequation %} 
יש?

כמובן, נצטרך להסביר את זה קצת.

ראשית, מבוכים יש משלל סוגים ומינים. אני מדבר על סוג מאוד קונקרטי - מבוכים שנראים ככה:

<img src="{{site.baseurl}}{{site.post_images}}/2026/maze.png" alt=""/>

במבוכים כאלו, ה" עולם" שלנו הוא לוח דו ממדי של {% equation %}n\times m{% endequation %} תאים ריבועיים. לכל תא יש ארבעה שכנים (למעלה/למטה/ימינה/שמאלה) למעט אלו שבקצוות, ובין כל שני שכנים או שיש קיר, או שאין קיר. בשביל שמשהו יהיה "מבוך" צריך שיהיה בדיוק מסלול **יחיד** בין כל שני תאים - כך שמצד אחד אפשר להגיע מכל מקום לכל מקום, ומצד שני אין לנו שתי דרכים שונות להגיע לאותו מקום. אפשר לחשוב על זה ככה - מבוך כזה ממקסם את מספר הקירות שיש בו תוך שמירה על התכונה שאפשר להגיע בו לכל מקום.

הנה דוגמא לכל 15 המבוכים הקיימים מגודל {% equation %}3\times2{% endequation %} :

<img src="{{site.baseurl}}{{site.post_images}}/2026/small_mazes.png" alt=""/>

אם כן, עבור גודל {% equation %}n\times m{% endequation %} עבור {% equation %}n,m{% endequation %} שרירותיים, איך סופרים כמה מבוכים יש? נתחיל מהשיטה הכי נאיבית; הרבה פעמים הגישה הנאיבית עובדת מספיק טוב בפועל ולא צריך לחשוב יותר מדי. לא הפעם. בגישה הנאיבית כאן, אפשר לבנות רשימה של כל הקירות הפוטנציאליים, ולכל תת-קבוצה של קירות לבדוק אם קיבלנו מבוך או לא, ואם כן להוסיף אותו לספירה. כמה קירות פוטנציאליים יש? אם נסתכל על השורה העליונה של המבוך, היא כוללת {% equation %}m{% endequation %} תאים שמופרדים ב-{% equation %}m-1{% endequation %} קירות אנכיים, אז יש {% equation %}n\left(m-1\right){% endequation %} קירות אנכיים בכל המבוך ובאופן דומה יש גם {% equation %}m\left(n-1\right){% endequation %} קירות אופקיים, כלומר בסך הכל יש {% equation %}2mn-\left(n+m\right){% endequation %} קירות. אם אנחנו רק רוצים לקבל אינטואיציה אפשר להניח ש-{% equation %}n,m{% endequation %} הם בערך מאותו סדר גודל ולהשתמש בסימן {% equation %}O{% endequation %} שבמדעי המחשב אוהבים להשתמש בו כדי להגיד "בערך"(בערך... למעשה {% equation %}\Theta{% endequation %} הוא סימון יותר מדויק כאן אבל למי אכפת) ולהגיד שיש לנו סדר גודל של {% equation %}O\left(n^{2}\right){% endequation %} קירות. עכשיו, אם {% equation %}A{% endequation %} היא קבוצה אז יש לה {% equation %}2^{\left|A\right|}{% endequation %} תת-קבוצות אז יש לנו {% equation %}O\left(2^{n^{2}}\right){% endequation %} מבוכים פוטנציאליים, ועבור כל אחד כזה צריך **לבדוק** אלגוריתמית שבאמת קיבלנו מבוך... זה לא יילך, יש מספר אקספוננציאלי של מבוכים פוטנציאליים ובדיקה שמשהו היא מבוך תשתמש באלגוריתם חיפוש כמו DFS שלוקח {% equation %}O\left(n^{2}\right){% endequation %} 
זמן (לפחות כמספר התאים, הרי הוא צריך לבקר בכולם). בקיצור, לא לא לא. הפתרון הנאיבי לא קשור למציאות פה.

אבל יש מושג שהכנסה שלו לתמונה מייד מפשטת את כל הסיפור - **עץ**. [הצגתי את המושג הזה בעבר בבלוג](https://gadial.net/2013/09/30/graphs_spanning_trees_and_code/) ספציפית מתוך הדוגמא של בניית מבוכים, אז אפשר להבין שאני אוהב את הנושא הזה - אבל שימוש בעצים לתאר מבוכים הוא רק קצה-קצהו של תחום עצום של כל הדברים שעצים משמשים להם. הנה התקציר: עץ הוא מקרה פרטי מעניין של מה שנקרא **גרף**, כשגרף הוא משהו שכולל אוסף של "צמתים" כך שכל שני צמתים יכולים להיות מחוברים בקשת, או לא מחוברים בקשת. אצלנו אפשר לחשוב על מבוך בתור גרף שבו התאים הם הצמתים, ויש קשת בין שני תאים סמוכים **שלא** מופרדים בקיר.

המושג של "אפשר להגיע מכל תא לכל תא" מתורגם לתורת הגרפים בתור האמירה ש" הגרף קשיר" , והקטע הזה שאין שתי דרכים שונות להגיע מנקודה א' לנקודה ב' מתואר בתור "הגרף חסר מעגלים" . ההגדרה הפורמלית של **עץ** היא בתור "גרף קשיר וחסר מעגלים" . אלו שתי תכונות שהן מנוגדות זו לזו במובן מסוים - ככל שמוסיפים קשתות כך אנחנו מגדילים את הסיכוי שהגרף יהיה קשיר אבל מקטינים את הסיכוי שהגרף יהיה חסר מעגלים, וההפך. לכן הנקודה שבה שתי התכונות הללו מתקיימות בו זמנית היא קסומה למדי (יש סיטואציה דומה מאוד באלגברה לינארית שבה קבוצת וקטורים יכולה להיות **בלתי תלויה לינארית** ויכולה להיות **פורשת** וכששתי התכונות הללו מתקיימות בו זמנית אנחנו מקבלים את המושג הקסום של **בסיס**; הדמיון הזה לא מקרי ושתי הסיטואציות הללו מוכללות על ידי מושג שנקרא מטרואיד, אבל נעזוב את זה).

אחד הדברים הנחמדים שאפשר להוכיח על עץ הוא שאם העץ כולל {% equation %}n{% endequation %} צמתים, אז הוא כולל בדיוק {% equation %}n-1{% endequation %} קשתות - כל קשת שנוסיף תיצור מעגל, וכל הסרת קשת תקלקל את הקשירות. מה שזה אומר לנו הוא שמלכתחילה אין טעם לבדוק את **כל** תתי-הקבוצות של הקירות האפשריים; במבוך שלנו יש {% equation %}nm{% endequation %} 
תאים אז אנחנו צריכים להסתכל רק על תת-קבוצות מגודל {% equation %}nm-1{% endequation %} של קבוצת כל הקירות האפשריים ולהסיר רק את הקירות הללו. העניין הוא שמספר תתי-הקבוצות הללו הוא... עדיין אקספוננציאלי. התיאוריה הבסיסית של עצים חוסכת לנו חלק מהעבודה, אבל לא חלק גדול במיוחד. צריך להוסיף משהו חזק יותר.

המשהו החזק יותר נקרא "משפט המטריצה-עץ של קירקהוף" והוא לטעמי תוצאה יפהפיה ממש. [יש לי כבר פוסט עליו](https://gadial.net/2011/09/13/kirkhoffs_matrix_tree_theorem/) שבו אני גם מוכיח אותו, אז פה מן הסתם אוותר על ההוכחה (הלא פשוטה אבל היפה מאוד בזכות עצמה). הרעיון פה הוא שאיכשהו אפשר להמיר את הבעיה של ספירת עצים לבעיה מתחום האלגברה הלינארית, של חישוב **דטרמיננטה** של מטריצה מסוימת שנבנית מתוך הגרף שלנו. חישוב דטרמיננטה הוא דבר קל יחסית מבחינה חישובית; והפוסט הזה יעסוק בעיקר באיך עבור הסיטואציה הספציפית שלנו של דטרמיננטה של מטריצה שהגיעה מגרף שהוא עץ שנבנה בצורה שמתאימה למבוך החישוב הזה אפילו עוד יותר קל מאשר בדרך כלל.

אז איך המשפט הולך? ראשית, מה שהמשפט עושה הוא לספור **עצים פורשים** של גרף נתון. הרעיון בעץ פורש הוא לקחת גרף שהוא כבר קשיר, ולהסיר ממנו קשתות עד שהוא הופך גם לחסר מעגלים (כלומר הוא עץ, והוא "פורש את הגרף" במובן זה שהוא על אותה קבוצת צמתים כמו הגרף המקורי ומשתמש בקשתות מתוך הגרף המקורי). אפשר להראות שלא משנה איך מסירים קשתות, כל עוד השיטה היא "תמצאו קשת שהסרה שלה לא פוגעת בקשירות של הגרף ותעיפו אותה עד שאין יותר כאלו" היא תמיד תחזיר עץ, אבל לפעמים יש עצים פורשים שהם יותר מעניינים; למשל, אם יש על הקשתות **משקלים** ואנחנו רוצים למצוא עץ פורש שהמשקל הכולל של הקשתות שלו הוא מינימלי, זו הזדמנות לשלוף את האלגוריתמים של קרוסקל ופרים שאוהבים להראות בקורס מבוא לאלגוריתמים ומוצאים עץ מינימלי שכזה בצורה לא רעה בכלל.

במקרה שלנו אנחנו לא רוצים **למצוא** עץ פורש אלא **לספור** כאלו, והגרף שאנחנו רוצים למצוא עצים פורשים שלו הוא הגרף שמתאר את המבוך כשאין בו בכלל קירות - כלומר, כשיש בו את כל הקשתות האפשריות. זה **לא** אומר שכל שני צמתים בגרף יהיו מחוברים בקשת - תזכרו, מלכתחילה קשת יכולה להיות רק בין תא במבוך ובין ארבעת השכנים שלו (או פחות שכנים, אם הוא בקצה כלשהו של המבוך וחלק מהשכנים חסרים). זה אומר שמלכתחילה, הגרף הוא "דליל" יחסית - רוב זוגות הצמתים לא הולכים להיות מחוברים בקשת, ולמעשה הדרגה של כל צומת (מספר הקשתות שמחוברות אליו) מראש מוגבלת על ידי מספר נמוך יחסית (4) שבכלל לא תלוי בגודל הגרף. ועוד יותר מכך - לגרף יש **מבנה נחמד** שמגיע מכך שהוא מתקבל ממבוך שנראה נחמד, עם יחסי שכנות די מסודרים. בשלב הראשון לא נשתמש בזה, אבל בהמשך בהחלט כן.

אני אניח שאנחנו יודעים מה זו מטריצה. אם לא, [יש לי פוסטים](https://gadial.net/2011/10/05/matrix_row_reducing/) בנושא ואפשר פשוט לחשוב עליה בתור טבלה של מספרים, אבל לא אכנס כאן להגדרות הפורמליות שלה.

בשביל משפט המטריצה-עץ אנחנו מגדירים מטריצה שנקראת **לפלסיאן** של גרף. אם {% equation %}G=\left(V,E\right){% endequation %} הוא הגרף שלנו, עם קבוצת צמתים {% equation %}V=\left\{ v_{1},\ldots,v_{n}\right\}{% endequation %} וקבוצת קשתות {% equation %}E{% endequation %} , אז מטריצה די טבעית שנהוג להגדיר עבור {% equation %}G{% endequation %} היא **מטריצת השכנויות** של {% equation %}G{% endequation %} : מטריצה {% equation %}A_{G}{% endequation %} כך ש-{% equation %}\left[A_{G}\right]_{ij}=\begin{cases}
1 & \left(v_{i},v_{j}\right)\in E\\
0 & \left(v_{i},v_{j}\right)\notin E
\end{cases}{% endequation %} . כלומר, אם יש קשת בין {% equation %}v_{i},v_{j}{% endequation %} אז כתוב בה 1 ואחרת כתוב בה 0. את זה אפשר להכליל די בקלות - אם בגרף שלנו מרשים שיותר מקשת אחת תחבר כל זוג צמתים (מה שמגדיל את מספר העצים הפורשים, כי אפשר פעם לבחור אחת מהקשתות הללו ופעם קשת אחרת) אז במקום לכתוב 1 פשוט נכתוב את מספר הקשתות שיש בין {% equation %}v_{i},v_{j}{% endequation %} . עוד פישוט שאני אעשה יהיה להניח ש-{% equation %}A_{ii}=0{% endequation %} תמיד, כלומר שאין קשת שמחברת צומת לעצמו ("חוג עצמי") - בהחלט **יכולות** להיות קשתות כאלו בגרף כללי, אבל בהקשר של ספירת עצים פורשים הן לא רלוונטיות כי כל קשת כזו יוצרת מעגל ולכן הן לא יהיו באף עץ פורש, ולכן אם רוצים שנמצא את מספר העצים הפורשים בגרף נתון, הוא יהיה שווה למספר העצים הפורשים באותו הגרף אחרי שהוסרו ממנו החוגים העצמיים, ולכן אפשר לבצע את ההנחה הזו "בלי הגבלת הכלליות" , כפי שנהוג לומר.

מטריצת השכנויות הזו היא **לא** הלפליסאן, בשביל זה נצטרך להגדיר עוד מטריצה שגם היא **לא** הלפלסיאן: מטריצת הדרגות {% equation %}\Delta_{G}{% endequation %} 
שהיא מטריצה אלכסונית כך ש-{% equation %}\Delta_{ii}=d\left(v_{i}\right){% endequation %} , כלומר היא מספר הקשתות שמחוברות אל {% equation %}v_{i}{% endequation %} . עכשיו אפשר לשלב את שתיהן כדי לקבל את מה שהוא **כן** הלפלסיאן:

{% equation %}L_{G}=\Delta_{G}-A_{G}{% endequation %} , כלומר זו המטריצה שבאלכסון שלה כתובות דרגות הצמתים, ובכל כניסה אחרת כתוב **מינוס** מספר הקשתות שמחברות שני צמתים נתונים.

אם ננסה לחשב את הדטרמיננטה ([הנה הפוסט שלי](https://gadial.net/2011/11/10/determinants/) על מה זו דטרמיננטה) של המטריצה הזו נגלה להפתעתנו הרבה שמקבלים 0... לא הבטחתי שנקבל את מספר העצים הפורשים? ובכן, לא, אבל הנה מה שעושים - בוחרים צומת שרירותי {% equation %}v_{i}{% endequation %} , מסלקים מהמטריצה את השורה והעמודה ה-{% equation %}i{% endequation %} (זה אומר שלוקחים **מינור** של המטריצה) ואז מחשבים את הדטרמיננטה - בסיטואציה הזו נקבל תמיד את אותה תוצאה בלי תלות באיזה צומת הסרנו, והתוצאה הזו תהיה מספר העצים הפורשים של הגרף (במקרה שבו הגרף **מכוון**, שלא עליו אני מדבר, יש יותר משמעות לשאלה איזה {% equation %}v_{i}{% endequation %} בוחרים - הספירה תהיה רק של העצים הפורשים ש-{% equation %}v_{i}{% endequation %} 
הוא **השורש** שלהם).

בואו נראה דוגמא לקסם הזה בפעולה, עבור המבוכים שלנו. כדי לשמור את העניינים עדיין סבירים בקושי, נסתכל על מבוך של {% equation %}2\times3{% endequation %} . כבר ראינו קודם שקיימים 15 מבוכים כאלו על ידי זה שציירנו אותם במפורש. הנה מטריצת הלפלסיאן במקרה הזה:

{% equation %}L_{G}=\left(\begin{array}{cccccc}
2 & -1 & 0 & -1 & 0 & 0\\
-1 & 3 & -1 & 0 & -1 & 0\\
0 & -1 & 2 & 0 & 0 & -1\\
-1 & 0 & 0 & 2 & -1 & 0\\
0 & -1 & 0 & -1 & 3 & -1\\
0 & 0 & -1 & 0 & -1 & 2
\end{array}\right){% endequation %} 
בגלל שלוח של {% equation %}2\times3{% endequation %} הוא ממש צפוף וכל תא נמצא בקצה כלשהו של המבוך, אנחנו לא רואים כל כך טוב פה את זה שעל האלכסון צפויים להיות בעיקר 4-ים ושבכל שורה ועמודה יהיו מעט יחסית {% equation %}-1{% endequation %} -ים ובעיקר יהיו אפסים, אבל לא נורא. לחשב את הדטרמיננטה של המטריצה הזו זה טיפה כאב ראש אבל אפשר לעשות את זה עם דירוג מטריצות יחסית מהר (מודולו עשר שגיאות החישוב שיהיו לי בדרך) ומקבלים, כמה מפתיע, 15! אז המשפט עובד. כאמור, לא אוכיח את המשפט כי יש לי פוסט ייעודי עבור ההוכחה, אבל זה ממש ממש מגניב שזה עובד.

האם סיימנו? לא. כי לא שאלתי על {% equation %}2\times3{% endequation %} . שאלתי על {% equation %}423\times855{% endequation %} . במקרה הזה אני אצטרך מטריצה מסדר {% equation %}t\times t{% endequation %} כאשר {% equation %}t=423\cdot855=361,665{% endequation %} . זו כבר מטריצה די גדולה, ולחשב את הדטרמיננטה **שלה** יהיה כאב ראש אמיתי, שלא לדבר על כך שהדטרמיננטה צפויה להיות מספר עצום ולכן נצטרך לעבוד עם מספרים שמיוצגים בנקודה צפה, ולוודא שאין לנו שגיאות נומריות שמצטברות בחישוב של הדטרמיננטה... את כל אלו **אפשר לעשות** - יש תחום שלם ומפואר שעוסק בחישובים עם מטריצות דלילות ומספרים גדולים - אבל מה שיפה פה הוא שבמקרה הקונקרטי שלנו אפשר לנצל את **המבנה המיוחד** של הגרף שלנו כדי לפשט בצורה משמעותית ביותר את החישוב.

## מה הולך ללכת כאן

עד עכשיו הבנו את כל המרכיבים העקרוניים של הפתרון, עכשיו אפשר להציג את הפתרון עצמו בלי יותר מדי הוכחות, ואז נגיע להוכחות עצמן (שהן כבדות יחסית ולכן עדיף לחכות איתן). ראשית, אם נסתכל על מטריצת הלפלסיאן {% equation %}L_{G}{% endequation %} 
ונסמן את הערכים העצמיים שלה ב-{% equation %}\lambda_{0},\lambda_{1},\ldots,\lambda_{t-1}{% endequation %} (זו מטריצה מסדר {% equation %}t\times t{% endequation %} ולכן יש לה {% equation %}t{% endequation %} ערכים עצמיים) כך ש-{% equation %}\lambda_{0}=0{% endequation %} הוא הערך העצמי 0 (אנחנו נראה ש-0 הוא תמיד ערך עצמי של {% equation %}L_{G}{% endequation %} ) אז הדטרמיננטה **של המינור** שלה היא {% equation %}\frac{1}{t}\lambda_{1}\lambda_{2}\cdots\lambda_{t-1}{% endequation %} . כלומר - אין צורך לחשב דטרמיננטה בכלל, מספיק למצוא את הערכים העצמיים.

שנית, הגרף {% equation %}G{% endequation %} הוא לא סתם גרף אקראי, יש לו כאמור מבנה יפה - אפשר להציג אותו בתור **מכפלה** של שני גרפים פשוטים בהרבה. יש כמה סוגים של מכפלות של גרפים, והסוג שמתאים כאן נקרא **מכפלת קופסה**, {% equation %}G=G_{1}\square G_{2}{% endequation %} , ונראה עוד מעט את הההגדרה שלו. זה מפשט את העניינים עבורנו כי אפשר להראות שאם הערכים העצמיים של {% equation %}L_{G_{1}}{% endequation %} הם {% equation %}\tau_{0},\tau_{1},\ldots,\tau_{n-1}{% endequation %} 
והערכים העצמיים של {% equation %}L_{G_{2}}{% endequation %} הם {% equation %}\rho_{0},\rho_{1},\ldots\rho_{m-1}{% endequation %} 
אז הערכים העצמיים של {% equation %}L_{G_{1}\square G_{2}}{% endequation %} הם מהצורה {% equation %}\lambda_{kh}=\tau_{k}+\rho_{h}{% endequation %} 
עבור {% equation %}0\le k\lt n{% endequation %} ו-{% equation %}0\le h\lt m{% endequation %} . זה, והנוסחה של {% equation %}\frac{1}{t}\lambda_{1}\lambda_{2}\cdots\lambda_{t-1}{% endequation %} 
שראינו קודם, יאפשרו לנו להגיע למסקנה שמספיק לחשב את המכפלה

{% equation %}\prod_{k=1}^{m-1}\prod_{h=1}^{n-1}\left(\tau_{k}+\rho_{h}\right){% endequation %} (שימו לב שה-{% equation %}\frac{1}{t}{% endequation %} נעלם והאינדקסים מתחילים מ-1 ולא מ-0; זה כמובן לא מקרי אלא הם יבטלו זה את זה איכשהו)

הגרפים {% equation %}G_{1},G_{2}{% endequation %} שבהם נשתמש יהיו **שרוכים**, כלומר גרפים שהם בסך הכל מסלול ישר, אחד עם {% equation %}n{% endequation %} צמתים ואחד עם {% equation %}m{% endequation %} צמתים, שיסומנו {% equation %}P_{n},P_{m}{% endequation %} . אלו גרפים כל כך פשוטים שאפשר לחשב בקלות יחסית את הערכים העצמיים שלהם, ואנחנו נשתמש במשהו שנקרא **פולינומי צ'בישב** כדי לקבל שהערך העצמי ה-{% equation %}k{% endequation %} -י של {% equation %}P_{n}{% endequation %} הוא {% equation %}4\cos^{2}\left(\frac{k\pi}{2n}\right){% endequation %} . מכאן נקבל את הנוסחה הסופית, שסופרת את מספר המבוכים מסדר {% equation %}n\times m{% endequation %} :

{% equation %}T\left(n,m\right)=\prod_{k=1}^{n-1}\prod_{h=1}^{m-1}\left(4\cos^{2}\left(\frac{k\pi}{2n}\right)+4\cos^{2}\left(\frac{h\pi}{2m}\right)\right){% endequation %} 
הנוסחה הזו אולי נראית קצת מפחידה, אבל היא פשוטה מאוד לחישוב בעזרת מחשב, גם עבור {% equation %}n=423,m=855{% endequation %} . החלק הטריקי היחיד הוא שאנחנו נגררים להכפלה של מספרי ענק, וזה קשה למחשבים, אבל יש תעלול סטנדרטי שפותר את זה - לוקחים לוגריתם של הכל, והוא הופך את המכפלה לסכום, ואז לסיום לוקחים את התוצאה שמקבלים ומוציאים את האקספוננט שלה. גם את זה אני הולך להראות במפורש.

יפה, אז עכשיו אנחנו מבינים מה הולך לקרות, אבל עדיין נשארו ההוכחות המסודרות שיעזרו לנו להבין למה בעצם כל הקסם הזה **עובד**.

## הדטרמיננטה של לפלסיאן

נתחיל עם מה שקל להראות - למטריצת הלפלסיאן יש ערך עצמי 0. בשביל לראות את זה בקלות בואו נחזור ללפלסיאן הדוגמא שלנו:

{% equation %}L_{G}=\left(\begin{array}{cccccc}
2 & -1 & 0 & -1 & 0 & 0\\
-1 & 3 & -1 & 0 & -1 & 0\\
0 & -1 & 2 & 0 & 0 & -1\\
-1 & 0 & 0 & 2 & -1 & 0\\
0 & -1 & 0 & -1 & 3 & -1\\
0 & 0 & -1 & 0 & -1 & 2
\end{array}\right){% endequation %} 
אם נסתכל על כל שורה, נראה שהיא מסתכמת ל-0. זה לא מקרי; על האלכסון בכניסה {% equation %}ii{% endequation %} יש לנו את הדרגה של הצומת {% equation %}v_{i}{% endequation %} , כלומר מספר הקשתות שמחוברות אליו. יתר השורה ה-{% equation %}i{% endequation %} -ית כוללת, לכל צומת {% equation %}v_{j}\ne v_{i}{% endequation %} , את המינוס של מספר הקשתות בין {% equation %}v_{i}{% endequation %} 
ו-{% equation %}v_{j}{% endequation %} . עכשיו, כל קשת שמחוברת אל {% equation %}v_{i}{% endequation %} מחוברת לצומת **כלשהו** וזה לא יכול להיות {% equation %}v_{i}{% endequation %} עצמו כי הנחנו שבגרף שלנו אין חוגים עצמיים, ולכן סך כל השורה חוץ מהאיבר על האלכסון הוא מינוס מספר הקשתות שמחוברות של {% equation %}v_{i}{% endequation %} , כלומר מינוס הדרגה שלו, ולכן בתוספת האיבר על האלכסון נקבל 0.

עכשיו, טריק ידוע מאלגברה לינארית הוא שאם **כל** השורות של מטריצה מסתכמות לאותו מספר {% equation %}\lambda{% endequation %} בדיוק, אז {% equation %}\lambda{% endequation %} היא ערך עצמי של המטריצה עם הוקטור העצמי

{% equation %}\left(\begin{array}{c}
1\\
1\\
\vdots\\
1
\end{array}\right){% endequation %} 
את זה אפשר לבדוק בצורה ישירה: כופלים את המטריצה בוקטור הזה, ונקבל אותו עצמו כפול {% equation %}\lambda{% endequation %} . במקרה שלנו, זה אומר ש-{% equation %}\lambda=0{% endequation %} 
הוא ערך עצמי של המטריצה, כמו שהבטחתי.

עכשיו, אם יש לנו מטריצה ריבועית {% equation %}A{% endequation %} **כלשהי** מעל שדה סגור אלגברית כמו {% equation %}\mathbb{C}{% endequation %} (וזה המקרה שלנו) אז יש לה **צורת ז'ורדן**, כלומר קיימת מטריצה משולשית עליונה {% equation %}J{% endequation %} ומטריצה הפיכה {% equation %}P{% endequation %} כך ש-{% equation %}A=P^{-1}JP{% endequation %} . יש הרבה מה לומר על המבנה של {% equation %}J{% endequation %} [ואני מדבר על זה כאן](https://gadial.net/2016/10/27/rational_and_jordan_form/), אבל מה שאנחנו צריכים פה הוא רק את זה שהאלכסון של {% equation %}J{% endequation %} כולל את כל הערכים העצמיים של {% equation %}A{% endequation %} , ושהדטרמיננטה של מטריצה משולשית עליונה היא מכפלת אברי האלכסון. בנוסף, **הכפליות של הדטרמיננטה** נותנת לנו

{% equation %}\left|A\right|=\left|P^{-1}\right|\left|J\right|\left|P\right|=\left|J\right|\left|P\right|^{-1}\left|P\right|=\left|J\right|{% endequation %} (כאן השתמשנו בקסם היפהפה שבו דטרמיננטה היא סך הכל מספר מרוכב, ומספרים מרוכבים מתחלפים בכפל, להבדיל ממטריצות).

כלומר, המסקנה היא שלכל מטריצה ריבועית {% equation %}A{% endequation %} מסדר {% equation %}n\times n{% endequation %} (לא רק מטריצת לפלסיאן) מעל שדה סגור אלגברית, הדטרמיננטה שלה היא מכפלת כל הערכים העצמיים שלה. בפרט עבור מטריצת הלפלסיאן ראינו ש-0 הוא ערך עצמי ולכן הדטרמיננטה שלה היא 0. אז האינפורמציה המעניינת צצה רק כשמוחקים שורה ועמודה ולוקחים את הדטרמיננטה של התוצאה, ואני טוען שאם זו השורה והעמודה ה-{% equation %}i{% endequation %} -יות, אז הדטרמיננטה תצא {% equation %}\frac{1}{n}\lambda_{1}\cdots\lambda_{n-1}{% endequation %} . אבל למה? זה לא נכון באופן כללי; אם למשל אני לוקח מטריצה אלכסונית עם {% equation %}\lambda_{0},\ldots,\lambda_{n-1}{% endequation %} על האלכסון ומוריד את השורה והעמודה הראשונים, אז אני אקבל מטריצה אלכסונית עם {% equation %}\lambda_{1},\ldots,\lambda_{n-1}{% endequation %} 
על האלכסון ולכן דטרמיננטה {% equation %}\lambda_{1}\cdots\lambda_{n-1}{% endequation %} . עבור מטריצות אחרות אני אקבל דטרמיננטות שונות. אז מה במבנה של הלפלסיאן מוסיף את הפקטור {% equation %}\frac{1}{n}{% endequation %} הזה?

ובכן, יש כמה דרכים להוכיח את זה. דרך מתבקשת אחת היא להגיד - שמעו, הלפליסאן הזה הוא מטריצה **סימטרית** ולכן קיים לו **לכסון אוניטרי** ולהשתמש בכל מני להטוטים [שדיברתי עליהם ממש לא מזמן](https://gadial.net/2025/09/06/unitary_diagonalization/). בהחלט אפשר לעשות את זה וזה כנראה גם יעבוד, אבל אני הולך לגשת לזה מכיוון שונה לגמרי שנראה לי במבט ראשון הזוי למדי, ולכן זה כיפי.

המושג שאני רוצה להכניס לתמונה הוא מה שנקרא **המטריצה המצורפת **(מה שנקרא באנגלית adjugate marix). [יש לי פוסט](https://gadial.net/2011/11/21/matrix_revolutions/) שבו אני מזכיר את המושג הזה אבל בואו ניזכר. באופן כללי, אם יש לי מטריצה ריבועית {% equation %}A{% endequation %} , אני יכול לעשות את הפעולה שכבר ראינו: למחוק את השורה ה-{% equation %}i{% endequation %} והעמודה ה-{% equation %}j{% endequation %} , ואז לקחת דטרמיננטה של התוצאה. אני אסמן את זה ב-{% equation %}\left|A^{ij}\right|{% endequation %} . למספר הזה קוראים cofactor של {% equation %}A{% endequation %} , ואם {% equation %}A{% endequation %} היא מסדר {% equation %}n\times n{% endequation %} אז יש לנו אחד כזה לכל {% equation %}1\le i,j\le n{% endequation %} . כשמחשבים דטרמיננטה של {% equation %}A{% endequation %} דרך אחרת לעשות את זה היא לבחור שורה קונקרטית, נאמר {% equation %}i{% endequation %} , ואז לחשב את {% equation %}\left|A\right|=\sum_{j=1}^{n}\left(-1\right)^{i+j}\left|A^{ij}\right|{% endequation %} . כלומר, צריך לקחת את כל ה-cofactor-ים שמתאימים לשורה הזו ולחבר ולחסר אותם לסירוגין, ואיכשהו באופן קסום זה נותן את הדטרמיננטה.

עכשיו, המטריצה המצורפת של {% equation %}A{% endequation %} שמסומנת {% equation %}\text{adj}A{% endequation %} היא מה שמקבלים כשלוקחים את כל ה-{% equation %}\left(-1\right)^{i+j}\left|A^{ij}\right|{% endequation %} 
הללו ושמים **את כולם** בתוך מטריצה משל עצמם - אבל שימו לב, מטריצה שבה התפקידים של {% equation %}i,j{% endequation %} הפוכים. פורמלית: {% equation %}\left[\text{adj}A\right]_{ji}=\left(-1\right)^{i+j}\left|A^{ij}\right|{% endequation %} . למה ההיפוך הזה? כי זה מבטיח שתתקיים התכונה המאוד יפה

{% equation %}A\cdot\text{adj}A=\left|A\right|\cdot I{% endequation %} 
שהוכחתי בפוסט שקישרתי אליו. במילים אחרות, {% equation %}\frac{\text{adj}A}{\left|A\right|}{% endequation %} 
היא ההופכית של {% equation %}A{% endequation %} במקרה שהיא קיימת (ואם היא לא קיימת אז הכפל ב-{% equation %}\text{adj}A{% endequation %} מחזיר 0). התכונה הזו מראה ש-{% equation %}\text{adj}A{% endequation %} 
זה לא סתם משהו אקראי שהמצאנו כי שיעמם לנו, ועכשיו נראה איך המושג הזה שימושי לנו כדי לנתח את {% equation %}L_{G}{% endequation %} .

בואו נסמן ב-{% equation %}\kappa{% endequation %} את מספר העצים הפורשים של {% equation %}G{% endequation %} . מה שמשפט קירקהוף מראה הוא ש-{% equation %}\left|L_{G}^{ii}\right|=\kappa{% endequation %} ; את זה אני לא הולך להוכיח שוב, אבל אני רוצה לטעון שמתקיים משהו קצת יותר כללי: שגם אם מוחקים שורה ועמודה שלא מתאימות לאותו אינדקס מקבלים את {% equation %}\kappa{% endequation %} 
כל עוד כופלים ב" תיקון" הרגיל, כלומר {% equation %}\left(-1\right)^{i+j}\left|L_{G}^{ij}\right|=\kappa{% endequation %} . ואת זה אפשר לנסח בצורה הקומפקטית הבאה: {% equation %}\text{adj}L_{G}=\kappa J{% endequation %} 
כאשר {% equation %}J{% endequation %} כאן הוא הסימון הסטנדרטי למטריצה הריבועית (מאותו סדר כמו {% equation %}L_{G}{% endequation %} ) שכולה 1-ים (לא לבלבל עם ה-{% equation %}J{% endequation %} 
של ז'ורדן שהזכרתי קודם ולא נזדקק לה יותר בפוסט הזה). כלומר, {% equation %}\kappa J{% endequation %} 
היא בסך הכל המטריצה שכל הכניסות שלה שוות {% equation %}\kappa{% endequation %} . אני מקווה שברור למה - כי הכניסה ה-{% equation %}ji{% endequation %} שלה היא {% equation %}\left(-1\right)^{i+j}\left|L_{G}^{ij}\right|=\kappa{% endequation %} . כמובן, צריך להוכיח את זה; וזה כל העניין, שיהיה לי יותר קל להוכיח את זה על ידי עבודה ישירה מול {% equation %}\text{adj}L_{G}{% endequation %} .

ראשית, צריך להפריד לשני מקרים על פי **הדרגה** של {% equation %}L_{G}{% endequation %} (המימד של מרחב השורות/מרחב העמודות של {% equation %}(L_{G}{% endequation %} . כזכור, הדרגה {% equation %}\text{rank} L_{G}{% endequation %} של מטריצה בפרט קובעת אם היא הפיכה או לא - אם למטריצה מסדר {% equation %}n\times n{% endequation %} יש דרגה קטנה מ-{% equation %}n{% endequation %} אז היא לא הפיכה, ולכן הדטרמיננטה שלה שווה לאפס. עכשיו, אנחנו כבר יודעים ש-{% equation %}L_{G}{% endequation %} 
לא הפיכה ולכן הדרגה שלה קטנה מ-{% equation %}n{% endequation %} , אבל אם מתקיים גם {% equation %}\text{rank} L_{G}\lt n-1{% endequation %} 
אז גם אחרי שנמחק מ-{% equation %}L_{G}{% endequation %} שורה ועמודה עדיין נקבל מטריצה מדרגה קטנה מ-{% equation %}n-1{% endequation %} כי אם אחרי המחיקה יש לנו קבוצה של {% equation %}n-1{% endequation %} שורות בלתי תלויות, אז גם אחרי שנוסיף להן עוד כניסה עבור העמודה שמחקנו הן עדיין יהיו בלתי תלויות וגם אם נוסיף למטריצה שורה חדשה הן עדיין יהיו בלתי תלויות, ולכן יוצא שכבר במטריצה המקורית הדרגה הייתה {% equation %}n-1{% endequation %} . אז הגענו לכך שאחרי המחיקה תהיה לנו מטריצה מסדר {% equation %}n-1{% endequation %} שהדרגה שלה קטנה מ-{% equation %}n-1{% endequation %} ולכן הדטרמיננטה שלה עדיין תהיה שווה לאפס, וזה עבור **כל** שורה ועמודה שנמחק, כלומר {% equation %}\text{adj}L_{G}=0{% endequation %} . מכיוון שבאופן כללי, {% equation %}\left|L_{G}^{11}\right|=\kappa{% endequation %} אז במקרה שלנו המסקנה היא ש-{% equation %}\kappa=0{% endequation %} ולכן באמת מתקיים {% equation %}\text{adj}L_{G}=\kappa J{% endequation %} ; לכן המקרה המעניין של ההוכחה הוא זה שבו {% equation %}\text{rank} L_{G}=n-1{% endequation %} (זה המקרה שבו {% equation %}G{% endequation %} הוא גרף מעניין שבאמת יש בו עצים פורשים).

בשביל המקרה הזה, לב העניין הוא הנוסחה {% equation %}A\cdot\text{adj}A=\left|A\right|\cdot I{% endequation %} 
שהראיתי קודם. במקרה שלנו התחלנו מזה של-{% equation %}L_{G}{% endequation %} יש ערך עצמי 0, ולכן {% equation %}\left|L_{G}\right|=0{% endequation %} , אז קיבלנו

{% equation %}L_{G}\cdot\text{adj}L_{G}=0{% endequation %} 
זה אומר שכל **עמודה** של {% equation %}\text{adj}L_{G}{% endequation %} שייכת לגרעין של {% equation %}L_{G}{% endequation %} . מה הגרעין הזה? מכיוון ש-{% equation %}\text{rank} L_{G}=n-1{% endequation %} , המימד של הגרעין הוא 1 (זה עוד להטוט אלגברה לינארית סטנדרטית שאני מניח שאנחנו מכירים) ואנחנו **כבר ראינו** איבר ששייך לגרעין של {% equation %}L_{G}{% endequation %} , בהתחלה: הוקטור שכולו 1-ים. המסקנה היא שכל עמודה של {% equation %}\text{adj}L_{G}{% endequation %} היא כפל של הוקטור הזה בסקלר כלשהו ובפרט כל האיברים של העמודה שווים. העניין הוא שבעמודה ה-{% equation %}i{% endequation %} 
של {% equation %}\text{adj}L_{G}{% endequation %} יש לנו את {% equation %}\left|L_{G}^{ii}\right|{% endequation %} 
שאנחנו **יודעים** בזכות קירקהוף ששווה ל-{% equation %}\kappa{% endequation %} , ולכן כל האיברים בעמודה הזו שווים ל-{% equation %}\kappa{% endequation %} , ולכן כל המטריצה שווה ל-{% equation %}\kappa{% endequation %} 
וקיבלנו {% equation %}\text{adj}L_{G}=\kappa J{% endequation %} בדיוק כפי שרצינו.

אוקיי, זה היה די מגניב (ולא ידעתי את זה לפני שהתחלתי לכתוב את הפוסט - כלומר, את העניין הזה שלא חייבים להסיר שורה ועמודה שמתאימות לאותו {% equation %}i{% endequation %} אלא אפשר להסיר {% equation %}i,j{% endequation %} כלליות ומקסימום לכפול במינוס 1). אבל איך זה עוזר לי?

ובכן, הנה תוצאה מרהיבה (שלהבנתי מופיעה לראשונה במאמר עם השם הבלתי קשור בעליל, "On the mutual cancellation of cluster integrals in Mayer's fugacity series," של H. Temperley) שמאפשרת לנו לקבל את {% equation %}\kappa{% endequation %} מתוך {% equation %}L_{G}{% endequation %} בלי בכלל כל העניין השרירותי הזה של לבחור {% equation %}i{% endequation %} ולמחוק מ-{% equation %}L_{G}{% endequation %} 
את השורה והעמודה ה-{% equation %}i{% endequation %} :

{% equation %}\kappa=\frac{\left|L_{G}+J\right|}{n^{2}}{% endequation %} 
כלומר, במקום למחוק אפשר **לחבר** 1 לכל כניסה של {% equation %}L_{G}{% endequation %} , לחשב דטרמיננטה, ובסוף לחלק ב-{% equation %}n^{2}{% endequation %} . לא רק שזו תוצאה יפהפייה בזכות עצמה, עוד רגע נראה שהיא גם נותנת לנו את {% equation %}\kappa=\frac{1}{n}\lambda_{1}\cdots\lambda_{n-1}{% endequation %} 
בלי כמעט מאמץ. אבל קודם כל בואו נוכיח אותה.

ההוכחה היא מאוד אלגברית - כלומר, כופלים ומחברים דברים והופס, פתאום מקבלים את הנוסחה משום מקום. בשביל זה קודם כל נשים לב לכך ש-{% equation %}J^{2}=nJ{% endequation %} (פשוט על פי ההגדרה הרגילה של כפל מטריצות וזה ש-{% equation %}J{% endequation %} היא מסדר {% equation %}n\times n{% endequation %} ) ו-{% equation %}JL_{G}=0{% endequation %} (כי כפי שכבר ראינו {% equation %}L_{G}J=0{% endequation %} ושתי המטריצות הללו סימטריות) ועכשיו נחשב אלגברית את

{% equation %}\left(nI-J\right)\left(J+L_{G}\right)=nJ-J^{2}+nL_{G}-JL_{G}=nL_{G}{% endequation %} 
עכשיו, באופן כללי אם יש לנו את המכפלה {% equation %}AB{% endequation %} אז אפשר להראות ש-{% equation %}\text{adj}\left(AB\right)=\text{adj}B\cdot\text{adj}A{% endequation %} . זו תכונה סטנדרטית ולכן לא אוכיח אותה כאן, אבל תראו מה היא נותנת לנו:

{% equation %}\text{adj}\left(J+L_{G}\right)\text{adj}\left(nI-J\right)=\text{adj}\left(nL_{G}\right){% endequation %} 
עכשיו, {% equation %}nI-J{% endequation %} זו מטריצה מעניינת. יש לה {% equation %}n-1{% endequation %} על האלכסון הראשי, ו-{% equation %}-1{% endequation %} בכל מקום אחד - זה הלפליסאן של **הגרף המלא** על {% equation %}n{% endequation %} צמתים. מספר העצים הפורשים של הגרף המלא על {% equation %}n{% endequation %} צמתים הוא פשוט מספר העצים על {% equation %}n{% endequation %} צמתים - זו תוצאה סטנדרטית שנקראת **נוסחת קיילי** וכשכתבתי את הפוסט הזה גיליתי למרבה הזוועה שעוד אין לי פוסט עליה - [אז עכשיו כבר יש](https://gadial.net/2025/11/28/cayleys_formula/). ההוכחה של הנוסחה הזו מרהיבה, אבל היא עצמה מאוד פשוטה: יש {% equation %}n^{n-2}{% endequation %} 
עצים כאלו. לכן {% equation %}\text{adj}\left(nI-J\right)=n^{n-2}J{% endequation %} .

עוד איבר שמופיע בנוסחה הוא {% equation %}\text{adj}\left(nL_{G}\right){% endequation %} . מה אני יכול להגיד עליו? האם אפשר להוציא את הסקלר {% equation %}n{% endequation %} החוצה מה-adj? ובכן, כן. באופן כללי אפשר להוציא סקלרים החוצה מדטרמיננטות: {% equation %}\left|\lambda A\right|=\lambda^{n}\left|A\right|{% endequation %} , כי מה שקורה פה הוא שהכלל עבור דטרמיננטות הוא שלכפול **שורה** בסקלר {% equation %}\lambda{% endequation %} מכפיל את כל הדטרמיננטה ב-{% equation %}\lambda{% endequation %} . לכן אם הכפלנו את **כל** המטריצה ב-{% equation %}\lambda{% endequation %} , ויש למטריצה {% equation %}n{% endequation %} 
שורות, האפקט יהיה להכפיל את הדטרמיננטה {% equation %}n{% endequation %} פעמים ב-{% equation %}\lambda{% endequation %} .

כשלוקחים adj של מטריצה {% equation %}A{% endequation %} מסדר {% equation %}n{% endequation %} , כל כניסה היא עצמה דטרמיננטה: {% equation %}\left[\text{adj}A\right]_{ji}=\left(-1\right)^{i+j}\left|A^{ij}\right|{% endequation %} , אבל זו לא הדטרמיננטה של {% equation %}A{% endequation %} אלא של **המינור**{% equation %}A^{ij}{% endequation %} 
שהתקבל מ-{% equation %}A{% endequation %} על ידי מחיקת שורה ועמודה, כלומר זו מטריצה עם {% equation %}n-1{% endequation %} 
שורות. לכן {% equation %}\left[\text{adj}\lambda A\right]_{ji}=\left(-1\right)^{i+j}\left|\lambda A^{ij}\right|=\lambda^{n-1}\left(-1\right)^{i+j}\left|A^{ij}\right|{% endequation %} . זה מוביל לכך שבמקרה שלנו:

{% equation %}\text{adj}\left(nL_{G}\right)=n^{n-1}\text{adj}\left(L_{G}\right){% endequation %} 
וכזכור, ראינו גם

{% equation %}\text{adj}L_{G}=\kappa J{% endequation %} 
אז בסך הכל {% equation %}\text{adj}\left(nL_{G}\right)=n^{n-1}\kappa J{% endequation %} 
אז בואו ניקח את הנוסחה {% equation %}\text{adj}\left(J+L_{G}\right)\text{adj}\left(nI-J\right)=\text{adj}\left(nL_{G}\right){% endequation %} 
שקיבלנו ונכתוב אותה מחדש עם מה שלמדנו:

{% equation %}\text{adj}\left(J+L_{G}\right)n^{n-2}J=n^{n-1}\kappa J{% endequation %} 
כלומר

{% equation %}\text{adj}\left(J+L_{G}\right)J=n\kappa J{% endequation %} 
איך נתקדם מפה? ובכן, זכרו את הנוסחה שמעניקה ל-adj את הכוח שלה: {% equation %}A\cdot\text{adj}A=\left|A\right|\cdot I{% endequation %} . בואו נשתמש בה פה - ניקח את {% equation %}\text{adj}\left(J+L_{G}\right)J=n\kappa J{% endequation %} ונכפול את שני האגפים במטריצה {% equation %}J+L_{G}{% endequation %} . נקבל:

{% equation %}\left(J+L_{G}\right)\text{adj}\left(J+L_{G}\right)J=\left(J+L_{G}\right)n\kappa J{% endequation %} 
נשתמש בנוסחה על אגף שמאל ונקבל

{% equation %}\left|\left(J+L_{G}\right)\right|J=\left(J+L_{G}\right)n\kappa J{% endequation %} 
באגף ימין, בואו ניזכר שראינו {% equation %}J^{2}=nJ{% endequation %} ו-{% equation %}L_{G}J=0{% endequation %} ולכן אפשר לפתוח את הסוגריים שם, ולקבל

{% equation %}\left|\left(J+L_{G}\right)\right|J=n^{2}\kappa J{% endequation %} 
קיבלנו שאותה מטריצה, מוכפלת בשני סקלרים, היא שווה - אז הסקלרים בהכרח שווים (כי אנחנו עובדים מעל שדה ממציין 0, אם רוצים להיות פדנטיים), כלומר 

{% equation %}\left|\left(J+L_{G}\right)\right|=n^{2}\kappa{% endequation %} 
או בסימון המקורי שלי:

{% equation %}\kappa=\frac{\left|L_{G}+J\right|}{n^{2}}{% endequation %} 
זה מסיים את ההוכחה של התוצאה המאוד יפה הזו, אבל איך זה עוזר לנו עם התמונה הגדולה? כזכור, המטרה שלי היא להראות שעבור מטריצת הלפלסיאן, הדטרמיננטה של כל מינור שלה היא מכפלת הערכים העצמיים ששונה מאפס חלקי {% equation %}n{% endequation %} :

{% equation %}\kappa=\frac{1}{n}\lambda_{1}\cdots\lambda_{n-1}{% endequation %} .

אז מספיק להראות ש-{% equation %}\left|L_{G}+J\right|=n\cdot\lambda_{1}\cdots\lambda_{n-1}{% endequation %} 
מה שצריך לזכור הוא שדטרמיננטה של מטריצה הוא מכפלת כל הערכים העצמיים שלה, כמו שהראיתי קודם. ומה הערכים העצמיים של {% equation %}L_{G}+J{% endequation %} ? או, כאן זה נהיה כיף. ראינו כזכור ש-{% equation %}L_{G}J=JL_{G}=0{% endequation %} , כלומר המטריצות הללו **מתחלפות בכפל**.

מטריצות לכסינות שמתחלפות בכפל הן **לכסינות סימולטנית**, כלומר **אותה מטריצה**{% equation %}P{% endequation %} מלכסנת את שתיהן ביחד. אם {% equation %}A,B{% endequation %} 
שתיהן לכסינות ומקיימות {% equation %}AB=BA{% endequation %} זה אומר שקיימת מטריצה **אחת**, {% equation %}P{% endequation %} כך ש-{% equation %}P^{-1}AP=D_{A}{% endequation %} ו-{% equation %}P^{-1}BP=D_{B}{% endequation %} , והערכים שמופיעים באלכסונים של המטריצות האלכסוניות {% equation %}D_{A},D_{B}{% endequation %} הם הערכים העצמיים של {% equation %}A,B{% endequation %} בהתאמה. שימו לב שהערכים הללו לא מופיעים בסדר שרירותי; הערך העצמי ה-{% equation %}k{% endequation %} -י באלכסון הוא הערך העצמי שמתאים לוקטור העצמי ה-{% equation %}k{% endequation %} -י ב-{% equation %}P{% endequation %} (העמודות של {% equation %}P{% endequation %} כולן וקטורים עצמיים של {% equation %}A,B{% endequation %} ; הרעיון בלכסון סימולטני הוא שיש לנו **את אותם וקטורים עצמיים** לשתי המטריצות בו זמנית).

עכשיו, {% equation %}P^{-1}\left(A+B\right)P=D_{A}+D_{B}{% endequation %} , ולכן הערכים העצמיים של {% equation %}A+B{% endequation %} הם בדיוק אברי האלכסון של {% equation %}D_{A}+D_{B}{% endequation %} , כלומר, הערכים העצמיים הללו הם מה שמתקבל כשמחלקים את הערכים העצמיים של {% equation %}A,B{% endequation %} 
לזוגות, בהתאם לוקטורים העצמיים שלהם, וסוכמים כל זוג.

את כל זה אפשר לעשות גם במקרה שבו המטריצות לא לכסינות אלא רק ניתנות לשילוש בעזרת צורת ז'ורדן. במקרה הספציפי שלנו, אנחנו יודעים על וקטורים עצמי משותף אחד: הוקטור שכולו 1-ים, שמתאים לערך העצמי {% equation %}0{% endequation %} של {% equation %}L_{G}{% endequation %} ולערך העצמי {% equation %}n{% endequation %} של {% equation %}J{% endequation %} , ולכן הערך העצמי של {% equation %}L_{G}+J{% endequation %} שמתאים אליו יהיה {% equation %}n{% endequation %} . כל שאר הערכים העצמיים של {% equation %}J{% endequation %} הם 0 (כי זו מטריצה מדרגה 1) ולכן כל יתר הערכים העצמיים של {% equation %}L_{G}+J{% endequation %} יהיו פשוט הערכים העצמיים {% equation %}\lambda_{1},\ldots,\lambda_{n-1}{% endequation %} כשמחברים 0 לכל אחד מהם. קיבלנו שהערכים העצמיים של {% equation %}L_{G}+J{% endequation %} הם בדיוק {% equation %}n,\lambda_{1},\ldots,\lambda_{n-1}{% endequation %} 
ולכן {% equation %}\left|L_{G}+J\right|=n\cdot\lambda_{1}\cdots\lambda_{n-1}{% endequation %} 
וזה מסיים את ההוכחה.

יפה! סיימנו את... השלב הראשון בכל הסיפור הזה. נותרו לנו עוד שניים: הקטע הזה של גרף מכפלה, והקטע הזה של פולינומי צ'בישב.

## הקטע הזה של גרף מכפלה

באופן כללי מתמטיקה זה מסובך ואובייקטים מתמטיים זה מסובך, אז המתמטיקאים מנסים בכל הזדמנות לקחת אובייקט מסובך ולהציג אותו בתור משהו שנבנה מאובייקטים פשוטים יותר, שקל לנו להבין יותר אותם ואת מה שקורה בעקבות הפעולות שביצענו עליהם כדי לקבל את הדבר המסובך. ככה זה עם הצגה של מספר טבעי בתור מכפלה של ראשוניים; של חבורה בתור מכפלה של תת-חבורות; של מרחב וקטורי בתור מכפלה של מרחבים וקטוריים; של... טוב, הבנתם, אני אוהב מכפלות. למה שלא יהיה משהו כזה גם לגרפים?

ובכן, לא רק שיש, יש הרבה. אני אדבר רק על ההגדרה הספציפית של מכפלה שאני צריך בפוסט הזה - לפעמים קוראים לה "מכפלה קרטזית" ולפעמים "מכפלת קופסה" . הרעיון הוא כזה: אם יש לנו שני גרפים, {% equation %}G_{1}=\left(V_{1},E_{1}\right){% endequation %} ו-{% equation %}G_{2}=\left(V_{2},E_{2}\right){% endequation %} 
אז נבנה גרף חדש, {% equation %}G_{1}\square G_{2}=\left(V,E\right){% endequation %} כך ש-

{% equation %}V=V_{1}\times V_{2}=\left\{ \left(v_{1},v_{2}\right)\ |\ v_{1}\in V_{1},v_{2}\in V_{2}\right\}{% endequation %} 
כלומר, הצמתים של הגרף החדש הם **זוגות** של צומת מכל אחד מהגרפים המקוריים - הקבוצה הזו היא בדיוק מה שנקרא "מכפלה קרטזית" של הקבוצות {% equation %}V_{1},V_{2}{% endequation %} ומכאן השם של המכפלה הזו גם כאן. אבל עוד לא סיימנו - גרף מוגדר לא רק על ידי הצמתים שלו אלא על ידי הקשתות, ובמקרה הזה **לא** יתקיים ש-{% equation %}E=E_{1}\times E_{2}{% endequation %} (למעשה, אין ממש משמעות להגדרה כזו - המכפלה של {% equation %}E_{1},E_{2}{% endequation %} לא נותנת לנו קבוצה של קשתות על צמתי {% equation %}V{% endequation %} ). ההגדרה, שתתאים בול למבוכים שאני ממדל בעזרת הגרפים הללו ואולי יהיה קל להבין אותה יותר באמצעותם, היא ששני צמתים מחוברים בקשת אם בקואורדינטה אחת שלהם הם **זהים** ובקואורדינטה השניה שלהם הם **מחוברים בקשת**. פורמלית (ואני לא בטוח שהכתיב הפורמלי עוזר לזה להיות ברור): 

{% equation %}E=\left\{ \left(\left(v_{1},v_{2}\right),\left(u_{1},v_{2}\right)\right)\ |\ \left(v_{1},u_{1}\right)\in E_{1}\right\} \cup\left\{ \left(\left(v_{1},v_{2}\right),\left(v_{1},u_{2}\right)\right)\ |\ \left(v_{2},u_{2}\right)\in E_{2}\right\}{% endequation %} 
הנה דרך אינטואיטיבית לחשוב על זה. נניח שלבי במזרח ואנוכי בסוף מערב ויש לי כוחות על שמאפשרים לי להתפצל תודעתית: חלק אחד שלי יצא לטיול בירושלים וחלק אחר מטייל בקורדובה בספרד. בשני המקרים הרחובות ארוכים וצרים ומתפתלים - אפשר למדל אותם עם גרף. צמתים הם מקומות שבהם אפשר לעצור ולהתפעל מהנוף, וקשתות הן הסמטאות שמחברות שני מקומות כאלו. אז יש לנו גרף {% equation %}G_{1}{% endequation %} עבור ירושלים וגרף {% equation %}G_{2}{% endequation %} עבור קורדובה. בדרך כלל כשאני מטייל אני נמצא רק במיקום גאוגרפי אחד, נאמר בירושלים, ואז הטיול שלי הוא סדרה של מעברים מצומת {% equation %}v\in V_{1}{% endequation %} אל צומת {% equation %}u\in V_{1}{% endequation %} 
בעזרת הקשת {% equation %}\left(v,u\right)\in E_{1}{% endequation %} . אבל עכשיו, כאמור, אני באורח פלא גם פה וגם שם: המיקום שלי הוא {% equation %}\left(v_{1},v_{2}\right){% endequation %} 
כש-{% equation %}v_{1}{% endequation %} הוא המיקום שלי בירושלים ו-{% equation %}v_{2}{% endequation %} הוא המיקום שלי בקורדובה.

עכשיו, יש עלי רק מגבלה אחת למרות כוח העל המדהים שלי: כשאני **זז**, אני לא מסוגל לזוז גם פה וגם שם בו זמנית, הסמטאות המפותלות דורשות יותר מדי ריכוז. אז אם אני רוצה לזוז ממקום {% equation %}v_{1}{% endequation %} למקום {% equation %}u_{1}{% endequation %} 
בירושלים אני "מקפיא" לרגע את מה שאני עושה בקורדובה - הייתי ב-{% equation %}v_{2}{% endequation %} ואשאר לעת עתה ב-{% equation %}v_{2}{% endequation %} . אז המעבר שלי הוא מהצומת {% equation %}\left(v_{1},v_{2}\right){% endequation %} אל הצומת {% equation %}\left(u_{1},v_{2}\right){% endequation %} 
- זזתי בקואורדינטה הראשונה, והשניה נשארה ללא שינוי. באותו אופן גם הייתי יכול לזוז בקורדובה ולהישאר בירושלים.

כל זה עובד מצוין עבור המבוכים שלנו. אצלנו, הגרף שאנחנו רוצים לספור לו עצים פורשים הוא מהצורה {% equation %}G=\left(V,E\right){% endequation %} עם {% equation %}V=\left\{ \left(i,j\right)\ |\ 1\le i\le n,1\le j\le m\right\}{% endequation %} (כאשר {% equation %}\left(i,j\right){% endequation %} אומר "התא בשורה ה-{% equation %}i{% endequation %} 
בעמודה ה-{% equation %}j{% endequation %} "). הקשתות הן מהצורה {% equation %}\left(\left(i,j\right),\left(i+1,j\right)\right){% endequation %} (כשזזים משורה אחת לאחרת, כלומר נעים בקו אנכי) ו-{% equation %}\left(\left(i,j\right),\left(i,j+1\right)\right){% endequation %} (כשזזים מעמודה אחת לאחרת, כלומר נעים בקו אופקי). אי אפשר במבוך לזוז "באלכסון" כמו שהיה קורה אם היה מותר לזוז ב-{% equation %}G_{1},G_{2}{% endequation %} "בו זמנית" . אז אפשר לחשוב על {% equation %}G{% endequation %} בתור המכפלה {% equation %}G_{1}\square G_{2}{% endequation %} כאשר כל אחד מהמוכפלים הוא פשוט מאוד: {% equation %}G_{1}=\left(V_{1},E_{1}\right){% endequation %} 
כך ש-{% equation %}V_{1}=\left\{ 1,2,\ldots,n\right\}{% endequation %} ו-{% equation %}E_{1}{% endequation %} כוללת את כל האיברים מהצורה {% equation %}\left(i,i+1\right){% endequation %} עבור {% equation %}1\le i\lt n{% endequation %} , ו-{% equation %}G_{2}{% endequation %} מוגדר באותו אופן עם {% equation %}m{% endequation %} במקום {% equation %}n{% endequation %} . מכיוון שאני עצלן ביקשתי מבינה מלאכותית לאייר לי את זה והתוצאה הזויה בהתאם אבל מדויקת למדי:

<img src="{{site.baseurl}}{{site.post_images}}/2026/product_graph.png" alt=""/>

מה שאני מתעניין בו בפוסט הזה הוא הלפלסיאן של גרפים, וספציפית הערכים העצמיים שלו כי כבר עברנו מהבעיה של חישוב הדטרמיננטה של הלפלסיאן לבעיה של מציאת הערכים העצמיים שלו. אז מה אני יכול לומר על הערכים העצמיים של {% equation %}L_{G_{1}\square G_{2}}{% endequation %} ? או, בשביל זה אני יכול להיעזר במה שאנחנו יודעים על תורת המטריצות, בתנאי שאני אבין איך לכתוב את {% equation %}L_{G_{1}\square G_{2}}{% endequation %} 
בעזרת {% equation %}L_{G_{1}},L_{G_{2}}{% endequation %} וזה, למרבה המזל, די קל: {% equation %}L_{G_{1}\square G_{2}}{% endequation %} 
הולך לצאת מה שנקרא **סכום קרונקר** של {% equation %}L_{G_{1}},L_{G_{2}}{% endequation %} , וזו הזדמנות טובה להציג את המושג הזה.

באופן כללי, אם {% equation %}A,B{% endequation %} הן שתי מטריצות ריבועיות מסדר {% equation %}n\times n{% endequation %} 
ו-{% equation %}m\times m{% endequation %} בהתאמה, אז **מכפלת קרונקר** שלהן, שמסומנת {% equation %}A\otimes B{% endequation %} , היא מה שמקבלים אם לוקחים את {% equation %}A{% endequation %} ובכל כניסה של {% equation %}A{% endequation %} שותלים **עותק שלם** של {% equation %}B{% endequation %} בתור בלוק, כשכל העותק הזה מוכפל במה שהיה בכניסה של {% equation %}A{% endequation %} במקור. הנה דוגמא פשוטה:

{% equation %}A=\left(\begin{array}{cc}
a_{11} & a_{12}\\
a_{21} & a_{22}
\end{array}\right),B=\left(\begin{array}{cc}
b_{11} & b_{12}\\
b_{21} & b_{22}
\end{array}\right){% endequation %} 
וכעת:

{% equation %}A\otimes B=\left(\begin{array}{cc}
a_{11}B & a_{12}B\\
a_{21}B & a_{22}B
\end{array}\right){% endequation %} 
שימו לב, אני לא אומר ש-{% equation %}a_{11}B{% endequation %} הוא **איבר** של המטריצה החדשה; אני אומר שזה תיאור של המטריצה החדשה בתור **מטריצת בלוקים**. כלומר, פורמלית קיבלנו את המטריצה

{% equation %}A\otimes B=\left(\begin{array}{cccc}
a_{11}b_{11} & a_{11}b_{12} & a_{12}b_{11} & a_{12}b_{12}\\
a_{11}b_{21} & a_{11}b_{22} & a_{12}b_{21} & a_{12}b_{22}\\
a_{21}b_{11} & a_{21}b_{12} & a_{22}b_{11} & a_{22}b_{12}\\
a_{21}b_{21} & a_{21}b_{22} & a_{22}b_{21} & a_{22}b_{22}
\end{array}\right){% endequation %} 
מקום אחד שבו המפלצת הזו צצה באופן טבעי והיא שימושית מאוד הוא חישוב קוונטי, [ויש לי פוסט](https://gadial.net/2022/08/01/quantum_computing_math_3/) שבו אני מתאר אותה בהקשר הזה. אבל מן הסתם יש לה שלל שימושים שונים ומשונים - זה עתה נתקלנו באחד חדש. רק שצריך טיפה להיזהר - אני הגדרתי כרגע את **מכפלת קרונקר**, אבל עבור {% equation %}L_{G_{1}\square G_{2}}{% endequation %} אני צריך משהו שנקרא **סכום קרונקר** שהוא מושג קשור שמתבסס על המכפלה אבל לא זהה.

בואו נגדיר סכום קרונקר בצורה זהירה. יש לנו כאמור מטריצה ריבועית {% equation %}A{% endequation %} 
מסדר {% equation %}n{% endequation %} ומטריצה ריבועית {% equation %}B{% endequation %} מסדר {% equation %}m{% endequation %} . מכפלת קרונקר שלהם תהיה מטריצה ריבועית מסדר {% equation %}nm{% endequation %} . גם סכום קרונקר יהיה מהסדר הזה, אבל הוא מתקבל בצורה שונה: ניקח את מטריצת היחידה מסדר {% equation %}m{% endequation %} 
ונסמן אותה {% equation %}I_{m}{% endequation %} ובדומה נסמן ב-{% equation %}I_{n}{% endequation %} את מטריצת היחידה מסדר {% equation %}n{% endequation %} , ועכשיו נסתכל על הביטוי הזה:

{% equation %}A\oplus B\triangleq A\otimes I_{m}+I_{n}\otimes B{% endequation %} 
כלומר, במקום לכפול את {% equation %}A,B{% endequation %} ישירות זה עם זה, אנחנו כופלים אותם עם מטריצות היחידה מהסדרים המתאימים, מקבלים שתי מטריצות מסדר {% equation %}nm{% endequation %} 
ומחברים אותן. אם נעשה את זה עבור שתי המטריצות מסדר {% equation %}2\times2{% endequation %} 
שהראיתי קודם, נקבל

{% equation %}A\oplus B=A\otimes I_{2}+I_{2}\otimes B=\left(\begin{array}{cc}
a_{11}I_{2} & a_{12}I_{2}\\
a_{21}I_{2} & a_{22}I_{2}
\end{array}\right)+\left(\begin{array}{cc}
B & 0\\
0 & B
\end{array}\right)={% endequation %}

{% equation %}=\left(\begin{array}{cccc}
a_{11}+b_{11} & b_{12} & a_{12} & 0\\
b_{21} & a_{11}+b_{22} & 0 & a_{12}\\
a_{21} & 0 & a_{22}+b_{11} & b_{12}\\
0 & a_{21} & b_{21} & a_{22}+b_{22}
\end{array}\right){% endequation %} 
כדי להבין מה הקטע, כדאי לזכור מה בעצם מכפלת קרונקר של מטריצות באה להשיג. אני לא מציג בפוסט הזה את המושג של **מכפלה טנזורית** של מרחבים וקטוריים אבל הזכרתי את זה בפוסט של החישוב הקוונטי (שם מכפלות טנזוריות צצות באופן טבעי - אפשר לחשוב על קיוביט בתור מרחב וקטורי ממימד 2, ועל אוסף של {% equation %}n{% endequation %} קיוביטים בתור מכפלה טנזורית של {% equation %}n{% endequation %} מרחבים שכאלו) וגם [יש לי פוסט ייעודי](https://gadial.net/2014/06/10/vector_space_tensor_product/) על הקונספט. עכשיו, בואו נגיד שיש לנו מכפלה טנזורית של שני מרחבים וקטוריים {% equation %}V\otimes U{% endequation %} ואיבר במכפלה הזו שהוא מהצורה {% equation %}v\otimes u{% endequation %} (לא כל איבר של {% equation %}V\otimes U{% endequation %} נראה ככה, אבל איברים מהצורה הזו פורשים את המרחב וזה מספיק טוב לנו). עכשיו, נניח שיש לנו טרנספורמציה לינארית על {% equation %}V{% endequation %} שמיוצגת על ידי {% equation %}A{% endequation %} וטרנספורמציה לינארית על {% equation %}U{% endequation %} 
שמיוצגת על ידי {% equation %}B{% endequation %} , אז מכפלת קרונקר שלהם משיגה את האפקט הבא:

{% equation %}\left(A\otimes B\right)\left(v\otimes u\right)=\left(Av\right)\otimes\left(Bu\right){% endequation %} 
בלשון של חישוב קוונטי, אם יש לנו שני שערים {% equation %}A,B{% endequation %} שפועלים כל אחד על קיוביט בודד, אז {% equation %}A\otimes B{% endequation %} יהיה השער שפועל על שני קיוביטים: על השער הראשון כמו {% equation %}A{% endequation %} ועל השער השני כמו {% equation %}B{% endequation %} . 

עכשיו, שימו לב שאם {% equation %}v{% endequation %} הוא וקטור עצמי של {% equation %}A{% endequation %} עם הערך העצמי {% equation %}\lambda{% endequation %} , כלומר {% equation %}Av=\lambda v{% endequation %} , ואם {% equation %}u{% endequation %} הוא וקטור עצמי של {% equation %}B{% endequation %} עם הערך העצמי {% equation %}\rho{% endequation %} , כלומר {% equation %}Bu=\rho u{% endequation %} , אז יתקיים

{% equation %}\left(A\otimes B\right)\left(v\otimes u\right)=\left(Av\right)\otimes\left(Bu\right)=\left(\lambda v\right)\otimes\left(\rho u\right)=\lambda\rho\left(v\otimes u\right){% endequation %} (המעבר האחרון משתמש בכללים של מכפלה טנזורית שלא הצגתי כאן במפורש)

כלומר, {% equation %}\lambda\rho{% endequation %} הוא ערך עצמי של {% equation %}A\otimes B{% endequation %} , וזה מה שקורה באופן כללי: הערכים העצמיים של {% equation %}A\otimes B{% endequation %} הם **המכפלות** של כל הזוגות האפשריים של ערך עצמי של {% equation %}A{% endequation %} וערך עצמי של {% equation %}B{% endequation %} . זה מה שקורה עבור **מכפלת** קרונקר. ועבור סכום? כפי שאפשר לנחש, נקבל **סכום** של הערכים העצמיים:

{% equation %}\left(A\otimes I_{m}+I_{n}\otimes B\right)\left(v\otimes u\right)=\left(A\otimes I_{m}\right)\left(v\otimes u\right)+\left(I_{n}\otimes B\right)\left(v\otimes u\right)={% endequation %}

{% equation %}\left(Av\otimes Iu\right)+\left(Iv\otimes Bu\right)=\left(\lambda v\otimes u\right)+\left(v\otimes\rho u\right)=\lambda\left(v\otimes u\right)+\rho\left(v\otimes u\right)={% endequation %}

{% equation %}\left(\lambda+\rho\right)\left(v\otimes u\right){% endequation %} (שוב, כל זה בעזרת הכללים הסטנדרטיים של מכפלה טנזורית).

יפה, אז אפשר לחזור לגרפים. אם אני אראה שהלפלסיאן {% equation %}L_{G_{1}\square G_{2}}{% endequation %} 
של גרף המכפלה הוא סכום קרונקר של הלפלסיאנים {% equation %}L_{G_{1}},L_{G_{2}}{% endequation %} 
אני אקבל מייד שהערכים העצמיים שלו הם סכומים של זוגות של הערכים העצמיים שלהם - בדיוק מה שרציתי.

במבט ראשון, זה נראה ממש מעייף להתחיל להוכיח את זה - {% equation %}A\oplus B{% endequation %} 
היא מטריצה מעיקה כבר בדוגמא הקטנה שנתתי למעלה, אז לטפל בה באופן כללי יהיה סיוט של טיפול באינדקסים. הסיוט הזה די נעלם אם חושבים על {% equation %}A\oplus B{% endequation %} 
בתור מטריצה שהאינדקסים שלה הם לא מספרים אלא **זוגות** של מספרים. כלומר, נמספר את השורות והעמודות על ידי זוגות {% equation %}\left(i,j\right){% endequation %} 
כך ש-{% equation %}1\le i\le n{% endequation %} ו-{% equation %}1\le j\le m{% endequation %} , ואז כניסה כללית של המטריצה תהיה מהצורה {% equation %}\left(i,j\right),\left(i^{\prime},j^{\prime}\right){% endequation %} . הסדר שבו אנחנו מסדרים בו את האיברים הללו הוא לקסיקוגרפי - קודם כל מגדילים את הכניסה השניה ואז, כשהיא הגיעה לערך המקסימלי שלה, מחזירים אותה לערך המינימלי ומגדילים את הכניסה הראשונה. כלומר הסדר הוא {% equation %}\left(1,1\right),\left(1,2\right),\left(2,1\right),\left(2,2\right){% endequation %} .

עכשיו, אם מסתכלים על הדוגמא למעלה עם האינדקסים מול העיניים

{% equation %}\begin{array}{c}
\begin{array}{c}
\\\left(1,1\right)\\
\left(1,2\right)\\
\left(2,1\right)\\
\left(2,2\right)
\end{array}\begin{array}{cccc}
\left(1,1\right) & \left(1,2\right) & \left(2,1\right) & \left(2,2\right)\\
a_{11}+b_{11} & b_{12} & a_{12} & 0\\
b_{21} & a_{11}+b_{22} & 0 & a_{12}\\
a_{21} & 0 & a_{22}+b_{11} & b_{12}\\
0 & a_{21} & b_{21} & a_{22}+b_{22}
\end{array}\end{array}{% endequation %} 
רואים שהכללים של מהי {% equation %}A\otimes I_{2}+I_{2}\otimes B{% endequation %} הם די פשוטים: 1. על האלכסון יש לנו במקום {% equation %}\left(i,j\right),\left(i,j\right){% endequation %} את {% equation %}a_{ii}+b_{jj}{% endequation %} .

1. בשורה {% equation %}\left(i,j\right){% endequation %} ובעמודה {% equation %}\left(i,j^{\prime}\right){% endequation %} עבור {% equation %}j\ne j^{\prime}{% endequation %} יש לנו את {% equation %}b_{j,j^{\prime}}{% endequation %} .

1. בשורה {% equation %}\left(i,j\right){% endequation %} ובעמודה {% equation %}\left(i^{\prime},j\right){% endequation %} 
עבור {% equation %}i\ne i^{\prime}{% endequation %} יש לנו את {% equation %}a_{i,i^{\prime}}{% endequation %} 
1. בכל מקום אחר יש לנו 0.

כמובן, זה אפילו יותר פשוט מזה: הכלל הכללי ביותר הוא שהכניסה בשורה {% equation %}\left(i,j\right){% endequation %} ועמודה {% equation %}\left(i^{\prime},j^{\prime}\right){% endequation %} 
מקבלת את המחובר {% equation %}a_{i,i^{\prime}}{% endequation %} אם {% equation %}j=j^{\prime}{% endequation %} ואת המחובר {% equation %}b_{j,j^{\prime}}{% endequation %} אם {% equation %}i=i^{\prime}{% endequation %} .

קל במיוחד לראות את זה עבור {% equation %}I_{2}\otimes B{% endequation %} , כלומר המטריצה שנראית כמו {% equation %}\left(\begin{array}{cccc}
B & 0 & 0 & 0\\
0 & B & 0 & 0\\
0 & 0 & \ddots & 0\\
0 & 0 & 0 & B
\end{array}\right){% endequation %} . כל בלוק של {% equation %}B{% endequation %} מתאים לאינדקסים מהצורה {% equation %}\left(1,j\right),\left(2,j\right),\ldots,\left(n,j\right){% endequation %} 
עבור {% equation %}1\le j\le m{% endequation %} כלשהו. (האינדקסים הללו מתאימים לשורת/עמודות רצופות בגלל הסדר הלקסיקוגרפי). אז בהינתן כניסה כלשהי בשורה {% equation %}\left(i,j\right){% endequation %} , הסיכוי היחידי שלה להיות שונה מאפס ב-{% equation %}I_{2}\otimes B{% endequation %} הוא שהעמודה תהיה באותו בלוק כמו השורה - כלומר העמודה צריכה להיות {% equation %}\left(i^{\prime},j\right){% endequation %} (אותו ה-{% equation %}j{% endequation %} ).

עכשיו נחזור אל הלפלסיאנים. בלפלסיאן של גרף, כל כניסה מייצגת צומת. כשהגרף הוא מכפלה {% equation %}G_{1}\square G_{2}{% endequation %} , כל צומת הוא זוג {% equation %}\left(i,j\right){% endequation %} 
כך ש-{% equation %}i{% endequation %} שייך לאינדקסים של צמתי {% equation %}G_{1}{% endequation %} ו-{% equation %}j{% endequation %} שייך לאינדקסים של צמתי {% equation %}G_{2}{% endequation %} - כבר טוב, כי ראינו שבסכום קרונקר גם כן נוח לנו לאנדקס דברים עם זוגות כאלו. עבור אברי האלכסון, כלומר זוגות מהצורה {% equation %}\left(i,j\right),\left(i,j\right){% endequation %} , **אמורה** להיות לנו הדרגה של הצומת {% equation %}\left(i,j\right){% endequation %} ובפועל כפי שראינו למעלה מה שיש לנו הוא את {% equation %}a_{ii}+b_{jj}{% endequation %} , כלומר את האיברים על האלכסון שמתאימים ל-{% equation %}i{% endequation %} ב-{% equation %}G_{1}{% endequation %} ול-{% equation %}j{% endequation %} ב-{% equation %}G_{2}{% endequation %} - כלומר את **סכום הדרגות** של הצמתים הללו בגרפים המקוריים שלהם. האם זה מה שצריך להיות? כן! כי מי השכנים של הצומת {% equation %}\left(i,j\right){% endequation %} 
בגרף המכפלה? כל הצמתים מהצורה {% equation %}\left(i,j^{\prime}\right){% endequation %} כך ש-{% equation %}j^{\prime}{% endequation %} היה שכן של {% equation %}j{% endequation %} ב-{% equation %}G_{2}{% endequation %} , וכל הצמתים מהצורה {% equation %}\left(i^{\prime},j\right){% endequation %} כך ש-{% equation %}i^{\prime}{% endequation %} היה שכן של {% equation %}i{% endequation %} ב-{% equation %}G_{2}{% endequation %} . כלומר בדיוק סכום השכנים של שני הצמתים הללו בגרפים המקוריים.

עבור כניסה {% equation %}\left(i,j\right),\left(i^{\prime},j^{\prime}\right){% endequation %} 
שלא על האלכסון, הלפלסיאן אמור לתת לנו את מינוס מספר הקשתות מהצומת {% equation %}\left(i,j\right){% endequation %} לצומת {% equation %}\left(i^{\prime},j^{\prime}\right){% endequation %} . אם גם {% equation %}i\ne i^{\prime}{% endequation %} וגם {% equation %}j\ne j^{\prime}{% endequation %} אז כפי שראינו המספר הזה הוא 0, וזה מה שהוא צריך להיות כי על פי הגדרת גרף מכפלה, אין קשת בין הצמתים הללו - יש קשת רק בין צמתים שנבדלים בדיוק ברכיב אחד. אז מה קורה אם למשל {% equation %}i=i^{\prime}{% endequation %} אבל {% equation %}j\ne j^{\prime}{% endequation %} ? במקרה הזה, הכניסה {% equation %}\left(i,j\right),\left(i,j^{\prime}\right){% endequation %} 
היא {% equation %}b_{j,j^{\prime}}{% endequation %} , כלומר הכניסה המתאימה בלפלסיאן של {% equation %}G_{2}{% endequation %} 
- והכניסה הזו נותנת את מספר הקשתות מ-{% equation %}j{% endequation %} אל {% equation %}j^{\prime}{% endequation %} , שהוא גם בדיוק מספר הקשתות מ-{% equation %}\left(i,j\right){% endequation %} אל {% equation %}\left(i,j^{\prime}\right){% endequation %} . אז הכל מסתדר יפה.

נסכם: אם יש לנו גרף מכפלה {% equation %}G_{1}\square G_{2}{% endequation %} , הלפלסיאן שלו אכן יוצא סכום קרונקר של הלפלסיאנים המעורבים, מה שאפשר לכתוב בנוסחה קומפקטית בתור

{% equation %}L_{G_{1}\square G_{2}}=L_{G_{1}}\oplus L_{G_{2}}{% endequation %} 
ואנחנו יודעים בדיוק מה הערכים העצמיים של סכום קרונקר - כל הסכומים של זוגות של ערכים עצמיים של המטריצות שאותן סוכמים.

עכשיו רק נשאר ליישם את זה למקרה הקונקרטי שלנו - גרף מכפלה שבנוי משני גרפים שהם "שרוך" ואפשר למצוא את הערכים העצמיים שלהם במפורש עם הקטע הזה של פולינומי צ'בישב.

## הקטע הזה של פולינומי צ'בישב

לפני שאני מתחיל לשלוף את צ'בישב, בואו נבין מה בכלל אנחנו רוצים לעשות ולמה זה לא לגמרי טריוויאלי. הצלחנו לרדקץ את כל המהומה של המבוכים אל ההבנה של גרף אחד ספציפי: {% equation %}P_{n}=\left(V,E\right){% endequation %} כך ש-{% equation %}V=\left\{ 1,2,\ldots,n\right\}{% endequation %} 
ו-{% equation %}E=\left\{ \left(1,2\right),\left(2,3\right),\ldots,\left(n-1,n\right)\right\}{% endequation %} . גרף שנראה כמו קו אחד ארוך - או בקיצור, "שרוך" . בואו נכתוב במפורש את הלפלסיאן של גרף כזה עם חמישה צמתים:

{% equation %}\left(\begin{array}{ccccc}
1 & -1 & 0 & 0 & 0\\
-1 & 2 & -1 & 0 & 0\\
0 & -1 & 2 & -1 & 0\\
0 & 0 & -1 & 2 & -1\\
0 & 0 & 0 & -1 & 1
\end{array}\right){% endequation %} 
זו מטריצה פשוטה מאוד, בצורה כמעט מרגיזה: שני האלכסונים המשניים שלה הם כולם {% equation %}-1{% endequation %} , האלכסון הראשי שלה הוא כמעט כולו 2 למעט שני הצדדים שהם 1. אולי אפשר לחשב את הפולינום האופייני שלה פשוט על ידי ההגדרה, באמצעות חישוב דטרמיננטה? אנחנו צריכים לחשב את הדטרמיננטה הבאה:

{% equation %}\left|\begin{array}{ccccc}
x-1 & 1 & 0 & 0 & 0\\
1 & x-2 & 1 & 0 & 0\\
0 & 1 & x-2 & 1 & 0\\
0 & 0 & 1 & x-2 & 1\\
0 & 0 & 0 & 1 & x-1
\end{array}\right|{% endequation %} 
אפשר להתחיל לחשב אותה על ידי פיתוח של השורה העליונה. זה אומר שלוקחים את {% equation %}x-1{% endequation %} ומכיפילים בדטרמיננטה שמתקבלת ממחיקת השורה והעמודה הראשונים. אחר כך **מפחיתים** את ה-1 שבעמודה השניה בשורה הראשונה, כשהוא מוכפל בדטרמיננטית המינור שמתקבל ממחיקת השורה הראשונה והעמודה השניה, כלומר

{% equation %}\left|\begin{array}{cccc}
1 & 1 & 0 & 0\\
0 & x-2 & 1 & 0\\
0 & 1 & x-2 & 1\\
0 & 0 & 1 & x-1
\end{array}\right|{% endequation %} 
את הדטרמיננטה **הזו** קל מאוד לפשט כי בעמודה הראשונה יש 1 רק ותו לא, אז מסירים את העמודה והשורה הראשונים ומקבלים

{% equation %}\left|\begin{array}{ccc}
x-2 & 1 & 0\\
1 & x-2 & 1\\
0 & 1 & x-1
\end{array}\right|{% endequation %} 
וזה מה שמקבלים כשמסירים מהמטריצה **המקורית** את שתי השורות והעמודות הראשונות. כלומר יש לנו מעין רקורסיה להתבסס עליה כאן - נחשב את הדטרמיננטה של המטריצה המקורית על ידי חישוב של דטרמיננטות של תת-מטריצות שמתקבלות ממנה על ידי מחיקת כך-וכך השורות והעמודות הראשונות. מקרי הבסיס הם כשמחקנו את הכל חוץ מהתא הימני-תחתון {% equation %}x-1{% endequation %} - נסמן זאת בתור {% equation %}p_{1}\left(x\right)=x-1{% endequation %} , והמקרה העוד יותר מנוון כשמחקנו את הכל ולכן יש לנו את "המכפלה הריקה"{% equation %}1{% endequation %} , ואת זה נסמן ב-{% equation %}p_{0}\left(x\right)=1{% endequation %} .

עכשיו, החישוב שעשיתי קודם כלל להסיר שורה ועמודה אחת ולהכפיל ב-{% equation %}x-1{% endequation %} , אבל זה היה למעשה מקרה מיוחד כי היה {% equation %}x-1{% endequation %} בפינה השמאלית-עליונה של המטריצה; בדרך כלל יהיה שם {% equation %}x-2{% endequation %} . אז אני מקבל את הנוסחה הבאה:

{% equation %}p_{k}=\left(x-2\right)p_{k-1}\left(x\right)-p_{k-2}\left(x\right){% endequation %} 
הנוסחה הזו עובדת עד שאנחנו מגיעים לשלב האחרון, ואז צריך יהיה להכפיל ב-{% equation %}x-1{% endequation %} כדי לקבל את {% equation %}L_{G}{% endequation %} . כלומר אנחנו מקבלים את הנוסחה הכללית הזו לחישוב סדרת פולינומים {% equation %}p_{k}{% endequation %} עבור {% equation %}1\le k\lt n{% endequation %} :

{% equation %}p_{0}\left(x\right)=1{% endequation %}

{% equation %}p_{1}\left(x\right)=x-1{% endequation %}

{% equation %}p_{k}\left(x\right)=\left(x-2\right)p_{k-1}\left(x\right)-p_{k-2}\left(x\right){% endequation %} 
עבור {% equation %}2\le k\lt n{% endequation %} .

ואז מגיע השלב האחרון:

{% equation %}L_{G}=\left(x-1\right)p_{n-1}\left(x\right)-p_{n-2}\left(x\right){% endequation %} 
הנוסחה עבור {% equation %}p_{k}{% endequation %} **מזכירה** בצורה חשודה את הנוסחה של סדרת פולינומים מפורסמת - **פולינומי צ'בישב**. אלו פולינומים חשובים ומועילים בזכות עצמם - אני בכלל הכרתי אותם לראשונה בהקשר של אנליזה נומרית וקירובים - אבל בפוסט הזה אני לא אכנס לזה. עדיין, כדאי להבין מאיפה הם מגיעים. והם מגיעים מהזוועה שהטרידה אותי בשיעורי המתמטיקה בתיכון - **זהויות טריגונומטריות**. ספציפית, הזהות של קוסינוס של זווית כפולה:

{% equation %}\cos\left(2\theta\right)=2\cos^{2}\theta-1{% endequation %} 
מה שאנחנו רואים כאן הוא שאפשר לבטא את קוסינוס של זווית כפולה בעזרת קוסינוס **רגיל** כל עוד אנחנו מרשים לכפול אותו בעצמו, ובמקדמים, ולחבר קבועים - זה מה שנקרא **פולינום**. אבל למה לעצור כאן? אפשר לנסות לטפל גם ב-{% equation %}\cos\left(3\theta\right){% endequation %} . כאן זווית כפולה לא תעזור לנו אבל אפשר לכתוב {% equation %}3\theta=2\theta+\theta{% endequation %} ולהשתמש בנוסחה הכללית לסכום זוויות, שהיא...

{% equation %}\cos\left(\theta+\varphi\right)=\cos\theta\cos\varphi-\sin\theta\sin\varphi{% endequation %} 
וזה... אה... לא טוב בכלל, כי יש לנו פה סינוס, ואני רציתי למצוא משהו שהוא פולינום אך ורק בקוסינוס. אבל רגע, לא להתאייש, אולי יש דרך לבטל את הסינוס כי הרי יש לנו גם נוסחה **להפרש** זוויות שנראית כמעט אותו דבר:

{% equation %}\cos\left(\theta-\varphi\right)=\cos\theta\cos\varphi+\sin\theta\sin\varphi{% endequation %} 
אם אני **אחבר** את שתי הנוסחאות הללו אני אפטר לגמרי מהסינוס:

{% equation %}\cos\left(\theta+\varphi\right)+\cos\left(\theta-\varphi\right)=2\cos\theta\cos\varphi{% endequation %} 
ואם אני אעביר אגף אני אקבל

{% equation %}\cos\left(\theta+\varphi\right)=2\cos\theta\cos\varphi-\cos\left(\theta-\varphi\right){% endequation %} 
יופי. עכשיו אפשר להציב {% equation %}\varphi=2\theta{% endequation %} ולקבל:

{% equation %}\cos\left(3\theta\right)=2\cos\theta\cos\left(2\theta\right)-\cos\theta{% endequation %} 
וזו התקדמות! כי את {% equation %}\cos\left(2\theta\right){% endequation %} אנחנו כבר יודעים לייצג בתור פולינום, אז יש לנו... רקורסיה! בואו נמצא את הנוסחה הכללית של הרקורסיה על ידי חזרה על הטריק של {% equation %}\cos\left(\theta+\varphi\right){% endequation %} , רק במקום {% equation %}\varphi=2\theta{% endequation %} נציב {% equation %}\varphi=n\theta{% endequation %} עבור {% equation %}n\gt 1{% endequation %} 
כלשהו, ונקבל

{% equation %}\cos\left(\left(n+1\right)\theta\right)=2\cos\theta\cos\left(n\theta\right)-\cos\left(\left(n-1\right)\theta\right){% endequation %} 
וזה מוכיח לי את התוצאה הבאה: אם אני מגדיר סדרת פולינומים {% equation %}T_{n}\left(x\right){% endequation %} 
על ידי

{% equation %}T_{0}\left(x\right)=1{% endequation %}

{% equation %}T_{1}\left(x\right)=x{% endequation %}

{% equation %}T_{n+1}\left(x\right)=2xT_{n}\left(x\right)-T_{n-1}\left(x\right){% endequation %} 
אז הסדרה תקיים {% equation %}\cos\left(n\theta\right)=T_{n}\left(\cos\theta\right){% endequation %} . הפולינומים {% equation %}T_{n}{% endequation %} הללו נקראים **פולינומי צ'בישב מן הסוג הראשון**.

האם זו הסדרה שקיבלנו עם הלפלסיאן שלנו?! אה... לא. הנה מה שקיבלנו:

{% equation %}p_{0}\left(x\right)=1{% endequation %}

{% equation %}p_{1}\left(x\right)=x-1{% endequation %}

{% equation %}p_{k}\left(x\right)=\left(x-2\right)p_{k-1}\left(x\right)-p_{k-2}\left(x\right){% endequation %} 
עבור {% equation %}2\le k\lt n{% endequation %} .

זה **דומה** אבל זה בוודאי לא זהה. יש כאן בהחלט הליכה של שני צעדים אחורה וחיסור של הפולינום של השני צעדים אחורה, אבל הכפל פה ב-{% equation %}x-2{% endequation %} 
ולא ב-{% equation %}2x{% endequation %} . השאלה היא האם זה הבדל מהותי או שאפשר למצוא דרך לבטא את הפולינומים שלנו בעזרת צ'בישב - ובהחלט יש דרך כזו. הנה דרך מסודרת לעשות את זה על ידי ניחוש מושכל.

מה שאני מנחש הוא שעבור {% equation %}k\lt n{% endequation %} מתקיים {% equation %}p_{k}\left(x\right)=T_{k}\left(Ax+B\right){% endequation %} , כלומר אני לוקח **העתקה לינארית**("אפינית" למי שרוצים להתקטנן) של הפרמטר של {% equation %}T{% endequation %} ובודק מה משתלם לי שהמקדמים {% equation %}A,B{% endequation %} יצאו. אני יודע שתחת ההנחה הזו מתקיים:

{% equation %}T_{k}\left(Ax+B\right)=2\left(Ax+B\right)T_{k-1}\left(Ax+B\right)-T_{k-2}\left(Ax+B\right)=\left(2Ax+2B\right)p_{k-1}\left(x\right)-p_{k-2}\left(x\right){% endequation %} 
ולכן עם השוואה לנוסחת הנסיגה שכבר ראיתי עבור {% equation %}p_{k}\left(x\right){% endequation %} 
אני אקבל

{% equation %}\left(x-2\right)p_{k-1}\left(x\right)-p_{k-2}\left(x\right)=\left(2Ax+2B\right)p_{k-1}\left(x\right)-p_{k-2}\left(x\right){% endequation %} 
כלומר, אני צריך שיתקיים {% equation %}x-2=2Ax+2B{% endequation %} , אז יהיה לי הכי פשוט לבחור {% equation %}A=\frac{1}{2}{% endequation %} ו-{% equation %}B=-1{% endequation %} , כלומר לקוות שמתקיים

{% equation %}p_{k}\left(x\right)=T_{k}\left(\frac{x-2}{2}\right){% endequation %} 
לרוע המזל, זה לא קורה. אמנם נוסחת הנסיגה כן עובדת, אבל מה עם תנאי ההתחלה? אמנם {% equation %}T_{0}\left(\frac{x-2}{2}\right)=1=p_{0}\left(x\right){% endequation %} 
אבל {% equation %}p_{1}\left(x\right)=x-1{% endequation %} ולעומת זאת {% equation %}T_{1}\left(\frac{x-2}{2}\right)=\frac{x-2}{2}{% endequation %} 
. החלוקה הזו ב-2 מקלקלת לנו קצת את הסיפור, אבל למרבה המזל אפשר לפתור את זה בקלות על ידי מעבר לפולינומי צ'בישב **מן הסוג השני**. זו סדרה שמוגדרת כמעט כמו הסוג הראשון, כולל אותה נוסחת נסיגה בדיוק, אבל אחד מתנאי ההתחלה טיפה שונה:

{% equation %}U_{0}\left(x\right)=1{% endequation %}

{% equation %}U_{1}\left(x\right)=2x{% endequation %}

{% equation %}U_{n+1}\left(x\right)=2xU_{n}\left(x\right)-U_{n-1}\left(x\right){% endequation %} 
כלומר ההבדל היחיד הוא ה-2 ב-{% equation %}U_{1}\left(x\right)=2x{% endequation %} . זה נותן לנו:

{% equation %}U_{1}\left(\frac{x-2}{2}\right)=x-2{% endequation %} 
וזה... עדיין לא מה שאנחנו צריכים! כי אנחנו רוצים את {% equation %}p_{1}\left(x\right)=x-1{% endequation %} ! אבל אפשר להוסיף פה אקסטרה התחכמות אם שמים לב לכך ש-{% equation %}U_{0}\left(\frac{x-2}{2}\right)=1{% endequation %} , כלומר

{% equation %}U_{1}\left(\frac{x-2}{2}\right)+U_{0}\left(\frac{x-2}{2}\right)=x-1=p_{1}\left(x\right){% endequation %} 
ואם נסמן {% equation %}U_{-1}\left(x\right)=0{% endequation %} נקבל גם

{% equation %}U_{0}\left(\frac{x-2}{2}\right)+U_{-1}\left(\frac{x-2}{2}\right)=1=p_{0}\left(x\right){% endequation %} 
מה שיפה הוא שצירוף לינארי של אובייקטים שמקיימים נוסחת נסיגה יקיים את אותה נוסחת הנסיגה. אז נקבל באופן כללי:

{% equation %}p_{k}\left(x\right)=U_{k}\left(\frac{x-2}{2}\right)+U_{k-1}\left(\frac{x-2}{2}\right){% endequation %} 
ולסיום:

{% equation %}L_{G}=\left(x-1\right)p_{n-1}\left(x\right)-p_{n-2}\left(x\right)={% endequation %}

{% equation %}=\left(x-1\right)U_{n-1}\left(\frac{x-2}{2}\right)+\left(x-1\right)U_{n-2}\left(\frac{x-2}{2}\right)-U_{n-2}\left(\frac{x-2}{2}\right)-U_{n-3}\left(\frac{x-2}{2}\right)={% endequation %}

{% equation %}=\left(x-1\right)U_{n-1}\left(\frac{x-2}{2}\right)+\left(x-2\right)U_{n-2}\left(\frac{x-2}{2}\right)-U_{n-3}\left(\frac{x-2}{2}\right){% endequation %} 
הגענו עכשיו לביטוי שאפשר לפשט חלק נכבד ממנו, אם כי אולי קשה לראות את זה כרגע. ניקח את החלק הזה:

{% equation %}\left(x-2\right)U_{n-2}\left(\frac{x-2}{2}\right)-U_{n-3}\left(\frac{x-2}{2}\right){% endequation %} 
וכדי שיהיה ברור מה אפשר לעשות פה, נסמן {% equation %}t=\frac{x-2}{2}{% endequation %} , כלומר קיבלנו

{% equation %}2tU_{n-2}\left(t\right)-U_{n-3}\left(t\right)=U_{n-1}\left(t\right)=U_{n-1}\left(\frac{x-2}{2}\right){% endequation %} 
כלומר, קיבלנו

{% equation %}\left(x-1\right)U_{n-1}\left(\frac{x-2}{2}\right)+\left(x-2\right)U_{n-2}\left(\frac{x-2}{2}\right)-U_{n-3}\left(\frac{x-2}{2}\right)={% endequation %}

{% equation %}=\left(x-1\right)U_{n-1}\left(\frac{x-2}{2}\right)+U_{n-1}\left(\frac{x-2}{2}\right)=xU_{n-1}\left(\frac{x-2}{2}\right){% endequation %} 
אחרי כל המהומה הזו, הנוסחה הסופית כמעט טריוויאלית: {% equation %}L_{G}=xU_{n-1}\left(\frac{x-2}{2}\right){% endequation %} . גם אם איבדתם אותי בדרך, זה מה שאנחנו צריכים - קיבלנו שהלפלסיאן של השרוך מאורך {% equation %}n{% endequation %} הוא {% equation %}xU_{n-1}\left(\frac{x-2}{2}\right){% endequation %} 
כש-{% equation %}U_{n-1}{% endequation %} הוא פולינום צ'בישב מן הסוג השני. עכשיו השאלה היא רק מה הערכים העצמיים של זה - כלומר, מה השורשים של הפולינום הזה. בבירור 0 הוא שורש - זו המשמעות של הכפל ב-{% equation %}x{% endequation %} , אבל כבר ידענו ש-0 הוא שורש. שאר השורשים הם השורשים של {% equation %}U_{n-1}\left(\frac{x-2}{2}\right){% endequation %} 
- כלומר, אם {% equation %}t{% endequation %} הוא שורש של {% equation %}U_{n-1}{% endequation %} אז נסמן {% equation %}t=\frac{x-2}{2}{% endequation %} 
ונקבל ש-{% equation %}x=2t+2{% endequation %} הוא שורש של {% equation %}L_{G}{% endequation %} .

מי השורשים של פולינומי צ'בישב? קל להבין את זה עבור {% equation %}T_{n}{% endequation %} , הפולינום מהסוג הראשון. ראינו איך הוא נבנה בצורה שתבטיח שיתקיים הדבר הבא:

{% equation %}T_{n}\left(\cos\theta\right)=\cos\left(n\theta\right){% endequation %} 
כאן {% equation %}T_{n}{% endequation %} הוא פולינום ממעלה {% equation %}n{% endequation %} ולכן יש לו {% equation %}n{% endequation %} שורשים לכל היותר - ומהנוסחה הזו קל למצוא {% equation %}n{% endequation %} שורשים שונים שכאלו. קוסינוס זו פונקציה שאנחנו מבינים מצוין ויודעים בדיוק איפה השורשים שלה - {% equation %}\cos\left(x\right)=0{% endequation %} 
אם ורק אם {% equation %}x=\frac{\pi}{2}+k\pi{% endequation %} כאשר {% equation %}k\in\mathbb{Z}{% endequation %} ([הנה פוסט שלי](https://gadial.net/2010/03/31/sine_and_cosine_via_ode/) על סינוסים וקוסינוסים שממנו אפשר להבין את זה) ואת זה אפשר לכתוב גם בתור {% equation %}x=\left(2k+1\right)\frac{\pi}{2}{% endequation %} . אז בואו נסתכל על סדרה {% equation %}\theta_{0},\theta_{1},\ldots,\theta_{n-1}{% endequation %} של ערכים כך ש-{% equation %}\theta_{k}=\frac{2k+1}{n}\frac{\pi}{2}{% endequation %} ; מובטח לנו ש-

{% equation %}T_{n}\left(\cos\left(\theta_{k}\right)\right)=\cos\left(n\theta_{k}\right)=\cos\left(\left(2k+1\right)\frac{\pi}{2}\right)=0{% endequation %} 
כדי לראות שכל השורשים הללו שונים זה מזה, נשים לב לכך ש-{% equation %}\theta_{0}=\frac{\pi}{2}{% endequation %} 
ו-{% equation %}\theta_{n-1}=\frac{2n-1}{n}\frac{\pi}{2}\lt \pi{% endequation %} , כלומר כל ה-{% equation %}\theta{% endequation %} -ות הללו חיות בתוך הקטע {% equation %}\left[\frac{\pi}{2},\pi\right]{% endequation %} שבו {% equation %}\cos{% endequation %} 
היא פונקציה מונוטונית יורדת - ולכן {% equation %}\cos\left(\theta_{0}\right),\ldots\cos\left(\theta_{n-1}\right){% endequation %} 
הם כולם ערכים שונים זה מזה, ומכאן שאלו כל השורשים של {% equation %}T_{n}{% endequation %} .

יופי, אבל רצינו את {% equation %}U_{n}{% endequation %} . פשוט קל יותר להבין את {% equation %}T_{n}{% endequation %} . השאלה היא איזו נוסחה דמויית {% equation %}T_{n}\left(\cos\theta\right)=\cos\left(n\theta\right){% endequation %} 
מתקיימת עבור {% equation %}U_{n}{% endequation %} . אז בואו ננסה להבין את זה - מהו {% equation %}U_{n}\left(\cos\theta\right){% endequation %} ?

ראשית, {% equation %}U_{0}\left(\cos\theta\right)=1{% endequation %} , זה בדיוק כמו עם {% equation %}T_{0}{% endequation %} . ההבדל הוא ב-{% equation %}U_{1}\left(x\right)=2x{% endequation %} . כלומר, {% equation %}U_{1}\left(\cos\theta\right)=2\cos\theta{% endequation %} . עכשיו, מה אני אמור לעשות עם {% equation %}2\cos\theta{% endequation %} ? את מה זה מזכיר לי? ובכן, זה מזכיר לי במעורפל את הזהות הטריגונומטרית

{% equation %}\sin2\theta=2\sin\theta\cos\theta{% endequation %} 
כלומר:

{% equation %}2\cos\theta=\frac{\sin2\theta}{\sin\theta}{% endequation %} 
כאשר כאן סימן החילוק מסתיר את המקרה הפרטי המיוחד שבו {% equation %}\theta=\pi k{% endequation %} , מה שמאפס גם את המונה וגם את המכנה. במקרה הזה אני פשוט מגדיר {% equation %}\frac{\sin2\theta}{\sin\theta}=2{% endequation %} (יש לזה הצדקה - קל לראות עם כלל לופיטל ש-{% equation %}\lim_{\theta\to\pi k}\frac{\sin2\theta}{\sin\theta}=2{% endequation %} ).

אז קיבלנו:

{% equation %}U_{1}\left(\cos\theta\right)=\frac{\sin2\theta}{\sin\theta}{% endequation %} 
וגם מתקיים

{% equation %}U_{0}\left(\cos\theta\right)=\frac{\sin\theta}{\sin\theta}{% endequation %} 
האם זה משהו שיכול להמשיך עם הרקורסיה הרגילה של פולינומי צ'בישב? ננסה להוכיח באינדוקציה ש-{% equation %}U_{n}\left(\cos\theta\right)=\frac{\sin\left(\left(n+1\right)\theta\right)}{\sin\theta}{% endequation %} :

{% equation %}U_{n}\left(\cos\theta\right)=2\cos\theta U_{n-1}\left(\cos\theta\right)-U_{n-2}\left(\cos\theta\right)={% endequation %}

{% equation %}=2\cos\theta\frac{\sin\left(n\theta\right)}{\sin\theta}-\frac{\sin\left(\left(n-1\right)\theta\right)}{\sin\theta}=\frac{2\cos\theta\sin\left(n\theta\right)-\sin\left(\left(n-1\right)\theta\right)}{\sin\theta}{% endequation %} 
עכשיו נשתמש בזהות {% equation %}2\cos\theta\sin\varphi=\sin\left(\theta+\varphi\right)+\sin\left(\varphi-\theta\right){% endequation %} 
כדי לקבל

{% equation %}\frac{2\cos\theta\sin\left(n\theta\right)-\sin\left(\left(n-1\right)\theta\right)}{\sin\theta}=\frac{\sin\left(\left(n+1\right)\theta\right)+\sin\left(\left(n-1\right)\theta\right)-\sin\left(\left(n-1\right)\theta\right)}{\sin\theta}=\frac{\sin\left(\left(n+1\right)\theta\right)}{\sin\theta}{% endequation %} 
הצלחה! אז קיבלנו את הנוסחה {% equation %}U_{n}\left(\cos\theta\right)=\frac{\sin\left(\left(n+1\right)\theta\right)}{\sin\theta}{% endequation %} . אנחנו כזכור רוצים את השורשים של {% equation %}U_{n-1}\left(\cos\theta\right)=\frac{\sin\left(n\theta\right)}{\sin\theta}{% endequation %} 
מה שטיפה מפשט לנו את הכתיבה - כל מה שאנחנו צריכים הוא למצוא מה {% equation %}n-1{% endequation %} 
הערכים שמאפסים את {% equation %}\sin\left(n\theta\right){% endequation %} ולא מאפסים את {% equation %}\sin\theta{% endequation %} . סינוס הוא קל יותר מקוסינוס - הוא מתאפס בכל {% equation %}\theta=\pi k{% endequation %} , ולכן אנחנו צריכים את השורשים {% equation %}\theta_{1},\ldots,\theta_{n-1}{% endequation %} המוגדרים על ידי {% equation %}\frac{k}{n}\pi{% endequation %} . מצאנו את היעד שלנו! הערכים שמאפסים את {% equation %}U_{n-1}{% endequation %} הם מהצורה {% equation %}\cos\left(\frac{k}{n}\pi\right){% endequation %} ולכן הערכים שמאפסים את {% equation %}L_{G}{% endequation %} הם מהצורה {% equation %}2\cos\left(\frac{k}{n}\pi\right)+2{% endequation %} . אלו הערכים העצמיים שחיפשתי!

...

בואו נפשט את זה עוד קצת.

בגדול מה שמפריע לי, כי אני ממש קטנוני, זה שיש לנו ביטוי עם חיבור. לא רוצה. כדי לפשט את זה אני שוב פושט על רשימת הזהויות הטריגונומטריות ומחפש משהו שיעזור לי. למרבה השמחה, יש כזה:

{% equation %}\cos^{2}x=\frac{1+\cos2x}{2}{% endequation %} 
או במילים אחרות:

{% equation %}1+\cos2x=2\cos^{2}x{% endequation %} 
נכפול את הכל ב-{% equation %}2{% endequation %} ונקבל באגף שמאל בדיוק את מה שרציתי לפשט:

{% equation %}2\cos2x+2=4\cos^{2}x{% endequation %} 
עכשיו נציב {% equation %}x=\frac{k\pi}{2n}{% endequation %} ונקבל:

{% equation %}2\cos\left(\frac{k}{n}\pi\right)+2=4\cos^{2}\left(\frac{k\pi}{2n}\right){% endequation %} 
וזהו! זה מה שהבטחתי בהתחלה! הערכים העצמיים של {% equation %}L_{P_{n}}{% endequation %} עבור השרוך מאורך {% equation %}n{% endequation %} הם 0 וכל הערכים מהצורה {% equation %}4\cos^{2}\left(\frac{k\pi}{2n}\right){% endequation %} 
עבור {% equation %}1\le k\le n-1{% endequation %} . זה מסיים את כל ההוכחות הכבדות ומשאיר רק את הסיכום.

## אז מה ראינו פה בעצם?

זה היה פוסט ארוך ועמוס בשלל נושאים, אז רגע לפני הסיום בואו נעשה סיכום של מה שהלך פה בעצם. 1. רצינו לספור כמה מבוכים יש מסדר {% equation %}n\times m{% endequation %} (עבור הגדרה ספציפית של "מבוך").

1. ראינו שזו בעיה שקולה לבעיה של ספירת עצים פורשים של גרף {% equation %}G{% endequation %} מסוים.

1. ראינו שספירת עצים פורשים שקולה לבעיה של חישוב דטרמיננטה של מינור של הלפלסיאן {% equation %}L_{G}{% endequation %} .

1. ראינו שכדי לחשב את הדטרמיננטה הזו מספיק למצוא את הערכים העצמיים השונים מאפס של {% equation %}L_{G}{% endequation %} .

1. ראינו ש-{% equation %}G=P_{n}\square P_{m}{% endequation %} כש-{% equation %}\square{% endequation %} הוא הסימון למכפלה של גרפים.

1. ראינו שנובע מזה ש-{% equation %}L_{G}=L_{P_{n}}\oplus L_{P_{m}}{% endequation %} כש-{% equation %}\oplus{% endequation %} 
הוא הסימון של סכום קרונקר של מטריצות.

1. ראינו שנובע מזה שהערכים העצמיים של {% equation %}L_{G}{% endequation %} הם סכומים של הערכים העצמיים של {% equation %}L_{P_{n}},L_{P_{m}}{% endequation %} .

1. ראינו שהערכים העצמיים של {% equation %}L_{P_{n}}{% endequation %} ששונים מאפס הם מהצורה {% equation %}4\cos^{2}\left(\frac{k\pi}{2n}\right){% endequation %} 
עבור {% equation %}k=1,2,\ldots,n-1{% endequation %} .

בואו נרכיב את כל זה ביחד כדי לקבל את הנוסחה שפותרת את הבעיה. ראשית, מה שראינו בשלב 4 הוא זה: שאם הערכים העצמיים של הלפלסיאן הם {% equation %}0=\lambda_{0},\lambda_{1},\ldots,,\lambda_{t-1}{% endequation %} אז הדטרמיננטה של כל מינור שלו היא {% equation %}\frac{1}{t}\lambda_{1}\cdots\lambda_{t-1}{% endequation %} 
- מכפלת כל הערכים העצמיים חוץ מ-0, וחלוקה ב-{% equation %}t{% endequation %} 
שהוא המספר הכולל של ערכים עצמיים.

עכשיו, נסמן את הערכים העצמיים של {% equation %}P_{n}{% endequation %} ב-{% equation %}0=\tau_{0},\tau_{1},\ldots,\tau_{n-1}{% endequation %} . בואו נשתמש בתוצאה על מכפלת הערכים העצמיים השונים מאפס על הגרף **הזה**. זה גרף שרוך, ושרוך הוא בעצמו עץ, כלומר קיים לו בדיוק עץ פורש יחיד - זה אומר שמתקיים {% equation %}\frac{1}{n}\prod_{k=1}^{n-1}\tau_{k}=1{% endequation %} . באופן דומה עבור {% equation %}P_{m}{% endequation %} נסמן את הערכים העצמיים ב-{% equation %}0=\rho_{0},\rho_{1},\ldots,\rho_{m-1}{% endequation %} 
ונקבל שמתקיים {% equation %}\frac{1}{m}\prod_{h=1}^{m-1}\tau_{h}=1{% endequation %} . שני אלו הולכים לסייע לי עוד מעט.

עכשיו מצאנו את הערכים המפורשים של הערכים העצמיים הללו בשלב 8 ועוד נציב אותם, אבל זה יהיה בהמשך. בינתיים נשתמש בשלב 7 כדי להסיק שמתקיים ש-{% equation %}t=mn{% endequation %} , ושכל ערך עצמי הוא מהצורה {% equation %}\lambda_{kh}=\tau_{k}+\rho_{h}{% endequation %} 
עבור {% equation %}0\le k\lt n{% endequation %} ו-{% equation %}0\le h\lt m{% endequation %} . אז בעצם יש לנו שלושה סוגים שונים של ערכים עצמיים: - הערך העצמי {% equation %}\lambda_{00}=\tau_{0}+\rho_{0}=0{% endequation %} - לא מפתיע שהוא קיים, לכל לפלסיאן יש ערך עצמי 0.

- הערכים העצמיים מהצורה {% equation %}\lambda_{k0}=\tau_{k}{% endequation %} ו-{% equation %}\lambda_{0h}=\rho_{h}{% endequation %} 
- אלו שהם פשוט הערכים העצמיים של אחד משני הגרפים {% equation %}P_{n},P_{m}{% endequation %} .

- כל היתר: {% equation %}\lambda_{kh}=\tau_{k}+\rho_{h}{% endequation %} עבור {% equation %}1\le k\lt n{% endequation %} 
ו-{% equation %}1\le h\lt m{% endequation %} .

עכשיו נציב ב-{% equation %}\frac{1}{t}\lambda_{1}\cdots\lambda_{t-1}{% endequation %} את כל הערכים העצמיים חוץ מ-{% equation %}\lambda_{00}{% endequation %} שלא משתתף בנוסחה הזו, כשבמקום אינדקס רץ בודד {% equation %}t{% endequation %} אני משתמש באינדקסים {% equation %}k,h{% endequation %} כמו קודם. אבל - אני אפריד את הערכים העצמיים מהצורה {% equation %}\lambda_{0h},\lambda_{k0}{% endequation %} 
מכל היתר. נקבל:

{% equation %}\frac{1}{mn}\prod_{k=1}^{n-1}\lambda_{k0}\cdot\prod_{h=1}^{m-1}\lambda_{0m}\cdot\prod_{k=1}^{n-1}\prod_{h=1}^{m-1}\lambda_{hk}{% endequation %} 
עכשיו, מה זה {% equation %}\prod_{k=1}^{n-1}\lambda_{k0}{% endequation %} ? זו פשוט המכפלה {% equation %}\prod_{k=1}^{n-1}\tau_{k}{% endequation %} של כל הערכים העצמיים השונים מאפס **של הגרף**{% equation %}P_{n}{% endequation %} . אם נכפול אותה ב-{% equation %}\frac{1}{n}{% endequation %} 
שנמצא שם נקבל {% equation %}\frac{1}{n}\prod_{k=1}^{n-1}\tau_{k}=1{% endequation %} . באופן דומה נשתמש גם ב-{% equation %}\frac{1}{m}\prod_{h=1}^{m-1}\tau_{h}=1{% endequation %} , ועכשיו הביטוי הפך להיות משמעותית יותר פשוט:

{% equation %}\prod_{k=1}^{n-1}\prod_{h=1}^{m-1}\lambda_{hk}=\prod_{k=1}^{n-1}\prod_{h=1}^{m-1}\left(\tau_{k}+\rho_{h}\right){% endequation %} **עכשיו** זה זמן טוב להציב את הערכים המפורשים:

{% equation %}\prod_{k=1}^{n-1}\prod_{h=1}^{m-1}\left(4\cos^{2}\left(\frac{k\pi}{2n}\right)+4\cos^{2}\left(\frac{h\pi}{2m}\right)\right){% endequation %} 
וזהו! קיבלנו את הנוסחה מתחילת הפוסט!

{% equation %}T\left(n,m\right)=\prod_{k=1}^{n-1}\prod_{h=1}^{m-1}\left(4\cos^{2}\left(\frac{k\pi}{2n}\right)+4\cos^{2}\left(\frac{h\pi}{2m}\right)\right){% endequation %} 
האם סיימנו? סוג של... יש לנו נוסחה סגורה יפה, אבל אני עדיין רוצה **לחשב** את הפתרון למקרה הקונקרטי שלי, {% equation %}423\times855{% endequation %} . אם אני אנסה סתם לחשב את זה בפייתון זה לא יעבוד - הולכים לצאת מספרים גדולים מדי והוא לא יצליח לעבוד איתם (כשאני עובד עם הספרייה numpy אני אקבל את התוצאה המרגשת np.float64)inf( - ניסיתי). 

אז אני אשתמש בטריק אחד אחרון ואוציא **לוגריתם** לשני האגפים. היופי בלוגריתמים הוא שהם הופכים מכפלות לסכומים, ולכן המספר שאני אקבל יהיה קטן משמעותית:

{% equation %}\log T\left(n,m\right)=\sum_{k=1}^{n-1}\sum_{h=1}^{m-1}\log\left(4\cos^{2}\left(\frac{k\pi}{2n}\right)+4\cos^{2}\left(\frac{h\pi}{2m}\right)\right){% endequation %} 
אבל מה המשמעות של מספר כזה? בואו ניקח לדוגמא את {% equation %}17,138,194{% endequation %} 
וניקח לו לוגריתם על בסיס 10 (שאני פשוט אסמן ב-{% equation %}\log{% endequation %} ):

{% equation %}\log17138194=7.233965054625744{% endequation %} 
מה שקיבלנו פה הוא בעצם שני מספרים: ה-7 מספר לנו כמה ספרות יש במספר שלנו - יותר במדויק, הוא אומר שהמספר שלנו גדול מ-{% equation %}10^{7}{% endequation %} 
אבל קטן מ-{% equation %}10^{8}{% endequation %} , כלומר יש בו 8 ספרות (הוא קטן יותר מ-1 שאחריו 8 אפסים, כלומר המספר הקטן ביותר עם 9 ספרות). כל ה-{% equation %}.233965054625744{% endequation %} 
שאחרי הנקודה מספר לנו בכמה צריך לכפול את {% equation %}10^{7}{% endequation %} כדי "לתקן" אותו ולקבל את המספר המדויק {% equation %}17138194{% endequation %} . ליתר דיוק, לא צריך לכפול את {% equation %}10^{7}{% endequation %} במספר הזה אלא ב-10 בחזקת המספר הזה, מה שיוצא **בערך**{% equation %}1.7138194{% endequation %} . למה זה עובד? פשוט כי אם באופן כללי {% equation %}\log a=n+x{% endequation %} כאשר {% equation %}n\in\mathbb{N}{% endequation %} ו-{% equation %}0\le x\lt 1{% endequation %} , אז 

{% equation %}a=10^{\log a}=10^{n+x}=10^{n}\cdot10^{x}{% endequation %} 
מכיוון ש-{% equation %}x\lt 1{% endequation %} אז {% equation %}10^{x}{% endequation %} הוא מספר קטן מ-10. זה מוביל אותנו לשיטה שבה אוהבים לתאר מספרים גדולים בצורה לא מדויקת: אם נסמן {% equation %}m=10^{x}{% endequation %} , אז נקבל {% equation %}a=m\cdot10^{n}{% endequation %} - כאן המספר {% equation %}m{% endequation %} נקרא **מנטיסה** ואילו {% equation %}n{% endequation %} נקרא **אקספוננט** ובמחשב נכתוב דברים כמו "1.7138e7" כדי לתאר את זה. אז אני לא באמת צריך לחשב את המספר המפלצתי שלי - אני צריך לחשב את הלוגריתם שלו, לקחת את הערך השלם שלו בתור האקספוננט, להעלות בחזקת 10 את היתר ולקבל את המנטיסה, להדפיס את זה יפה וסיימנו.

הנה קוד פייתון שמבצע את כל החישוב ב-4 שניות במחשב המקרטע שלי:

{% highlight python %}
import numpy as np
import itertools
n = 423
m = 855
vals = [np.log10(4*(np.cos(k*np.pi/(2*n)))**2 + 4*(np.cos(h*np.pi/(2*m)))**2)
 for (k,h) in itertools.product(range(1,n), range(1,m))
 ]
a = sum(vals)
n = int(a)
m = 10**(a - n)
print(f"{m}e{n}")
{% endhighlight %}

והתוצאה היא... תחזיקו חזק... זה:

3.142182277684719e182690

מה המספר הזה אומר, בעצם? כלום. פשוט כלום. אני לא רואה שום דבר שאפשר לעשות עם הידע הזה. זה סתם רצף אקראי של ספרות. אבל מה שיפה זה שאם אחרים ינסו לבצע את אותו חישוב, אבל בשיטות השונות שלהם, בסופו של דבר נגיע לאותו רצף ספרות אקראי ותתחזק אצלנו עוד יותר התחושה שמה שעשינו הוא נכון - שהנוסחה המגוחכת שהגענו אליה היא נכונה.

בואו נסתכל עליה שוב:

{% equation %}\log T\left(n,m\right)=\sum_{k=1}^{n-1}\sum_{h=1}^{m-1}\log\left(4\cos^{2}\left(\frac{k\pi}{2n}\right)+4\cos^{2}\left(\frac{h\pi}{2m}\right)\right){% endequation %} 
אם היו שואלים אותי על מבוכים לפני שהכרתי את כל הסיפור הזה ואז מראים לי את הנוסחה, הייתי חושב שהעולם השתגע ולא מבין מאיפה זה בא בכלל. אז בפוסט הזה ראינו בפירוט ניכר בדיוק מאיפה זה בא בכלל, ועכשיו אני מרגיש די מיודד עם הנוסחה הזו ועם מבוכים באופן כללי. כנראה שהנוסחה האמיתית הייתה המתמטיקה שפגשנו בדרך. 