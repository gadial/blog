---
id: 3331
title: "אינטגרל קווי"
date: 2016-04-19 16:51:59
layout: post
categories: 
  - אנליזה מתמטית
tags: 
  - אינטגרל קווי
  - משפט גרין
  - משפט סטוקס
---
בראשית בראו ניוטון ולייבניץ את <a href="http://www.gadial.net/2010/11/27/integral/">אינטגרל רימן</a> (רימן בא אחרי ניוטון ולייבניץ, אז מה זה השם הזה? לא נורא, בכל סיפור בריאה טובה צריך סתירות פנימיות). ויהא אינטגרל רימן אינטגרל של פונקציה {% equation %}f:\mathbb{R}\to\mathbb{R}{% endequation %} שמוגדר על קטע {% equation %}\left[a,b\right]\subseteq\mathbb{R}{% endequation %}. ויהי ערב ויהי בוקר אינפי 1.

ההתחלה הזו כל כך יפה ונקייה, ומייד אחריה מגיע תוהו ובוהו וחושך על פני תהום. מסתבר שיש אינספור דרכים שונות ומשונות להכליל את האינטגרל הזה. <a href="http://www.gadial.net/2015/11/09/d-dimensional_integrals/">בפוסטים קודמים שלי ראינו </a>דרך אחרת - להכליל אותו לאינטגרל של פונקציות {% equation %}f:\mathbb{R}^{n}\to\mathbb{R}{% endequation %} כאשר האינטגרל נלקח על קבוצה פתוחה {% equation %}A\subseteq\mathbb{R}^{n}{% endequation %}. ההגדרה הזו הייתה ישירה למדי - אותם רעיונות של אינטגרל רימן, כשהם מורחבים ל-{% equation %}\mathbb{R}^{n}{% endequation %} בצורה טבעית.

בפוסט הזה אני רוצה לדבר על הכללה קצת שונה, אבל לא מנותקת לגמרי ממה שראינו עד כה - <strong>אינטגרל קווי</strong>. הייתי יכול, תיאורטית, לוותר על הפוסט הזה לגמרי; המטרה הסופית שלי בסדרת הפוסטים הזו היא להציג את ההכללה המאוד חזקה של כל סוגי האינטגרלים שאציג כאן ומתבססת על קסם שנקרא <strong>תבנית דיפרנציאלית</strong>. אבל אני רוצה לדבר על אינטגרלים קווים משתי סיבות: ראשית, פרקטית: אלו אינטגרלים שימושיים מאוד שצצים בשלל תחומים והקשרים ואין שום סיבה להציג אותם רק בתור מקרה פרטי של מושג מורכב הרבה יותר שלא כולם יטרחו להכיר; ושנית, מן הסתם יותר קל להבין הכללות (בפרט כאלו, כמו תבניות דיפרנצאליות, שדורשות הרבה הכנה ומושגים מקדימים לפני שאפשר להציג) אם מבינים טוב חלק מהמקרים הפרטיים שאותם מכלילים. אם כן, בפוסט הזה אני הולך לעבוד ברמה מאוד בסיסית של הגדרות, ואני מקווה שהפוסט יהיה נגיש לכל מי שמכיר כבר את אינטגרל רימן ולא הרבה מעבר לכך.

אינטגרל קווי הוא משהו שבין אינטגרל במימד יחיד ובין אינטגרל ב-{% equation %}\mathbb{R}^{n}{% endequation %}: הוא מוגדר על פונקציות שתחומן הוא {% equation %}\mathbb{R}^{n}{% endequation %}, אבל הקבוצה שמעליה הוא מוגדר היא <strong>עקומה</strong> - אובייקט ב-{% equation %}\mathbb{R}^{n}{% endequation %} שהוא חד ממדי. תחשבו על מעגל היחידה במישור - אוסף כל הנקודות {% equation %}\left(x,y\right){% endequation %} כך ש-{% equation %}x^{2}+y^{2}=1{% endequation %} - זו דוגמה לעקום. הוא נראה כמו קו ישר שלקחנו את הקצוות שלו והדבקנו אותם. זאת להבדיל מ<strong>עיגול </strong>היחידה, שכולל גם את כל ה"בפנים" של המעגל, והוא דוגמא לקבוצה דו ממדית שעליה מבצעים את האינטגרציה המוכללת שכבר ראינו בעבר.

עוד נקודה מהותית היא שישנם <strong>שני</strong> סוגים של אינטגרלים קוויים, שמתאימים ל<strong>טווח</strong> של הפונקציה שמבצעים עליה אינטגרציה. אם זו פונקציה {% equation %}f:\mathbb{R}^{n}\to\mathbb{R}{% endequation %} אומרים שהפונקציה הזו היא <strong>שדה סקלרי</strong> והאינטגרל הקווי שלה נקרא "אינטגרל קווי מסוג ראשון" ועד כאן זה הכל נראה מוכר; אבל בניגוד למה שראינו עד כה על אינטגרלים במספר ממדים, אנחנו מאפשרים גם אינטגרציה של פונקציות {% equation %}F:\mathbb{R}^{n}\to\mathbb{R}^{n}{% endequation %}, שמחזירות לא ערך סקלרי אלא <strong>וקטור</strong> ב-{% equation %}\mathbb{R}^{n}{% endequation %}; לפונקציה כזו קוראים <strong>שדה וקטורי</strong> ולאינטגרל הקווי שלה קוראים "אינטגרל קווי מסוג שני". שני הסוגים כמובן קשורים זה לזה ואדבר פה על שניהם. מבין שניהם, זהו דווקא הסוג השני שנפוץ וחשוב יותר. אני אתן דוגמה זריזה אחת ומרכזית לשימוש בפיזיקה - <strong>עבודה</strong>: בנפנוף ידיים לא לגמרי מדויק, <strong>עבודה</strong> של כוח על גוף היא מדד לשינוי באנרגיה הקינטית (האנרגיה של המהירות של הגוף) שכוח מסויים גורם לו. מה שמעניין כאן הוא שתיאור של השינוי הזה לא תלוי בכלל ב<strong>זמן</strong>; מספיק לדעת רק מה המסלול שהגוף נע בו (זו העקומה שלנו) ומה הכוח שפועל עליו בכל נקודה של המסלול (זה השדה הוקטורי שלנו) כדי לדעת את השינוי באנרגיה של הגוף בין שני קצוות המסלול. נתעמק קצת יותר בדוגמה הזו בהמשך, כשיהיו לנו עוד הגדרות.

בפוסט הזה, כאמור, אני רוצה ללכת על הפשוט והבסיסי ביותר, ולכן אדבר על האינטגרלים הללו בדו-מימד - ב-{% equation %}\mathbb{R}^{2}{% endequation %}, ואזכיר טיפה מתישהו גם את {% equation %}\mathbb{R}^{3}{% endequation %}. ההכללות ל-{% equation %}\mathbb{R}^{n}{% endequation %} הן די מיידיות לרוב הדברים שאתאר פה ואין צורך לדבר מראש בצורה כללית שכזו.

לפני שמתחילים לדבר על אינטגרלים, צריך לדבר על האובייקט שמעליו מתבצעת האינטגרציה - <strong>עקומה</strong>. עקומה היא מה שקורה כשלוקחים קטע ישר חד ממדי - נאמר {% equation %}\left[a,b\right]{% endequation %}, זורקים אותו לתוך המרחב הדו ממדי ומתחילים למשוך ולהזיז חלקים שלו ימינה ושמאלה ולהתפרע איתו - אבל בלי לקרוע. התיאור המוזר שלעיל ניתן לפורמלזיציה באמצעות פונקציות: עקומה היא פשוט פונקציה {% equation %}\gamma:\left[a,b\right]\to\mathbb{R}^{2}{% endequation %} שהיא <strong>רציפה</strong> (זה הקטע של "בלי לקרוע") ובשביל השימושים שלנו גם נרצה לדרוש שהיא תהיה <strong>גזירה</strong> בקטע ושהנגזרת שלה תהיה רציפה ב-{% equation %}\left(a,b\right){% endequation %}(אפשר להרשות נקודות אי-גזירות מבודדות, אבל גם לזה לא אכנס). על עקומה עם תכונת הגזירות הזו אומרים שהיא <strong>חלקה</strong> (Smooth). הנה דוגמאות פשוטות לעקומות: {% equation %}\gamma_{1}\left(x\right)=\left(x^{2},\sqrt{1-x^{2}}\right){% endequation %} היא עקומה שנותנת לנו את מעגל היחידה כשמפעילים אותה על הקטע {% equation %}\left[-1,1\right]{% endequation %}. {% equation %}\gamma_{2}\left(x\right)=\left(x,x^{2}\right){% endequation %} נותנת לנו <strong>פרבולה</strong>, בעוד ש-{% equation %}\gamma_{3}\left(x\right)=\left(x,\frac{1}{x}\right){% endequation %} נותנת לנו חלק מ<strong>היפרבולה</strong> (למשל, על הקטע {% equation %}\left[1,2\right]{% endequation %}). ומה עם {% equation %}\gamma_{4}\left(x\right)=\left(-\sqrt{1-x^{2}},x^{2}\right){% endequation %}? גם היא נותנת את מעגל היחידה, אבל בצורה שונה מאשר {% equation %}\gamma_{1}{% endequation %}. ו-{% equation %}\gamma_{5}\left(x\right)=\left(\frac{x}{2},\frac{x^{2}}{4}\right){% endequation %} תיתן לנו פרבולה כמו {% equation %}\gamma_{2}{% endequation %}, אבל שוב משהו פה מרגיש לנו שונה. אלו נקודות שכדאי להתעכב עליהן.

כשאני מדבר על מעגל היחידה, מה שאני מדבר עליו בתכל'ס הוא <strong>קבוצה של נקודות במישור</strong>. לרוב אני מתאר אותן בתור "אוסף כל הנקודות שהן פתרון של מערכת משוואות מסויימת", במקרה שלנו {% equation %}x^{2}+y^{2}=1{% endequation %}. כאן, לעומת זאת, אני מדבר על משהו שונה - אני מדבר על <strong>פונקציה</strong>, שמעגל היחידה יוצא <strong>התמונה</strong> שלה על קטע מסויים. ייתכנו פונקציות רבות ושונות שיתנו את אותה התמונה. כדי לפשט את העניינים בואו נדבר על אוסף הנקודות במישור שמקיימות {% equation %}x=y{% endequation %} בין הנקודות {% equation %}\left(0,0\right){% endequation %} ו-{% equation %}\left(1,1\right){% endequation %} - זה פשוט קו ישר ב-45 מעלות עם ציר {% equation %}x{% endequation %}. הנה ארבע עקומות שונות שהתמונה שלהן יוצאת האוסף הזה:

{% equation %}\gamma_{1}\left(x\right)=\left(x,x\right){% endequation %} על הקטע {% equation %}\left[0,1\right]{% endequation %}

{% equation %}\gamma_{2}\left(x\right)=\left(2x,2x\right){% endequation %} על הקטע {% equation %}\left[0,\frac{1}{2}\right]{% endequation %}

{% equation %}\gamma_{3}\left(x\right)=\left(1-x,1-x\right){% endequation %} על הקטע {% equation %}\left[0,1\right]{% endequation %}

{% equation %}\gamma_{4}\left(x\right)=\begin{cases}\left(2x,2x\right) & 0\le x\le\frac{1}{2}\\\left(2\left(1-x\right),2\left(1-x\right)\right) & \frac{1}{2}\le x\le1\end{cases}{% endequation %}

מה קורה כאן? {% equation %}\gamma_{1}{% endequation %} מתאימה כנראה לאינטואיציה הבסיסית שלנו. לעומת זאת, {% equation %}\gamma_{2}{% endequation %} עושה את הכל "מהר יותר" - אינטואיטיבית, היא מהירה פי 2 יותר מאשר {% equation %}\gamma_{1}{% endequation %}. לעומת זאת, {% equation %}\gamma_{3}{% endequation %} נעה "באותה מהירות" כמו {% equation %}\gamma_{1}{% endequation %} אבל <strong>לכיוון ההפוך</strong>, ו-{% equation %}\gamma_{4}{% endequation %} לוקחת את הטוב שבשני העולמות: אצה רצה לה בכיוון ה"נכון" אל {% equation %}\left(1,1\right){% endequation %}, מגיעה לשם באמצע ה"זמן" שלה, ואז פונה וחוזרת על עקבותיה, תוך שהיא עוברת במקומות שהיא כבר הייתה בהם קודם. לכל ארבע העקומות הללו יש, כאמור, את אותה תמונה, אבל הן מתארות דברים שונים.

לפעמים מנסים להשתמש בטרמינולוגיה כדי להבדיל בין הדברים הללו. אני מכיר את השימוש ב<strong>עקום</strong> בעיקר כדי לתאר את קבוצת הנקודות, בזמן ש<strong>עקומה</strong> מתארת את הפונקציה (ולפעמים אומרים גם "מסלול", ו"אינטגרל מסלולי"). גם באנגלית נהוג לדבר לפעמים על Curve במשמעות של עקום ועל Path במשמעות של עקומה (אבל זה לא אומר שלא תצליחו למצוא גם Curve במשמעות של עקומה אם תחפשו מספיק - טרמינולוגיה זה לא חוק). אני אשתמש לרוב ב-{% equation %}C{% endequation %} (מלשון curve) כדי לתאר את העקום עצמו, ולזוג של פונקציה {% equation %}\gamma{% endequation %} ותחום שלה {% equation %}\left[a,b\right]{% endequation %} אני אתייחס בתור <strong>פרמטריזציה</strong> של העקום הזה. נראה בהמשך שכמעט ואין חשיבות לבחירת הפרמטריזציה כשמחשבים את הערך של האינטגרל (מה שמתאים למה שסיפרתי קודם על עבודה, שהיא אינה תלויה בזמן או במהירות של הגוף, אלא רק במסלול שהוא עובר).

בדו-מימד נוח לי לתאר עקומה באופן הבא: {% equation %}\gamma\left(t\right)=\left(x\left(t\right),y\left(t\right)\right){% endequation %}, כלומר העקומה היא זוג של פונקציות {% equation %}x\left(t\right),y\left(t\right){% endequation %} שהן בעצמן רציפות וגזירות וכל מה שתרצו. הסימון {% equation %}t{% endequation %} לקלט של {% equation %}\gamma{% endequation %} מן הסתם עדיף על {% equation %}x{% endequation %} כי כך אנחנו יכולים להשתמש ב-{% equation %}x{% endequation %} כדי לתאר את קואורדינטת ה-{% equation %}x{% endequation %} במישור של התמונה של העקומה על {% equation %}t{% endequation %}. מבחינת אינטואיציה, נוח לחשוב על {% equation %}t{% endequation %} בתור "זמן" ועל {% equation %}\gamma{% endequation %} מעל {% equation %}\left[a,b\right]{% endequation %} כאילו היא מתארת "טיול" במישור שמתחיל ב-{% equation %}\gamma\left(a\right){% endequation %} בזמן {% equation %}a{% endequation %} ומסתיים ב-{% equation %}\gamma\left(b\right){% endequation %} בזמן {% equation %}b{% endequation %}. אבל "זמן" כאן הוא רק אינטואיציה ותו לא.

כעת, אם {% equation %}f\left(x,y\right){% endequation %} היא פונקציה ממשית, מה שקראתי לו "שדה סקלרי" קודם, מה סביר להגדיר בתור האינטגרל שלה על העקום {% equation %}C{% endequation %}, עם הפרמטריזציה {% equation %}\gamma{% endequation %}, שאסמן {% equation %}\int_{C}f\left(x,y\right)d\gamma{% endequation %}? באינטגרל רימן הרגיל, של פונקציה ב-{% equation %}\mathbb{R}{% endequation %} שמוגדרת מעל קטע, גישה אחת (גישת סכומי רימן) היא לפרק את הקטע לקטעים קטנים, לבחור נקודה אקראית בכל תת-קטע שכזה, לחשב את הערך של הפונקציה עליו, לכפול באורך הקטע ולחבר את הכל. אם רואים שככל שהקטעים קטנים יותר, כך הסכום שמקבלים שואף לערך ספציפי (בלי תלות בנקודות האקראיות שבוחרים בתוך תתי-הקטעים, ואופן הפירוק שלנו לתתי-קטעים) אז אומרים שהפונקציה אינטגרבילית והסכום הוא האינטגרל שלה. על פניו, זה גם בדיוק מה שאנחנו יכולים לעשות כאן: נפרק את הקטע {% equation %}\left[a,b\right]{% endequation %} לתת-קטעים קטנים, נבחר נקודה אקראית {% equation %}t^{*}{% endequation %} בכל תת-קטע, נחשב את {% equation %}f\left(x\left(t^{*}\right),y\left(t^{*}\right)\right){% endequation %}, ואז נכפול באורך תת-הקטע... רגע, רגע, רגע. לא להתבלבל. הפונקציה {% equation %}f{% endequation %} שלנו חיה <strong>על העקומה</strong>. זה אומר שאנחנו רוצים לכפול את הערך שלה לא באורך תת-הקטע, אלא באורך <strong>התמונה</strong> של תת-הקטע של {% equation %}\left[a,b\right]{% endequation %}, דהיינו באורך של תת-העקומה שחיה בין שתי נקודות הקצה של תת-הקטע.

מה שמוביל אותנו לשאלה - איך מחשבים אורך של עקומה? ליתר דיוק, איך בכלל <strong>מגדירים</strong> אורך של עקומה? ובכן, בואו ניקח דוגמא מאינטגרלים: באינטגרל אנחנו מקרבים <strong>שטח</strong> באמצעות <strong>מלבנים</strong>, אז בואו נקרב אורך (האנלוג החד-ממדי של שטח) באמצעות קווים ישרים (האנלוג החד-ממדי של מלבן). פורמלית, אם אנחנו רוצים לחשב את האורך של {% equation %}\gamma{% endequation %} שמוגדרת על הקטע {% equation %}\left[a,b\right]{% endequation %}, ניקח חלוקה {% equation %}P{% endequation %} של {% equation %}\left[a,b\right]{% endequation %} (כלומר, אוסף של נקודות {% equation %}t_{1},t_{2},\dots,t_{N}{% endequation %} כך ש-{% equation %}a=t_{1}&lt;t_{2}&lt;\dots&lt;t_{n}=b{% endequation %}), נעביר קטע ישר בין כל שתי נקודות סמוכות ונחבר את סכום כל הקטעים הללו. נקבל:

{% equation %}\sum_{i=1}^{N-1}\left|\gamma\left(t_{i+1}\right)-\gamma\left(t_{i}\right)\right|{% endequation %}

כאשר ערך מוחלט כאן מייצג את הערך המוחלט הרגיל בדו-ממד: {% equation %}\left|\left(x,y\right)\right|=\sqrt{x^{2}+y^{2}}{% endequation %}.

האינטואיציה היא שהקו הישר בין שתי נקודות הוא בעל האורך הקטן ביותר מבין כל העקומות שמחברות אותם, ולכן הסכום הזה תמיד קטן מאורך העקומה האמיתי, והוא שואף אליו ככל שהחלוקה קטנה יותר. לכן אפשר לקחת את החסם העליון של כל הסכום מהצורה שלעיל ולהגדיר את אורך העקומה להיות שווה לה.

אצלנו, כזכור, העקומה היא <strong>חלקה</strong>. זה מאפשר לנו לעשות משהו יותר נחמד. בואו נזכור את משפט הערך הממוצע של לגראנז': אם {% equation %}f{% endequation %} רציפה על {% equation %}\left[a,b\right]{% endequation %} וגזירה על {% equation %}\left(a,b\right){% endequation %} אז קיימת {% equation %}c\in\left(a,b\right){% endequation %} כך ש-{% equation %}f\left(b\right)-f\left(a\right)=f^{\prime}\left(c\right)\left(b-a\right){% endequation %}. אם נפעיל את זה על קירוב העקומה שלנו, נקבל

{% equation %}\sum_{i=1}^{N-1}\left|\gamma^{\prime}\left(c_{i}\right)\right|\Delta t_{i}{% endequation %}

כאשר {% equation %}\Delta t_{i}=t_{i+1}-t_{i}{% endequation %} ו-{% equation %}t_{i}&lt;c_{i}&lt;t_{i+1}{% endequation %}.

הדבר הזה הוא <strong>סכום רימן</strong> של האינטגרל של {% equation %}\gamma^{\prime}{% endequation %} על הקטע {% equation %}\left[a,b\right]{% endequation %}, אינטגרל שקיים בזכות ההנחה שלנו ש-{% equation %}\gamma^{\prime}{% endequation %} רציפה (זהו המשפט היסודי של החדו"א). לכן אם משאיפים את גודל החלוקות ל-0, מה שנותן לנו את אורך העקומה, מקבלים גם בדיוק את האינטגרל {% equation %}\int_{a}^{b}\left|\gamma^{\prime}\left(t\right)\right|dt{% endequation %}. אם כן, מצאנו דרך נוחה <strong>לחשב</strong> את האורך של עקומה חלוקה באמצעות אינטגרל רימן רגיל, ואני מקווה שנחה דעתנו שהדרך הזו מסתדרת עם ההגדרה המתבקשת ביותר לאורך של עקומה.

כעת נחזור לאינטגרל קווי. שם הניתוח המדויק מסובך קצת יותר, כי הסכום הטיפוסי שלנו נראה כך:

{% equation %}\sum_{i=1}^{N-1}f\left(\gamma\left(c_{i}\right)\right)\left|\gamma\left(t_{i+1}\right)-\gamma\left(t_{i}\right)\right|{% endequation %}

וזאת אחרי שכבר ביצענו את הפישוט שעכשיו נראה מתבקש - במקום לכפול באורך העקומה בין {% equation %}\gamma\left(t_{i}\right){% endequation %} ו-{% equation %}\gamma\left(t_{i+1}\right){% endequation %}, אנחנו כופלים באורך הקטע שמחבר את שתי הנקודות הללו. הבעיה היא שאם ננסה להשתמש במשפט ערך הביניים כמו קודם נקבל

{% equation %}\sum_{i=1}^{N-1}f\left(\gamma\left(c_{i}\right)\right)\left|\gamma^{\prime}\left(d_{i}\right)\right|{% endequation %}

כך ש-{% equation %}c_{i},d_{i}{% endequation %} הן נקודות ביניים, אבל לא בהכרח <strong>אותן</strong> נקודות ביניים. לכן זה לא סכום רימן. זה דורש הערכה קצת יותר זהירה של {% equation %}\left|\gamma\left(t_{i+1}\right)-\gamma\left(t_{i}\right)\right|{% endequation %} שכן תשתמש ב-{% equation %}c_{i}{% endequation %}, ולא אכנס לכך כאן. השורה התחתונה היא שזה עובד ומקבלים את האינטגרל המתבקש:

{% equation %}\int_{C}fds=\int_{a}^{b}f\left(\gamma\left(t\right)\right)\left|\gamma^{\prime}\left(t\right)\right|dt{% endequation %}

וברוב הספרים מעדיפים להביא את האינטגרל הזה בתור <strong>ההגדרה</strong> של אינטגרל קווי מסוג ראשון.

ה-ds שבאינטגרל השמאלי הוא מבחינתנו כרגע סימון בלבד, שנותן אינדיקציה לכך שהאינטגרל הוא אינטגרל קווי, כלומר שהוא מהצורה "ערך הפונקציה כפול יחידת אורך קטנה מאוד על העקומה".

זה מסיים לעת עתה עם אינטגרל קווי מהסוג הראשון. בואו נעבור אל השני, זה שבו אנחנו מבצעים אינטגרציה על שדה וקטורי שאסמן {% equation %}F\left(x,y\right)=\left(P\left(x,y\right),Q\left(x,y\right)\right){% endequation %} (כלומר, אני מייצג את {% equation %}F{% endequation %} באמצעות שתי פונקציות סקלריות עם שני משתנים כל אחת, {% equation %}P{% endequation %} ו-{% equation %}Q{% endequation %}). כדי להבין את האינטואיציה שמאחורי אינטגרל קווי מסוג שני כדאי לחזור לדיבורים על <strong>עבודה </strong>בפיזיקה. בואו נחשוב על שתי סיטואציות: רץ אולימפי שרץ כשהרוח היא <strong>עם</strong> כיוון הריצה, ורץ עם רוח <strong>נגד</strong> כיוון הריצה. במקרה הראשון די ברור לנו שהרוח "עוזרת" לרץ ובמקרה השני היא מפריעה לו. במקרה הראשון הרוח <strong>מוסיפה לו אנרגייה קינטית</strong> ובשני היא גוזלת אותה ממנו. מכאן אנו רואים שהעבודה של כוח תלויה בכיוון שלו.

אבל זה יותר מחוכם ממה שזה נראה במבט ראשון. הנה הדוגמה השלישית: לווין שמקיף את כדור הארץ. בואו נזניח השפעה של כל דבר מלבד כדור הארץ ונניח שהמסלול של הלווין מעגלי לחלוטין - איך הקסם הזה קורה? משהו גורם ללווין להסתובב כל הזמן סביב כדור הארץ בלי להשקיע בו אנרגיה נוספת. המשהו הזה הוא כדור הארץ עצמו; כוח המשיכה של כדור הארץ פועל על הלווין בכל עת בכיוון שהוא <strong>מאונך</strong> לכיוון התנועה של הלווין. זה גורם לשינוי ב<strong>מסלול</strong> של הלווין - במקום שהוא ימשיך בקו ישר, כפי שקורה לגופים בתנועה שלא פועלים עליהם כוחות, המסלול שלו הוא מעגלי. עם זאת, הכוח שכדור הארץ משנה לא מגדיל את <strong>גודל</strong> המהירות של הלווין, רק את הכיוון שלה; המהירות היא וקטור שמשתנה כל הזמן אבל הערך המוחלט שלו נותר קבוע. אם גודל המהירות לא השתנה, האנרגיה הקינטית של הגוף לא השתנתה. במילים אחרות, כדור הארץ מפעיל כוח שפועל על הלווין ללא הרף וגורם לו להישאר במסלול מעגלי, אבל הוא לא מבצע על הלווין שום <strong>עבודה</strong>. זה נכון באופן כללי: כוח שפועל על גוף <strong>במאונך למסלול תנועתו</strong> לא מבצע עליו עבודה.

אם כן, מה שעושים באופן כללי עם כוח שפועל על גוף הוא לפרק את הכוח לשני רכיבים. הרכיב שמאונך למסלול הגוף ולא מבצע שום עבודה ואפשר לכוח ממנו; והרכיב שתואם למסלול הגוף והוא זה שמשתתף בעבודה. בניסוח מתמטי, אנחנו <strong>מטילים</strong> את הכוח על <strong>וקטור הכיוון</strong> של מסלול התנועה בכל רגע נתון. הטלה כזו מתבצעת במתמטיקה על ידי <strong>מכפלה סקלרית</strong>. כזכור, אם {% equation %}v_{1}\left(x_{1},y_{1}\right){% endequation %} ו-{% equation %}v_{2}\left(x_{2},y_{2}\right){% endequation %} הם שני וקטורים ב-{% equation %}\mathbb{R}^{n}{% endequation %} אז המכפלה הסקלרית שלהם מוגדרת להיות {% equation %}v_{1}\cdot v_{2}=x_{1}x_{2}+y_{1}y_{2}{% endequation %} - כופלים "רכיב רכיב" ומחברים את כל המכפלות.

כלומר, הפעם אנחנו לא כופלים את ערך הפונקציה ב<strong>אורך</strong> הקטע מ-{% equation %}\gamma\left(t_{i}\right){% endequation %} אל {% equation %}\gamma\left(t_{i+1}\right){% endequation %}; אנחנו כופלים <strong>סקלרית </strong>את ערך הפונקציה (שהוא, כזכור, וקטור ב-{% equation %}\mathbb{R}^{2}{% endequation %}) ב<strong>וקטור</strong> ההעתק מ-{% equation %}\gamma\left(t_{i}\right){% endequation %} אל {% equation %}\gamma\left(t_{i+1}\right){% endequation %}. באופן דומה לניתוח של האינטגרל מהסוג הראשון, זה יביא אותנו בסופו של דבר אל הנוסחה:

{% equation %}\int_{C}F\cdot d\gamma=\int_{a}^{b}F\left(\gamma\left(t\right)\right)\cdot\gamma^{\prime}\left(t\right)dt{% endequation %}

ושוב - רוב הספרים מעדיפים <strong>להגדיר</strong> אינטגרל קווי מסוג שני באמצעות הנוסחה הזו. עוד סימון אפשרי לאינטגרל קווי, שבו לא כותבים את {% equation %}F{% endequation %} אלא את ה-{% equation %}P,Q{% endequation %} שמרכיבות אותו, הוא {% equation %}\int_{C}Pdx+Qdy{% endequation %}. זה סימון קצת מבלבל ואני לא אוהב אותו במיוחד, אבל צריך להכיר אותו ולפעמים הוא שימושי מאוד (כשרוצים להציג בו זמנית את {% equation %}P,Q{% endequation %} בצורה נוחה). שימו לב ש-{% equation %}\gamma{% endequation %} נעלמה לחלוטין מהסימון הזה; כשמשתמשים בו מניחים שאפשר להסיק מתוך {% equation %}C{% endequation %} מהי ה-{% equation %}\gamma{% endequation %} הרלוונטית (עוד מעט נראה שיש לנו חופש בחירה די גדול של {% equation %}\gamma{% endequation %} כזו בהינתן {% equation %}C{% endequation %} מבלי שמשמעות האינטגרל תשתנה). עוד סימון שכדאי להכיר הוא {% equation %}\oint_{C}{% endequation %} שמשתמשים בו כדי לתאר אינטגרל קווי כאשר {% equation %}C{% endequation %} הוא עקום <strong>סגור</strong>, כלומר נקודת הסוף של העקומה שמתארת אותו שווה לנקודת ההתחלה. זה סימון קוסמטי למדי - אפשר היה לוותר על העיגול במרכז ושום דבר לא היה משתנה, אבל אני אוהב להשתמש בו.

בואו נראה איך ההגדרה הזו מסתדרת עם מושג העבודה בפיזיקה. נניח שיש לנו גוף שמבצע תנועה במישור שמתחילה ב-{% equation %}t_{1}{% endequation %} ומסתיימת ב-{% equation %}t_{2}{% endequation %}. נתאר את המיקום שלו במישור בזמן {% equation %}t{% endequation %} באמצעות הפונקציה {% equation %}r\left(t\right){% endequation %}, את המהירות שלו עם {% equation %}v\left(t\right){% endequation %} ואת התאוצה שלו עם {% equation %}a\left(t\right){% endequation %}. הכוח שפועל עליו במהלך התנועה יהיה פונקציה של המיקום שלו במישור, כלומר פונקציה {% equation %}F\left(r\left(t\right)\right){% endequation %}. אנחנו כבר רואים איך זה מתאים יפה למבנה של האינטגרל הקווי שהגדרנו.

עכשיו, בואו ניזכר בכמה דברים מפיזיקה. ראשית, <strong>האנרגיה הקינטית</strong> של גוף שמהירותו {% equation %}v{% endequation %} ומסתו {% equation %}m{% endequation %} מוגדרת להיות {% equation %}\frac{mv^{2}}{2}{% endequation %}. שנית, על פי הגדרתם ממש, {% equation %}v\left(t\right)=r^{\prime}\left(t\right){% endequation %} ו-{% equation %}a\left(t\right)=v^{\prime}\left(t\right)=r^{\prime\prime}\left(t\right){% endequation %}. לבסוף,<strong> החוק השני של ניוטון</strong> קובע ש-{% equation %}F=ma{% endequation %} (יש גם ניסוח כללי יותר שלא רלוונטי לנו כאן).

כעת, העבודה שמתבצעת על הגוף על ידי הכוח במהלך תנועתו היא, על פי ההגדרה כאינטגרל קווי מסוג שני:

{% equation %}\int_{t_{1}}^{t_{2}}F\left(r\left(t\right)\right)\cdot r^{\prime}\left(t\right)dt=\int_{t_{1}}^{t_{2}}ma\left(t\right)\cdot v\left(t\right)dt=m\int_{t_{1}}^{t_{2}}v\left(t\right)\cdot v^{\prime}\left(t\right)dt{% endequation %}

עכשיו, איזו פונקציה, כשנגזור אותה, תיתן לנו את הנגזרת {% equation %}v\left(t\right)v^{\prime}\left(t\right){% endequation %}? המבנה הזה קצת מזכיר את כלל השרשרת, ועם קצת משחק/נסיון באינטגרציה לא קשה לראות ש-{% equation %}\left[\frac{1}{2}v^{2}\left(t\right)\right]^{\prime}=v\left(t\right)v^{\prime}\left(t\right){% endequation %}. מכאן נקבל:

{% equation %}m\int_{t_{1}}^{t_{2}}v\left(t\right)\cdot v^{\prime}\left(t\right)dt=\frac{m}{2}\left(v^{2}\left(t_{2}\right)-v^{2}\left(t_{2}\right)\right)=\frac{mv^{2}\left(t_{2}\right)}{2}-\frac{mv^{2}\left(t_{1}\right)}{2}{% endequation %}

כלומר, קיבלנו שהעבודה אכן שווה לשינוי באנרגיה הקינטית, כפי שקיווינו.

עכשיו בואו נדבר על מה שהציק לנו מתחילת הפוסט: האם האינטגרל שלנו מוגדר היטב על <strong>עקום</strong> נתון, או שיש כאן תלות בבחירת <strong>העקומה</strong> שמגדירה את העקום? התשובה המיידית היא שפרט לכמה דברים כמעט מובנים מאליהם, אין חשיבות לבחירת העקומה. מה ברור, לפחות אינטואיטיבית, שכן ישפיע? למשל, שתי עקומות שמגדירות את אותו עקום אבל נעות לכיוונים ההפוכים. בואו ניתן את הניסוחים הפורמליים וההוכחות ואז הכל יהיה ברור יותר.

בואו נתבונן על שני עקומות{% equation %}\gamma\left(t\right){% endequation %} ו-{% equation %}\delta\left(t\right){% endequation %}. נניח ש-{% equation %}\gamma{% endequation %} מוגדרת על הקטע {% equation %}\left[a,b\right]{% endequation %} ו-{% equation %}\delta{% endequation %} מוגדרת על הקטע {% equation %}\left[c,d\right]{% endequation %}. אם {% equation %}\delta{% endequation %} מתארת את אותו דבר כמו {% equation %}\gamma{% endequation %} היינו מצפים שלכל {% equation %}t\in\left[c,d\right]{% endequation %} יהיה איזה {% equation %}s_{t}\in\left[a,b\right]{% endequation %} כך ש-{% equation %}\delta\left(t\right)=\gamma\left(s_{t}\right){% endequation %}. זה מגדיר לנו <strong>פונקציה</strong> {% equation %}u:\left[c,d\right]\to\left[a,b\right]{% endequation %} שמקיימת {% equation %}\delta\left(t\right)=\gamma\left(u\left(t\right)\right){% endequation %}. בואו נתבונן לצורך הדוגמה בעקומות שהראיתי בתחילת הפוסט:

{% equation %}\gamma_{1}\left(x\right)=\left(x,x\right){% endequation %} על הקטע {% equation %}\left[0,1\right]{% endequation %}

{% equation %}\gamma_{2}\left(x\right)=\left(2x,2x\right){% endequation %} על הקטע {% equation %}\left[0,\frac{1}{2}\right]{% endequation %}

{% equation %}\gamma_{3}\left(x\right)=\left(1-x,1-x\right){% endequation %} על הקטע {% equation %}\left[0,1\right]{% endequation %}

{% equation %}\gamma_{4}\left(x\right)=\begin{cases}\left(2x,2x\right) & 0\le x\le\frac{1}{2}\\\left(2\left(1-x\right),2\left(1-x\right)\right) & \frac{1}{2}\le x\le1\end{cases}{% endequation %}

אז כאן למשל מתקיים {% equation %}\gamma_{2}\left(t\right)=\gamma_{1}\left(u\left(t\right)\right){% endequation %} כאשר {% equation %}u\left(t\right)=2t{% endequation %}. וכמו כן מתקיים {% equation %}\gamma_{3}\left(t\right)=\gamma_{1}\left(u\left(t\right)\right){% endequation %} כאשר {% equation %}u\left(t\right)=1-t{% endequation %}, ו-{% equation %}\gamma_{4}\left(t\right)=\gamma_{1}\left(u\left(t\right)\right){% endequation %} עם {% equation %}u\left(t\right)=\begin{cases}2t & 0\le t\le\frac{1}{2}\\2\left(1-t\right) & \frac{1}{2}\le t\le1\end{cases}{% endequation %}.

עכשיו, אם נחשב את האינטגרל הקווי של השדה הוקטורי {% equation %}f\left(x,y\right)=\left(x,y\right){% endequation %} עבור ארבעת העקומות הללו, מה נקבל?

במקרה הראשון, {% equation %}\int_{0}^{1}\left(t,t\right)\cdot\left(1,1\right)dt=\int_{0}^{1}2t=\left[t^{2}\right]_{0}^{1}=1{% endequation %}.

במקרה השני, {% equation %}\int_{0}^{\frac{1}{2}}\left(2t,2t\right)\cdot\left(2,2\right)dt=\int_{0}^{\frac{1}{2}}8t=\left[4t^{2}\right]_{0}^{\frac{1}{2}}=1{% endequation %}.

במקרה השלישי, {% equation %}\int_{0}^{1}\left(1-t,1-t\right)\cdot\left(-1,-1\right)dt=\int_{0}^{1}\left(2t-2\right)dt=\left[t^{2}-2t\right]_{0}^{1}=-1{% endequation %}

במקרה הרביעי, {% equation %}\int_{0}^{\frac{1}{2}}\left(2t,2t\right)\cdot\left(2,2\right)dt+\int_{\frac{1}{2}}^{1}\left(2\left(1-t\right),2\left(1-t\right)\right)\cdot\left(-2,-2\right)dt={% endequation %}

{% equation %}=\int_{0}^{\frac{1}{2}}8tdt+\int_{\frac{1}{2}}^{1}8\left(t-1\right)dt=\left[4t^{2}\right]_{0}^{\frac{1}{2}}+\left[4t^{2}-8t\right]_{\frac{1}{2}}^{1}=1+\left(-4+3\right)=0{% endequation %}

די ברור מה "משתבש" במקרים השלישי והרביעי - במקרה השני אנחנו הולכים "בכיוון ההפוך" על העקום, ולכן מקבלים תוצאה הפוכה; ובמקרה הרביעי אנחנו הולכים "לשם ובחזרה" ולכן סוכמים את תוצאות ההליכה בשני הכיוונים ומסיימים עם אפס. כל זה מצביע על כך שאנחנו רוצים לדרוש מ-{% equation %}u{% endequation %} להיות <strong>חד-חד-ערכית</strong> ולהבדיל בין המקרה שבו היא הולכת בכיוון הנכון לבין זה שבו היא הולכת בכיוון ההפוך. דרך נוחה לעשות זאת היא לדרוש ש-{% equation %}u{% endequation %} תהיה <strong>גזירה</strong> ושהנגזרת שלה תהיה שונה מ-0 בכל הקטע; זה מבטיח ש-{% equation %}u{% endequation %} היא עולה בכל הקטע, או יורדת בכל הקטע. אם היא עולה (הנגזרת חיובית), הכל בסדר; אם היא יורדת (הנגזרת שלילית) אז נצפה לקבל היפוך של האינטגרל. פורמלית: אם {% equation %}\gamma{% endequation %} ו-{% equation %}\delta{% endequation %} הן עקומות המתאימות לעקום {% equation %}C{% endequation %} כך שקיימת {% equation %}u:\left[c,d\right]\to\left[a,b\right]{% endequation %} רציפה וגזירה עם {% equation %}u^{\prime}&gt;0{% endequation %} בכל התחום עבורה מתקיים {% equation %}\delta\left(t\right)=\gamma\left(u\left(t\right)\right){% endequation %}, אז {% equation %}\int_{C}F\cdot d\gamma=\int_{C}F\cdot d\delta{% endequation %}. אם קיימת {% equation %}u{% endequation %} כזו כך ש-{% equation %}u^{\prime}&lt;0{% endequation %} בכל התחום אז {% equation %}\int_{C}F\cdot d\gamma=-\int_{C}F\cdot d\delta{% endequation %}. זוהי <strong>אי התלות בפרמטר</strong> שחיפשנו. היא מצביעה על כך שבהינתן {% equation %}C{% endequation %}, לא באמת חשוב איך אנחנו בוחרים לבנות את הפרמטריזציה של {% equation %}C{% endequation %}, כלומר לא חשוב באיזו {% equation %}\gamma{% endequation %} אנחנו משתמשים, כל עוד אנחנו מקפידים לזכור ש<strong>הכיוון חשוב</strong> וש<strong>מספר הפעמים</strong> שבהן העקומה שלנו מכסה את {% equation %}C{% endequation %} חשוב. למשל, אם {% equation %}C{% endequation %} הוא מעגל, חשוב לדעת אם הפרמטריזציה שלנו נעה עם כיוון השעון או נגדו, וכמה פעמים היא "משלימה הקפה".

לסיום, בואו נעבור לדבר על הכללות של <strong>המשפט היסודי של החדו"א</strong> עבור האינטגרלים שראינו. כאן אנחנו שולחים יד מגששת ונוגעים לראשונה במה שהוא היעד הסופי של סדרת הפוסטים הזו ולטעמי אחת מגולות הכותרת של כל הנושאים הללו - <strong>משפט סטוקס</strong>. אבל יש עוד זמן עד שאפשר יהיה להבין מה בכלל משפט סטוקס אומר, ולכן מה שנעשה כעת יהיה לדבר על דוגמאות (שכמובן, היו ידועות הרבה לפני משפט סטוקס המדובר).

בשביל להבין מאיפה זה מגיע בכלל, בואו ניזכר איך הולך המשפט היסודי של החדו"א. אם {% equation %}f{% endequation %} רציפה ו-{% equation %}F{% endequation %} היא פונקציה קדומה שלה (דהיינו, {% equation %}f=F^{\prime}{% endequation %}) אז מתקיים {% equation %}\int_{a}^{b}f\left(x\right)dx=F\left(b\right)-F\left(a\right){% endequation %}. המשפט הזה נראה לי כמו קסם - איכשהו אנחנו מצליחים לדעת מה הערך של האינטגרל המסויים על {% equation %}f{% endequation %} בכל הקטע {% equation %}\left[a,b\right]{% endequation %} רק על ידי הסתכלות על <strong>מה שקורה בקצוות</strong> הקטע. באיזה שהוא אופן קסום, הפונקציה {% equation %}F{% endequation %} מקודדת את המידע על {% equation %}f{% endequation %} בצורה כזו שמספיק לדגום אותה בשתי נקודות הקצה של הקטע כדי לדעת את ערכו של האינטגרל.

ועכשיו בואו נחשוב על אינגטרל כפול, כלומר אינטגרל ב-{% equation %}\mathbb{R}^{2}{% endequation %} שמוגדר בצורה שתיארתי בפוסטים קודמים. כאן האינטגרציה היא לא על קטע אלא על תחום דו-ממדי כלשהו (התחלנו עם מלבן אבל בסופו של דבר הגענו לקבוצה פתוחה כלשהי). בואו נניח שיש לנו פונקציה {% equation %}f:\mathbb{R}^{2}\to\mathbb{R}{% endequation %} שמוגדרת על תחום {% equation %}R{% endequation %} ב-{% equation %}\mathbb{R}^{2}{% endequation %} שהוא נחמד - הוא חסום והשפה שלו {% equation %}C{% endequation %} היא פשוטה יחסית (לא אכנס כרגע להגדרות - אתם מוזמנים בינתיים להניח שהתחום הוא מלבן אם זה עוזר לכם). אין ל-{% equation %}R{% endequation %} "נקודות קצה" כמו במימד אחד, אבל יש לו את <strong>השפה</strong> שלו; אז האם קיימת פונקציה {% equation %}F{% endequation %} כלשהי כך שאפשר להמיר את האינטגרל הכפול של {% equation %}f{% endequation %} על {% equation %}R{% endequation %} ב<strong>אינטגרל קווי</strong> על איזו שהיא פונקציה {% equation %}F{% endequation %}? באופן די נפלא, התשובה היא כן, ולתוצאה הזו קוראים <strong>משפט גרין</strong>. בואו ננסח אותו באופן מסודר. נתחיל דווקא מהפונקציה ה"קדומה": ניקח {% equation %}F\left(x,y\right)=\left(P\left(x,y\right),Q\left(x,y\right)\right){% endequation %} כלשהי ועקומה סגורה {% equation %}C{% endequation %}, ויהא {% equation %}R{% endequation %} התחום ש-{% equation %}C{% endequation %} חוסמת, ונניח שהפרמטריזציה של {% equation %}C{% endequation %} היא "נגד כיוון השעון" ועוד כל מני הנחות שבטח פספסתי (אל תשתמשו במשפט הזה בלי לוודא את כל ההנחות שלו!) אז מתקיים הדבר הבא:

{% equation %}\iint_{R}\left(\frac{\partial Q}{\partial x}-\frac{\partial P}{\partial y}\right)dxdy=\oint_{C}Pdx+Qdy{% endequation %}

אם כן, מה שצץ באגף שמאל הוא <strong>לא</strong> הנגזרת של {% equation %}F{% endequation %} כמו במשפט היסודי של החדו"א, אלא משהו קצת יותר מוזר - פונקציה שמתקבלת מלקיחת הרכיבים של {% equation %}F{% endequation %}, גזירה שלהם לפי המשתנה "הלא נכון" לכאורה (כלומר, רכיב ה-{% equation %}x{% endequation %} של {% equation %}F{% endequation %} נגזר לפי {% equation %}y{% endequation %} ולהפך) ועוד יש לנו סכום וסימן מינוס שצצים מאי שם. לא יודע מה איתכם, אבל בי זה מעורר אוטומטית סקרנות להבין מה החוקיות הכללית שיש כאן. אני לא מאמין גדול בלהסתיר דברים, אז הנה החוקיות הכללית, שכרגע כנראה אין לנו דרך להבין: משפט הסטוקס הכללי. הוא אומר שאם {% equation %}M{% endequation %} היא יריעה שמקיימת כך-וכך ו-{% equation %}\omega{% endequation %} היא תבנית דיפרנציאלית שמקיימת כך וכך, אז {% equation %}\int_{M}d\omega=\int_{\partial M}\omega{% endequation %}, ובמילים - האינטגרל על {% equation %}M{% endequation %} של <strong>הנגזרת החיצונית</strong> של התבנית {% equation %}\omega{% endequation %} שווה לאינטגרל של {% equation %}\omega{% endequation %} על השפה של {% equation %}M{% endequation %}. יש כאן שלל מושגים שאין לנו הגדרה עבורם כרגע (ובצדק; ההגדרות, שנראה בהמשך, הן לא קלות לעיכול), אבל אפשר להתאים את הנוסחה הכללית למשפט שראינו. ה"יריעה" {% equation %}M{% endequation %} אצלנו היא בסך הכל הקבוצה {% equation %}R{% endequation %} במישור. ה"תבנית הדיפרנציאלית" {% equation %}\omega{% endequation %} היא ה-{% equation %}Pdx+Qdy{% endequation %} הזה (בהמשך ניתן משמעות פורמלית ל-{% equation %}dx,dy{% endequation %} הללו סוף כל סוף!). אני יכול גם לגלות ש-{% equation %}Pdx+Qdy{% endequation %} זה משהו שנקרא 1-תבנית (יש גם 0-תבנית, 2-תבנית וכן הלאה) ושמשפט סטוקס תובע שהמימד של {% equation %}M{% endequation %} יהיה גדול ב-1 מהמספר של התבנית (אצלנו {% equation %}M{% endequation %} היא ממימד 2, כמובן). לבסוף, באיזו שהיא דרך, ה-{% equation %}\frac{\partial Q}{\partial x}-\frac{\partial P}{\partial y}{% endequation %} היא התבנית שמתקבלת בתור נגזרת חיצונית של {% equation %}Pdx+Qdy{% endequation %}. אני לא אתעמק במשפט סטוקס יותר מכך כרגע; בהמשך נראה את ההכללה של אינטגרל קווי - <strong>אינטגרל משטחי</strong> - וזה יאפשר לנו להציג עוד שני משפטים הדומים למשפט גרין - <strong>משפט גאוס ומשפט סטוקס הקלאסי</strong>, שגם הם מקרים פרטיים של משפט סטוקס, ואז הרעיון הכללי יהיה טיפה יותר ברור (ולכן גם תהיה יותר מוטיבציה להילחם עם ההגדרות של יריעות ושל תבניות דיפרנציאליות).

אז ראינו את משפט גרין שהיה מעין הכללה של המשפט היסודי של החדו"א, אבל עבור אינטגרלים כפולים בכלל; האינטגרל הקווי מילא כאן את התפקיד של "נקודות הקצה" במשפט היסודי הרגיל של החדו"א. השאלה היא אם קיים גם משהו הפוך - משפט יסודי שבו אפשר לצמצם את חישוב האינטגרל הקווי להסתכלות על נקודות הקצה. כלומר, בהינתן עקומה {% equation %}\gamma{% endequation %} על {% equation %}\left[a,b\right]{% endequation %} ושדה וקטורי {% equation %}F{% endequation %}, האם קיימת איזו שהיא פונקציה "קדומה" {% equation %}\Phi{% endequation %} כך ש-

{% equation %}\int_{a}^{b}F\cdot d\gamma=\Phi\left(b\right)-\Phi\left(a\right){% endequation %}?

התשובה היא שזה אפשרי <strong>לפעמים</strong>. צריך ש-{% equation %}F{% endequation %} יקיים תכונה נחמדה כלשהי; שהוא יהיה <strong>שדה משמר</strong>. צריך להבין מה זה אומר שהמשוואה לעיל מתקיימת - זה אומר שהאינטגרל הקווי בין הנקודות {% equation %}\gamma\left(a\right){% endequation %} ו-{% equation %}\gamma\left(b\right){% endequation %} <strong>לא תלוי בעקום</strong> אלא רק בנקודות הקצה שלו. שימו לב - זה לא כמו קודם, כאשר לקחנו פרמטריזציות שונות <strong>לאותו עקום</strong>; כאן אנחנו מדברים על <strong>אותן נקודות קצה</strong> אבל על עקומים שיכולים להיות שונים לגמרי. אפשר קו ישר בין הנקודות; ואפשר קו מתפתל ומזגזג והולך אחורה וקדימה ושוב אחורה וחותך את עצמו ומשתגע ועושה ספירלות וסלטות באוויר וכל מה שתרצו - ועדיין, צריך לצאת שערך האינגטרל הקווי יהיה זהה כמו במקרה של קו ישר (והנה אפיון אלטרנטיבי: האינטגרל של {% equation %}F{% endequation %} על כל מסלול סגור צריך להיות 0; הסיבה לכך היא שאפשר לבחור שתי נקודות על המסלול הסגור ולפרק אותו לאיחוד של שתי עקומות שהולכות "לשם ובחזרה"). לכן זו שאלה טובה ואפילו מצויינת באילו תנאים על {% equation %}F{% endequation %} הקסם הזה יתרחש. והתשובה היא פשוטה להפתיע: צריך ש-{% equation %}F{% endequation %} יהיה <strong>גרדיאנט</strong> של שדה סקלרי. כלומר, שתהיה פונקציה סקלרית {% equation %}f:\mathbb{R}^{2}\to\mathbb{R}{% endequation %} כך ש-{% equation %}F=\nabla f{% endequation %}, דהיינו ש-{% equation %}F=\left(\frac{\partial f}{\partial x},\frac{\partial f}{\partial y}\right){% endequation %}. עם הסימונים הללו נקבל את הנוסחה

{% equation %}\int_{a}^{b}\nabla f\cdot d\gamma=f\left(b\right)-f\left(a\right){% endequation %}

והנוסחה הזו <strong>ממש</strong> אנלוגית למשפט היסודי הרגיל של החדו"א - הרי {% equation %}\nabla f{% endequation %} במקרה החד ממדי זו בדיוק {% equation %}f^{\prime}{% endequation %}. היא גם נותנת לנו עוד הצצה אל משפט סטוקס הכללי - כאן {% equation %}f{% endequation %} היא התבנית הדיפרנציאלית ו-{% equation %}\nabla f{% endequation %} היא הנגזרת החיצונית שלה (אז כבר קיבלנו שתי דוגמאות לנגזרות חיצוניות של תבניות דיפרנציאליות, בלי שנדע מה זה בכלל). הטרמינולוגיה שבה משתמשים בהקשר של תבניות היא לומר שתבנית היא <strong>מדויקת</strong> אם היא הנגזרת החיצונית של תבנית אחרת, ולכן אפשר לנסח את המשפט הקודם בכך שאם השדה הוקטורי הוא תבנית מדויקת, אז הוריאנט של המשפט היסודי מתקיים עבורו.

בכך הגענו לסוף הדיון הנוכחי על אינטגרלים קוויים, אבל כפי שאנחנו כבר רואים - אינטגרלים קווים הם רק ההתחלה; כרטיס הכניסה שלנו לעולם חדש, מופלא, של חדו"א. ויהי ערב ויהיה בוקר וירא אלי קרטן כי טוב ויברא את התבנית הדיפרנציאלית.
