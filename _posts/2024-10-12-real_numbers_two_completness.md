---
title: "אז מה זה בעצם המספרים הממשיים? (חלק ג': על שתי שלמויות)"
layout: post
categories:
  - אנליזה מתמטית
tags:
  - מספרים ממשיים
---


<h2>מבוא</h2>

היה זה הטוב בזמנים, היה זה הרע בזמנים. ספציפית, השנה הייתה 1872, והמתמטיקה הייתה בשיאו של תהליך של בניית עצמה מחדש אחרי שהגאומטריה ההיפרבולית שמטה את הבסיס שעליו היא ניצבה במשך אלפי שנים. אני לא אכנס לסיפור הזה כאן (והוא מסופר היטב ב"משפטי גדל ובעיית היסודות של המתמטיקה" של ארנון אברון, למשל) אבל השורה התחתונה שלו הייתה שמאמץ כביר של שלל מתמטיקאים במאה ה-19 הוביל ליצירת החשבון הדיפרנציאלי והאינטגרלי בגרסה המודרנית שלו שבה אנחנו משתמשים גם היום, מה שנתן למתמטיקה בסיס יציב (וחייבים להשחיל פנימה את המילה האהובה "ריגורוזי") ואז הגיע גאורג קנטור והעמיד את הבסיס היציב הזה על הבסיס היציב עוד יותר של תורת הקבוצות. אז אם הכל כל כך טוב, מה היה רע? שמעבר לאופק כבר הציצו הפרדוקסים שיתגלו בתורת הקבוצות הנאיבית ובפרט הפרדוקס של ראסל, ויגרמו לכך שהמתמטיקה תצטרך לבנות את עצמה מחדש פעם נוספת בתחילת המאה ה-20 והבניה הזו תסתיים בצורה שלא לגמרי עונה על השאיפות המלאות של העוסקים בה.

אבל זה כאמור סיפור לפעם אחרת. כרגע אנחנו בשנת 1872 (שנה לפני שקנטור יתחיל לפרסם מאמרים על תורת הקבוצות) ובשנה הזו מתפרסמים שני מאמרים, אחד של ריכארד דדקינד ("Stetigkeit und irrationale Zahlen", "רציפות ומספרים אי רציונליים") והשני של גאורג קנטור ("Ueber die Ausdehnung eines Satzes aus der Theorie der trigonometrischen Reihen ", "על הכללה של משפט מהתורה של טורים טריגונומטריים"), ובמאמרים הללו מופיעות בניות פורמליות של המספרים הממשיים שהן כל כך מוצלחות שעד היום הן הבניות המפורסמות ביותר (יש עוד, אבל זה באמת כבר יחכה לפעם אחרת). בשני המקרים, הבניות מופיעות לא כי התחשק למחברים שלהם להמציא את המתמטיקה מחדש, אלא כי הם גילו שהמתמטיקה הקיימת פשוט לא מספיק פורמלית בשביל שהם יצליחו להוכיח טענות פשוטות יחסית בצורה משביעת רצון; היה צורך בהגדרות פורמליות של הממשיים כדי שאפשר יהיה להוכיח פורמלית דברים שהיו סטנדרטיים בחשבון הדיפרנציאלי והאינטגרלי של זמנם. זה גם לא ממש מקרי ששתי ההגדרות צצו באותה בשנה - קנטור ודדקינד היו מיודדים והתכתבו, ודדקינד ספציפית קיבל מוטיבציה לפרסם את הרעיונות שלו (שהיו לו כבר שנים קודם לכן) אחרי שראה את המאמר של קנטור. אבל למרות סמיכות הזמנים והקשר בין המחברים, שתי הבניות הן שונות למדי באופיין והמוטיבציה שלהן שונה, מה שהופך את שתיהן למעניינות (ואת שתיהן לניתנות להכללה בדרכים שונות גם לדברים שאינם הממשיים), כך שלדעתי שווה לדבר על שתיהן.

דבר אחד שאני לא הולך לעשות בפוסט הוא להציג את הבניות בצורה <strong>פורמלית</strong>, להוכיח שהן עובדות כמו שצריך וכדומה; את זה אשאיר לפוסט הבא. מה שמעניין אותי כרגע הוא הרעיון הכללי של הבניות, אילו בעיות הן מנסות לפתור ולאילו תוצאות תיאורטיות הן מתקשרות. אז למרות שהפוסט הזה בהחלט ייכנס לפרטים טכניים, הם לא יהיו של הבניות עצמן אלא של ה"מסביב". ספציפית, אנחנו נראה שכל אחת מהבניות באה ללכוד את מושג ה"שלמות" של {% equation %}\mathbb{R}{% endequation %} והן עושות את זה בצורה די שונה - אפילו שונה <strong>מהותית</strong>, כמו שנראה בסוף.

לפני שאני נכנס לעובי הקורה, הנה בגדול שתי הבניות:

<ul> <li><strong>דדקינד</strong> מגדיר <strong>חתך</strong> בתור פירוק של {% equation %}\mathbb{Q}{% endequation %} לשתי קבוצות {% equation %}A_{1},A_{2}{% endequation %} כך שכל איבר של {% equation %}A_{1}{% endequation %} קטן מכל איבר של {% equation %}A_{2}{% endequation %}. עכשיו דדקינד מגדיר את המספרים הממשיים בתור אוסף כל החתכים, כשהרעיון הוא שהמספר שחתך מייצג הוא המספר שנמצא "באמצע" בין {% equation %}A_{1}{% endequation %} ו-{% equation %}A_{2}{% endequation %}.</li>


<li><strong>קנטור</strong> מסתכל על <strong>סדרות קושי</strong> של מספרים רציונליים ומגדיר את המספרים הממשיים בתור אוסף כל סדרות הקושי הללו כשהוא מזהה שתי סדרות קושי ש"שואפות אחת לשניה" בתור אותו מספר. הרעיון הוא שהמספר הממשי שסדרת קושי מייצגת הוא המספר שהסדרה "שואפת" אליו.</li>

</ul>

ההגדרה של דדקינד אמורה להיות ברורה יחסית אפילו ברמה הפורמלית כבר בשלב הזה למי שעקבו אחרי סדרת הפוסטים הזו, כי ראינו בפוסט הקודם את המושג של "קטן מ-". לעומת זאת ההגדרה של קנטור משתמשת במושגים שהם אמנם בסיסיים למדי בחשבון דיפרנציאלי ואינטגרלי אבל לא דיברתי עליהם בסדרת הפוסטים הזו בכלל - סדרות קושי ו"שאיפה". אלו הדברים הראשונים שארצה להבהיר בפוסט הזה ולא אניח שאנחנו כבר מכירים אותם ממקום אחר. יותר מכך - יש חשיבות בהצגה שלהם מאפס מהטעם הפשוט שבדרך כלל רואים אותם בחדו"א שעושים במסגרת {% equation %}\mathbb{R}{% endequation %} - כלומר, הלימודים מתחילים קודם כל עם זה ש-{% equation %}\mathbb{R}{% endequation %} קיים ואז הצגת מושגים כמו שאיפה וסדרות קושי באמצעותו. הפעם אני לא אעשה את זה בכלל. אז יאללה, לעבודה.

<h2>הגדרת הגבול</h2>

השינוי הגדול שעבר החדו"א במאה ה-19 היה ויתור על גישה לא פורמלית ואינטואיטיבית (שהובילה בסך הכל לתורה שעובדת מצויין אבל יש לה גם פינות אפלות שגויות) לטובת פורמליות שכמותה לא נראתה עד אז במתמטיקה. זה אמר להפסיק להסתמך על האינטואיציה הגאומטרית לגבי מהי "רציפות" ולנסות להגדיר אותה במפורש, וזה אמר גם להפסיק להשתמש באינפיניטסימלים ולהשתמש במושג בסיסי אחר, מדויק יותר, שנקרא <strong>גבול</strong>. זה לא מושג פשוט או קל לעיכול (ואחת הסיבות שחדו"א הוא תחום ידוע לשמצה בקושי שלו למי שמתחילים ללמוד מתמטיקה היא בדיוק ההסתמכות שלו על מושג לא קל שכזה), אבל ההגדרה שלו חזקה להפתיע. <a href="https://gadial.net/2010/10/03/limit_of_sequence/">יש לי פוסט</a> על גבולות, אז כאן אני ארשה לעצמי לפרט פחות.

בשביל להגדיר גבול צריך קודם כל להגדיר <strong>מרחק</strong>, וזה למרבה השמחה משהו שקל לנו להגדיר על {% equation %}\mathbb{Q}{% endequation %} בזכות פונקציית <strong>הערך המוחלט</strong> שראינו בפוסט הקודם שאפשר להגדיר ישירות מתוך <strong>הסדר</strong> שיש על {% equation %}\mathbb{Q}{% endequation %}. אפשר לחשוב על {% equation %}\left|q\right|{% endequation %} בתור "המרחק של {% equation %}q{% endequation %} מ-0" ואז להכליל את זה ולומר שהמרחק של {% equation %}a{% endequation %} מ-{% equation %}b{% endequation %} הוא {% equation %}d\left(a,b\right)=\left|a-b\right|{% endequation %}. עכשיו, בואו נראה אילו תכונות של פונקציית המרחק {% equation %}d{% endequation %} אפשר להסיק מתוך התכונות של הערך המוחלט. בפוסט הקודם ראינו ש:

<ul> <li>אם {% equation %}x\ne0{% endequation %} אז {% equation %}\left|x\right|\ne0{% endequation %} ו-{% equation %}\left|0\right|=0{% endequation %}.</li>


<li>{% equation %}\left|xy\right|=\left|x\right|\cdot\left|y\right|{% endequation %} ו-{% equation %}\left|-1\right|=1{% endequation %}</li>


<li>{% equation %}\left|x+y\right|\le\left|x\right|+\left|y\right|{% endequation %}</li>

</ul>

את שלוש התכונות הללו אפשר לתרגם לשלוש תכונות של פונקציית המרחק, {% equation %}d{% endequation %}:

<ul> <li>{% equation %}d\left(a,b\right)=0{% endequation %} אם ורק אם {% equation %}a=b{% endequation %}.</li>


<li>{% equation %}d\left(a,b\right)=d\left(b,a\right){% endequation %} לכל {% equation %}a,b{% endequation %}.</li>


<li>{% equation %}d\left(a,c\right)\le d\left(a,b\right)+d\left(b,c\right){% endequation %} לכל {% equation %}a,b,c{% endequation %}.</li>

</ul>

בואו נוכיח את זה: 

<ul> <li>{% equation %}d\left(a,b\right)=0{% endequation %} אם ורק אם {% equation %}\left|a-b\right|=0{% endequation %} כלומר אם ורק אם {% equation %}a-b=0{% endequation %} כלומר אם ורק אם {% equation %}a=b{% endequation %}.</li>


<li>{% equation %}d\left(a,b\right)=\left|a-b\right|=\left|\left(-1\right)\left(b-a\right)\right|=\left|-1\right|\left|b-a\right|=d\left(b,a\right){% endequation %}</li>


<li>{% equation %}d\left(a,c\right)=\left|a-c\right|=\left|\left(a-b\right)+\left(b-c\right)\right|\le\left|a-b\right|+\left|b-c\right|=d\left(a,b\right)+d\left(b,c\right){% endequation %}</li>

</ul>

עכשיו שיש לנו פונקציית מרחק, אפשר לנסח את מושג הגבול באמצעותה. בדרך כלל כשמלמדים חדו"א לא טורחים לעשות את זה ופשוט עובדים ישירות עם ערך מוחלט, אבל יש יתרון גם בגישה הכללית יותר - מה שאנחנו מנסחים בלשון של פונקציית המרחק תקף בכל <strong>מרחב מטרי</strong> שהוא בסך הכל קבוצה שמוגדרת עליה פונקציית מרחק שכזו. גם פונקציית מרחק מוזרות על {% equation %}\mathbb{Q}{% endequation %} כמו זו שבה {% equation %}d\left(a,b\right){% endequation %} הוא {% equation %}\frac{1}{2^{n}}{% endequation %} כש-{% equation %}2^{n}{% endequation %} היא החזקה הגדולה ביותר של 2 שמחלקת את {% equation %}a-b{% endequation %} (אלא אם {% equation %}a=b{% endequation %} ואז {% equation %}d\left(a,b\right)=0{% endequation %}). המטריקה המוזרה הזו נקראת "המטריקה ה-2-אדית" והיא מרתקת בפני עצמה אבל אני לא ארחיב עליה יותר מדי כאן (<a href="https://gadial.net/2010/01/12/padic_numbers_analytic_constructions/">יש לי פוסט</a> על זה).

אפשר להגדיר גבול על שני אובייקטים: סדרות, ופונקציות. על סדרה {% equation %}a_{0},a_{1},a_{2},\ldots{% endequation %} אפשר לחשוב בעצם בתור פונקציה {% equation %}g:\mathbb{N}\to\mathbb{Q}{% endequation %} כך ש-{% equation %}g\left(i\right)=a_{i}{% endequation %}, אז המרחק בין זה ובין גבולות של פונקציות {% equation %}f:\mathbb{Q}\to\mathbb{Q}{% endequation %} הוא באמת לא כזה גדול, אבל אני עדיין אתחיל עם ניסוח ספציפי עבור סדרות כי הוא פשוט יותר.

<ul> <li>בהינתן סדרה {% equation %}\left\{ a_{n}\right\} _{n=0}^{\infty}{% endequation %} אני אומר שהיא <strong>שואפת</strong> אל {% equation %}L{% endequation %} ומסמן את זה {% equation %}\lim_{n\to\infty}a_{n}=L{% endequation %} או {% equation %}a_{n}\to L{% endequation %} אם לכל {% equation %}\varepsilon>0{% endequation %} קיים {% equation %}N{% endequation %} טבעי כך שלכל {% equation %}n>N{% endequation %} מתקיים {% equation %}d\left(a_{n},L\right)<\varepsilon{% endequation %}.</li>

</ul>

במילים: לכל <strong>רמת קרבה</strong> גדולה מאפס, קיים מקום בסדרה שהחל ממנו <strong>כל</strong> אברי הסדרה נמצאים ברמת הקרבה הזו אל {% equation %}L{% endequation %}. בלי שום יוצאים מן הכלל. בלי שהסדרה פתאום "תקפוץ" למקום אחר ואז תחזור. החל משלב מסויים בסדרה, זהו, נגמר - הסדרה קרובה כולה עד כדי {% equation %}\varepsilon{% endequation %} אל {% equation %}L{% endequation %}, וזה נכון <strong>לכל</strong> {% equation %}\varepsilon{% endequation %} חיובי, לא משנה כמה קטן. הדבר היחיד שאני לא דורש בשום צורה הוא שהסדרה <strong>תגיע</strong> אל {% equation %}L{% endequation %}. אפילו לא איבר אחד שלה צריך להיות שווה אל {% equation %}L{% endequation %}.

ההגדרה עבור פונקציה קצת יותר מסובכת, כי בניגוד לטבעיים שהם דיסקרטיים, הרציונליים הם צפופים ולכן לכל נקודה אפשר "להתקרב" עם סדרה של רציונליים, כך שאם יש לי פונקציה שמוגדרת על כל הרציונליים ואני רוצה להגיד שהיא שואפת למשהו, עולה השאלה <strong>איפה</strong> היא שואפת אל המשהו הזה - לאילו ערך <strong>הקלטים</strong> שלה צריכים להתקרב כדי שאפשר יהיה להגיד <strong>שהפלטים</strong> שלה מתקרבים אל משהו. אז הנה הפורמליזם:

<ul> <li>בהינתן פונקציה {% equation %}f:\mathbb{Q}\to\mathbb{Q}{% endequation %} אני אומר שהיא <strong>שואפת</strong> אל {% equation %}L{% endequation %} בנקודה {% equation %}x_{0}{% endequation %} ומסמן את זה {% equation %}\lim_{x\to x_{0}}f\left(x\right)=L{% endequation %} או {% equation %}f\left(x\right)\underset{x\to x_{0}}{\to}L{% endequation %} אם לכל {% equation %}\varepsilon>0{% endequation %} קיים {% equation %}\delta>0{% endequation %} כך שלכל {% equation %}x{% endequation %} עבורו {% equation %}0<d\left(x,x_{0}\right)<\delta{% endequation %} מתקיים {% equation %}d\left(f\left(x\right),L\right)<\varepsilon{% endequation %}</li>

</ul>

ההבדל הבולט בין ההגדרות הוא שבהגדרה עבור סדרות לא היה {% equation %}\delta{% endequation %} אלא היה {% equation %}N{% endequation %} והסתכלנו על כל ה"קלטים" {% equation %}n{% endequation %} שגדולים מ-{% equation %}N{% endequation %}, ואילו כאן אנחנו מסתכלים על כל ה-{% equation %}x{% endequation %}-ים שקרובים אל {% equation %}x_{0}{% endequation %} עד כדי {% equation %}\delta{% endequation %}. כאמור, יש דרך לאגד את שתי ההגדרות הללו ביחד אבל נעזוב את זה.

עוד נקודה שכדאי לשים לב אליה היא {% equation %}0<d\left(x,x_{0}\right){% endequation %}. אי השוויון הזה אומר שאני <strong>לא</strong> מניח ש-{% equation %}x_{0}{% endequation %} עצמה הפונקציה קרובה ל-{% equation %}L{% endequation %}. הפונקציה אפילו לא חייבת להיות מוגדרת ב-{% equation %}L{% endequation %}. אם <strong>כן</strong> הייתי דורש שהקרבה ל-{% equation %}L{% endequation %} תתקיים גם ב-{% equation %}x_{0}{% endequation %}, זו הייתה דרישה חזקה יותר מ-{% equation %}f{% endequation %}, וזו דרישה חשובה כל כך שיש לה שם מיוחד: אומרים ש-{% equation %}f{% endequation %} <strong>רציפה</strong> ב-{% equation %}x_{0}{% endequation %} אם הדרישה הזו מתקיימת - מה ששקול לטענה ש-{% equation %}\lim_{x\to x_{0}}f\left(x\right)=f\left(x_{0}\right){% endequation %}.

<h2>סדרות מונוטוניות מתכנסות</h2>

עכשיו, כשיש לנו את מושג הגבול אפשר להתחיל לראות את מה שהיה חסר לדדקינד וקנטור והוביל אותם להגדרה פורמלית של הממשיים, {% equation %}\mathbb{R}{% endequation %}, כשכאן "הממשיים" פירושם "הקבוצה שבה מתרחשת החדו"א" ולכן כל המשפטים שאתאר יעסקו בה. דדקינד מדבר על במפורש במאמר שלו על מה שהפריע לו. הוא מתאר איך ב-1858, כשלימד קורס חדו"א, התעורר בו תסכול מחוסר הפורמליות של ההוכחות הבסיסיות. הפריע לו שבסופו של דבר, ההוכחות הללו פונות לטיעונים גאומטריים או לכל הפחות "בהשראה" גאומטרית, ומשתמשים בצורה עמומה במושג ה"רציפות" של המספרים הממשיים. לא חייתי בזמנו של דדקינד ואני לא יודע איך נראתה הוראת המתמטיקה אז, אבל אני יכול להבין אותו; הייתה לי תחושה דומה בשעתו עם ההוכחה ש-{% equation %}\lim_{x\to0}\frac{\sin x}{x}=1{% endequation %}. על הטענה הזו נבנה כל החדו"א של פונקציות טריגונומטריות, אבל רוב ספרי החדו"א שמוכיחים אותה קופצים על שלב או שניים, ולרוב יש להם איזה "קל לראות" גאומטרי לגמרי באופיו. זה לא מפריע בדרך כלל (והמשפט כמובן נכון ויש לו הוכחות פורמליות עד הסוף <a href="https://gadial.net/2008/01/20/lim_sin_x_over_x/">וכבר דיברתי על זה</a> בבלוג), אבל מה שלא מפריע לך בתור סטודנט בהחלט יכול להתחיל להציק כשאתה בא ללמד את הנושא (או לכתוב עליו פוסט בבלוג...) ומגלה שיש איזה <strong>משהו</strong> שם שלא לגמרי עובד עד הסוף.

לדעתי (ושוב, לא הייתי בסביבה בזמנו של דדקינד) חוסר הפורמליות הזה לא בהכרח היה האופי הכללי של לימודי החדו"א; אני בטוח שרוב ההוכחות היו פורמליות וסבבה. הסיבה לכך היא שמרגע שמוכיחים טענה <strong>ספציפית</strong> שדורשת הסתמכות על ההגדרה הפורמלית של המספרים הממשיים, אפשר להוכיח טענות אחרות בעזרתה, בצורה פורמלית מלאה, כך שהמחסור בפורמליות מתבטא רק בהוכחה אחת ספציפית (בדיוק כמו עם ה-{% equation %}\lim_{x\to0}\frac{\sin x}{x}=1{% endequation %}) שלי. דדקינד מביא כדוגמא משפט אחד ספציפי, שהוא אכן "קרש קפיצה" כזה שממנו אפשר להוכיח את יתר הדברים:

<ul> <li>כל סדרה מונוטונית עולה וחסומה מלעיל היא מתכנסת.</li>

</ul>

צריך להסביר את המונחים הללו. סדרה היא <strong>מתכנסת</strong> אם היא שואפת לגבול כלשהו (גבול סופי, לא אינסוף, אבל לא הגדרתי פה שאיפה לאינסוף בכל מקרה). סדרה היא <strong>מונוטונית עולה</strong> אם {% equation %}a_{n}\le a_{n+1}{% endequation %} לכל {% equation %}n{% endequation %}, כלומר האיברים שלה יכולים רק לגדול, לא לקטון. וסדרה היא <strong>חסומה מלעיל</strong> אם קיים {% equation %}M{% endequation %} כך ש-{% equation %}a_{n}\le M{% endequation %} לכל {% equation %}n{% endequation %} (על זה דיברתי בפוסט הקודם). זו אולי נראית כמו טענה פשוטה ותמימה יחסית, אבל למעשה היא הרבה יותר ערמומית מזה - זו סדרה שמבטיחה <strong>קיום</strong> של מספר מסוים - מספר שמהווה גבול של הסדרה - והמספר הזה יכול להיות אי-רציונלי. כל אי רציונלי. כי בואו נראה דוגמא עבור {% equation %}\sqrt{2}=1.4142\ldots{% endequation %}:

{% equation %}1,1.4,1.41,1.414,1.4142,\ldots{% endequation %}

מה עשיתי פה? כתבתי סדרת מספרים שנבנית מהפיתוח העשרוני של {% equation %}\sqrt{2}{% endequation %}, כשבכל פעם אני מוסיף איבר נוסף אחרי הנקודה העשרונית ולכן מגדיל את המספר שבניתי ולכן זו סדרה מונוטונית עולה. היא בוודאי חסומה, למשל על ידי 2, ולכן על פי הטענה של דדקינד היא מתכנסת - ומן הסתם אנחנו מבינים שהגבול שלה יהיה חייב להיות {% equation %}\sqrt{2}{% endequation %}. כלומר הטענה הזו מבטיחה את קיום {% equation %}\sqrt{2}{% endequation %}, ואת קיום {% equation %}\pi{% endequation %} וכל מספר ממשי אחר שנרצה ואנחנו יודעים איך לתאר בעצם, וכמובן שהטענה הזו לא נכונה ב-{% equation %}\mathbb{Q}{% endequation %}. אבל איך מוכיחים אותה פורמלית עבור {% equation %}\mathbb{R}{% endequation %}?

טרם בניתי את {% equation %}\mathbb{R}{% endequation %} פורמלית, אבל בשביל להוכיח משפטים במסגרת {% equation %}\mathbb{R}{% endequation %} אני לא צריך לבנות אותו פורמלית, למעשה; אני אוכיח משפטים עבור <strong>השדה הסדור השלם</strong>, שזה מושג שהצגתי בפוסט הקודם, ולכן בהמשך כשאתן בניה פורמלית ל-{% equation %}\mathbb{R}{% endequation %} שאכן תניב שדה סדור שלם, ההוכחה שלי תעבוד עליה אוטומטית. אז למרות שזה לא מה שדדקינד עשה, בואו נראה איך מוכיחים את המשפט הזה עם האקסיומות של שדה סדור שלם, ומה עוד אני יכול להוכיח כשזו נקודת המוצא שלי.

למרבה השמחה ההוכחה קלה למדי. נסתכל על הקבוצה {% equation %}A=\left\{ a_{n}\ |\ n\in\mathbb{N}\right\} {% endequation %} של אברי הסדרה. זו בוודאי קבוצה לא ריקה (אפילו אם הסדרה קבועה, עדיין יהיה ב-{% equation %}A{% endequation %} איבר אחד לפחות) ועל פי ההנחה שהסדרה חסומה מלעיל, {% equation %}A{% endequation %} חסומה מלעיל. לכן <strong>על פי אקסיומת השלמות</strong>, יש {% equation %}L=\sup A{% endequation %}. מה שאני ארצה להוכיח הוא ש-{% equation %}a_{n}\to L{% endequation %} הזה.

יהא {% equation %}\varepsilon>0{% endequation %} כלשהו. מכיוון ש-{% equation %}L=\sup A{% endequation %}, קיים {% equation %}N{% endequation %} כך ש-{% equation %}d\left(a_{N},L\right)<\varepsilon{% endequation %}. זה דורש הסבר; אם לא היה אף איבר שקרוב ל-{% equation %}L{% endequation %} עד כדי {% equation %}\varepsilon{% endequation %}, היה נובע מכך ש-{% equation %}L^{\prime}=L-\varepsilon{% endequation %} הוא בעצמו חסם מלעיל של {% equation %}A{% endequation %}, בסתירה לכך ש-{% equation %}L{% endequation %} הוא החסם העליון שלה. {% equation %}L^{\prime}{% endequation %} היה חסם מלעיל כזה כי בואו ניקח {% equation %}a\in A{% endequation %} כלשהו. אני יודע ש-{% equation %}d\left(a,L\right)\ge\varepsilon{% endequation %}, כלומר {% equation %}\left|a-L\right|\ge\varepsilon{% endequation %}. אני גם יודע ש-{% equation %}a\le L{% endequation %} (כי {% equation %}L{% endequation %} הוא חסם מלעיל של {% equation %}A{% endequation %}) כלומר {% equation %}\left|a-L\right|=L-a{% endequation %}. קיבלתי ש-{% equation %}L-a\ge\varepsilon{% endequation %}, כלומר {% equation %}a\le L-\varepsilon=L^{\prime}{% endequation %} וזה <strong>לכל</strong> {% equation %}a\in A{% endequation %}.

אם כן, קיים {% equation %}N{% endequation %} כך ש-{% equation %}d\left(a_{N},L\right)<\varepsilon{% endequation %}. עכשיו בואו נסתכל על {% equation %}n>N{% endequation %} כלשהו: מצד אחד, {% equation %}a_{N}\le a_{n}{% endequation %} (כי הסדרה מונוטונית עולה) ומצד שני {% equation %}a_{n}\le L{% endequation %} (כי {% equation %}L{% endequation %} הוא חסם מלעיל) ולכן

{% equation %}d\left(a_{n},L\right)=L-a_{n}\le L-a_{N}<\varepsilon{% endequation %} (כאן אני משתמש בתכונות שכבר ראינו של ערך מוחלט ואי שוויונים).

זה מסיים את ההוכחה ומראה לנו את השימושיות הרבה של אקסיומת השלמות ואת חוסר השימושיות הבולט של הסימון {% equation %}d\left(a,b\right){% endequation %} שלי במקום להשתמש פשוט בערך מוחלט - ההוכחה שלי מסתמכת חזק מאוד על תכונות של ערך מוחלט, ולדבר על מטריקה כללית לא עוזר לי פה בכלל. המשפט מנוסח מלכתחילה על קבוצה סדורה ולא לגמרי ברור מה המשמעות שלו בסיטואציות כלליות יותר - אפילו במשהו כמו {% equation %}\mathbb{R}^{2}{% endequation %} עם פונקציית המרחק הסטנדרטית {% equation %}d\left(\left(x_{1},y_{1}\right),\left(x_{2},y_{2}\right)\right)=\sqrt{\left(x_{1}-x_{2}\right)^{2}+\left(y_{1}-y_{2}\right)^{2}}{% endequation %}.

לכאורה המשפט סובל מחוסר סימטריה מוזר - הוא מדבר על סדרה מונוטונית עולה וחסומה מלעיל. אבל מה עם סדרות מונוטוניות יורדות וחסומות מלרע? להן לא מגיע להתכנס? ובכן, אם {% equation %}\left\{ a_{n}\right\} _{n=0}^{\infty}{% endequation %} סדרה מונוטונית יורדת ({% equation %}a_{n}\ge a_{n+1}{% endequation %}) וחסומה מלרע (קיים {% equation %}M{% endequation %} כך ש-{% equation %}a_{n}\ge M{% endequation %} לכל {% equation %}n{% endequation %}) אז הסדרה {% equation %}\left\{ b_{n}\right\} _{n=0}^{\infty}{% endequation %} שמוגדרת על ידי {% equation %}b_{n}=-a_{n}{% endequation %} היא מונוטונית עולה (כי {% equation %}-a_{n}\le-a_{n+1}{% endequation %}) וחסומה מלעיל (כי {% equation %}-M{% endequation %} מקיים {% equation %}-a_{n}\le-M{% endequation %} לכל {% equation %}n{% endequation %}) ולכן היא מתכנסת לגבול {% equation %}L{% endequation %} וזה עכשיו עניין של משחק קליל עם ההגדרה כדי להראות ש-{% equation %}a_{n}{% endequation %} מתכנסת אל {% equation %}-L{% endequation %}.

<h2>בולצאנו-ויירשטראס</h2>

סיימנו עם המשפט על הסדרות המונוטוניות. העניין הוא שהמשפט הזה הוא מעין הקדמה למשפט מרכזי מאין כמוהו - <strong>משפט בולצאנו-ויירשטראס</strong>, שהוא כנראה המשפט שמבטא בצורה הכי ברורה את תחושת ה"רציפות" של {% equation %}\mathbb{R}{% endequation %} בכל הנוגע לסדרות:

<ul> <li>(בולצאנו-ויירשטראס): לכל סדרה חסומה קיימת תת-סדרה מתכנסת.</li>

</ul>

גם פה צריך לתת הסבר: "תת-סדרה" היא פשוט סדרה אינסופית שמתקבלת מסדרה קיימת על ידי בחירה של חלק מהאיברים שלה, על פי הסדר שלהם בתוך הסדרה המקורית. פורמלית (וזה כואב לכתוב את זה פורמלית) אם יש לנו סדרה {% equation %}\left\{ a_{n}\right\} _{n=0}^{\infty}{% endequation %} אז תת-סדרה שלה היא סדרה {% equation %}\left\{ b_{k}\right\} _{k=0}^{\infty}{% endequation %} כך ש-{% equation %}b_{k}=a_{n_{k}}{% endequation %} עבור {% equation %}n_{0}<n_{1}<n_{2}<\ldots{% endequation %}, כלומר עבור <strong>סדרה מונוטונית עולה ממש</strong> של אינדקסים. עוד דבר שכדאי להזכיר הוא ש"חסומה" אומר שקיימים גם חסם מלעיל וגם חסם מלרע.

אפשר לנסח את בולצאנו-ויירשטראס גם באופן שקול, שיהיה רלוונטי כשנדבר על קנטור: לכל קבוצה {% equation %}A{% endequation %} שהיא אינסופית וחסומה קיימת <strong>נקודת הצטברות</strong>. כש"נקודת הצטברות" היא נקודה {% equation %}b\in\mathbb{R}{% endequation %} (לאו דווקא כזו ששייכת ל-{% equation %}A{% endequation %}) כך שלכל {% equation %}\varepsilon>0{% endequation %} קיימת {% equation %}a\in A{% endequation %} כך ש-{% equation %}d\left(b,a\right)<\varepsilon{% endequation %} (לא קשה להראות שבאופן שקול זה אומר שלכל {% equation %}\varepsilon>0{% endequation %} יש <strong>אינסוף</strong> נקודות {% equation %}a\in A{% endequation %} כך ש-{% equation %}d\left(b,a\right)<\varepsilon{% endequation %}). זה תרגיל נחמד להוכיח ששני הניסוחים שקולים, אז לא אעשה את זה בעצמי פה.

<a href="https://gadial.net/2009/06/07/lion_in_the_desert/">יש לי בבלוג</a> פוסט שמרפרף על ההוכחה של בולצאנו-ויירשטראס, אבל הפעם אכנס יותר לפרטים. למעשה, אני רוצה להראות שתי הוכחות, כל אחת עם היתרונות שלה. נתחיל מהפשוטה יותר, שתשתמש במה שראינו על התכנסות של סדרות מונוטוניות וחסומות. נתונה לי הסדרה {% equation %}\left\{ a_{n}\right\} _{n=0}^{\infty}{% endequation %}, ואני אגיד שאיבר כלשהו בסדרה הוא <strong>פסגה</strong> אם הוא גדול מכל האיברים שבאים אחריו. כלומר {% equation %}a_{n}{% endequation %} הוא פסגה אם לכל {% equation %}n<m{% endequation %} מתקיים {% equation %}a_{m}<a_{n}{% endequation %}. עכשיו, יש שתי אפשרויות: או שבסדרה יש אינסוף פסגות, או שיש מספר סופי. נטפל בכל מקרה בנפרד.

במקרה שבו יש אינסוף פסגות, אני אבנה את תת-הסדרה המתכנסת {% equation %}\left\{ b_{k}\right\} _{k=0}^{\infty}{% endequation %} ככה: ראשית {% equation %}b_{0}{% endequation %} תהיה הפסגה הראשונה בסדרה. שנית, בואו נניח שכבר בניתי את {% equation %}b_{k}{% endequation %} והוא פסגה בסדרה המקורית (זה נכון עבור {% equation %}b_{0}{% endequation %} ואני אבנה את {% equation %}b_{k+1}{% endequation %} כדי שזה ימשיך להיות נכון). מכיוון שבסדרה המקורית יש אינסוף פסגות, נבחר את {% equation %}b_{k+1}{% endequation %} להיות פסגה כלשהי בסדרה המקורית שמגיעה אחרי {% equation %}b_{k}{% endequation %}. עכשיו, שימו לב שבגלל ש-{% equation %}b_{k}{% endequation %} היא פסגה היא גדולה <strong>מכל</strong> איבר שבה אחריה, כלומר {% equation %}b_{k+1}<b_{k}{% endequation %}. במילים אחרות, בנינו פה תת-סדרה מונוטונית יורדת {% equation %}b_{0}>b_{1}>b_{2}>\ldots{% endequation %} והיא חסומה בגלל שהסדרה {% equation %}\left\{ a_{n}\right\} _{n=0}^{\infty}{% endequation %} חסומה (זו ההנחה של משפט בולצאנו-ויירשטראס). לכן סדרת ה-{% equation %}b_{k}{% endequation %}-ים מתכנסת.

עכשיו נניח שדווקא אין אינסוף פסגות. אז קיים {% equation %}N{% endequation %} כך ש-{% equation %}a_{N}{% endequation %} הוא הפסגה האחרונה בסדרה. נגדיר {% equation %}b_{0}=a_{N+1}{% endequation %}, כלומר {% equation %}b_{0}{% endequation %} <strong>אינה</strong> פסגה. נניח עכשיו באופן כללי שכבר בנינו את {% equation %}b_{k}{% endequation %} והיא אינה פסגה, אז מכיוון שהיא אינה פסגה קיים איבר שמופיע אחרי {% equation %}b_{k}{% endequation %} וגדול ממנו: נבחר את האיבר הזה להיות {% equation %}b_{k+1}{% endequation %}, ונשים לב שגם הוא לא יהיה פסגה כי אין יותר פסגות בסדרה המקורית. לכן {% equation %}b_{k}<b_{k+1}{% endequation %} ואפשר להמשיך ככה ולקבל סדרה מונוטונית עולה {% equation %}b_{0}<b_{1}<b_{2}<\ldots{% endequation %} ולכן מתכנסת. זה מסיים את ההוכחה הזו ומראה את השימושיות היפה של הטענה על סדרות מונוטוניות מתכנסות.

אבל אני רוצה, כאמור, להראות עוד הוכחה, כי היא תיתן לי מוטיבציה לעוד משפט שימושי שאני רוצה להציג. זו ההוכחה שהצגתי ברפרוף בפוסט הקודם ומשתמשת ברעיון שאוהבים לקרוא לו <strong>אריה במדבר</strong> בהתאם ל"בדיחה" הזו: איך תופסים אריה במדבר? קודם כל מקיפים את המדבר בגדר. עכשיו מעבירים גדר באמצע המדבר. האריה נמצא באחד משני החצאים, אז הולכים לחצי שבו האריה נמצא ומעבירים גדר באמצע שלו וכן הלאה. בסופו של דבר האריה מוגבל לשטח של מטר על מטר - תפסנו אותו!

מה שנחמד בדימוי הזה, כשמקזזים את ההתעללות בבעלי חיים ואת העובדה שאין אריות במדבר, הוא שאנחנו אוטומטית כבר מקבלים הצצה אל איך זה יכול לעבוד בדו-מימד, או במספר כלשהו של ממדים, וזאת להבדיל מההוכחה הקודמת שהייתה מאוד חד ממדית באופי שלה. עדיין, אני מתעסק כאן רק עם {% equation %}\mathbb{R}{% endequation %} אז אני אנסח את ההוכחה רק עבור המקרה החד ממדי, מה שיוביל לכך שהיא תהיה טיפה יותר מסורבלת מהקודמת - אבל כאמור, הרווח הוא שקל להכליל אותה (גם את ההוכחה השניה אפשר להכליל עם לא יותר מדי מאמץ, אבל לטעמי זה פחות מיידי).

אז יש לנו את הסדרה {% equation %}\left\{ a_{n}\right\} _{n=0}^{\infty}{% endequation %} שאני רוצה למצוא לה תת-סדרה מתכנסת ואני יודע שהיא <strong>חסומה</strong>, כלומר קיים {% equation %}M>0{% endequation %} כך ש-{% equation %}\left|a_{n}\right|\le M{% endequation %} לכל {% equation %}n{% endequation %}. זו ה"גדר" שבה מקיפים את כל המדבר. עכשיו אני הולך להגדיר סדרה של <strong>קטעים</strong>, {% equation %}C_{n}=\left[\alpha_{n},\beta_{n}\right]{% endequation %}. ההגדרה של קטע כזה, למי שלא זוכרים, היא {% equation %}\left[\alpha,\beta\right]\triangleq\left\{ x\in\mathbb{R}\ |\ \alpha\le x\le\beta\right\} {% endequation %}. זה מה שנקרא קטע <strong>סגור</strong> כי הוא כולל את נקודות הקצה שלו: זה יהיה חשוב בהמשך.

את סדרת הקטעים אני הולך לבנות ככה שמתקיימים הדברים הבאים:

<ol> <li>בכל קטע {% equation %}C_{n}{% endequation %} יש <strong>אינסוף</strong> איברים של הסדרה {% equation %}\left\{ a_{n}\right\} _{n=0}^{\infty}{% endequation %} (זו המקבילה לכך ש"האריה נמצא בתוך הקטע").</li>


<li>{% equation %}\left|C_{n}\right|=\beta_{n}-\alpha_{n}=\frac{M}{2^{n-1}}{% endequation %}, כלומר <strong>האורך</strong> של {% equation %}C_{n}{% endequation %} לא סתם ידוע לנו אלא הוא <strong>שואף לאפס</strong> כש-{% equation %}n{% endequation %} שואף לאינסוף (זה כל מה שנזדקק לו, האורך המדויק לא חשוב).</li>


<li>{% equation %}C_{n-1}\supseteq C_{n}{% endequation %}, כלומר כל קטע מוכל בקטע שקודם לו.</li>

</ol>

הקטע הראשון בסדרה יהיה {% equation %}C_{0}=\left[-M,M\right]{% endequation %} והוא בוודאי מקיים את תכונות 1 ו-2. תכונה 3 מתקיימת "באופן ריק" כי אין קטע שקודם לו. עכשיו, בואו נניח שבנינו כבר את {% equation %}C_{n}{% endequation %} והוא אכן מקיים את תכונות 1-3 ונבנה את {% equation %}C_{n+1}{% endequation %}. מה שנעשה הוא לקחת את {% equation %}C_{n}=\left[\alpha_{n},\beta_{n}\right]{% endequation %} ו<strong>לחצות אותו לשניים</strong> (זו המקבילה לכך ש"מעבירים גדר באמצע המדבר"), כלומר נסתכל על הקטעים {% equation %}\left[\alpha_{n},\frac{\alpha_{n}+\beta_{n}}{2}\right]{% endequation %} ו-{% equation %}\left[\frac{\alpha_{n}+\beta_{n}}{2},\beta_{n}\right]{% endequation %}. 

האיחוד של שני הקטעים הללו הוא בדיוק {% equation %}C_{n}{% endequation %} ולכן הוא מכיל אינסוף איברים של הסדרה; לכן אחד משני החצאים חייב להכיל אינסוף איברים של הסדרה כי אם בשני החצאים היה רק מספר סופי של איברים, גם באיחוד שלהם היה רק מספר סופי של איברים. נבחר את {% equation %}C_{n+1}{% endequation %} להיות החצי שיש בו אינסוף איברים ("החצי עם האריה"). עם ההגדרה הזו של {% equation %}C_{n+1}{% endequation %} מקבלים מייד את תכונות 2-3 (תוכיחו אותן לעצמכם!)

עכשיו אני רוצה לבנות את תת-הסדרה שלי, {% equation %}\left\{ b_{k}\right\} _{k=0}^{\infty}{% endequation %}. נניח שכבר בניתי את כל האיברים עד {% equation %}b_{k}{% endequation %} ונראה איך בונים אותו: בקטע {% equation %}C_{k}{% endequation %} יש אינסוף איברים של הסדרה המקורית, ובתת-הסדרה שבניתי עד כה יש רק מספר סופי של איברים, אז אני אבחר את {% equation %}b_{k}{% endequation %} להיות איבר של הסדרה המקורית עם אינדקס גדול משל כל האיברים שמופיעים בתת-הסדרה שבניתי עד עכשיו. זה מסיים את הבניה, ורק נשאר להוכיח שתת-הסדרה הזו <strong>מתכנסת</strong>.

אינטואיטיבית, תת-הסדרה הזו נמצא באיזורים שהולכים וקטנים כל הזמן, ולכן יש הרגשה שהיא "חייבת להתכנס", אבל ההרגשה הזו (שבהמשך אתן לה שם פורמלי: <strong>סדרת קושי</strong>) לא נותנת לי איבר ספציפי שאליו הולכים להתכנס - ואכן, אם אנחנו עובדים מעל {% equation %}\mathbb{Q}{% endequation %} כל תהליך הבניה שתיארתי עד כה עובד מושלם אבל תת-הסדרה לא תהיה חייבת להתכנס. אני חייב להכניס פה לתמונה משפט שמשתמש בתכונת השלמות של הממשיים, והמשפט שאני רוצה להשתמש בו הוא מה שאני הולך עוד מעט לתאר: <strong>משפט החיתוך של קנטור</strong>.

הנה ניסוח פורמלי של המשפט: אם {% equation %}\left\{ C_{n}\right\} _{n=0}^{\infty}{% endequation %} היא סדרה של קטעים <strong>סגורים</strong> כך ש-{% equation %}C_{n}\supseteq C_{n+1}{% endequation %} ו-{% equation %}\lim_{n\to\infty}\left|C_{n}\right|=0{% endequation %} אז קיים {% equation %}c\in\mathbb{R}{% endequation %} <strong>יחיד</strong> כך ש-{% equation %}c\in\bigcap_{n=0}^{\infty}C_{n}{% endequation %}. במילים: קיימת נקודה <strong>יחידה</strong> שנמצאת בכל הקטעים בסדרה. זה ה<strong>קיום</strong> שאנחנו זקוקים לו.

אם כן, יש לנו נקודה {% equation %}c{% endequation %} והייתי רוצה להראות שתת-הסדרה שבניתי מתכנסת אליה, כלומר {% equation %}\lim_{k\to\infty}b_{k}=c{% endequation %}. זו הוכחה סטנדרטית: מתחילים עם "יהא {% equation %}\varepsilon>0{% endequation %}" ואז לוקחים {% equation %}N{% endequation %} כך שאם {% equation %}k>N{% endequation %} אז {% equation %}\left|C_{k}\right|<\varepsilon{% endequation %} (קיים כזה, כי {% equation %}\lim_{n\to\infty}\left|C_{n}\right|=0{% endequation %}). עכשיו, {% equation %}c\in C_{k}{% endequation %} (על פי משפט החיתוך של קנטור) וגם {% equation %}b_{k}\in C_{k}{% endequation %} (על פי הבניה של {% equation %}b_{k}{% endequation %}) ולכן אני יכול להסיק ש-{% equation %}d\left(b_{k},c\right)<\varepsilon{% endequation %} ונגמר הסיפור. אני אסביר עכשיו איך אני מסיק את זה במקרה של {% equation %}\mathbb{R}{% endequation %}, מה שכמובן מוסיף סרבול להוכחה; אני אגלה שבאופן כללי, משפט החיתוך של קנטור לא דורש שמה שיישאף לאפס הוא <strong>האורך</strong> של קטע, אלא <strong>הקוטר</strong> של קבוצה במרחב מטרי, כש"הקוטר" הוא המרחק המקסימלי בין זוג איברים מהקבוצה - כלומר, במקרה הכללי המסקנה ש-{% equation %}d\left(b_{k},c\right)<\varepsilon{% endequation %} מגיעה בחינם.

במקרה שלנו, נניח בלי הגבלת הכלליות ש-{% equation %}b_{k}<c{% endequation %}, כלומר

{% equation %}d\left(b_{k},c\right)=\left|b_{k}-c\right|=c-b_{k}{% endequation %}

עכשיו שימו לב ש-{% equation %}b_{k},c\in\left[\alpha_{k},\beta_{k}\right]{% endequation %} ולכן בפרט {% equation %}c\le\beta_{k}{% endequation %} וגם {% equation %}b_{k}\ge\alpha_{k}{% endequation %}, כלומר {% equation %}-b_{k}\le-\alpha_{k}{% endequation %}, ולכן

{% equation %}c-b_{k}\le\beta_{k}-\alpha_{k}=\left|C_{k}\right|<\varepsilon{% endequation %}

מה שמסיים את ההוכחה. השגנו את בולצאנו-ויירשטראס וקיבלנו מוטיבציה להוכיח את משפט החיתוך של קנטור, אבל לפני שאני אעשה את זה - בואו נראה מה בכלל <strong>עושים</strong> עם בולצאנו-ויירשטראס ועם משפט החיתוך של קנטור שבגללו אנחנו כל כך אוהבים אותם.

<h2>משפט ערך הביניים ומשפטי ויירשטראס</h2>

הדבר המרכזי שבו מתעסקים בחדו"א הוא <strong>פונקציות ממשיות</strong>, {% equation %}f:\mathbb{R}\to\mathbb{R}{% endequation %}. בואו ניזכר מה ראינו קודם לגבי מושג הגבול עבור פונקציות כאלו:

<ul> <li>אומרים ש-{% equation %}f\left(x\right){% endequation %} <strong>מתכנסת</strong> ב-{% equation %}x_{0}{% endequation %} אל {% equation %}L{% endequation %} ומסמנים זאת {% equation %}\lim_{x\to x_{0}}f\left(x\right)=L{% endequation %} אם לכל {% equation %}\varepsilon>0{% endequation %} יש {% equation %}\delta>0{% endequation %} כך שאם {% equation %}0<d\left(x,x_{0}\right)<\delta{% endequation %} אז {% equation %}d\left(f\left(x\right),L\right)<\varepsilon{% endequation %}</li>


<li>אומרים ש-{% equation %}f\left(x\right){% endequation %} <strong>רציפה</strong> ב-{% equation %}x_{0}{% endequation %} אם {% equation %}\lim_{x\to x_{0}}f\left(x\right)=f\left(x_{0}\right){% endequation %}</li>

</ul>

מושג הרציפות הוא <strong>נקודתי</strong>; אנחנו מדברים על נקודה קונקרטית שבה {% equation %}f{% endequation %} רציפה. אבל המושג הזה באמת זורח כשיש לנו סיטואציה שבה {% equation %}f{% endequation %} לא רציפה רק בנקודה אחת, אלא בתוך קבוצה "נחמדה" של נקודות. למשל, קטע (קטע הוא דבר טוב כי אין בו "חורים באמצע" שבהם פתאום הפונקציה לא צריכה להיות רציפה ויכולה להשתולל). אני רוצה להראות כמה משפטים בסיסיים שמסתמכים על כך שפונקציה רציפה בקבוצה נחמדה מתנהגת נחמד, אבל לפני כן בואו נראה דרך לחבר את מושג הגבול של סדרה עם מושג הרציפות.

נניח ש-{% equation %}f{% endequation %} רציפה בנקודה {% equation %}a{% endequation %} ונניח שבנוסף לכך יש לנו סדרה {% equation %}a_{0},a_{1},a_{2},\ldots{% endequation %} כך ש-{% equation %}\lim_{n\to\infty}a_{n}=a{% endequation %}. עכשיו, בואו נפעיל את {% equation %}f{% endequation %} על אברי הסדרה ונקבל סדרה חדשה, {% equation %}f\left(a_{0}\right),f\left(a_{1}\right),\ldots{% endequation %}. אני טוען שהרציפות של {% equation %}f{% endequation %} גוררת ש-{% equation %}\lim_{n\to\infty}f\left(a_{n}\right)=f\left(a\right){% endequation %}. כדי לראות את זה בואו נשתמש בהוכחה סטנדרטית: נגיד שיהא {% equation %}\varepsilon>0{% endequation %} כלשהו, ומהרציפות של {% equation %}f{% endequation %} נסיק שקיים {% equation %}\delta{% endequation %} כך שאם {% equation %}d\left(x,a\right)<\delta{% endequation %} אז {% equation %}d\left(f\left(x\right),f\left(a\right)\right)<\varepsilon{% endequation %}. עכשיו, נעבור לפתוח את הגדרת הגבול {% equation %}\lim_{n\to\infty}a_{n}=a{% endequation %}: מהגדרת הגבול נובע שעבור ה-{% equation %}\delta{% endequation %} שמצאנו קודם קיים {% equation %}N{% endequation %} כך שאם {% equation %}n>N{% endequation %} אז {% equation %}d\left(a_{n},a\right)<\delta{% endequation %}, אבל זה אומר ש-{% equation %}d\left(f\left(a_{n}\right),f\left(a\right)\right)<\varepsilon{% endequation %} כפי שרצינו, וסיימנו. עכשיו, כשיש לי את המשפט המועיל הזה, אני יכול להתחיל להראות תוצאות מגניבות של רציפות.

בואו נתחיל עם <strong>המשפט היסודי של האלגברה</strong>. המשפט בעל השם המפוצץ הזה אומר שבמספרים המרוכבים {% equation %}\mathbb{C}{% endequation %}, לכל פולינום יש שורש, כלומר אם {% equation %}p\left(x\right)=a_{n}x^{n}+a_{n-1}x^{n-1}+\ldots+a_{1}x+a_{0}{% endequation %} הוא פולינום, קיים {% equation %}z\in\mathbb{C}{% endequation %} כך ש-{% equation %}p\left(z\right)=0{% endequation %}. במבט ראשון לא ברור איך זה קשור אלינו, הרי זה משפט שמדבר על מספרים מרוכבים; אבל מספרים ממשיים הם מקרה פרטי חשוב של מרוכבים, ובפרט אם יש לנו פולינום שהמקדמים שלו ממשיים והדרגה שלו <strong>אי-זוגית</strong> אז קל לראות ש<strong>חייב</strong> להיות לו לפחות שורש ממשי אחד (כי השורשים הלא ממשיים בהכרח באים בזוגות של {% equation %}z,\overline{z}{% endequation %}), כלומר מקרה פרטי של המשפט היסודי הוא הטענה "לפולינום ממשי מדרגה אי זוגית יש שורש ממשי". בשעתו הראיתי בבלוג <a href="https://gadial.net/2009/10/29/fundemental_theorem_of_algebra_algebraic_proof/">הוכחה יפה</a> למשפט היסודי של האלגברה שהשתמשה בטכניקות אלגבריות מתורת גלואה - אבל הטכניקות הללו לא יכלו להוכיח בעצמן את הטענה עבור פולינום ממשי ממעלה אי זוגית, ונזקקו להוכחה שאני הולך להראות עכשיו, שהיא חדו"אית לגמרי (ועל כן יש כאלו שאוהבים ללגלג בצורה לא הוגנת ש"המשפט היסודי של האלגברה הוא משפט באנליזה").

הרעיון הוא זה: ראשית, פולינום הוא פונקציה <strong>רציפה</strong> (אני לא הולך להוכיח את זה, אבל זה לא קשה; {% equation %}f\left(x\right)=x{% endequation %} הוא די בבירור רציף ועכשיו רק צריך להראות שסכומים ומכפלות סופיים של פונקציות רציפות הם רציפים). שנית, אם הפולינום הוא ממעלה <strong>אי-זוגית</strong>, ואפשר להניח שהוא מתוקן כלומר שהמעלה של החזקה הגבוהה ביותר {% equation %}x^{n}{% endequation %} היא 1, אז לא קשה לראות שעל ידי הצבת ערך {% equation %}a{% endequation %} שלילי שהוא מספיק גדול בערכו המוחלט אפשר לקבל ש-{% equation %}p\left(a\right)<0{% endequation %} ובדומה אפשר למצוא {% equation %}b{% endequation %} כך ש-{% equation %}p\left(b\right)>0{% endequation %}. כלומר, קיבלנו שני ערכים ש-{% equation %}p{% endequation %} "מחליף סימן" ביניהם, בקטע {% equation %}\left[a,b\right]{% endequation %}. מכיוון ש-{% equation %}p{% endequation %} רציף, אנחנו מדמיינים אותו בתור קו כזה שמציירים על הנייר בלי להרים את העיפרון מהדף, ולכן אם ברגע אחד הוא מתחת לציר {% equation %}x{% endequation %} ורגע אחר כך הוא מעל ציר {% equation %}x{% endequation %} היה שבריר שניה שבו הוא היה <strong>בדיוק</strong> על ציר {% equation %}x{% endequation %}, כלומר יש נקודה {% equation %}c\in\left(a,b\right){% endequation %} כך ש-{% equation %}f\left(c\right)=0{% endequation %}. משכנע?

לא, לא ממש משכנע. בדיוק בגלל זה צריך הוכחות. הטענה שאני רוצה להוכיח נקראת <strong>משפט ערך הביניים</strong> והנה הניסוח הפורמלי יותר שלה: אם {% equation %}f{% endequation %} היא פונקציה רציפה בקטע {% equation %}\left[a,b\right]{% endequation %} כך ש-{% equation %}f\left(a\right)<0<f\left(b\right){% endequation %}, אז קיימת {% equation %}c\in\left(a,b\right){% endequation %} כך ש-{% equation %}f\left(c\right)=0{% endequation %} (אפשר לנסח בצורה כללית יותר, עבור כל ערך ביניים ולא רק 0, אבל זה ניתן לרדוקציה למקרה של {% equation %}0{% endequation %} כי מחליפים את הפונקציה {% equation %}f{% endequation %} שרוצים להראות שמקבלת את הערך {% equation %}T{% endequation %} בפונקציה {% equation %}f\left(x\right)-T{% endequation %}).

איך מוכיחים את זה? הנה הוכחת "אריה במדבר" סטייל עם משפט החיתוך של קנטור. נבנה סדרה של קטעים {% equation %}\left[a_{n},b_{n}\right]{% endequation %} כשהקטע הראשון הוא {% equation %}a_{0}=a,b_{0}=0{% endequation %}. הכלל המנחה יהיה שבכל הקטעים הללו מתקיים {% equation %}f\left(a_{n}\right)<0<f\left(b_{n}\right){% endequation %}, שהם מכילים אחד את השני ושהאורך של כל אחד מהם הוא <strong>חצי</strong> מהאורך של הקודם, כלומר שהאורכים שלהם שואפים לאפס. נעשה את זה בצורה פשוטה מאוד: נסתכל על נקודת האמצע של כל קטע, {% equation %}x_{n}=\frac{a_{n}+b_{n}}{2}{% endequation %}. אם {% equation %}f\left(x_{n}\right)=0{% endequation %} מצאנו את ה-{% equation %}c{% endequation %} שחיפשנו ואפשר לסיים את ההוכחה; אחרת, אם {% equation %}f\left(x_{n}\right)>0{% endequation %} אז נגדיר {% equation %}a_{n+1}=a{% endequation %} ו-{% equation %}b_{n+1}=x_{n}{% endequation %}, ואילו אם {% equation %}f\left(x_{n}\right)<0{% endequation %} אז נגדיר {% equation %}a_{n+1}=x_{n}{% endequation %} ו-{% equation %}b_{n+1}=b_{n}{% endequation %}.

עכשיו, משפט החיתוך של קנטור אומר לנו שקיימת נקודה יחידה {% equation %}c\in\bigcap_{n=1}^{\infty}\left[a_{n},b_{n}\right]{% endequation %}. האינטואיציה היא שזו הנקודה שחיפשתי, שבה {% equation %}f\left(c\right)=0{% endequation %}, כי עם הקטעים {% equation %}\left[a_{n},b_{n}\right]{% endequation %} אני עושה "זום אין" מדויק על רגע שבו הפונקציה עוברת משלילית לחיובית. אבל איך אני מוכיח את זה? כאן הרציפות נכנסת לתמונה. ראשית, קל להראות ש-{% equation %}a_{n}\to c{% endequation %}. שנית, בגלל ש-{% equation %}f{% endequation %} רציפה נובע ממה שהראיתי קודם ש-{% equation %}\lim_{n\to\infty}f\left(a_{n}\right)=f\left(c\right){% endequation %}. בנוסף, {% equation %}f\left(a_{n}\right)<0{% endequation %} לכל {% equation %}n{% endequation %} כי ככה בניתי את סדרת ה-{% equation %}n{% endequation %}-ים. אז קיבלנו ש-{% equation %}f\left(c\right){% endequation %} הוא הגבול של סדרה של מספרים שליליים, וגבול כזה חייב להיות שלילי או אפס, כי אם הוא {% equation %}L>0{% endequation %} אז <strong>כל</strong> איבר בסדרה יהיה לפחות במרחק {% equation %}L{% endequation %} ממנו ולכן עבור {% equation %}\varepsilon<L{% endequation %} הוכחת הגבול תיכשל. כלומר, {% equation %}f\left(c\right)\le0{% endequation %}. באופן דומה בעזרת סדרת ה-{% equation %}b{% endequation %}-ים מראים ש-{% equation %}f\left(c\right)\ge0{% endequation %}, והמסקנה משני אלו היא ש-{% equation %}f\left(c\right)=0{% endequation %}, כפי שרצינו.

מה קרה פה? הרציפות היא זו שנתנה לנו את {% equation %}f\left(c\right)\le0{% endequation %} ואת {% equation %}f\left(c\right)\ge0{% endequation %}, אבל מה שתכונת <strong>השלמות</strong> נתנה לנו הוא את זה שבכלל קיים {% equation %}c{% endequation %} כזה - קיים חלקיק שניה מדויק שבו אפשר לעצור את הסרט של {% equation %}f{% endequation %} ולהגיד "הנה! רואים?! זו השניה המדויקת שבה עברנו את ציר {% equation %}x{% endequation %}!" במספרים הרציונליים זה פשוט לא עובד: אם למשל נסתכל על הפונקציה {% equation %}f\left(x\right)=x-\pi{% endequation %}: אין מספר רציונלי שמאפס אותה, אבל היא כמובן רציפה. פשוט אין בסרט שלנו את הפריים עבור {% equation %}x=\pi{% endequation %} שבו רואים אותה מתאפסת, כי הסרט כולל רק פריימים שנלקחו בנקודות רציונליות.

בואו נעבור עכשיו למה שמכונה <strong>משפט ערך הקיצון של ויירשטראס</strong> (Extreme value theorem) ולפעמים מחלקים לשני משפטים - "משפט ויירשטראס הראשון" ו"משפט ויירשטראס השני" (שההוכחה שלו מסתמכת על הראשון) וגם אני כאן אדבר עליהם בתור שני משפטים. הרעיון בהם די פשוט: אם אני מצייר פונקציה רציפה בקטע סגור, העפרון שלי מתחיל בנקודה אחת ומצייר איזה קו עד שהוא מגיע לנקודה בקצה השני. הוא לא יכול בשום שלב לברוח לאינסוף, כי פונקציה רציפה היא "רגועה". אני אצייר את כולה על הנייר שעל השולחן ולא אמצא את עצמי פתאום נאלץ ללכת עד לקוטב הצפוני בשביל לצייר אותה (זה לא נכון, אני משקר כדי לתת אינטואיציה, פונקציה רציפה בהחלט עלולה לדרוש ממני ללכת עד לקוטב הצפוני, פשוט לא עד <strong>לאינסוף</strong>). באופן פורמלי: פונקציה רציפה על קטע סגור וחסום היא <strong>חסומה</strong> בו. זה משפט ויירשטראס הראשון, והשני מרחיב: לא סתם חסומה, אלא מקבלת את המקסימום והמינימום שלה, כלומר אם יש לנו את הקטע {% equation %}\left[a,b\right]{% endequation %} ופונקציה רציפה {% equation %}f:\left[a,b\right]\to\mathbb{R}{% endequation %} אז קיימות נקודות {% equation %}c_{1},c_{2}\in\left[a,b\right]{% endequation %} כך ש-{% equation %}f\left(c_{1}\right)=\min\left\{ f\left(x\right)\ |\ x\in\left[a,b\right]\right\} {% endequation %} ו-{% equation %}f\left(c_{2}\right)=\max\left\{ f\left(x\right)\ |\ x\in\left[a,b\right]\right\} {% endequation %}.

האם המשפט הראשון מתבסס רק על הרציפות של {% equation %}f{% endequation %} או גם על השלמות של {% equation %}\mathbb{R}{% endequation %}? לכאורה לא צריך פה את השלמות, הרי הטענה היא לא מהצורה "קיימת נקודה בקטע שמקיימת כך וכך" אלא "קיים חסם אחיד עבור כל הנקודות בקטע". אבל הנקודה היא שבלי ש-{% equation %}\mathbb{R}{% endequation %} יהיה שלם, פונקציה יכולה "להשתגע" כשהערכים שלה מתקרבים לנקודה ש"חסרה" ב-{% equation %}\mathbb{R}{% endequation %} ועדיין להיחשב רציפה, כי הדוגמא הנגדית לרציפות שלה היא נקודה שלא קיימת בכלל.

איך גורמים לפונקציה "להשתגע"? פשוט מאוד, מחלקים באפס. למשל, נסתכל על הקטע {% equation %}\left(0,1\right){% endequation %} ועל הפונקציה {% equation %}f\left(x\right)=\frac{1}{x}{% endequation %}. הפונקציה הזו בבירור <strong>כן</strong> רציפה בקטע (זה דורש טיפה הוכחה) אבל כש-{% equation %}x{% endequation %} מתקרב ל-{% equation %}0{% endequation %} הפונקציה "מתפוצצת", גדלה ועוברת כל חסם אפשרי; היא בוודאי לא חסומה ב-{% equation %}\left(0,1\right){% endequation %}, והסיבה שזו לא דוגמא נגדית למשפט ויירשטראס היא שעל הקטע <strong>הסגור </strong>{% equation %}\left[0,1\right]{% endequation %} הפונקציה לא תהיה רציפה כי היא בכלל לא מוגדרת ב-0. זה ממחיש את החשיבות בכך שהקטע הוא <strong>סגור</strong>; בלי זה המשפט לא עובד.

עכשיו, בואו נניח לרגע ש-0 בכלל לא קיים ביקום שלנו ואנחנו מסתכלים עדיין על {% equation %}f\left(x\right)=\frac{1}{x}{% endequation %}, אבל בקטע {% equation %}\left[-1,1\right]{% endequation %}. הפונקציה עדיין לא חסומה בו כי בסביבות {% equation %}x=0{% endequation %} היא "מתפוצצת", אבל האם היא לא רציפה? בכל נקודה חוץ מ-0 היא כן רציפה, אז אם 0 לא קיים ביקום שלנו, קיבלנו פונקציה שרציפה בקטע הסגור והחסום {% equation %}\left[-1,1\right]{% endequation %} אבל לא חסומה בו. כמובן, 0 <strong>כן קיים</strong> ביקום שלנו, אבל אם אנחנו לא ב-{% equation %}\mathbb{R}{% endequation %} אלא ב-{% equation %}\mathbb{Q}{% endequation %} אז מספרים אחרים כמו {% equation %}\pi{% endequation %} לא קיימים בו ואפשר לתקן את הדוגמא כדי שתהיה סביבם, באופן הבא: נסתכל על הקטע {% equation %}\left[3,4\right]{% endequation %} ועל הפונקציה {% equation %}f\left(x\right)=\frac{1}{x-\pi}{% endequation %} ש"מתפוצצת" ב-{% equation %}x=\pi{% endequation %}.

ההוכחה של משפט ויירשטראס הראשון מתבססת על הדוגמא הנגדית המטופשת הזו: היא מניחה בשלילה שהפונקציה לא חסומה ולכן יש מקום שבו היא "מתפוצצת", ואז משתמשת בשלמות של הממשיים כדי למצוא נקודה שנמצאת במרכז הפיצוץ הזה והפונקציה פשוט לא יכולה להיות רציפה בה. בואו נניח בשלילה ש-{% equation %}f\left(x\right){% endequation %} הרציפה לא חסומה בקטע {% equation %}\left[a,b\right]{% endequation %}, אז לכל {% equation %}n{% endequation %} קיימת נקודה {% equation %}x_{n}\in\left[a,b\right]{% endequation %} כך ש-{% equation %}f\left(x_{n}\right)\ge n{% endequation %}. קיבלנו סדרה {% equation %}\left\{ x_{n}\right\} _{n=0}^{\infty}{% endequation %} של נקודות שביחד מתארות את ה"התפוצצות" של {% equation %}f{% endequation %}, אלא שלרוע המזל ייתכן שהנקודות הללו נמצאות במקומות שונים לגמרי של הקטע {% equation %}\left[a,b\right]{% endequation %} ואני רוצה התפוצצות שמרוכזת בנקודה אחת; כאן בדיוק בא משפט בולצאנו-ויירשטראס לעזרתי ומוצא תת-סדרה מתכנסת {% equation %}\left\{ c_{n}\right\} _{n=0}^{\infty}{% endequation %} של {% equation %}\left\{ x_{n}\right\} _{n=0}^{\infty}{% endequation %}. תחשבו על בולצאנו-ויירשטראס כאילו הוא מתמקד בנקודת "התפוצצות" כלשהי ומעיף מהסדרה {% equation %}\left\{ x_{n}\right\} _{n=0}^{\infty}{% endequation %} את כל הנקודות שלא קשורות אליה אלא מתארות התפוצצויות אחרות או סתם מקומות שבהם הפונקציה מגיעה לגבהים בלי להתפוצץ ("הקוטב הצפוני"). נסמן {% equation %}c=\lim_{n\to\infty}c_{n}{% endequation %}, וכאן השתמשנו בשלמות של {% equation %}\mathbb{R}{% endequation %}: בלי זה הנקודה {% equation %}c{% endequation %} לא הייתה בהכרח קיימת, אפילו אם היינו מצליחים לבנות מקבץ {% equation %}\left\{ c_{n}\right\} _{n=0}^{\infty}{% endequation %} של נקודות שנראה כאילו הוא סובב סביב נקודת התפוצצות כלשהי.

הטיעון עכשיו הוא שבגלל הרציפות של {% equation %}f{% endequation %} צריך להתקיים {% equation %}f\left(c\right)=\lim_{n\to\infty}f\left(c_{n}\right){% endequation %} אבל מכיוון שהסדרה {% equation %}f\left(c_{n}\right){% endequation %} לא חסומה (קל להראות ש-{% equation %}f\left(c_{n}\right)\ge n{% endequation %} כי כשיצרנו את תת-הסדרה {% equation %}c_{n}{% endequation %} מתוך {% equation %}x_{n}{% endequation %} התכונה {% equation %}x_{n}\ge n{% endequation %} רק התחזקה) נובע שהגבול לא קיים בכלל (הוא קיים במובן הרחב, של {% equation %}\lim_{n\to\infty}f\left(c_{n}\right)=\infty{% endequation %}, אבל זו הגדרה שונה) ולכן {% equation %}f\left(c\right){% endequation %} לא מוגדרת בכלל; זה תרגיל טוב ולא קשה לנסח את זה פורמלית עד הסוף. סיימנו את ההוכחה של משפט ויירשטראס הראשון במובן זה שהראינו שהפונקציה חסומה מלעיל, ובאותו אופן מוכיחים שהיא חסומה מלרע.

עכשיו אפשר לעבור למשפט ויירשטראס השני - ננצל את זה שאנחנו כבר יודעים שהפונקציה חסומה כדי להראות שהיא מקבלת את הערך המקסימלי שלה. כרגיל, כדי להבין מה זה אומר ולמה השלמות של הממשיים קריטית לזה, בואו נסתכל על דוגמת צעצוע: הפונקציה הרציפה {% equation %}f\left(x\right)=1-\left|x\right|{% endequation %}. קל לראות ש-{% equation %}f\left(0\right)=1{% endequation %} הוא הערך המקסימלי של הפונקציה הזו, אבל אם {% equation %}0{% endequation %} לא היה חלק מהיקום המתמטי שלנו, הפונקציה לא הייתה מגיעה ל-1 אף פעם, רק שואפת אליו. רק מה, 0 הוא כן חלק מהעולם שלנו אז אפשר לעשות את הטריק הרגיל של להזיז את הכל כך שהנקודה שאנחנו מדברים עליה תהיה {% equation %}\pi{% endequation %} ולא 0, כלומר להגדיר {% equation %}f\left(x\right)=1-\left|x-\pi\right|{% endequation %}. אני חוזר שוב ושוב על השטיק הזה כדי שיהיה ברור שהפואנטה של השלמות של {% equation %}\mathbb{R}{% endequation %} היא לא שקיים מספר מעניין ומיוחד כמו {% equation %}\pi{% endequation %}, כי אין למהות של {% equation %}\pi{% endequation %} תפקיד אמיתי כאן; מה שחשוב הוא המבנה של קבוצת הממשיים בכללותה, המחסור הזה בחורים, כי אם יש אפילו חור אחד אפשר "להזיז" את כל העולם כך שהחור יהיה מרכז העולם, ולא משנה אם זה חור ב-0 או ב-{% equation %}\pi{% endequation %}.

בדוגמא {% equation %}f\left(x\right)=1-\left|x-\pi\right|{% endequation %} יש לנו פונקציה שאם תוגדר על הרציונליים, לא תקבל את המקסימום שלה בקטע {% equation %}\left[3,4\right]{% endequation %}, אבל מה שכן יהיה נכון הוא שלפחות יהיה סופרמום לקבוצת הערכים שהיא מקבלת שם: {% equation %}\sup\left\{ f\left(x\right)\ |\ x\in\left[3,4\right]\right\} =1{% endequation %}. גם את זה אפשר לקלקל בקלות אם מגדירים {% equation %}f\left(x\right)=\pi-\left|x-\pi\right|{% endequation %}. כלומר, כדי שמשפט ויירשטראס השני יעבוד אנחנו צריכים להשתמש בשלמות <strong>פעמיים</strong>: פעם אחת בשביל התחום של {% equation %}f{% endequation %}, כדי להוכיח את קיום הנקודה שבה יתקבל המקסימום; ופעם שניה, עוד יותר מוקדמת, עבור <strong>הטווח</strong> של {% equation %}f{% endequation %} כדי להוכיח שבכלל יש ערך מקסימלי ששווה לנסות ולקבל.

ההוכחה הסטנדרטית הולכת כך: בואו באמת נסתכל על {% equation %}\sup\left\{ f\left(x\right)\ |\ x\in\left[a,b\right]\right\} {% endequation %}. מכיוון שידוע לנו ש-{% equation %}f{% endequation %} חסומה ב-{% equation %}\left[a,b\right]{% endequation %} (זה משפט ויירשטראס הראשון) ומכיוון ש-{% equation %}\left[a,b\right]{% endequation %} כולל לפחות נקודה אחת (אם {% equation %}a=b{% endequation %} הקטע עדיין כולל את {% equation %}a{% endequation %}) אז {% equation %}A=\sup\left\{ f\left(x\right)\ |\ x\in\left[a,b\right]\right\} {% endequation %} קיים כי לקחנו סופרמום של קבוצה חסומה לא ריקה; זה שימוש ישיר ב<strong>אקסיומת השלמות</strong> של שדה סדור שלם. עכשיו אפשר להשתמש בטריק בולצאנו-ויירשטראסי בדיוק כמו קודם, רק במקום עם סדרה שמתפוצצת, עם סדרה ששואפת אל {% equation %}A{% endequation %}: לכל {% equation %}n{% endequation %} נמצא {% equation %}x_{n}\in\left[a,b\right]{% endequation %} כך ש-{% equation %}A-\frac{1}{n}\le f\left(x_{n}\right)\le A{% endequation %} (קיים כזה כי {% equation %}A{% endequation %} סופרמום), ניקח תת-סדרה מתכנסת {% equation %}\left\{ c_{n}\right\} _{n=0}^{\infty}{% endequation %}, נסמן {% equation %}c=\lim_{n\to\infty}c_{n}{% endequation %}, נשתמש ברציפות של {% equation %}f{% endequation %} כדי להסיק {% equation %}f\left(c\right)=\lim_{n\to\infty}f\left(c_{n}\right){% endequation %} ונוכיח די בקלות (תרגיל טוב!) ש-{% equation %}\lim_{n\to\infty}f\left(c_{n}\right)=A{% endequation %}.

ההוכחה הזו פשוטה ונהדרת, ולרוע המזל היא גורמת לי אי נוחות בפוסט הספציפי הזה כי קלעתי את עצמי לפינה שבה אני מנסה <strong>לא</strong> להשתמש ישירות באקסיומת השלמות, כי אני רוצה להראות שטבעי באותה מידה להתחיל מהניסוח האלטרנטיבי של קנטור לשלמות ו"להיפגש באמצע", כלומר להשתמש במשפט החיתוך של קנטור או בבולצאנו-ויירשטראס. אבל כאן אני לא רואה דרך לא מסורבלת לעשות את זה. זו כנראה נקודה פדגוגית לזכות ההצגה המוקדמת של אקסיומת השלמות.

לסיכום חלק הדוגמאות הזה, רציתי להביא כאן גם את <strong>משפט הערך הממוצע של לגראנז'</strong> שהוא באמת משפט שימושי בצורה יוצאת דופן, אבל אני לא אעשה את זה כי זה ייאלץ אותי לדבר גם על <strong>נגזרות</strong> ומשפטים שקשורים אליהן שאני לא רוצה להוכיח, אז הנה שורה אחת על לגראנז' למי שמכירות אותו: כדי להוכיח את לגראנז' אנחנו עושים תעלול אלגברי קטן שמבצע לו רדוקציה אל <strong>משפט רול</strong>. את משפט רול מוכיחים על ידי שילוב של שני משפטים: משפט פרמה, שאומר שנגזרת של פונקציה בנקודת קיצון מתאפסת; ומשפט ויירשטראס השני, שמראה שבתנאים של משפט רול יש לפונקציה נקודת קיצון. במילים אחרות, בכל מקרה אין כאן תוכן מתמטי רלוונטי שלא ראינו כי אנחנו מסתמכים פה על משפט ויירשטראס; ומצד שני בלי לגראנז' באמת שאין חדו"א כמו שאנחנו מכירים. וכך זה ממשיך ומפעפע עוד ועוד לכל רחבי החדו"א.

כל זה כנראה משכנע שאקסיומת השלמות היא דבר חשוב ושהגישה של דדקינד נכונה; אבל עכשיו הגיע הזמן לדבר גם על הגישה הנוספת.

<h2>סדרות קושי</h2>

בשלבים הקודמים של הפוסט ראינו את <strong>משפט החיתוך של קנטור</strong>. הנה תזכורת איך הוא הולך: אם {% equation %}\left\{ C_{n}\right\} _{n=0}^{\infty}{% endequation %} היא סדרה של קטעים <strong>סגורים</strong> כך ש-{% equation %}C_{n}\supseteq C_{n+1}{% endequation %} ו-{% equation %}\lim_{n\to\infty}\left|C_{n}\right|=0{% endequation %} אז קיים {% equation %}c\in\mathbb{R}{% endequation %} <strong>יחיד</strong> כך ש-{% equation %}c\in\bigcap_{n=0}^{\infty}C_{n}{% endequation %}. איך אפשר להוכיח את זה? ובכן, הנה גישה אחת: מכיוון שהקטעים {% equation %}C_{n}{% endequation %} הם סגורים כל אחד כולל לפחות נקודה אחת, אז פשוט ניקח {% equation %}c_{n}\in C_{n}{% endequation %} לכל קטע וקיבלנו סדרה. עכשיו נגדיר {% equation %}c=\lim_{n\to\infty}c_{n}{% endequation %} וקיבלנו את ה-{% equation %}c{% endequation %} שלנו. עכשיו צריך עדיין להוכיח שהוא בחיתוך של כל הקטעים ושהוא יחיד, אבל עברנו את השלב הקשה של להוכיח שהוא קיים... רגע רגע רגע, לא הוכחנו שום דבר. אני לא יכול להגדיר {% equation %}c=\lim_{n\to\infty}c_{n}{% endequation %} כי אני לא יודע שהסדרה {% equation %}\left\{ c_{n}\right\} _{n=0}^{\infty}{% endequation %} מתכנסת בכלל. אבל מה שאני כן יודע הוא שהסדרה הזו נראית <strong>כאילו היא אמורה להתכנס</strong>. למה? ובכן, כי בגלל שהאיברים שלה שייכים לסדרת קטעים שהולכת ומצטופפת, גם האיברים שלה צריכים, ובכן, ללכת ולהצטופף יחד. וכשיש לי סדרה שנראה שהאיברים שלה מצטופפים סביב מקום אחד, הייתי יכול לקוות שהיא תתכנס, לא?

זה הרעיון מאחורי המושג שנקרא <strong>סדרת קושי</strong> (במאמר שלו קנטור קרא לה "סדרה יסודית", אבל זה לא המושג המקובל כיום). פורמלית, {% equation %}\left\{ a_{n}\right\} _{n=0}^{\infty}{% endequation %} היא <strong>סדרת קושי</strong> אם לכל {% equation %}\varepsilon>0{% endequation %} קיים {% equation %}N{% endequation %} כך שלכל {% equation %}n,m>N{% endequation %} מתקיים {% equation %}d\left(a_{n},a_{m}\right)<\varepsilon{% endequation %}. כלומר, לכל אפסילון קיים מקום בסדרה שהחל ממנו <strong>כל זוג איברים</strong> בסדרה קרובים זה לזה עד כדי אפסילון. ניסוח שימושי שקול הוא שלכל {% equation %}\varepsilon>0{% endequation %} קיים {% equation %}N{% endequation %} כך שלכל {% equation %}n>N{% endequation %} מתקיים {% equation %}d\left(a_{n},a_{N}\right)<\varepsilon{% endequation %}, כלומר לכל אפסילון קיים איבר בסדרה שכל יתר אברי הסדרה קרובים אליו עד כדי אפסילון.

שימו לב להבדל בין זה ובין הגדרת הגבול. גבול אומר שלכל אפסילון, קיים מקום בסדרה שהחל ממנו כל יתר איברי הסדרה קרובים <strong>אל הגבול</strong> עד כדי אפסילון - הגבול עצמו בכלל לא צריך להיות איבר בסדרה. לעומת זאת בסדרת קושי לכל אפסילון אנחנו בוחרים איבר מהסדרה שאליו כל יתר האיברים יהיו קרובים - והאיבר הזה <strong>תלוי באפסילון</strong>, כלומר זה לא שיש בסדרה איבר בודד שכל יתר האיברים קרובים אליו לכל אפסילון שנרצה (להבדיל מגבול שכן מקיים את זה). כלומר, התכונה שמגדירה סדרת קושי מרגישה קצת "חלשה יותר" מקיום גבול.

האמנם? ובכן, יש כאן שני משפטים שאפשר להוכיח: ראשית, שאם סדרה מתכנסת לגבול אז היא סדרת קושי (מה שמראה שקיום גבול "חזק לפחות כמו" להיות סדרת קושי) ושנית, שאם סדרה היא סדרת קושי אז היא אכן מתכנסת לגבול. בואו נוכיח את שניהם.

ראשית, נניח ש-{% equation %}\left\{ a_{n}\right\} _{n=0}^{\infty}{% endequation %} מתכנסת, {% equation %}\lim_{n\to\infty}a_{n}=a{% endequation %}, ונוכיח ש-{% equation %}\left\{ a_{n}\right\} _{n=0}^{\infty}{% endequation %} היא סדרת קושי ממש על פי ההגדרה. ניקח {% equation %}\varepsilon>0{% endequation %}, אז קיים מקום {% equation %}N{% endequation %} בסדרה כך שלכל {% equation %}n>N{% endequation %} מתקיים {% equation %}d\left(a_{n},a\right)<\frac{\varepsilon}{2}{% endequation %} (השתמשנו בהגדרת הגבול של סדרה עם {% equation %}\frac{\varepsilon}{2}{% endequation %}). עכשיו, ניקח {% equation %}n,m>N{% endequation %}, נשתמש באי שיוויון המשולש ונקבל

{% equation %}d\left(a_{n},a_{m}\right)\le d\left(a_{n},a\right)+d\left(a,a_{m}\right)<\frac{\varepsilon}{2}+\frac{\varepsilon}{2}=\varepsilon{% endequation %}

וסיימנו. זה היה כיוון קל.

מה עם הכיוון השני? ובכן, אם {% equation %}\left\{ a_{n}\right\} _{n=0}^{\infty}{% endequation %} היא סדרת קושי אנחנו עדיין לא יודעים אם היא מתכנסת או לא, אבל בזכות <strong>בולצאנו-ויירשטראס</strong> אנחנו יודעים שקיימת לה <strong>תת-סדרה</strong> מתכנסת. נסמן את הגבול של תת-הסדרה הזו ב-{% equation %}a{% endequation %}. עכשיו נראה ש-{% equation %}\lim_{n\to\infty}a_{n}=a{% endequation %} בשיטה הסטנדרטית: ניקח {% equation %}\varepsilon>0{% endequation %} כלשהו ונמצא {% equation %}N{% endequation %} כך שאם {% equation %}n>N{% endequation %} אז {% equation %}d\left(a_{n},a\right)<\varepsilon{% endequation %}. בשביל זה נשלב גם את התכונה של סדרת קושי וגם את הקטע של תת-סדרה מתכנסת.

ראשית, בגלל ש-{% equation %}\left\{ a_{n}\right\} _{n=0}^{\infty}{% endequation %} היא סדרת קושי, קיים {% equation %}N{% endequation %} כך שלכל {% equation %}n,m>N{% endequation %} מתקיים {% equation %}d\left(a_{n},a_{m}\right)<\frac{\varepsilon}{2}{% endequation %}. עכשיו, בתת-הסדרה המתכנסת של {% equation %}\left\{ a_{n}\right\} _{n=0}^{\infty}{% endequation %} קיים מקום {% equation %}N^{\prime}{% endequation %} כך שלכל {% equation %}n>N^{\prime}{% endequation %}, אם {% equation %}a_{n}{% endequation %} שייך לתת-הסדרה אז {% equation %}d\left(a_{n},a\right)<\frac{\varepsilon}{2}{% endequation %}. בואו ניקח {% equation %}m{% endequation %} כך ש-{% equation %}m>\max\left\{ N,N^{\prime}\right\} {% endequation %} אז בפרט מתקיים {% equation %}d\left(a_{m},a\right)<\frac{\varepsilon}{2}{% endequation %} ובנוסף, לכל {% equation %}n>N{% endequation %}, מכיוון ש-{% equation %}n,m>N{% endequation %} אז {% equation %}d\left(a_{n},a_{m}\right)<\frac{\varepsilon}{2}{% endequation %} ואפשר להשתמש באי שוויון המשולש:

{% equation %}d\left(a_{n},a\right)\le d\left(a_{n},a_{m}\right)+d\left(a_{m},a\right)<\frac{\varepsilon}{2}+\frac{\varepsilon}{2}=\varepsilon{% endequation %}

וסיימנו גם את הכיוון הזה. אבל שימו לב מה היה המחיר ששילמנו: בניגוד להוכחה של הכיוון הקודם שהייתה אלמנטרית, כאן השתמשנו במשפט המאוד לא טריוויאלי של <strong>בולצאנו-ויירשטראס</strong>. זה רומז לנו שיש כאן משהו מהותי, ובעצם זה לא צריך להיות מפתיע - אנחנו שוב פעם בוראים איבר יש מאין, במקרה הזה את גבול הסדרה. כבר ראינו בפוסט הזה את הסדרה {% equation %}1,1.4,1.41,1.414,1.4142,\ldots{% endequation %} ש"אמורה להתכנס" אל {% equation %}\sqrt{2}{% endequation %}; הבאתי אותה במקור בתור סדרה מונוטונית חסומה, אבל זו גם בבירור סדרת קושי של מספרים ב-{% equation %}\mathbb{Q}{% endequation %} ולכן בלי ש-{% equation %}\sqrt{2}{% endequation %} יהיה חלק מהעולם שלנו פשוט לא יהיה לה לאן להתכנס.

זה זמן טוב לעצור לרגע ולראות את שרשרת ההוכחות שיש לנו:

<ul> <li><strong>אקסיומת השלמות</strong> {% equation %}\leftarrow{% endequation %} כל סדרה מונוטונית וחסומה מתכנסת {% equation %}\leftarrow{% endequation %} בולצאנו ויירשטראס (הוכחת ה"פסגות") {% equation %}\leftarrow{% endequation %} כל סדרת קושי מתכנסת</li>

</ul>

בתוך כל זה גם הכנסתי את משפט החיתוך של קנטור, בתור דרך <strong>אחרת</strong> להוכיח את בולצאנו ויירשטראס, וקיבלתי מוטיבציה להוכחה של משפט החיתוך של קנטור דווקא מסדרות קושי. זה רומז לנו במעורפל שאולי אפשר גם לקחת את שרשרת ההוכחות הזו בכיוון ההפוך - להתחיל מכך שכל סדרת קושי מתכנסת ולהסיק מכך את בולצאנו ויירשטראס, את ההתכנסות של כל סדרה מונוטונית וחסומה, ואת אקסיומת השלמות.

כלומר, אני מציע שבמקום להתחיל מאקסיומת השלמות, נתחיל ממה שאני אקרא לו "שלמות-קנטור", בזמן שלשלמות ה"רגילה" אני אקרא "שלמות-דדקינד":

<ul> <li><strong>שלמות-קנטור</strong>: כל סדרת קושי מתכנסת.</li>


<li><strong>שלמות-דדקינד</strong>: לכל קבוצה לא ריקה וחסומה קיים חסם עליון.</li>

</ul>

נתחיל אם כן מהאקסיומה שבמספרים הממשיים מתקיימת שלמות-קנטור ונראה לאן נגיע עם זה. כרגיל, אני מזהיר שהמילה <strong>אקסיומה</strong> פה לא אומרת "משהו שברור מאליו ולא צריך להוכיח" אלא "תכונה שהיא בסיסית מספיק כדי שנציין אותה במפורש ואנחנו מצפים מהבניה של המרחב שלנו לוודא שהיא מתקיימת". בבניה של קנטור למספרים הממשיים, שלמות-קנטור היא מה שכל הבניה סובבת סביבו כדי להבטיח שיתקיים, בעוד שבבניה של דדקינד, באופן לא מפתיע, הבניה סובבת סביב להראות ששלמות-דדקינד מתקיימת. את שתי הבניות, כאמור, אני לא אציג בפוסט הזה כי הוא גם ככה ארוך מדי.

בואו נוכיח דברים עם שלמות-קנטור. בראש ובראשונה, את משפט החיתוך של קנטור. כבר התחלתי את זה: הייתה לי סדרה {% equation %}\left\{ C_{n}\right\} _{n=0}^{\infty}{% endequation %} של קטעים <strong>סגורים</strong> כך ש-{% equation %}C_{n}\supseteq C_{n+1}{% endequation %} ו-{% equation %}\lim_{n\to\infty}\left|C_{n}\right|=0{% endequation %}. אמרתי שאני בונה סדרה {% equation %}c_{n}\in C_{n}{% endequation %}. בגלל התכונה {% equation %}C_{n}\supseteq C_{n+1}{% endequation %} נובע שאם {% equation %}n>N{% endequation %} אז {% equation %}a_{n}\in C_{N}{% endequation %}, ולכן קל להראות שזו סדרת קושי: עבור {% equation %}\varepsilon>0{% endequation %} כלשהו, נשתמש בכך ש-{% equation %}\lim_{n\to\infty}\left|C_{n}\right|=0{% endequation %} כדי למצוא {% equation %}N{% endequation %} כך ש-{% equation %}\left|C_{N}\right|<\varepsilon{% endequation %}. כלומר, פורמלית, {% equation %}C_{N}=\left[a_{N},b_{N}\right]{% endequation %} כך ש-{% equation %}\left|a_{N}-b_{N}\right|<\varepsilon{% endequation %}, אבל אפשר לחשוב על זה קצת יותר כללי: לחשוב על{% equation %}\left|C_{n}\right|{% endequation %} בתור סימון של <strong>הקוטר</strong> של הקבוצה {% equation %}C_{N}{% endequation %}, המרחק המקסימלי בין כל שני איברים שלה. כשמכלילים את משפט קנטור למרחבים מטריים כלליים, זה המושג שנעזרים בו.

גם במקרה הפרטי שלנו זה מתקיים: אם {% equation %}x,y\in\left[a,b\right]{% endequation %} אני טוען ש-{% equation %}\left|x-y\right|\le\left|a-b\right|{% endequation %}. כדי לראות את זה צריך קצת חשבונות קטנים וקטנוניים: אני מניח בלי הגבלת הכלליות ש-{% equation %}a\le x\le y\le b{% endequation %} ולכן בפרט {% equation %}-a\ge-x{% endequation %} ולכן {% equation %}b-a\ge y-a\ge y-x{% endequation %} ולכן {% equation %}\left|x-y\right|\le\left|a-b\right|{% endequation %}.

זה נותן לנו את סדרת הקושי שלנו: ניקח {% equation %}n,m>N{% endequation %} אז בגלל ש-{% equation %}c_{n},c_{m}\in C_{N}{% endequation %} נקבל ש-{% equation %}d\left(c_{n},c_{m}\right)\le\left|C_{N}\right|<\varepsilon{% endequation %}, כפי שרצינו. ועכשיו נשתמש בשלמות-קנטור כדי לקבל {% equation %}c{% endequation %} כך ש-{% equation %}c=\lim_{n\to\infty}c_{n}{% endequation %}. זה היה החלק הקריטי - לעבור ממצב שבו אין לנו איבר ביד למצב שבו יש לנו אותו ביד. עכשיו צריך להראות עדיין ש-{% equation %}c\in\bigcap_{n=0}^{\infty}C_{n}{% endequation %} ושהוא האיבר היחיד שמקיים את זה, אבל זה החלק הקל.

ראשית, כדי להראות ש-{% equation %}c\in C_{n}{% endequation %} לכל {% equation %}n\ge0{% endequation %}, נשים לב לכך ש-{% equation %}c{% endequation %} הוא הגבול של הסדרה {% equation %}a_{n},a_{n+1},a_{n+2},\ldots{% endequation %} (כלומר, הסדרה {% equation %}\left\{ c_{n}\right\} _{n=0}^{\infty}{% endequation %} שבניתי כשאני זורק לפח את האיברים הראשונים עד {% equation %}a_{n}{% endequation %}). בגלל התכונה {% equation %}C_{n}\supseteq C_{n+1}{% endequation %} אנחנו יודעים שכל אברי הסדרה הזו שייכים ל-{% equation %}C_{n}{% endequation %}, כך ש-{% equation %}a{% endequation %} הוא גבול של סדרה ששייכת ל-{% equation %}C_{n}{% endequation %}, ו-{% equation %}C_{n}{% endequation %} הוא קטע <strong>סגור</strong> ולכן הוא בפרט <strong>קבוצה סגורה</strong> וההגדרה של קבוצה סגורה היא "קבוצה של הגבולות של איבריה שייכים אליה" ולכן {% equation %}c\in C_{n}{% endequation %}. שכנעתי אתכם? בוודאי שלא, מאיפה שלפתי את ההגדרה הזו של קבוצה סגורה? תכף נחזור לזה.

שנית, בואו נראה את היחידות של {% equation %}c{% endequation %}. ניקח {% equation %}c_{1},c_{2}\in\bigcap_{n=0}^{\infty}C_{n}{% endequation %} כלשהם. כעת, לכל {% equation %}n{% endequation %} מתקיים {% equation %}d\left(c_{1},c_{2}\right)\le\left|C_{n}\right|{% endequation %} כי {% equation %}c_{1},c_{2}\in C_{n}{% endequation %}, ולכן {% equation %}d\left(c_{1},c_{2}\right)\le\lim_{n\to\infty}\left|C_{n}\right|=0{% endequation %} והמסקנה היא ש-{% equation %}d\left(c_{1},c_{2}\right)=0{% endequation %} כלומר {% equation %}c_{1}=c_{2}{% endequation %} (ושוב - זה תרגיל טוב לפרמל את זה עד הסוף אם אתם מרגישים שמשהו חסר). אז הכל פה באמת קל, ורק נשארה לי הטענה "קטע סגור הוא קבוצה סגורה" שלא באמת קשורה להוכחה הזו אלא היא משהו כללי יותר.

כדי לעשות לעצמנו סדר בהגדרות, הנה הן שוב, במפורט:

<ul> <li><strong>קבוצה סגורה</strong> היא קבוצה {% equation %}D{% endequation %} כך שלכל סדרה מתכנסת {% equation %}\left\{ a_{n}\right\} _{n=0}^{\infty}{% endequation %}, אם {% equation %}a_{n}\in D{% endequation %} לכל {% equation %}n{% endequation %}, גם {% equation %}\lim_{n\to\infty}a_{n}\in D{% endequation %}.</li>


<li><strong>קטע סגור</strong> הוא קבוצה מהצורה {% equation %}D=\left[a,b\right]=\left\{ x\in\mathbb{R}\ |\ a\le x\le b\right\} {% endequation %}</li>

</ul>

במבט ראשון לא נראה שיש ביניהן קשר וזה סתם שימוש מבלבל כפול ב"סגור", אבל בפועל קל להראות שקטע סגור הוא אכן קבוצה סגורה. ניקח {% equation %}D=\left[a,b\right]{% endequation %} שכזה. אם יש לנו סדרה מתכנסת {% equation %}\left\{ c_{n}\right\} _{n=0}^{\infty}{% endequation %} שכל אבריה שייכים ל-{% equation %}D{% endequation %}, נסמן את הגבול שלה ב-{% equation %}c=\lim_{n\to\infty}c_{n}{% endequation %}. אם {% equation %}a\le c\le b{% endequation %} הכל בסדר, אז בואו נראה למשל איך מגיעים לסתירה אם {% equation %}c<a{% endequation %}. זה די פשוט: נסמן {% equation %}\varepsilon=a-c{% endequation %}, ולכן על פי הגדרת הגבול קיים {% equation %}c_{n}{% endequation %} כך ש-{% equation %}d\left(c_{n},c\right)<\varepsilon{% endequation %}. אבל {% equation %}c_{n}\in D{% endequation %}, כלומר {% equation %}a\le c_{n}{% endequation %}, כלומר

{% equation %}d\left(c_{n},c\right)=\left|c_{n}-c\right|=c_{n}-c=\left(c_{n}-a\right)+\left(a-c\right)\ge\varepsilon{% endequation %}

וזו סתירה ל-{% equation %}d\left(c_{n},c\right)<\varepsilon{% endequation %}, מה שמסיים את ההוכחה הזו.

סיכום ביניים: הראינו איך שלמות-קנטור גוררת את משפט החיתוך של קנטור, וראינו עוד קודם שמשפט החיתוך של קנטור גורר את בולצאנו-ויירשטראס. מה שנחמד הוא שאפשר לדבר על כל התוצאות הללו בהקשרים כלליים יותר של מרחבים מטריים וההוכחות די דומות, אבל לא אכנס לזה כאן - אנחנו מאוד ממוקדים באובייקט של "שדה סדור שלם".

מה נשאר לנו להראות? ראינו את המשפט על כך שסדרה מונוטונית חסומה היא מתכנסת. האם בולצאנו-ויירשטראס מוכיח אותו? אם {% equation %}\left\{ a_{n}\right\} _{n=0}^{\infty}{% endequation %} היא הסדרה המונוטונית החסומה אז החסימות שלה נותנת לנו את בולצאנו-ויירשטראס ואנחנו מקבלים תת-סדרה {% equation %}\left\{ c_{n}\right\} _{n=0}^{\infty}{% endequation %} שמתכנסת אל {% equation %}c{% endequation %}. שימו לב שבהכרח {% equation %}c_{n}\le c{% endequation %} לכל איבר בתת-הסדרה, בגלל המונוטוניות שלה: אם היה מתקיים {% equation %}c<c_{N}{% endequation %} עבור {% equation %}N{% endequation %} כלשהו, אז עבור {% equation %}\varepsilon=c_{N}-c{% endequation %} היינו מקבלים שלכל {% equation %}n>N{% endequation %}, {% equation %}d\left(c_{n},c\right)=\left(c_{n}-c_{N}\right)+\left(c_{N}-c\right)\ge\varepsilon{% endequation %}.

בואו נוכיח ש-{% equation %}\lim_{n\to\infty}a_{n}=c{% endequation %}: ניקח {% equation %}\varepsilon>0{% endequation %} כלשהו, אז קיים {% equation %}N{% endequation %} כך ש-{% equation %}a_{N}{% endequation %} שייך לתת-הסדרה וגדול מספיק כדי שיתקיים {% equation %}d\left(a_{N},c\right)<\varepsilon{% endequation %}, כלומר {% equation %}c-a_{N}<\varepsilon{% endequation %}. עכשיו, לכל {% equation %}n>N{% endequation %} מתקיים {% equation %}a_{N}<a_{n}\le c{% endequation %} ולכן {% equation %}c-a_{n}<c-a_{N}<\varepsilon{% endequation %}, כמו שרצינו (הסיבה שבגללה {% equation %}a_{n}\le c{% endequation %} היא שאם היה מתקיים {% equation %}a_{n}>c{% endequation %} זה היה מכריח גם איברים של תת-הסדרה שמופיעים בסדרה אחרי {% equation %}a_{n}{% endequation %} להיות גדולים מ-{% equation %}c{% endequation %} וראינו שזה לא יכול לקרות).

אם כן, לסיכום - הראינו איך משלמות-קנטור נובעות אותן התוצאות בחדו"א שעניינו אותנו - מלבד אחת, זו של שלמות-דדקינד עצמה. בשביל זה כדאי לעבור לחלק נוסף ואחרון.

<h2>שלמות דדקינד נגד שלמות קנטור - הקרב האחרון</h2>

מה ראינו עד כה?

<ul> <li>שלמות-דדקינד גוררת את שלמות-קנטור.</li>


<li>שלמות-קנטור גוררת את כל התוצאות שראינו בפוסט בערך חוץ מאשר את שלמות-דדקינד (ולכן בעצם גם המשפט השני של ויירשטראס שמשתמש בה).</li>

</ul>

אם נחזור לטרמינולוגיה של הפוסט הקודם, ראינו ששדה סדור שלם הוא גם שלם-קנטור. למעשה, סביר להניח שחלק נכבד מהקוראים נתקלו בשלמות-קנטור בתור המשמעות של "שלם"; כשמדברים בטופולוגיה על "מרחב מטרי שלם" ועל "השלמה של מרחב מטרי" זה במובן של שלמות-קנטור. האם ההפרדה הזו בין שלמות-דדקינד ושלמות-קנטור היא לא קצת מלאכותית? אי אפשר לקרוא לשני אלו "שלמות" וזהו?

ובכן, למרבה הצער, לא בדיוק.

הטענה "אם {% equation %}\mathbb{F}{% endequation %} הוא שדה סדור שבו כל סדרת קושי מתכנסת, אז הוא שלם" היא פשוט לא נכונה.

מה שנכון, ואני הולך להוכיח, הוא הטענה "אם {% equation %}\mathbb{F}{% endequation %} הוא שדה סדור <strong>ארכימדי</strong> שבו כל סדרת קושי מתכנסת, אז הוא שלם". אבל צריך את הארכימדיות. מה זו ארכימדיות? כזכור, זו התכונה לפיה לכל {% equation %}a\in\mathbb{F}{% endequation %} קיים {% equation %}n\in\mathbb{Z}{% endequation %} כך ש-{% equation %}a<n{% endequation %}. כשיש לנו שדה סדור <strong>שלם</strong> הוא אוטומטית ארכימדי. זה כבר אומר שיהיה לנו קצת קשה להראות דוגמא לשדה סדור שהוא שלם-קנטור אבל לא שלם-דדקינד, כי הוא יצטרך להיות <strong>מוזר</strong> בגלל חוסר הארכימדיות שלו. יש דוגמא סטנדרטית עם שדה של <strong>טורי לורן</strong> אבל אני לא אכנס לזה כאן כי היא טכנית וארוכה. במקום זה אני אעשה משהו טכני וארוך אחר: אוכיח ששדה סדור ארכימדי שבו כל סדרת קושי מתכנסת הוא שלם.

יש כל מני הוכחות שראיתי ואני אלך דווקא על אחת טכנית יחסית כי אני מרגיש שזו דרך טובה להרגיש בידיים "מה הולך פה". אני לוקח קבוצה לא ריקה וחסומה {% equation %}A\subseteq\mathbb{F}{% endequation %} ורוצה להוכיח ש-{% equation %}\sup A{% endequation %} קיים. בשביל זה אני צריך כלי כלשהו שיודע להראות לי שמשהו קיים, והכלי הזה עבורי יהיה משפט החיתוך של קנטור, שכבר ראינו שנובע משלמות-קנטור. הרעיון המרכזי הוא פשוט: נבנה סדרה של קטעים, {% equation %}\left[a_{n},b_{n}\right]{% endequation %}, שמקיימים את התנאים הרגילים של משפט החיתוך כלומר {% equation %}\left[a_{n},b_{n}\right]\supseteq\left[a_{n+1},b_{n+1}\right]{% endequation %} ו-{% equation %}\lim_{n\to\infty}\left(b_{n}-a_{n}\right)=0{% endequation %}, ובנוסף הם מקיימים את התכונה הבאה: לכל {% equation %}n{% endequation %}, {% equation %}b_{n}{% endequation %} הוא <strong>חסם מלעיל</strong> של {% equation %}A{% endequation %} אבל {% equation %}a_{n}{% endequation %} <strong>אינו</strong> חסם מלעיל של {% equation %}A{% endequation %}. עכשיו נשתמש במשפט החיתוך ונקבל {% equation %}c{% endequation %} שמקיים ש-{% equation %}a_{n}\le c\le b_{n}{% endequation %} לכל {% equation %}n{% endequation %}.

מצד אחד, {% equation %}c{% endequation %} חייב להיות חסם מלעיל של {% equation %}A{% endequation %}, כי אם הוא לא היה כזה, אז היה קיים {% equation %}a\in A{% endequation %} כך ש-{% equation %}c<a{% endequation %}, ומכאן בפרט ש-{% equation %}a_{n}<a{% endequation %} לכל {% equation %}n{% endequation %} (כלומר, נקודות הקצה השמאליות של הקטעים שלנו "לא מתקרבות מספיק לקצה של {% equation %}A{% endequation %}"). אבל תזכרו שסדרת נקודות הקצה הימניות, ה-{% equation %}b_{n}{% endequation %}-ים, מתקרבות כרצוננו אל ה-{% equation %}a_{n}{% endequation %}-ים, אז ברור שנוכל להנדס פה סתירה עם טכניקות שכבר ראינו לא אחת בפוסט הבא: נגדיר {% equation %}\varepsilon=a-c{% endequation %} (מכיוון ש-{% equation %}c<a{% endequation %} אז {% equation %}\varepsilon>0{% endequation %}) וניעזר בכך ש-{% equation %}\lim_{n\to\infty}\left(b_{n}-a_{n}\right)=0{% endequation %} כדי למצוא {% equation %}N{% endequation %} עבורו {% equation %}b_{N}-a_{N}<\varepsilon{% endequation %}. אבל עכשיו תראו מה קרה: {% equation %}a_{N}<c<a\le b_{N}{% endequation %}, כשאי השוויון האחרון נובע מכך ש-{% equation %}b_{N}{% endequation %} הוא חסם מלעיל של {% equation %}A{% endequation %} וש-{% equation %}a\in A{% endequation %}. המסקנה מהשרשרת היא ש

{% equation %}\varepsilon=a-c\le b_{N}-c<b_{N}-a_{N}<\varepsilon{% endequation %}

וזו סתירה. אז קיבלנו ש-{% equation %}c{% endequation %} הוא חסם מלעיל של {% equation %}A{% endequation %}. 

בנוסף, אני טוען ש-{% equation %}c{% endequation %} הוא החסם מלעיל המינימלי של {% equation %}A{% endequation %}, כי אם הוא לא היה כזה אז היה קיים {% equation %}b{% endequation %} שהוא חסם מלעיל של {% equation %}A{% endequation %} כך ש-{% equation %}b<c{% endequation %}, ומכאן בפרט ש-{% equation %}b<b_{n}{% endequation %} לכל {% equation %}n{% endequation %} (כלומר, נקודות הקצה הימניות של הקטעים שלנו "הן לא חסמים מלעיל מספיק קטנים של {% equation %}A{% endequation %}"). רואים את הדז'ה-וו? בואו נסיים את זה באותו האופן: נגדיר {% equation %}\varepsilon=c-b{% endequation %} ונמצא {% equation %}N{% endequation %} עבורו {% equation %}b_{N}-a_{N}<\varepsilon{% endequation %} ועכשיו תראו מה קרה: {% equation %}a_{N}\le b<c<b_{N}{% endequation %} כשאי השוויון הראשון נובע מכך ש-{% equation %}b{% endequation %} הוא חסם מלעיל של {% equation %}A{% endequation %} (גדול או שווה לכל אברי {% equation %}A{% endequation %}) ואילו {% equation %}a_{N}{% endequation %} אינו חסם מלעיל כזה (קיים איבר ב-{% equation %}A{% endequation %} שגדול ממנו, ו-{% equation %}b{% endequation %} גדול או שווה מאותו איבר). המסקנה מהשרשרת היא ש

{% equation %}\varepsilon=c-b<b_{N}-b\le b_{N}-a_{N}<\varepsilon{% endequation %}

וזו סתירה. אז קיבלנו ש-{% equation %}c{% endequation %} קטן מכל חסם מלעיל אחר של {% equation %}A{% endequation %}, ולכן הוא החסם מלעיל המינימלי, ולכן {% equation %}c=\sup A{% endequation %}. זה מסיים את החלק התיאורטי יותר בהוכחה ונשאר לעבור לחלק הקונקרטי - איך בונים בפועל סדרת קטעים {% equation %}\left[a_{n},b_{n}\right]{% endequation %} כזו שעוטפת בצורה כל כך אפקטיבית את הקצה הימני של הקבוצה {% equation %}A{% endequation %}? וכאן הארכימדיות הולכת לצוץ בכל הכוח כי בלעדיה יכול להיות חור <strong>עצום</strong> בין קבוצת האיברים ב-{% equation %}A{% endequation %} וקבוצת החסמים מלעיל שלהם.

הרעיון הבסיסי הוא זה: בואו נחלק את כל ציר המספרים למקטעים באורכים קצרים - נאמר, {% equation %}\frac{1}{2}{% endequation %}. עכשיו נעבור על נקודות הקצה של המקטעים הללו: {% equation %}-\frac{1}{2},0,\frac{1}{2},1,\frac{3}{2},\ldots{% endequation %}. מתישהו יגיע הרגע הראשון שבו אנחנו עוברים את {% equation %}A{% endequation %}, כלומר מוצאים מספר {% equation %}\frac{k}{2}{% endequation %} שהוא חסם מלעיל של {% equation %}A{% endequation %} אבל {% equation %}\frac{k-1}{2}{% endequation %} הוא לא חסם מלעיל של {% equation %}A{% endequation %}. כשזה קורה, נסמן {% equation %}a_{1}=\frac{k-1}{2}{% endequation %} ו-{% equation %}b_{1}=\frac{k}{2}{% endequation %}.

איך נגדיר עכשיו את {% equation %}a_{2},b_{2}{% endequation %}? כדאי לחלק את העולם לחלקים <strong>עוד יותר קטנים</strong>, כי ככל שאנחנו מקטינים את העולם ככה הדיוק שלנו משתפר. אבל צריך להיות זהירים <strong>מאוד</strong> כאן: אם למשל אני אחלק את העולם לשלישים, {% equation %}-\frac{1}{3},0,\frac{1}{3},\frac{2}{3},\ldots{% endequation %}, נקודות הקצה ממש לא בהכרח יהיו שיפור ביחס לקודם. למשל, אם הסופרמום של {% equation %}A{% endequation %} הוא {% equation %}\frac{1}{2}{% endequation %} אז נקבל {% equation %}a_{1}=0,b_{1}=\frac{1}{2}{% endequation %} אבל {% equation %}a_{2}=\frac{1}{3},b_{2}=\frac{2}{3}{% endequation %}. במקרה הזה אמנם {% equation %}a_{1}<a_{2}{% endequation %} כפי שהיינו רוצים שיקרה (כי אנחנו רוצים שיתקיים {% equation %}\left[a_{1},b_{1}\right]\supseteq\left[a_{2},b_{2}\right]{% endequation %}) אבל ממש לא מתקיים {% equation %}b_{2}<b_{1}{% endequation %}. אז לא מספיק להגדיל את המכנה - צריך להגדיל אותו בצורה שבעצם לוקחת את החלוקה הקודמת ומחלקת אותה עוד קצת. אם קודם חילקנו לקטעים באורך {% equation %}\frac{1}{2}{% endequation %}, עכשיו משתלם לחלק לקטעים באורך {% equation %}\frac{1}{4}{% endequation %}, וכן הלאה: באופן כללי נחלק לקטעים באורך {% equation %}\frac{1}{2^{n}}{% endequation %}.

אם כן, הבניה שלי תהיה כזו: לכל {% equation %}n\ge1{% endequation %} אני אמצא מספר שלם {% equation %}k_{n}{% endequation %} שהוא המספר השלם המינימלי עבורו {% equation %}\frac{k_{n}}{2^{n}}{% endequation %} הוא חסם מלעיל של {% equation %}A{% endequation %} - כלומר, כך ש-{% equation %}\frac{k_{n}}{2^{n}}{% endequation %} הוא חסם מלעיל של {% equation %}A{% endequation %} אבל {% equation %}\frac{k_{n}-1}{2^{n}}{% endequation %} אינו חסם מלעיל של {% equation %}A{% endequation %} (אני כמובן אצטרך להוכיח שקיים {% equation %}k_{n}{% endequation %} כזה) ואז אגדיר {% equation %}a_{n}=\frac{k_{n}-1}{2^{n}}{% endequation %} ו-{% equation %}b_{n}=\frac{k_{n}}{2^{n}}{% endequation %}.

תחת ההגדרה הזו, {% equation %}b_{n}-a_{n}=\frac{k_{n}-\left(k_{n}-1\right)}{2^{n}}=\frac{1}{2^{n}}{% endequation %} ולכן {% equation %}\lim_{n\to\infty}\left(b_{n}-a_{n}\right)=0{% endequation %} וזה אחד משני הדברים שרצינו עבור תנאי משפט החיתוך של קנטור. הדבר השני שאנחנו צריכים להוכיח הוא {% equation %}\left[a_{n},b_{n}\right]\supseteq\left[a_{n+1},b_{n+1}\right]{% endequation %}.

ראשית, להוכיח ש-{% equation %}b_{n+1}\le b_{n}{% endequation %} יהיה קל יחסית. נסתכל על {% equation %}b_{n}=\frac{k_{n}}{2^{n}}{% endequation %} ונכפול ונחלק את זה ב-2, כלומר

{% equation %}b_{n}=\frac{k_{n}}{2^{n}}=\frac{2k_{n}}{2^{k+1}}{% endequation %}

המכנה עכשיו הוא מה שאנחנו מחפשים. המונה? ובכן, תזכרו שאנחנו לוקחים את {% equation %}k_{n+1}{% endequation %} להיות המספר <strong>הקטן ביותר</strong> עבורו {% equation %}\frac{k_{n+1}}{2^{n+1}}{% endequation %} הוא חסם מלעיל של {% equation %}A{% endequation %} אבל {% equation %}\frac{k_{n+1}-1}{2^{n+1}}{% endequation %} לא. ואנחנו כבר יודעים ש-{% equation %}b_{n}{% endequation %} הוא חסם מלעיל של {% equation %}A{% endequation %}, ולכן {% equation %}k_{n+1}\le2k_{n}{% endequation %}, כלומר קיבלנו

{% equation %}b_{n+1}=\frac{k_{n+1}}{2^{n+1}}\le\frac{2k_{n}}{2^{n+1}}=b_{n}{% endequation %}

יהיה קצת יותר טריקי להראות ש-{% equation %}a_{n}\le a_{n+1}{% endequation %}, כלומר להראות ש-{% equation %}\frac{k_{n}-1}{2^{n}}\le\frac{k_{n+1}-1}{2^{n+1}}{% endequation %}. נכפול את שני האגפים ב-{% equation %}2^{n+1}{% endequation %} ונקבל שמספיק להראות {% equation %}2\left(k_{n}-1\right)\le k_{n+1}-1{% endequation %}, ואחרי העברת אגפים נקבל שמספיק להראות {% equation %}2k_{n}-1\le k_{n+1}{% endequation %}.

כדי לראות את זה, בואו נסתכל על {% equation %}2k_{n}-2{% endequation %}. כזכור, בחרנו את {% equation %}k_{n}{% endequation %} כך ש-{% equation %}\frac{k_{n}}{2^{n}}{% endequation %} הוא חסם מלעיל של {% equation %}A{% endequation %} אבל {% equation %}\frac{k_{n}-1}{2^{n}}{% endequation %} אינו חסם מלעיל שכזה. אם נכפול מונה ומכנה ב-2 נקבל ש-{% equation %}\frac{2k_{n}-2}{2^{n+1}}{% endequation %} אינו חסם מלעיל של {% equation %}A{% endequation %}. אנחנו יודעים ש-{% equation %}\frac{k_{n+1}}{2^{n+1}}{% endequation %} הוא <strong>כן</strong> חסם מלעיל של {% equation %}A{% endequation %} ולכן {% equation %}2k_{n}-2<k_{n+1}{% endequation %}, ומכיוון שבשני האגפים יש מספרים שלמים, הוספת 1 לאגף שמאל יכולה לכל היותר להפוך את אי השוויון לשוויון, אגף שמאל לא יכול להפוך לגדול יותר מאגף ימין. לכן {% equation %}2k_{n}-1\le k_{n+1}{% endequation %}, כפי שרצינו.

כל מה שנשאר לנו לעשות הוא להסביר איך עושים את זה: לכל {% equation %}n{% endequation %}, למצוא מספר שלם {% equation %}k_{n}{% endequation %} כך ש-{% equation %}\frac{k_{n}}{2^{n}}{% endequation %} הוא חסם מלעיל של {% equation %}A{% endequation %} אבל {% equation %}\frac{k_{n}-1}{2^{n}}{% endequation %} אינו חסם מלעיל של {% equation %}A{% endequation %}. 

הנתון שלנו הוא ש-{% equation %}A{% endequation %} היא קבוצה לא ריקה וחסומה. מכך שהיא לא ריקה נסיק שיש {% equation %}x\in A{% endequation %} כלשהו. מכך שהיא חסומה נסיק קיים מספר {% equation %}M\in\mathbb{F}{% endequation %} שהוא חסם מלעיל של {% equation %}A{% endequation %}.

עכשיו הגיע הזמן להשתמש בארכימדיות. אני אצטט את אחד מהניסוחים של ארכימדיות שנתתי בפוסט הקודם:

"עוד דרך לחשוב על זה, שאני אוהב במיוחד, היא זו: בואו ניקח {% equation %}\varepsilon>0{% endequation %} כלשהו, כשהאינטואיציה היא לחשוב על {% equation %}\varepsilon{% endequation %} בתור משהו ממש ממש קטן (זה השימוש הסטנדרטי של האות הזו בחדו"א). בואו ניקח גם {% equation %}M>0{% endequation %} כלשהו, כשהאינטואיציה היא לחשוב עליו בתור מספר ממש ממש ענק. אז ארכימדיות פירושה שקיים {% equation %}n{% endequation %} כך ש-{% equation %}n>\frac{M}{\varepsilon}{% endequation %}, או במילים אחרות {% equation %}n\varepsilon>M{% endequation %}. זה אומר שלא משנה עד כמה משהו קטן - אם אנחנו בשדה ארכימדי, לחבר אותו מספר פעמים לעצמו יגרום לו לעבור בגודלו כל מספר כולל ענקיים."

אוקיי, "מספר ענק" {% equation %}M{% endequation %} כבר יש לנו - זה החסם מלעיל של {% equation %}A{% endequation %}. המספר הקטן שלנו יהיה {% equation %}\varepsilon=\frac{1}{2^{n}}{% endequation %}, והארכימדיות תיתן לנו מספר שלם {% equation %}T{% endequation %} כך ש-{% equation %}\frac{T}{2^{n}}>M{% endequation %} - כלומר, קיבלנו שקיים חסם מלעיל של {% equation %}A{% endequation %} שהוא מהצורה {% equation %}\frac{T}{2^{n}}{% endequation %} כאשר {% equation %}T{% endequation %} שלם. הרעיון הוא שעכשיו אפשר להתחיל "ללכת אחורה" מה-{% equation %}T{% endequation %} הזה עד שמוצאים את הערך המינימלי שעדיין נשאר חסם מלעיל, אבל בשביל זה צריך כמובן להשתכנע שאם נלך <strong>מספיק</strong> אחורה באמת נגיע למצב שבו האיברים שלנו הם כבר לא חסמים מלעיל. כאן נזדקק ל-{% equation %}x\in A{% endequation %} שמצאנו, ולתכונה הארכימדית פעם נוספת.

מה שהייתי רוצה למצוא הוא {% equation %}S{% endequation %} שלם כך ש-{% equation %}\frac{S}{2^{n}}<x{% endequation %}, כי אז {% equation %}\frac{S}{2^{n}}{% endequation %} הוא בודאות לא חסם מלעיל של {% equation %}A{% endequation %}. אבל איך מוצאים את זה עם ארכימדיות, שנותנת לנו משהו <strong>גדול יותר</strong>? בפוסט הקודם אמרנו שזו לא בעיה כי עושים טריק של כפל ב-{% equation %}-1{% endequation %}, אז בואו נעשה טריק של כפל ב-{% equation %}-1{% endequation %}: נשתמש בארכימדיות כדי למצוא {% equation %}R{% endequation %} שלם כך ש-{% equation %}-x<\frac{R}{2^{n}}{% endequation %}, ואז נכפול את שני האגפים ב-{% equation %}-1{% endequation %}, נסמן {% equation %}S=-R{% endequation %} ונקבל שמצאנו {% equation %}S{% endequation %} שלם כך ש-{% equation %}\frac{S}{2^{n}}<x{% endequation %}.

עכשיו סיימנו: קיבלנו את הסדרה הסופית {% equation %}S,S+1,S+2,\ldots,T{% endequation %} שהאיבר הראשון בה <strong>לא נותן</strong> חסם מלעיל של {% equation %}A{% endequation %} והאיבר האחרון בה <strong>כן נותן</strong> חסם מלעיל כזה, אז פשוט ניקח את {% equation %}k_{n}{% endequation %} להיות האיבר <strong>המינימלי</strong> בסדרה שנותן חסם מלעיל. הוא בודאות קיים (כי זו סדרה סופית, ויש לפחות איבר אחד בסדרה שמקיים את הקריטריון הזה) והוא בודאות גדול מ-{% equation %}S{% endequation %} ולכן {% equation %}k_{n}-1{% endequation %} הוא גם כן איבר בסדרה, והוא איבר שעבורו <strong>לא מתקבל</strong> חסם מלעיל של {% equation %}A{% endequation %} - בדיוק מה שרצינו.

אם כן - סיימנו את ההוכחה, הבנו את הקשר בין שלמות-דדקינד ושלמות-קנטור, ועכשיו נשאר לנו רק דבר אחד: להראות את הבניות של קנטור ודדקינד ואיך הן שתיהן נותנות לנו את {% equation %}\mathbb{R}{% endequation %}. 