---
id: 3300
title: "אינטגרלים כפולים, משולשים ו-d-ממדיים"
date: 2015-11-09 17:35:32
layout: post
categories: 
  - אנליזה מתמטית
tags: 
  - אינטגרל
  - אינטגרלים רב ממדיים
  - אנליזה וקטורית
  - משפט פוביני
---
בסדרת הפוסטים שלי על אנליזה וקטורית סיימנו לעת עתה לדבר על נגזרות, ואנחנו עוברים אל עמוד התווך השני של האנליזה - אינטגרלים. הדיון באינטגרלים מתחלק לשלושה שלבים: בשלב הראשון, שהוא מה שנעשה הפעם, אנחנו לוקחים את אינטגרל רימן התמים והנחמד מחדו"א בסיסית ורואים איך ההגדרות שלו מוכללות באופן טבעי ל-{% equation %}\mathbb{R}^{d}{% endequation %} לכל {% equation %}d{% endequation %} טבעי. בשלב השני אנחנו רואים שדרך ההתבוננות הזו היא צרה מדי ובעצם צריך לדבר על עוד סוגים של אינטגרלים שרלוונטיים למרחבים רב-ממדיים, ואז מתחיל לצוץ ערב-רב של משפטים שמחברים את סוגי האינטגרלים השונים (משפטי גרין, גאוס, וסטוקס). בשלב השלישי, המטורלל ביותר, אנחנו מרחיבים מאוד את נקודת המבט שלנו ומגיעים מכך למשפט כללי מאוד (משפט סטוקס הכללי) שמכליל את כל המשפטים הללו, ובאופן כללי אנחנו מצליחים לראות שכל סוגי האינטגרלים השונים הם בעצם היבטים שונים של אותו דבר. זה היעד שאני חותר אליו, אבל הרבה לפני שנגיע לשם, בואו נתחיל מלדבר על ההכללה הפשוטה של אינטגרל רימן, שאנחנו מקבלים על ידי כך שאנחנו לוקחים את ההגדרה הרגילה של אינטגרל רימן ומנסים להפעיל אותה ב-{% equation %}d{% endequation %} ממדים. אנחנו נראה שההגדרות הן פשוטות למדי - אין כאן סיבוך רציני ביחס למה שקורה במימד אחד - אבל שה<strong>חישוב</strong> של אינטגרל כזה הוא מן הסתם מסובך יותר, ובדרך כלל מסתמך על היכולת שלנו לבצע רדוקציה לאינטגרלים במימד אחד.

אני מניח כאן שאתם כבר מכירים אינטגרלים במימד אחד ואין צורך לתת שיחת מוטיבציה מיוחדת או לחזור על ההגדרות במימד אחד. מי שמעוניין יכול לקרוא את <a href="http://www.gadial.net/2010/11/27/integral/">הפוסט שלי בנושא</a>. אז בואו נעבור ישר לאקשן - איך מגדירים את זה?

במימד אחד אינטגרל מוגדר על קטע {% equation %}\left[a,b\right]{% endequation %}. ב-{% equation %}d{% endequation %}-מימדים הוא מוגדר מעל קוביה {% equation %}d{% endequation %}-ממדית, שהיא קבוצה מהצורה {% equation %}Q=\left[a_{1},b_{1}\right]\times\dots\times\left[a_{d},b_{d}\right]{% endequation %}. כלומר, יש לנו פונקציה <strong>חסומה </strong>{% equation %}f:Q\to\mathbb{R}{% endequation %} ואנו רוצים להגדיר את האינטגרל שלה. לקטע מאורך 1 היה <strong>אורך</strong>, {% equation %}b-a{% endequation %}; לקוביה כזו יש <strong>נפח</strong>, {% equation %}v\left(Q\right)\triangleq\prod_{i=1}^{d}\left(b_{i}-a_{i}\right){% endequation %}. במימד אחד הרעיון היה לחלק את הקטע {% equation %}\left[a,b\right]{% endequation %} לחלקים קטנים, לכפול את אורך כל חלק כזה בערך המקסימלי/מינימלי בקטע של הפונקציה שמאנטגרלים, ולסכום. חלוקה של {% equation %}\left[a,b\right]{% endequation %} מסומנת בתור {% equation %}P{% endequation %} (מלשון Partition) והיא סדרה סופית של נקודות בקטע {% equation %}\left[a,b\right]{% endequation %} שכוללת את הקצוות, כלומר {% equation %}P=\left(x_{1},x_{2},\dots,x_{t}\right){% endequation %} כך ש-{% equation %}x_{1}=a,x_{t}=b{% endequation %} ו-{% equation %}x_{1}&lt;x_{2}&lt;\dots&lt;x_{t}{% endequation %}. דרך אחת לחלק קוביה {% equation %}d{% endequation %}-ממדית להרבה קוביות קטנות היא על ידי כך שלוקחים חלוקה של כל אחד מהקטעים שמגדירים את הקוביה, {% equation %}\left(P_{1},\dots,P_{d}\right){% endequation %}, כלומר {% equation %}P_{i}{% endequation %} היא חלוקה של הקטע {% equation %}\left[a_{i},b_{i}\right]{% endequation %}. תחשבו על איך אנחנו מציירים טבלה בדו מימד - קווים אנכיים ואופקיים שחוצים זה את זה ויוצרים ריבועים. כמובן, יש <strong>עוד דרכים</strong> לחלק קוביה {% equation %}d{% endequation %}-ממדית לקוביות קטנות, אבל אנחנו פשוט לא נזקקים להן. העיקר מבחינתנו הוא שבדרך החלוקה שלנו אפשר לקבל חלקים שקטנים עד לאינסוף.

בחלוקה {% equation %}P=\left(P_{1},\dots,P_{d}\right){% endequation %} אנחנו מקבלים תת-קוביות שהן מהצורה {% equation %}I_{1}\times\dots\times I_{d}{% endequation %} כאשר {% equation %}I_{i}{% endequation %} הוא קטע שמוגדר על ידי החלוקה {% equation %}P_{i}{% endequation %}. נסמן תת-קוביה ב-{% equation %}R{% endequation %}. נסמן את הנפח של הקוביה ב-{% equation %}v\left(R\right){% endequation %}. עכשיו, זכרו שיש לנו פונקציה {% equation %}f:Q\to\mathbb{R}{% endequation %}; נסמן ב-{% equation %}M_{R}\left(f\right)=\sup\left\{ f\left(x\right)\ |\ x\in R\right\} {% endequation %} את החסם העליון על הערך של {% equation %}f{% endequation %} במלבן {% equation %}R{% endequation %} ובדומה ב-{% equation %}m_{R}\left(f\right)=\sup\left\{ f\left(x\right)\ |\ x\in R\right\} {% endequation %} את האינפימום (כאן העובדה ש-{% equation %}f{% endequation %} חסומה באה לידי ביטוי, אחרת הערכים הללו לאו דווקא היו מוגדרים והיינו בצרות). עכשיו אפשר לחקות את ההגדרה של סכומי דארבו מאינטגרלים חד ממדיים: להגדיר <strong>סכום תחתון</strong> של הפונקציה {% equation %}f{% endequation %} ביחס לחלוקה {% equation %}P{% endequation %} בתור הסכום {% equation %}L\left(f,P\right)=\sum_{R}m_{R}\left(f\right)v\left(R\right){% endequation %} ואת <strong>הסכום העליון</strong> בתור {% equation %}U\left(L,P\right)=\sum_{R}M_{R}\left(f\right)v\left(R\right){% endequation %} כאשר בשני המקרים הסכום נלקח על כל תת-הקוביות שמוגדרות על ידי {% equation %}P{% endequation %} - קל לראות שהמספר שלהן הוא סופי ולכן הסכום בוודאי מוגדר היטב. השלב האחרון הוא הגדרה של אינטגרל תחתון ועליון: {% equation %}\underline{\int_{Q}}f=\sup_{P}L\left(f,P\right){% endequation %} ו-{% equation %}\overline{\int_{Q}}f=\inf_{P}U\left(f,P\right){% endequation %}. אם {% equation %}\underline{\int_{Q}}f=\overline{\int_{Q}}f{% endequation %} אומרים ש-{% equation %}f{% endequation %} <strong>אינטגרבילית</strong> מעל {% equation %}Q{% endequation %} ומסמנים את הערך המשותף הזה פשוט ב-{% equation %}\int_{Q}f{% endequation %}.

השלב האחרון, של האינטגרל העליון והתחתון, דורש עוד הבהרה מסויימת כדי שיהיה ברור למה "נכון" לנקוט בו. לא קשה לראות שאם ניקח חלוקה קיימת {% equation %}P{% endequation %} ונחלק אותה עוד קצת על ידי הוספת נקודות עד לקבלת חלוקה {% equation %}P^{\prime}{% endequation %}, אנחנו יכולים רק <strong>להגדיל</strong> את הסכום התחתון ו<strong>להקטין</strong> את הסכום העליון, כלומר {% equation %}L\left(f,P\right)\le L\left(f,P^{\prime}\right){% endequation %} ו-{% equation %}U\left(f,P\right)\ge U\left(f,P^{\prime}\right){% endequation %}. למה? כי השטח הכולל שעליו אנחנו סוכמים לא משתנה, אבל ה-{% equation %}M_{R}\left(f\right),m_{R}\left(f\right){% endequation %} שלנו עשויים להשתנות ולהיות יותר מדוייקים. לדוגמה, נאמר שבתת-קוביה עם נפח 10 יש לנו {% equation %}m_{R}\left(f\right)=3{% endequation %}, אז תת-הקוביה הזו תתרום לסכום 30; אבל עכשיו, אם נחלק אותה לשתי תת-קוביות שכל אחד מנפח 5, לא ייתכן שה-{% equation %}m_{R}\left(f\right){% endequation %} של אף אחד משתי תת-הקוביות הללו יהיה קטן יותר מ-3 (אחרת ה-{% equation %}m_{R}\left(f\right){% endequation %} המקורי היה נמוך יותר) ולכן ייתכן, למשל, שבאחת הקוביות הוא עדיין 3 אך בשניה הוא 4, ואז נקבל סכום כולל של {% equation %}3\cdot5+4\cdot5=35{% endequation %}, שגדול מ-30. עוד דבר שברור מייד הוא שעבור חלוקה {% equation %}P{% endequation %} נתונה מתקיים {% equation %}L\left(f,P\right)\le U\left(f,P\right){% endequation %}, פשוט כי {% equation %}\inf{% endequation %} תמיד קטן או שווה ל-{% equation %}\sup{% endequation %} שנלקח על אותה פונקציה ואותו תחום.

עכשיו, בואו ניקח שתי חלוקות {% equation %}P_{1},P_{2}{% endequation %} <strong>כלשהן</strong>. אפשר לבנות מהן חלוקה חדשה שמתקבלת מאיחוד קבוצות הנקודות של שתיהן (חשבו על שתי טבלאות שונות שאנחנו שמים אחת על השניה תוך שימוש בנייר שקוף). נסמן את החלוקה שנקבל כך ב-{% equation %}P^{\prime}{% endequation %}. אז נקבל

{% equation %}L\left(f,P_{1}\right)\le L\left(f,P^{\prime}\right)\le U\left(f,P^{\prime}\right)\le U\left(f,P_{2}\right){% endequation %}

המסקנה: <strong>לכל</strong> שתי חלוקות, הסכום התחתון של האחת קטן מהסכום העליון של השניה. זה מצביע מייד על כך שהסכומים העליונים והתחתונים חסומים, ולכן האינטגרלים העליון והתחתון שהגדרתי אכן מוגדרים היטב, ושהאינטגרל העליון תמיד גדול או שווה מהאינטגרל התחתון, כלומר שניהם מהווים את הקירוב "הטוב ביותר" שאנחנו מסוגלים להשיג בשיטת האינטגרציה הנוכחית שלנו אל מה שאנחנו תופסים בתור האינטגרל של הפונקציה - קירוב אחד הוא מלמעלה והשניה מלמטה, ואם הם משתווים, מה טוב (ואם הם לא משתווים? יש שיטות אינטגרציה חכמות יותר - למשל, אינטגרל לבג - שהדיון בהן שייך לזמן אחר).

כדאי לתת עוד הערה קטנה על הסימון. אינטגרלים במימד אחד לרוב נכתבים בתור {% equation %}\int_{a}^{b}f\left(x\right)dx{% endequation %}. אנחנו שינינו שני דברים. הראשון הוא שאנחנו לא כותבים את הגבולות העליונים והתחתונים אלא סתם כותבים {% equation %}Q{% endequation %}; זה זהה לכך שבמימד אחד היינו כותבים {% equation %}\int_{\left[a,b\right]}f{% endequation %}. הדבר השני הוא שחיסלנו את ה-{% equation %}dx{% endequation %} הזה שתקוע בתוך אינטגרלים במימד אחד. ליצור הזה יש במימד אחד שימוש פרקטי, של להגיד לנו מי משתנה האינטגרציה במקרה שבו ב-{% equation %}f{% endequation %} יש גם פרמטרים; אבל יש לו גם משמעות מעבר לכך, שעדיין לא פירמלנו בהקשר שלנו ולכן בינתיים נוותר עליה לחלוטין.

עם זאת, יש כתיב מקובל לאינטגרלים עבור {% equation %}d=2{% endequation %} ו-{% equation %}d=3{% endequation %} שהכרחי להציג כי הוא מה שמשתמשים בו רוב הזמן בשימושים מעשיים. כאשר {% equation %}d=2{% endequation %} האינטגרל שהגדרנו נקרא <strong>אינטגרל כפול</strong> ומסומן ב-{% equation %}\iint_{Q}f\left(x,y\right)dxdy{% endequation %}, וכאשר {% equation %}d=3{% endequation %} הוא נקרא <strong>אינטגרל משולש</strong> ומסומן ב-{% equation %}\iiint_{Q}f\left(x,y,z\right)dxdydz{% endequation %}. זאת, כמובן, בנוסף לסימון ה"כללי" שכבר הצגתי.

עוד נקודה שכדאי להתייחס אליה כבר עכשיו היא ש-{% equation %}Q{% endequation %} לא חייב להיות קוביה. אפשר להגדיר את האינטגרל על כל קבוצה <strong>חסומה </strong>{% equation %}S{% endequation %}, כאשר "חסומה" פירושו שקיימת קוביה {% equation %}Q{% endequation %} שמכילה אותה. דהיינו, אם יש לנו פונקציה {% equation %}f:S\to\mathbb{R}{% endequation %} יש משמעות לאינטגרל {% equation %}\int_{S}f{% endequation %}. בסיטואציה הזו אפשר להגדיר פונקציה {% equation %}f_{Q}:Q\to\mathbb{R}{% endequation %} כאשר {% equation %}Q{% endequation %} היא קוביה כלשהי שמכילה את {% equation %}S{% endequation %}, ומוגדרת על ידי {% equation %}f_{Q}\left(x\right)=\begin{cases}f\left(x\right) & x\in S\\0 & x\notin S\end{cases}{% endequation %} ואז להגדיר {% equation %}\int_{S}f=\int_{Q}f_{Q}{% endequation %}. כמובן, נדרשת כאן הוכחה לכך שההגדרה הזו <strong>מוגדרת היטב</strong> - שעבור בחירות שונות של {% equation %}Q{% endequation %} נקבל את אותו אינטגרל. אני קופץ על ההוכחה הזו כי אני מניח שהתוצאה אינטואיטיבית מספיק גם כך.

עכשיו עולות מאליהן שתי שאלות - הראשונה, באילו מצבים האינטגרל של {% equation %}f{% endequation %} קיים? ראינו שהיות {% equation %}f{% endequation %} חסומה היא תנאי הכרחי לכך שבכלל ננסה להגדיר את האינטגרל, אבל זה בוודאי לא תנאי מספיק. השאלה השניה היא - אם האינטגרל קיים, איך מחשבים אותו?

נתחיל מהשאלה הראשונה. הדוגמה הנגדית הקלאסית של פונקציה חסומה שאיננה אינטגרבילית היא פונקציית דיריכלה, שבמימד אחד מוגדרת להיות {% equation %}f\left(x\right)=\begin{cases}1 & x\in\mathbb{Q}\\0 & x\notin\mathbb{Q}\end{cases}{% endequation %} - בניסוח אחר, זוהי הפונקציה המציינת של הרציונליים, {% equation %}\chi_{\mathbb{Q}}{% endequation %}. היא לא אינטגרבילית מכיוון שכל קטע לא מנוון מכיל גם רציונליים וגם אי רציונליים, ולכן {% equation %}m_{R}{% endequation %} יוצא תמיד 0 ו-{% equation %}M_{R}{% endequation %} יוצא תמיד 1 ולכן האינטגרל העליון יצא האורך של הקטע שעליו מבצעים את האינטגרציה והאינטגרל התחתון יצא תמיד 0; אותו דבר יקרה גם עבור גרסה {% equation %}d{% endequation %}-ממדית של הפונקציה. עכשיו, אינטגרל לבג שהזכרתי למעלה פותר את הבעיה ויוצא שאינטגרל לבג של הפונקציה הזו הוא 0; האינטואיציה הוא ש-{% equation %}\mathbb{Q}{% endequation %} היא קבוצה "קטנה" למדי מבחינת ה"נפח" (ה<strong>מידה</strong> שלה) ולכן היא לא משפיעה לנו על האינטגרל ואפשר לחשוב על האינטגרל כאילו הוא נלקח רק מעל האי-רציונליים, ומעליהם הפונקציה היא 0 (ברמה אינטואיטיבית יותר, אפשר לשנות כרצוננו את הערכים של הפונקציה על הרציונליים ועדיין לקבל את אותו אינטגרל, ולכן אם נשנה את ערכי הפונקציה ל-0 נקבל את הפונקציה הקבועה 0 ואין פלא שהאינטגרל יוצא 0).

מצד שני, די קל להוכיח שאם {% equation %}f{% endequation %} היא רציפה, אז האינטגרל שלה קיים תמיד. ההוכחה מתבססת על כך שאם {% equation %}f{% endequation %} היא רציפה בקבוצה סגורה וחסומה, אז היא רציפה בה <strong>במידה שווה</strong>. רציפות במידה שווה פירושה שאפשר לתת גודל כלשהו של תת-קוביות, כך ש<strong>כל</strong> זוג נקודות <strong>בכל</strong> תת-מלבן מהגודל הזה יהיו בעלות התכונה שהתמונה של {% equation %}f{% endequation %} עליהן היא יחסית קרובה. פורמלית, לכל {% equation %}\varepsilon&gt;0{% endequation %} קיים {% equation %}\delta&gt;0{% endequation %} כך שאם {% equation %}\left|x_{1}-x_{2}\right|&lt;\delta{% endequation %} אז {% equation %}\left|f\left(x_{1}\right)-f\left(x_{2}\right)\right|&lt;\varepsilon{% endequation %}. המשמעות היא שככל ש-{% equation %}R{% endequation %} נהיה קטן יותר ויותר, כך {% equation %}m_{R}{% endequation %} ו-{% equation %}M_{R}{% endequation %} הופכים לקרובים יותר ויותר, ולכן {% equation %}L\left(f,P\right){% endequation %} ו{% equation %}U\left(f,P\right){% endequation %} מתקרבים יותר ויותר וניתן להראות שהאינטגרלים העליון והתחתון ישתוו. בדרך כלל רואים את ההוכחה הזו עבור אינטגרל חד ממדי ואין טעם לחזור עליה כאן.

המשפט הכללי על אינטגרביליות רימן של {% equation %}f{% endequation %} הוא מעין שילוב של שני הדברים שדיברנו עליהם לעיל: זה לא <strong>הכרחי</strong> שהפונקציה תהיה רציפה, אבל היא צריכה להיות <strong>כמעט רציפה</strong>. הניסוח הפורמלי הוא ש-{% equation %}f{% endequation %} אינטגרבילית רימן ב-{% equation %}Q{% endequation %} אם ורק אם קבוצת נקודות אי-הרציפות שלה ב-{% equation %}Q{% endequation %} היא ממידה אפס. אני לא מוכיח את התוצאה הזו כאן כי לדעתי נכון לדבר עליה רק במסגרת דיון על מידת לבג (למרות שאפשר להגדיר את "מידה אפס" גם בלי להגדיר את מידת לבג הכללית, וזה מה שבדרך כלל עושים בספרי לימוד בנושא - קבוצה היא ממידה אפס אם לכל {% equation %}\varepsilon{% endequation %} אפשר לכסות אותה על ידי סדרת קוביות שסכום נפחיה הכולל - וזה עשוי להיות סכום אינסופי - הוא קטן מ-{% equation %}\varepsilon{% endequation %}). כל הדיון הזה מתבצע לרוב כבר עבור פונקציה חד ממדית; העניין הוא בכך ש-{% equation %}d{% endequation %}-ממדים לא הופכים את הסיפור למסובך כמעט בכלל.

נעבור, אם כן, לשאלה של איך <strong>מחשבים</strong> אינטגרלים {% equation %}d{% endequation %}-ממדים. וכאן זו כבר בעיה קשה בהרבה. התשובה הקצרה היא שלרוב עושים את זה על ידי <strong>רדוקציה</strong> למקרה החד-ממדי, כלומר מסתמכים בעיקר על כך שאנחנו יודעים לפתור אינטגרלים חד-ממדיים, אז כדאי להיזכר מה קורה במקרה החד-ממדי. גם במקרה החד-ממדי, חישוב אינטגרלים יכול להיות עניין קשה. עבור {% equation %}f{% endequation %} שאינה רציפה, לרוב מפצלים את האינטגרל לסכום של כמה אינטגרלים שכל אחד מהם נוגע לתחום שבו {% equation %}f{% endequation %} רציפה. כאשר {% equation %}f{% endequation %} כן רציפה, יש לנו קסם, קסם מדהים לחלוטין, שנקרא <strong>המשפט היסודי של החדו"א</strong>. המשפט הזה אומר שאם {% equation %}f{% endequation %} היא רציפה בקטע {% equation %}\left[a,b\right]{% endequation %} ואם {% equation %}F{% endequation %} היא <strong>פונקציה קדומה</strong> של {% equation %}f{% endequation %}, כלומר מתקיים {% equation %}F^{\prime}=f{% endequation %} - הנגזרת של {% equation %}F{% endequation %} היא {% equation %}f{% endequation %} - אז {% equation %}\int_{a}^{b}f\left(x\right)dx=F\left(b\right)-F\left(a\right){% endequation %}. בעיני זו תוצאה מדהימה לגמרי, וכבר מהפעם הראשונה שבה ראיתי אותה התקשיתי להאמין לה. ה"קסם" פה הוא שכדי לדעת מה האינטגרל של {% equation %}f{% endequation %} על <strong>כל הקטע</strong> {% equation %}\left[a,b\right]{% endequation %} אנחנו רק צריכים לדעת את הערכים של {% equation %}F{% endequation %} <strong>בקצוות הקטע</strong>. איך זה אפשרי בכלל? האם {% equation %}f{% endequation %} לא יכולה "להשתגע" בתוך הקטע? התשובה היא כמובן שהיא יכולה, אבל זה ישפיע על {% equation %}F{% endequation %}. איכשהו {% equation %}F{% endequation %} "דוחסת" את כל המורכבות של {% equation %}f{% endequation %} אל תוך קצוות הקטע. אחרי קצת מחשבה על הנושא המשפט נראה כמעט מובן מאליו - {% equation %}F\left(b\right){% endequation %} הוא <strong>בדיוק</strong> סכום כל השינויים שה"שיגועים" של {% equation %}f{% endequation %} בתוך הקטע גרמו ל-{% equation %}F{% endequation %}, החל מהערך ההתחלתי {% equation %}F\left(a\right){% endequation %} - אבל זה שמבינים למה הקסם עובד לא מפחית מהמגניבות שלו, לטעמי.

למי שעדיין חושבים שהמשפט מגניב, הבשורה הטובה שלי היא שמשפט סטוקס - הדבר המאוד-כללי ומאוד-מאוד-מגניב שאני מבטיח שנגיע אליו כל הזמן - הוא בעצם הכללה אדירה של המשפט היסודי של החדו"א. דוגמה לכך היא במקרה פרטי פשוט במיוחד שלו, <strong>משפט גרין</strong>, שאומר שהאינטגרל הדו-ממדי של פונקציה בקטע שמוגדר על ידי עקום סגור במישור שווה ל<strong>אינטגרל מסלולי</strong> על העקום הזה של משהו שהוא כמו פונקציה קדומה של הפונקציה הדו ממדית. נשמע מעורפל, נכון? כי אני מקדים את זמני ומדבר על הגדרות שעוד לא קיימות כמו "אינטגרל מסלולי". נעזוב את זה לבינתיים.

ה"קסם" שנותן לנו המשפט היסודי של החדו"א לא בא בלי מחיר. בהינתן {% equation %}f{% endequation %}, זה יכול להיות קשה מאוד למצוא לה פונקציה קדומה {% equation %}F{% endequation %}. יש פונקציות תמימות למראה, כמו {% equation %}e^{x^{2}}{% endequation %}, שאין להן פונקציה קדומה שניתנת להצגה בצורה "נחמדה" בכלל. אין אלגוריתם כללי שמאפשר לנו למצוא פונקציה קדומה של פונקציה נתונה (בעוד שעבור נגזרת כן יש אלגוריתם עבור מחלקה רחבה מאוד של פונקציות). יש שלל טריקים מגניבים שמאפשרים להקל על החיפוש, אבל לא אכנס אליהם כרגע.

אם כן, יש לנו פתרון שמבוסס על רדוקציה למקרה החד-ממדי. אני אחזור עוד רגע לשאלה איך עושים את זה, ועם השאלה הזו נסיים את הפוסט, אבל אני כבר רוצה לרמוז אל המקום הבא שאני הולך אליו. הרבה פעמים לפני שמבצעים רדוקציה למקרה החד ממדי אנחנו רוצים להביא את האינטגרל לצורה <strong>פשוטה</strong> יותר, על ידי שינוי של {% equation %}f{% endequation %} לפונקציה שיותר קל לנו לבצע לה אינטגרציה חד-ממדית. התעלול הזה נקרא <strong>החלפת משתנים</strong> (קצת מוקדם מדי להציג דוגמה). המשפט הרלוונטי לעניין מגדיר לנו מה זו "החלפת משתנים" לגיטימית, ואיך האינטגרל הולך להשתנות עקב כך - ההבדל העיקרי הוא שצריך יהיה לכפול את {% equation %}f{% endequation %} ב"תיקון" כלשהו שמחושב מתוך הפונקציה שמבצעת את החלפת המשתנים. התוצאה יוצאת אלגנטית למראה ושימושית בצורה מטורפת; לרוע המזל, <strong>ההוכחה</strong> של המשפט הזה היא אחת מהקשות ביותר שבהן ניתן להיתקל בקורסי המבוא לנושא. אני אקח על עצמי לנסות ולהציג את ההוכחה כאן, ובתקווה לחפף כמה שפחות, אבל זה באמת שייך כבר לפוסט (או סדרת פוסטים) אחר.

בואו נעבור לדוגמה. נניח שאנחנו רוצים לחשב את האינטגרל של {% equation %}f\left(x,y\right)=x+y{% endequation %} על המלבן {% equation %}Q=\left[0,1\right]\times\left[0,1\right]{% endequation %}. חשבו על המלבן הזה כאילו הוא מורכב מאינסוף קווים אופקיים דקים באורך 1 - קו לכל ערך של {% equation %}y{% endequation %} בין 0 ל-1. על כל קו כזה, {% equation %}f\left(x,y\right){% endequation %} היא פונקציה במשתנה יחיד {% equation %}y{% endequation %}, כאשר {% equation %}x{% endequation %} הוא פרמטר - אינטגרל חד ממדי של הדבר הזה אנחנו בוודאי יודעים לחשב לכל {% equation %}x{% endequation %}: {% equation %}\int_{0}^{1}\left(x+y\right)dy=\left[xy+\frac{y^{2}}{2}\right]_{0}^{1}=\frac{1}{2}+x{% endequation %}. עכשיו, {% equation %}f\left(x,y\right){% endequation %} מתאר כמה הערך של הפונקציה {% equation %}f{% endequation %} בקואורדינטה {% equation %}\left(x,y\right){% endequation %} תורם לסכום שהאינטגרל מהווה (כמובן, זה לא שהערך {% equation %}f\left(x,y\right){% endequation %} מתווסף לסכום כמות שהוא; אינטואיטיבית, הוא מתווסף כשהוא משוקלל על פי ה"גודל" של הנקודה {% equation %}\left(x,y\right){% endequation %}, שהוא אינפיניטסימלי. זה שאפשר לפרמל את האינטואיציה הזו ומקבלים משהו שעובד, זה מה שמגניב באינטגרל). באופן דומה, האינטואיציה היא ש-{% equation %}\frac{1}{2}+x{% endequation %} כאן מתאר מה <strong>כל הקו</strong> האנכי עם קו רוחב {% equation %}x{% endequation %} תורם לסכום. לכן כדי לדעת מה הסכום הכולל צריך לבצע אינטגרציה על הערכים הללו - להגדיר פונקציה {% equation %}I\left(x\right)=\frac{1}{2}+x{% endequation %} ולחשב את האינטגרל {% equation %}\int_{0}^{1}I\left(x\right)dx=\int_{0}^{1}\left(\frac{1}{2}+x\right)=\left[\frac{1}{2}x+\frac{1}{2}x^{2}\right]_{0}^{1}=1{% endequation %}.

את כל התהליך הזה אפשר לתאר אינטואיטיבית בעזרת המשוואה הבאה:

{% equation %}\iint_{Q}\left(x+y\right)dxdy=\int_{0}^{1}\left(\int_{0}^{1}\left(x+y\right)dy\right)dx{% endequation %}

כלומר, אנחנו מפרקים את האינטגרל הכפול להפעלה כפולה של אינטגרל רגיל. הסימונים נבחרו בקפידה כדי שההפרדה הזו תיראה לנו טבעית ככל הניתן, אבל מן הסתם זו תוצאה לא טריוויאלית שצריך להוכיח. למרבה המזל, ההוכחה היא יחסית ישירה ולא יהיה לנו קושי לראות אותה כאן.

יש נקודה טכנית מעצבנת אחת שחייבים לתת עליה את הדעת לפני שאני מציג את הניסוח הכללי של המשפט, והיא שלפעמים פירוק לא יכול לעבוד בכלל. הנה דוגמה פשוטה: {% equation %}f\left(x,y\right)=\begin{cases}1 & x=0\wedge y\in\mathbb{Q}\\0 & \mbox{else}\end{cases}{% endequation %}. הפונקציה הזו היא 0 כמעט בכל מקום, למעט נקודות מהצורה {% equation %}\left(0,r\right){% endequation %} כאשר {% equation %}r{% endequation %} הוא מספר רציונלי. אני רוצה להסתכל על האינטגרל שלה על {% equation %}\left[0,1\right]\times\left[0,1\right]{% endequation %}. בבירור הפונקציה אינטגרבילית; כל נקודות אי הרציפות שלה הן על הישר {% equation %}\left(0,y\right){% endequation %}, ולכן הן ממידה אפס (לקו במישור יש מידה אפס, לא קשה להראות את זה). עם זאת, ה"חתך" {% equation %}f_{0}\left(y\right)=f\left(0,y\right){% endequation %} שמתקבל מהצבת {% equation %}x=0{% endequation %} הוא פונקציית דיריכלה שהזכרתי קודם, והיא לא אינטגרבילית. אז אני לא יכול לרשום פירוק כמו {% equation %}\iint_{Q}f\left(x,y\right)dxdy=\int_{0}^{1}\left(\int_{0}^{1}f\left(x,y\right)dy\right)dx{% endequation %} מהטעם הפשוט שה-{% equation %}\int_{0}^{1}f\left(x,y\right)dy{% endequation %} שבפנים לא בהכרח מוגדר (הפונקציה {% equation %}I\left(x\right)=\int_{0}^{1}f\left(x,y\right)dy{% endequation %} לא מוגדרת לכל {% equation %}x{% endequation %}).

פתרון אחד הוא לעבור לדבר על אינטגרל לבג שבו דברים מעצבנים כאלו לא קורים, אבל אין בכך צורך, אפשר לתקן את הבעיה על ידי שימוש באינטגרלים ש<strong>כן</strong> מוגדרים תמיד - האינטרלים העליונים והתחתונים. באיזה מהם להשתמש? לא משנה, שניהם יעבדו. אם כן, בואו נעבור לניסוח הגרסה הכללית של המשפט - <strong>משפט פוביני</strong>: אם {% equation %}f:Q\to\mathbb{R}{% endequation %} היא פונקציה אינטגרבילית, ו-{% equation %}Q=A\times B{% endequation %} כך ש-{% equation %}A{% endequation %}קוביה ב-{% equation %}\mathbb{R}^{k}{% endequation %} ו-{% equation %}B{% endequation %} קוביה ב-{% equation %}\mathbb{R}^{n}{% endequation %}, אז נסמן {% equation %}f\left(x,y\right){% endequation %} בתור הפונקציה {% equation %}f{% endequation %} כאשר חילקנו את המשתנים שלה לשתי קבוצות, ה-{% equation %}x{% endequation %}-ים וה-{% equation %}y{% endequation %}-ים, עבור {% equation %}x\in A{% endequation %} ו-{% equation %}y\in B{% endequation %}. אז

{% equation %}\int_{Q}f=\int_{x\in A}\underline{\int_{y\in B}}f\left(x,y\right)=\int_{x\in A}\overline{\int_{y\in B}}f\left(x,y\right){% endequation %}

ההוכחה היא לא הרבה יותר מאשר משחק זהיר עם קוביות וסכומים עליונים ותחתונים וכל שאר המושגים שראינו בפוסט - הזדמנות טובה לתרגל אותם.

כדי להקל לעצמנו על החיים, בואו נשתמש בסימון המקוצר {% equation %}\underline{I}\left(x\right)=\underline{\int_{y\in B}}f\left(x,y\right){% endequation %} ו-{% equation %}\overline{I}\left(x\right)=\overline{\int_{y\in B}}f\left(x,y\right){% endequation %}. דהיינו, משפט פוביני אומר ש-{% equation %}\int_{A\times B}f\left(x,y\right)=\int_{x\in A}\underline{I}\left(x\right)=\int_{x\in A}\overline{I}\left(x\right){% endequation %}. שימו לב למה שנאמר כאן באופן מובלע - ש-{% equation %}\underline{I}\left(x\right){% endequation %} ו-{% equation %}\overline{I}\left(x\right){% endequation %} הם אינטגרביליים מעל {% equation %}A{% endequation %}. נוכיח את השוויון ואת האינטגרביליות בבת אחת - התעלול יהיה להראות שאפשר לחסום סכומים עליונים ותחתונים של ה-{% equation %}I{% endequation %}-ים בין סכומים עליונים ותחתונים של {% equation %}f{% endequation %}; מכיוון ש-{% equation %}f{% endequation %} אינטגרבילית, הסכומים הללו יכולים להיות קרובים ככל שנרצה, ולכן כך יהיו הסכומים עבור ה-{% equation %}I{% endequation %}-ים.

עכשיו, סכומים עליונים ותחתונים הם תמיד ביחס לחלוקה {% equation %}P{% endequation %} של {% equation %}Q{% endequation %}. חלוקה של קוביה רב-ממדית מורכבת מחלוקות של הצירים, ולכן כל חלוקה {% equation %}P{% endequation %} "מתפרקת" לזוג {% equation %}\left(P_{A},P_{B}\right){% endequation %} של החלוקות של ההיטלים {% equation %}A,B{% endequation %} של {% equation %}Q{% endequation %}. אם נסמן קוביה כלשהי בחלוקה של {% equation %}A{% endequation %} בתור {% equation %}R_{A}{% endequation %}, ובדומה {% equation %}R_{B}{% endequation %} תהיה קוביה בחלוקה של {% equation %}B{% endequation %}, אז {% equation %}R_{A}\times R_{B}{% endequation %} תהיה קוביה בחלוקה של {% equation %}Q{% endequation %}. מה שאני ארצה להוכיח הוא

{% equation %}L\left(f,P\right)\le L\left(\underline{I}\left(x\right),P_{A}\right)\le U\left(\underline{I}\left(x\right),P_{A}\right)\le U\left(f,P\right){% endequation %}

ובאופן דומה גם עבור {% equation %}\overline{I}\left(x\right){% endequation %}. כמובן, אי השוויון האמצעי כבר ידוע לנו. למה אי השוויון הזה מסיים את ההוכחה? כי לכל {% equation %}\varepsilon&gt;0{% endequation %} ניקח {% equation %}P{% endequation %} כך ש-{% equation %}\left|U\left(f,P\right)-L\left(f,P\right)\right|&lt;\varepsilon{% endequation %} (קיים כזה {% equation %}P{% endequation %} כי {% equation %}f{% endequation %} אינטגרבילית). מאי השוויונים נקבל {% equation %}\left|U\left(\underline{I}\left(x\right),P_{A}\right)-L\left(\underline{I}\left(x\right),P_{A}\right)\right|&lt;\varepsilon{% endequation %} וזה מוכיח ש-{% equation %}\sup L\left(\underline{I}\left(x\right),P_{A}\right)=\inf U\left(\underline{I}\left(x\right),P_{A}\right){% endequation %}.

אז בואו ננסה להבין למה {% equation %}L\left(f,P\right)\le L\left(\underline{I}\left(x\right),P_{A}\right){% endequation %}. אם נבין את זה, גם אי השוויון האחר ינבע באותו האופן. בשביל זה נצטרך לרדת רמה אחת נוספת למטה, מרמת הסכום התחתון אל רמת הסכום על קוביה בודדת:

{% equation %}L\left(\underline{I}\left(x\right),P_{A}\right)=\sum_{R_{A}}m_{R_{A}}\left(\underline{I}\right)v\left(R_{A}\right){% endequation %}

{% equation %}L\left(f,P\right)=\sum_{R_{A}\times R_{B}}m_{R_{A}\times R_{B}}\left(f\right)v\left(R_{A}\times R_{B}\right)=\sum_{R_{A}}\sum_{R_{B}}m_{R_{A}\times R_{B}}\left(f\right)v\left(R_{A}\right)v\left(R_{B}\right){% endequation %}

לכן אי השוויון שאנחנו רוצים להוכיח הוא בעצם

{% equation %}\sum_{R_{A}}\sum_{R_{B}}m_{R_{A}\times R_{B}}\left(f\right)v\left(R_{A}\right)v\left(R_{B}\right)\le\sum_{R_{A}}m_{R_{A}}\left(\underline{I}\right)v\left(R_{A}\right){% endequation %}

ואפשר לחלק ב-{% equation %}v\left(R_{A}\right){% endequation %} ולקבל

{% equation %}\sum_{R_{A}}\left[\sum_{R_{B}}m_{R_{A}\times R_{B}}\left(f\right)v\left(R_{B}\right)\right]\le\sum_{R_{A}}m_{R_{A}}\left(\underline{I}\right){% endequation %}

מסקנה: מספיק אם נוכיח, עבור {% equation %}R_{A}{% endequation %} כללי, ש-

{% equation %}\sum_{R_{B}}m_{R_{A}\times R_{B}}\left(f\right)v\left(R_{B}\right)\le m_{R_{A}}\left(\underline{I}\right){% endequation %}

יפה. בואו נתמקד לרגע ב-{% equation %}m_{R_{A}\times R_{B}}\left(f\right){% endequation %}. זהו האינפימום של ערכי {% equation %}f{% endequation %} על הקוביה {% equation %}R_{A}\times R_{B}{% endequation %}. לכן הוא קטן או שווה <strong>לכל</strong> ערך של {% equation %}f{% endequation %} על הקוביה הזו; בפרט, אם נקפיא את {% equation %}x{% endequation %} לרגע (ונסמן אותו {% equation %}x_{0}\in R_{A}{% endequation %} כדי שיהיה ברור, ועכשיו {% equation %}f\left(x_{0},y\right){% endequation %} היא הפונקציה של {% equation %}y{% endequation %} שמתקבלת מהצבה ב-{% equation %}f{% endequation %} כאשר {% equation %}x_{0}{% endequation %} "מוקפא"), אנחנו יודעים ש-{% equation %}m_{R_{A}\times R_{B}}\left(f\right)\le f\left(x_{0},y\right){% endequation %} עבור כל {% equation %}y\in R_{B}{% endequation %}. לכן אם ניקח את האינפימום של אגף ימין, אי השוויון ישתמר: {% equation %}m_{R_{A}\times R_{B}}\left(f\right)\le m_{R_{B}}\left(f\left(x_{0},y\right)\right){% endequation %}

בהינתן {% equation %}x_{0}{% endequation %} קבוע, אי השוויון הזה נכון <strong>לכל</strong> קוביה {% equation %}R_{B}{% endequation %}. לכן הוא ישתמר גם אם נכפול את שני האגפים ב-{% equation %}v\left(R_{B}\right){% endequation %} ונסכום על כלל ה-{% equation %}R_{B}{% endequation %}-ים. קיבלנו:

{% equation %}\sum_{R_{B}}m_{R_{A}\times R_{B}}\left(f\right)v\left(R_{B}\right)\le\sum_{R_{B}}m_{R_{B}}\left(f\left(x_{0},y\right)\right)v\left(R_{B}\right)=L\left(f\left(x_{0},y\right),P_{B}\right)\le\underline{\int_{y\in B}}f\left(x_{0},y\right)=\underline{I}\left(x_{0}\right){% endequation %}

האם סיימנו? כמעט. אגף ימין הוא מה שרצינו לקבל, אבל באגף שמאל צריך להיות {% equation %}m_{R_{A}}\left(\underline{I}\right){% endequation %}. אבל זה מיידי: ראינו שאגף ימין קטן או שווה מכל ערך של {% equation %}\underline{I}{% endequation %} על {% equation %}x{% endequation %} ב-{% equation %}R_{A}{% endequation %}, ולכן אגף ימין יהיה קטן או שווה לאינפימום - וסיימנו.

כאן גם סיימנו עם ההוכחות הפשוטות. האתגר הבא שלי הוא להוכיח את משפט החלפת המשתנים, מה שידרוש לא מעט הכנה מוקדמת ועבודה טכנית. יהיה כיף.
