---
id: 1464
title: "להטיל לכסון סימולטני בתת-מרחב שמור, בערך"
date: 2011-12-24 22:18:01
layout: post
categories: 
  - אלגברה לינארית
tags: 
  - אלגברה לינארית
  - הטלות
  - לכסון סימולטני
  - פולינום מינימלי
  - תת מרחב שמור
---
<h2><strong>תת-מרחבים שמורים</strong></h2>
כזכור, בסדרת הפוסטים על אלגברה לינארית הגענו להתעסק בשאלה הבאה: נתונה טרנספורמציה לינארית {% equation %}T:V\to V{% endequation %} ואנו רוצים למצוא בסיס שבו המטריצה שמייצגת את {% equation %}T{% endequation %} היא פשוטה. המקרה הטוב ביותר כבר טופל: ראינו כי {% equation %}T{% endequation %} מיוצגת בידי מטריצה אלכסונית אם ורק אם יש ל-{% equation %}V{% endequation %} בסיס שכולו מורכב מוקטורים עצמיים של {% equation %}T{% endequation %}. אני רוצה להתחיל בלהיזכר מה הלך בהוכחה הזו.

מה שעשינו היה להראות שוקטורים עצמיים השייכים לערכים עצמיים שונים הם בלתי תלויים לינארית, במובן זה שאם {% equation %}v_{1}+\dots+v_{k}=0{% endequation %} כשכל {% equation %}v_{i}{% endequation %} הוא וקטור המקיים {% equation %}T\left(v_{i}\right)=\lambda_{i}v_{i}{% endequation %} עבור {% equation %}\lambda_{i}{% endequation %}-ים שונים כולם, אז {% equation %}v_{1}=\dots=v_{k}=0{% endequation %}. ואז בא איזה שלב מזוויע שבו כתבתי צירוף לינארי של אוספי וקטורים שכל אחד מהם הוא בסיס לתת-מרחב עצמי אחר... אבל בעצם, עם קצת יותר סימונים והגדרות, אפשר היה לעשות את זה טיפה פחות מזוויע.

את מה שעשינו אפשר היה לנסח גם כך: לכל ערך עצמי {% equation %}\lambda_{i}{% endequation %} הגדרנו תת-מרחב {% equation %}U_{i}\subseteq V{% endequation %} - "המרחב העצמי של {% equation %}\lambda_{i}{% endequation %}" - של כל הוקטורים המקיימים {% equation %}T\left(v\right)=\lambda_{i}v{% endequation %} (כל הוקטורים העצמיים של {% equation %}\lambda_{i}{% endequation %} בתוספת וקטור האפס), ואז ראינו שמתקיים {% equation %}V=U_{1}\oplus\dots\oplus U_{k}{% endequation %}, כאשר {% equation %}U_{1},\dots,U_{k}{% endequation %} הם כל המרחבים העצמיים של הערכים העצמיים של {% equation %}T{% endequation %}. תזכורת: להגיד ש-{% equation %}V=U_{1}\oplus\dots\oplus U_{k}{% endequation %} ("{% equation %}V{% endequation %} הוא סכום ישר של {% equation %}U_{1},\dots,U{}_{k}{% endequation %}") אומר שכל איבר ב-{% equation %}V{% endequation %} ניתן לכתיבה כסכום {% equation %}v_{1}+\dots+v_{k}{% endequation %} של איברים מ-{% equation %}U_{1},\dots,U_{k}{% endequation %}, ושכל המרחבים הללו זרים זה לזה, במובן זה שאם ניקח ולו אחד מהם ונוריד אותו מהסכום, אז לו וליתר הסכום לא יהיה איבר משותף השונה מ-0 (פורמלית {% equation %}U_{i}\cap\left(U_{1}+\dots+U_{i-1}+U_{i+1}+\dots+U_{k}\right)=\left\{ 0\right\} {% endequation %}; אולי טבעי יותר לדרוש ש-{% equation %}U_{i}\cap U_{j}=\left\{ 0\right\} {% endequation %} וחסל אבל זו לא דרישה חזקה מספיק). זה תרגיל טוב להוכיח שהדרישה השניה שקולה לכך שדרך ההצגה של איבר ב-{% equation %}V{% endequation %} כסכום איברים מתתי-המרחבים תהיה <strong>יחידה</strong>.

עכשיו, לכתוב את {% equation %}V{% endequation %} כסכום ישר של תתי-מרחבים כלשהם זה דבר קל למדי - קחו כל בסיס שתרצו, חלקו את אברי הבסיס לכמה קבוצות שתרצו, ותת-המרחבים שנפרסים על ידי אברי הקבוצות (כל תת-מרחב נפרס על ידי אברי קבוצה אחת) יהוו סכום ישר שנותן את {% equation %}V{% endequation %}. יש אינספור דרכים לפרק את {% equation %}V{% endequation %} כך, ורובן לא אומרות לנו משהו מועיל על הטרנספורמציה הלינארית {% equation %}T{% endequation %}. העסק מתחיל להיות מעניין כאשר יש לנו תת-מרחב {% equation %}W{% endequation %} שמקיים את התכונה "כל מה שקורה ב-{% equation %}W{% endequation %} (על ידי {% equation %}T{% endequation %}) נשאר ב-{% equation %}W{% endequation %}", ופורמלית {% equation %}T\left(W\right)\subseteq W{% endequation %} (התמונה של כל איבר ב-{% equation %}W{% endequation %} על ידי {% equation %}T{% endequation %} נמצאת גם היא ב-{% equation %}W{% endequation %}). תת-מרחב כזה נקרא <strong>תת-מרחב שמור</strong> (ביחס ל-{% equation %}T{% endequation %}).

מכיוון שבמבט ראשון אולי לא ברור למה זו הגדרה מעניינת, בואו ונבין ראשית כל מה ינבע מכך שאני יודע לכתוב את {% equation %}V{% endequation %} בתור סכום ישר {% equation %}U\oplus W{% endequation %} כאשר {% equation %}U,W{% endequation %} שניהם תתי-מרחבים שמורים של {% equation %}T{% endequation %}. ניקח בסיס ל-{% equation %}U{% endequation %} ובסיס ל-{% equation %}W{% endequation %} ואז איחודם הוא בסיס ל-{% equation %}V{% endequation %} ואפשר להסתכל על המטריצה המיצגת של {% equation %}T{% endequation %} בבסיס הזה. אז אני טוען שהמטריצה המייצגת תורכב משני <strong>בלוקים</strong> - תת-מטריצות ריבועיות מסויימות, כך שכל שאר המטריצה שווה לאפס. משהו כזה: {% equation %}\left[T\right]_{V}=\left[\begin{array}{cc}\left[T\right]_{U} & 0\\0 & \left[T\right]_{W}\end{array}\right]{% endequation %} (כאן אני מתעלל בסימונים בצורה נוראית - {% equation %}\left[T\right]_{V}{% endequation %} כאן פירושו "המטריצה המייצגת של {% equation %}T{% endequation %} בבסיס שזה עתה דיברתי עליו של {% equation %}V{% endequation %}; באופן כללי אין לסימון {% equation %}\left[T\right]_{V}{% endequation %} משמעות כי לכל בסיס של {% equation %}V{% endequation %} שניקח נקבל מטריצה מייצגת אחרת). שימו לב ששני הבלוקים של המטריצה אינם כוללים תוכן מקרי, אלא את המטריצה המייצגת של {% equation %}T{% endequation %} לפי הבסיסים של תתי-המרחבים. הסיבה שבגללה זה עובד היא שאם נפעיל את {% equation %}T{% endequation %} על איבר בסיס של {% equation %}U{% endequation %} נקבל איבר ב-{% equation %}U{% endequation %} ולכן הוא יוצג כצירוף לינארי של אברי {% equation %}U{% endequation %} בלבד; אברי {% equation %}W{% endequation %} לא משתתפים בכלל במשחק. לכן על עמודה שמתאימה לאיבר בסיס של {% equation %}U{% endequation %} מכילה אפסים בשורות שמתאימות לבסיס של {% equation %}W{% endequation %}, ואותו הדבר גם עבור העמודות שמתאימות לאברי בסיס של {% equation %}W{% endequation %}. אותיר לכם לכתוב את ההוכחה הפורמלית לעצמכם אם אתם עוד לא משוכנעים.

מכאן ממשיכים באינדוקציה ומקבלים את התוצאה הכללית: אם {% equation %}V=V_{1}\oplus\dots\oplus V_{k}{% endequation %} כך ש-{% equation %}V_{i}{% endequation %} הם תתי-מרחבים שמורים של {% equation %}T{% endequation %}, אז כאשר מייצגים את {% equation %}T{% endequation %} בבסיס שהוא איחוד הבסיסים של אותם תת-מרחבים, {% equation %}T{% endequation %} היא מטריצה בת {% equation %}k{% endequation %} בלוקים. מה שמעניין אותנו עכשיו הוא אם אפשר להגיד עוד משהו על האופן שבו {% equation %}T{% endequation %} מתפרקת בין כל תתי-המרחבים השמורים, וכמובן לשאול את עצמנו האם פירוק כזה קיים בכלל.

תתי-מרחבים שמורים הם הכללה ברורה של מרחבים עצמיים. אם {% equation %}U{% endequation %} הוא מרחב עצמי של טרנספורמציה {% equation %}T{% endequation %} הוא בוודאי יהיה תת-מרחב שמור שלה, כי כל מה שהפעלת {% equation %}T{% endequation %} על איבר ב-{% equation %}U{% endequation %} עושה היא לכפול אותו בסקלר, וזו פעולה שמשאירה את התוצאה בתוך התת-מרחב מעצם הההגדרה של תת-מרחב. למעשה, אם {% equation %}v{% endequation %} הוא וקטור עצמי אז תת-המרחב שנפרש על ידו בלבד הוא תת-מרחב שמור. זה מבהיר לנו מייד מדוע אם יש למרחב בסיס של וקטורים עצמיים אז {% equation %}T{% endequation %} לכסינה בבסיס זה - במקרה זה אפשר לפרק את {% equation %}V{% endequation %} לסכום ישר של {% equation %}n{% endequation %} תתי-מרחבים שכל אחד מהם ממימד 1, ולכן המטריצה שמייצגת את {% equation %}T{% endequation %} היא מטריצת "בלוקים" שבה כל בלוק הוא מטריצה מסדר {% equation %}1\times1{% endequation %}. אין כאן שום רעיון חדש - הנימוק שכבר הבאתי לכך שטרנספורמציה היא לכסינה אם יש בסיס של וקטורים עצמיים השתמש באותם נימוקים שבהם השתמשתי כאן כדי להסביר איך מתקבלת מטריצת בלוקים - אבל זו עדיין דרך מחשבה נחמדה.

אם {% equation %}W\subset V{% endequation %} הוא תת-מרחב שמור של {% equation %}T{% endequation %}, אז אפשר להסתכל על {% equation %}T{% endequation %} כאשר היא מצומצמת רק לתת-מרחב {% equation %}W{% endequation %}. בואו נגדיר את זה פורמלית כדי למנוע בלבול: יש לנו טרנספורמציה {% equation %}T:V\to V{% endequation %}, ואפשר להגדיר טרנספורמציה חדשה {% equation %}T_{W}:W\to W{% endequation %} שפשוט מוגדרת בתור {% equation %}T_{W}\left(w\right)=T\left(w\right){% endequation %} לכל {% equation %}w\in W{% endequation %}. הנקודה היא שבגלל ש-{% equation %}T_{W}{% endequation %} מוגדרת על מרחב קטן יותר, קל יותר לחקור אותה - למשל, המטריצה המייצגת שלה תהיה קטנה יותר. עוד תכונה מעניינת שתהיה רלוונטית בהמשך היא שהפולינום המינימלי של {% equation %}T_{W}{% endequation %} מחלק את הפולינום המינימלי של {% equation %}T{% endequation %}, אבל הם ממש לא חייבים להיות זהים. למה הוא מחלק? ובכן, אם {% equation %}m\left(T\right){% endequation %} היא טרנספורמציית האפס על {% equation %}V{% endequation %} זה אומר שהיא מחזירה 0 לכל איבר של {% equation %}V{% endequation %} ולכן בפרט לכל איבר של {% equation %}W{% endequation %}, ולכן {% equation %}p{% endequation %} הוא פולינום שמאפס את {% equation %}T_{W}{% endequation %}; אבל כזכור, הפולינום המינימלי של {% equation %}T_{W}{% endequation %} מחלק כל פולינום אחר שמאפס את {% equation %}T_{W}{% endequation %}.
<h2><strong>לכסון סימולטני</strong></h2>
בואו נעבור להמחשה של השימוש במושג של תת-מרחבים שמורים - לכסון סימולטני של טרנספורמציות (או מטריצות; זכרו שעבורנו זה אותו הדבר). בואו נניח ש-{% equation %}S,T{% endequation %} הם שני אופרטורים לכסינים; זה אומר שקיים בסיס שבו {% equation %}T{% endequation %} מיוצגת על ידי מטריצה אלכסונית, וקיים בסיס שבו {% equation %}S{% endequation %} מיוצגת על ידי מטריצה אלכסונית, אבל האם קיים בסיס שבו <strong>שתיהן גם יחד</strong> מיוצגות על ידי מטריצה אלכסונית? התשובה היא שלא תמיד; קל לראות שהכרחי שהן <strong>יתחלפו</strong>, כלומר שיתקיים {% equation %}ST=TS{% endequation %} (זכרו שטרנספורמציות ומטריצות לא מתחלפות תמיד בכפל - נסו למצוא דוגמאות!). הסיבה לכך היא שמטריצות אלכסוניות כן מתחלפות בכפל, ולכן אם {% equation %}S,T{% endequation %} ניתנות בו זמנית להצגה בידי מטריצות אלכסוניות הן אכן יתחלפו בכפל. זו דוגמה לתנאי הכרחי, אבל מה שמפתיע כאן הוא שהוא גם מספיק: שתי טרנספורמציות לכסינות הן בעלות לכסון משותף אם ורק אם הן מתחלפות בכפל. למעשה, ההוכחה שאציג כעת עובדת גם אם יש יותר משתי טרנספורמציות - אפילו עבור מספר אינסופי שלהן, כל עוד כולן לכסינות וכל זוג טרנספורמציות מתחלפות בכפל.

תכונת ההתחלפות-בכפל תועיל לי באופן הבא: נניח של-{% equation %}T{% endequation %} יש ערך עצמי {% equation %}\lambda{% endequation %}, אז המרחב העצמי השייך לערך העצמי הזה הוא בעצם הגרעין של הטרנספורמציה {% equation %}T-\lambda I{% endequation %}, ואם {% equation %}T{% endequation %} מתחלף עם {% equation %}S{% endequation %} כך גם הטרנספורמציה {% equation %}T-\lambda I{% endequation %}. כעת אני יכול לטעון טענה כללית קצת יותר: אם {% equation %}U,S{% endequation %} טרנספורמציות לינאריות שמתחלפות בכפל, אז הגרעין של {% equation %}U{% endequation %} הוא תת-מרחב שמור של {% equation %}S{% endequation %}, שהרי אם {% equation %}u{% endequation %} נמצא בגרעין הזה נקבל ש-{% equation %}US\left(u\right)=SU\left(u\right)=S\left(0\right)=0{% endequation %}, כלומר גם {% equation %}S\left(u\right){% endequation %} בגרעין של {% equation %}U{% endequation %}.

מכאן נובע המשפט על לכסינות סימולטנית כמעט מאליו: אם לכל הטרנספורמציות יש רק ערך עצמי אחד אז כל בסיס שנבחר ילכסן את כולן בו זמנית (זכרו שהן לכסינות, כלומר הריבוי הגיאומטרי של הערך העצמי היחיד של כל אחת מהן הוא מימד {% equation %}V{% endequation %}). בואו נניח אם כן שיש {% equation %}T{% endequation %} עם יותר מערך עצמי אחד, {% equation %}\lambda_{1},\dots,\lambda_{t}{% endequation %}. זה מגדיר פירוק של {% equation %}V{% endequation %} לתת-מרחבים עצמיים: {% equation %}V=W_{1}\oplus\dots\oplus W_{t}{% endequation %} כש-{% equation %}W_{i}{% endequation %} הוא המרחב העצמי של {% equation %}T{% endequation %} שמתאים לערך העצמי {% equation %}i{% endequation %}. כעת בואו ניקח טרנספורמציה אחרת {% equation %}S{% endequation %}. אני בהחלט <strong>לא</strong> יכול לומר ש-{% equation %}W_{i}{% endequation %} הוא מרחב עצמי שלה, אבל בגלל שהיא מתחלפת עם {% equation %}T{% endequation %} אני בהחלט <strong>כן</strong> יכול לומר שהוא תת-מרחב שמור שלה, מהנימוק שהבאתי קודם (במקרה הזה, {% equation %}U=T-\lambda I{% endequation %}). מה שנותר עכשיו לשים לב אליו הוא שכל {% equation %}S{% endequation %} היא לכסינה גם כשהיא מצומצמת ל-{% equation %}W_{i}{% endequation %} כי הפולינום המינימלי שלה ב-{% equation %}W_{i}{% endequation %} מחלק את הפולינום המינימלי שלה ב-{% equation %}V{% endequation %} (כאן אני מתבסס על טענה שטרם הוכחתי - שמטריצה היא לכסינה אם ורק אם לפולינום המינימלי שלה אין שורשים מרובים), ולכן אפשר באינדוקציה להניח שכל הצמצומים של הטרנספורמציות על {% equation %}W_{i}{% endequation %} הן לכסינות סימולטנית ולסיים על ידי איחוד כל הבסיסים המלכסנים-סימולטנית של כל ה-{% equation %}W_{i}{% endequation %}.

למי שנראה לו שרימתי עם האינדוקציה בסוף, שימו לב לכך שבמרחב ממימד 1 כל בחירת בסיס "תלכסן סימולטנית" את כל הטרנספורמציות כי מטריצה {% equation %}1\times1{% endequation %} היא תמיד אלכסונית; ושבגלל שבחרתי לעבוד עם {% equation %}T{% endequation %} שיש לה יותר מערך עצמי אחד, יש לה יותר מ-{% equation %}W_{i}{% endequation %} אחד ולכן המימד של כולם קטן יותר מהמימד של {% equation %}V{% endequation %} ואפשר להשתמש באינדוקציה. ההוכחה הזו מבליטה היטב את הכוח שבדיבור על תתי-מרחבים שמורים - הם מאפשרים להוכיח דברים בשיטת הפרד ומשול.
<h2><strong>הטלות</strong></h2>
בואו נשכח לרגע מתתי-מרחבים שמורים ונדבר על פירוק כלשהו לסכום ישר, {% equation %}V=W_{1}\oplus\dots\oplus W_{k}{% endequation %}. בכל פירוק שכזה יש טרנספורמציות לינאריות שמאפיינות את הפירוק בדיוק כשם ש-{% equation %}W_{1},\dots,W_{k}{% endequation %} מאפיינות אותו - <strong>ההטלות</strong> למרחבים {% equation %}W_{1},\dots,W_{k}{% endequation %}. פורמלית נהוג להגדיר באלגברה לינארית <strong>הטלה</strong> בתור כל טרנספורמציה לינארית {% equation %}T:V\to V{% endequation %} המקיימת {% equation %}T^{2}=T{% endequation %}. בואו נבין למה: נסמן {% equation %}U=\mbox{Im}T{% endequation %}, ניקח בסיס ל-{% equation %}U{% endequation %} ונשלים אותו לבסיס של {% equation %}V{% endequation %} וניקח את אברי הבסיס שאינם של {% equation %}U{% endequation %} ונביט במרחב {% equation %}U^{\prime}{% endequation %} שהם פורשים - נקבל ש-{% equation %}V=U\oplus U^{\prime}{% endequation %}, ושאת {% equation %}T{% endequation %} אפשר לתאר כך: אם {% equation %}v=u+u^{\prime}{% endequation %} כאשר {% equation %}u\in U{% endequation %} ו-{% equation %}u^{\prime}\in U^{\prime}{% endequation %} (קיימת בדיוק דרך אחת להציג כך את {% equation %}v{% endequation %}) אז {% equation %}T\left(v\right)=u{% endequation %}, כלומר {% equation %}T{% endequation %} לוקחת את הרכיב של {% equation %}v{% endequation %} שנמצא בתוך {% equation %}U{% endequation %} ומוחקת את היתר. זה מתאים לאינטואיציה שיש לנו לגבי הטלות "קלאסיות" (הטלות כאלו הן בדרך כלל ביחס למערכת צירים שבה הצירים מאונכים זה לזה; גם לכך נגיע בסדרת הפוסטים הזו, אבל עוד חזון למועד).

את הרעיון הזה אפשר להכליל למקרה של {% equation %}V=W_{1}\oplus\dots\oplus W_{k}{% endequation %}. במקרה הזה, כל וקטור {% equation %}v{% endequation %} ניתן להציג בצורה יחידה כ-{% equation %}v=w_{1}+\dots+w_{k}{% endequation %} כאשר {% equation %}w_{i}\in W_{i}{% endequation %}; נגדיר טרנספורמציה לינארית {% equation %}E_{i}:V\to V{% endequation %} על ידי {% equation %}E_{i}\left(v\right)=w_{i}{% endequation %}. קל לראות שזוהי הטלה, כלומר {% equation %}E_{i}^{2}=E_{i}{% endequation %}וקל לראות ש={% equation %}\mbox{Im}E_{i}=W_{i}{% endequation %}. מההגדרה נובע גם כמעט מייד ש-{% equation %}E_{i}E_{j}=0{% endequation %} אם {% equation %}i\ne j{% endequation %}, ועם עוד טיפה עבודה אפשר לראות ש-{% equation %}I=\sum E_{i}{% endequation %}, כלומר הסכום של כל ההטלות הללו נותן לנו את טרנספורמציית הזהות.

מה שבאמת מעניין הוא שכל קבוצה של {% equation %}k{% endequation %} הטלות {% equation %}E_{1},\dots,E_{k}{% endequation %} שמקיימות את התכונה שהרכבה של שתיים מהן היא אפס וסכום כולן הוא הזהות מגדירות פירוק של {% equation %}V{% endequation %} לסכום ישר של מרחבים שהם התמונות של ההטלות. גם זו טענה קלה יחסית אבל אוכיח אותה כאן כי היא לא מיידית כמו הכיוון השני. לפני כן רק אסביר לאן אני חותר עם זה - לב האתגר במשפט הפירוק הפרימרי (שהוא המטרה העיקרית של הפוסט הזה ואחד מה"גביעים הקדושים" בסדרת הפוסטים כולה באופן כללי) הוא למצוא הטלות שמקיימות תכונות מסויימות, ואז הפירוק נובע מהן בדיוק על פי המשפט שזה עתה אוכיח.

טוב, אז מה עושים? ראשית מגדירים {% equation %}W_{i}=\mbox{Im}E_{i}{% endequation %}. עכשיו צריך להראות גם שכל איבר ב-{% equation %}V{% endequation %} ניתן לכתיבה כסכום של איברים ב-{% equation %}W_{i}{% endequation %}-ים הללו, וגם שדרך ההצגה הזו היא יחידה. התכונה הראשונה נובעת מכך ש-{% equation %}I=\sum E_{i}{% endequation %}: פשוט נשים לב לכך ש-{% equation %}v=I\left(v\right)=\sum E_{i}\left(v\right){% endequation %} והנה קיבלנו הצגה של {% equation %}v{% endequation %} כסכום של איברים ב-{% equation %}W_{i}{% endequation %}. כדי לראות שדרך ההצגה הזו היא יחידה, בואו קודם כל נשים לב לכך שאם {% equation %}v\in W_{i}{% endequation %} אז {% equation %}E_{i}\left(v\right)=v{% endequation %} ואילו {% equation %}E_{j}\left(v\right)=0{% endequation %}. למה? כי אם {% equation %}v\in W_{i}{% endequation %} זה אומר ש-{% equation %}v{% endequation %} הוא בתמונה של {% equation %}E_{i}{% endequation %}, כלומר {% equation %}v=E_{i}\left(u\right){% endequation %}, ולכן {% equation %}E_{i}\left(v\right)=E_{i}^{2}\left(u\right)=E_{i}\left(u\right)=v{% endequation %} ובדומה, {% equation %}E_{j}\left(v\right)=E_{j}E_{i}\left(u\right)=0{% endequation %}.

כעת, אם {% equation %}v=w_{1}+\dots+w_{k}{% endequation %} אז מהתכונות לעיל נובע ש-{% equation %}E_{i}\left(v\right)=w_{i}{% endequation %} - אבל הערך של {% equation %}E_{i}\left(v\right){% endequation %} ודאי אינו תלוי באופן שבו אנו בוחרים לפרק את {% equation %}v{% endequation %} לסכום! במילים אחרות, גם אם היינו כותבים {% equation %}v=\alpha_{1}+\dots+\alpha_{k}{% endequation %} כך ש-{% equation %}\alpha_{i}\in W_{i}{% endequation %} היינו מקבלים {% equation %}E_{i}\left(v\right)=\alpha_{i}{% endequation %} ולכן {% equation %}w_{i}=\alpha_{i}{% endequation %} ודרך ההצגה הזו היא יחידה.

עכשיו אפשר לחזור למרחבים שמורים. מה שמעניין אותנו הוא השאלה הבאה: נתון פירוק {% equation %}V=W_{1}\oplus\dots\oplus W_{k}{% endequation %} ונתונה טרנספורמציה {% equation %}T{% endequation %} - מתי כל המרחבים {% equation %}W_{i}{% endequation %} הם תתי-מרחבים שמורים של {% equation %}T{% endequation %}? התשובה מקסימה, לטעמי, באלגנטיות שלה: אם ורק אם {% equation %}T{% endequation %} מתחלפת עם ההטלות {% equation %}E_{i}{% endequation %} המתאימות למרחבים.

כיוון אחד הוא קלי קלות: אם {% equation %}T{% endequation %} מתחלפת עם {% equation %}E_{i}{% endequation %} ו-{% equation %}w\in W_{i}{% endequation %} אז {% equation %}T\left(w\right)=TE_{i}\left(w\right)=E_{i}T\left(w\right)\in W{% endequation %} כשסימן השייכות בסוף נובע מכך ש-{% equation %}W_{i}{% endequation %} הוא תמונת {% equation %}E_{i}{% endequation %}. מה שמעניין הוא הכיוון השני, להראות ש-{% equation %}T{% endequation %} מתחלפת עם {% equation %}E_{i}{% endequation %}.

אם כן, הבה וניקח {% equation %}v\in V{% endequation %} כלשהו ונפרק אותו לרכיביו, {% equation %}v=\sum w_{i}{% endequation %}. אז {% equation %}T\left(v\right)=\sum T\left(w_{i}\right)=\sum u_{i}{% endequation %} כאשר {% equation %}u_{i}\in W_{i}{% endequation %} - זה נובע מכך שמדובר על תתי-מרחבים שמורים של {% equation %}T{% endequation %}. כעת הבה ונפעיל על כל זה הטלה: {% equation %}E_{i}T\left(v\right)=u_{i}{% endequation %} (מאותן סיבות שכבר ראינו עד כה). מצד שני, {% equation %}TE_{i}\left(v\right)=T\left(w_{i}\right)=u_{i}=E_{i}T\left(v\right){% endequation %}, והנה קיבלנו ש-{% equation %}TE_{i}=ET_{i}{% endequation %} (כי ההוכחה הייתה על {% equation %}v{% endequation %} כלשהו).

הדבר הבא שאני רוצה להראות הוא אפיון אלטרנטיבי ללכסינות, שבכלל לא מדבר על ערכים עצמיים, בסיסים, ריבוי אלגברי וגאומטרי ושום דבר דומה לזה, אלא רק על הטלות. בואו נתחיל מכך שאם {% equation %}T{% endequation %} לכסינה עם ערכים עצמיים {% equation %}\lambda_{1},\dots,\lambda_{k}{% endequation %} אז כפי שכבר אמרתי מאות פעמים, אפשר לפרק את {% equation %}V{% endequation %} לסכום של מרחבים עצמיים. בואו ניקח את {% equation %}E_{1},\dots,E_{k}{% endequation %} להיות ההטלות על אותם מרחבים עצמיים, אז כמו תמיד הן יקיימו {% equation %}I=\sum E_{i}{% endequation %} ו-{% equation %}E_{i}E_{j}=0{% endequation %} לכל {% equation %}i\ne j{% endequation %}. יופי. רק שהן יקיימו הפעם תכונה נוספת: {% equation %}T=\sum\lambda_{i}E_{i}{% endequation %}. למה? ובכן, קחו {% equation %}v\in V{% endequation %} כלשהו, אז כמקודם {% equation %}v=I\left(v\right)=\sum E_{i}\left(v\right){% endequation %}, ומכיוון ש-{% equation %}E_{i}\left(v\right){% endequation %} נמצא במרחב העצמי {% equation %}W_{i}{% endequation %} אז {% equation %}T\left(E_{i}\left(v\right)\right)=\lambda_{i}E_{i}\left(v\right){% endequation %}, כלומר {% equation %}T\left(v\right)=\sum\lambda_{i}E_{i}\left(v\right){% endequation %} לכל {% equation %}v{% endequation %}, ולכן {% equation %}T=\sum\lambda_{i}E_{i}{% endequation %}.

מסתבר שהתכונה הזו היא גם מספיקה כדי ש-{% equation %}T{% endequation %} תהיה לכסינה. במילים אחרות, {% equation %}T{% endequation %} לכסינה אם קיימים סקלרים שונים {% equation %}\lambda_{1},\dots,\lambda_{k}{% endequation %} וטרנספורמציות לינאריות {% equation %}E_{1},\dots,E_{k}{% endequation %} שונות מאפס כך ש-{% equation %}T=\sum\lambda_{i}E_{i}{% endequation %} ו-{% equation %}I=\sum E_{i}{% endequation %} ו-{% equation %}E_{i}E_{j}=0{% endequation %} (ובאופן צפוי, {% equation %}\lambda_{i}{% endequation %} הם הערכים העצמיים שלה, ו-{% equation %}E_{i}^{2}=E_{i}{% endequation %} כך ש-{% equation %}E_{i}{% endequation %} הן הטלות). ההוכחה היא תרגיל טוב ולא שונה כל כך ממה שכבר ראינו אז אוותר עליה. במקום זה בואו נראה שימוש מיידי של התוצאה הזו: אם {% equation %}T=\sum\lambda_{i}E_{i}{% endequation %}, מהו {% equation %}T^{2}{% endequation %}? לכאורה על פי חוקי הכפל נקבל {% equation %}T^{2}=\sum_{i,j}\lambda_{i}\lambda_{j}E_{i}E_{j}{% endequation %}, אבל אם נשתמש בכך ש-{% equation %}E_{i}E_{j}=0{% endequation %} ובכך ש-{% equation %}E_{i}^{2}=E_{i}{% endequation %} נקבל ש-{% equation %}T^{2}=\sum\lambda_{i}^{2}E_{i}{% endequation %}, ובאופן כללי לא קשה לראות שאם {% equation %}p{% endequation %} הוא פולינום כלשהו אז {% equation %}p\left(T\right)=\sum p\left(\lambda_{i}\right)E_{i}{% endequation %}. לא רק שהאבחנה הזו תעזור לנו בהמשך, היא כבר כעת מוכיחה מייד שאם יש לנו טרנספורמציה {% equation %}T{% endequation %}, אז הערכים העצמיים של {% equation %}p\left(T\right){% endequation %} הם בדיוק הפעלת {% equation %}p{% endequation %} על הערכים העצמיים של {% equation %}T{% endequation %} - לא תוצאה טריוויאלית כלל ממבט ראשון.

כעת אוכיח סוף סוף את הקריטריון ללכסינות שמבוסס על הפולינום המינימלי: טרנספורמציה היא לכסינה אם ורק אם לפולינום המינימלי שלה אין שורש מרובה (כלומר, הוא מהצורה {% equation %}\left(x-\lambda_{1}\right)\cdots\left(x-\lambda_{k}\right){% endequation %} כאשר כל ה-{% equation %}\lambda_{i}{% endequation %} שונים זה מזה).

נתחיל מהכיוון הקל. נניח של-{% equation %}T{% endequation %} יש את הערכים העצמיים {% equation %}\lambda_{1},\dots,\lambda_{k}{% endequation %}, אז {% equation %}T=\sum\lambda_{i}E_{i}{% endequation %}. אם {% equation %}p{% endequation %} פולינום שמאפס את {% equation %}T{% endequation %}, אז בהכרח {% equation %}\sum p\left(\lambda_{i}\right)E_{i}=0{% endequation %}. על ידי הפעלות של {% equation %}E_{j}{% endequation %} על המשוואה הזו רואים שבהכרח נובע ממנה ש-{% equation %}p\left(\lambda_{i}\right)=0{% endequation %} לכל {% equation %}\lambda_{i}{% endequation %}. כלומר: כל פולינום שמאפס את {% equation %}T{% endequation %} חייב להתאפס על ידי כל הערכים העצמיים. כמו כן, הפולינום {% equation %}\left(x-\lambda_{1}\right)\cdots\left(x-\lambda_{k}\right){% endequation %} מאפס את כל הערכים העצמיים בו זמנית ולכן מאפס את {% equation %}T{% endequation %}, ולכל פולינום שמחלק אותו קיים ערך עצמי שהוא לא מחלק. מסקנה: {% equation %}\left(x-\lambda_{1}\right)\cdots\left(x-\lambda_{k}\right){% endequation %} הוא הפולינום המינימלי של {% equation %}T{% endequation %}.

הכיוון השני הוא העיקר - נניח ש-{% equation %}\left(x-\lambda_{1}\right)\cdots\left(x-\lambda_{k}\right){% endequation %} הוא הפולינום המינימלי של טרנספורמציה {% equation %}T{% endequation %} ונוכיח שהיא לכסינה ועם הערכים העצמיים {% equation %}\lambda_{1},\dots,\lambda_{k}{% endequation %}. הרעיון יהיה לבנות הטלות שמקיימות את התכונות של המשפט שלעיל - סכומן הוא {% equation %}I{% endequation %}, סכומן המשוקלל עם {% equation %}\lambda_{1},\dots,\lambda_{k}{% endequation %} הוא {% equation %}T{% endequation %}, וההרכבה של כל זוג מהן היא אפס. האופן שבו מוצאים את ההטלות הללו הוא מקסים למדי ונותן לי תירוץ להציג יותר בפירוט משהו שכבר דיברתי עליו - אינטרפולציית לגראנז'.

הרעיון באינטרפולציית לגראנז' הוא לבנות פולינום בעל ערכים נתונים. נותנים לי סדרת זוגות של נקודות {% equation %}\left(x_{0},y_{0}\right),\left(x_{1},y_{1}\right),\dots,\left(x_{d},y_{d}\right){% endequation %} ודורשים ממני למצוא פולינום {% equation %}g{% endequation %} ממעלה {% equation %}d{% endequation %} לכל היותר שמקיים {% equation %}g\left(x_{i}\right)=y_{i}{% endequation %} לכל זוג מזוגות הנקודות (לא קשה להוכיח שאם קיים פולינום כזה, הוא יחיד - כל שני פולינומים ממעלה לכל היותר {% equation %}d{% endequation %} שמסכימים על {% equation %}d+1{% endequation %} נקודות הם זהים). הפתרון הוא להשתמש במעין בסיס (לא במובן הסטנדרטי) שמותאם לסדרת ה-{% equation %}x_{i}{% endequation %}-ים הנתונה ומאפשרת, לכל סדרת {% equation %}y_{i}{% endequation %}-ים, לבנות בקלות את {% equation %}g{% endequation %} המתאים. לב העניין הוא בבניה של פולינומים {% equation %}p_{0},p_{1},\dots,p_{d}{% endequation %} שכל אחד מהם מקיים {% equation %}p_{i}\left(x_{j}\right)=\delta_{ij}{% endequation %}, כלומר הוא מתאפס על כל ה-{% equation %}x{% endequation %}-ים פרט לאחד, ועליו הוא מקבל 1. פולינום כזה קל לבנות במפורש: {% equation %}p_{i}\left(x\right)=\prod_{j\ne i}\frac{x-x_{j}}{x_{i}-x_{j}}{% endequation %} (כאשר {% equation %}\prod{% endequation %} כאן מייצג מכפלה). הציבו בפולינום הזה {% equation %}x_{i}{% endequation %} ותראו מה מקבלים, ואחר כך חשבו מה קורה כשמציבים בו {% equation %}x_{j}{% endequation %} אחר.

עכשיו, אם ה-{% equation %}p{% endequation %}-ים הללו נתונים לנו, אז את {% equation %}g{% endequation %} בונים בצורה הבאה: {% equation %}g\left(x\right)=\sum y_{i}p_{i}\left(x\right){% endequation %}. כשמציבים ב-{% equation %}g{% endequation %} את {% equation %}x_{i}{% endequation %}, מה שנשאר כשהעשן מתפזר הוא {% equation %}y_{i}{% endequation %}. הדבר הזה מאוד דומה להטלות, שבתורן מאוד דומות לבסיסים למרחבים וקטוריים (ובפרט לבסיס אורתונורמליים, אבל עוד חזון למועד...) ולא סתם - הנה לנו דוגמה יפה למקום שבו כל הקשרים הללו באים לידי ביטוי.

איך כל זה קשור לענייננו, תשאלו? פשוט מאוד: ניקח את סדרת ה-{% equation %}x{% endequation %}-ים שלנו להיות {% equation %}\lambda_{1},\dots,\lambda_{k}{% endequation %} ונבנה פולינומים {% equation %}p_{1},\dots,p_{k}{% endequation %} מתאימים. כעת נבצע בעזרתם אינטרפולציה לשני פולינומים: אחד שמחזיר 1 על הכל, ושני שאם הוא מקבל {% equation %}x{% endequation %} הוא מחזיר {% equation %}x{% endequation %}. מנוסחת האינטרפולציה שלנו נקבל:

{% equation %}1=\sum p_{i}{% endequation %}

{% equation %}x=\sum\lambda_{i}p_{i}{% endequation %}

(אני מניח כאן באופן סמוי ש-{% equation %}k&gt;1{% endequation %} אבל זה בסדר כי {% equation %}k=1{% endequation %} אומר ש-{% equation %}T-\lambda I=0{% endequation %} (פשוט הצבתי את {% equation %}T{% endequation %} בפולינום המינימלי) ולכן {% equation %}T{% endequation %} בבירור לכסינה).

עכשיו הטוויסט הסופי מגיע: נגדיר את {% equation %}E_{i}=p_{i}\left(T\right){% endequation %}. הצבנו את {% equation %}T{% endequation %} בפולינומי האינטרפולציה, וקיבלנו מייד שמתקיים:

{% equation %}I=\sum E_{i}{% endequation %}

{% equation %}T=\sum\lambda_{i}E_{i}{% endequation %}

טוב ויפה, אבל למה {% equation %}E_{i}E_{j}=0{% endequation %}? או, טוב ששאלתם: כי {% equation %}p{% endequation %} בהכרח מחלק את {% equation %}p_{i}p_{j}{% endequation %}, וזאת מכיוון ש-{% equation %}p_{i}p_{j}{% endequation %} הוא פולינום שמתאפס על כל {% equation %}\lambda_{1},\dots,\lambda_{j}{% endequation %} ולכן בהכרח מכיל בתוכו רכיב מהצורה {% equation %}\prod\left(x-\lambda_{i}\right){% endequation %} - הפולינום המינימלי בכבודו ובעצמו (כאן השתמשתי בהנחה שאין לפולינום המינימלי שורש מרובה).

הדבר האחרון שעוד צריך להשתכנע בו הוא שכל ה-{% equation %}E_{i}{% endequation %}-ים שונים מאפס (זה תנאי הכרחי של המשפט שאותו לא הוכחתי). גם זה פשוט - אם {% equation %}E_{i}=0{% endequation %} זה אומר ש-{% equation %}p_{i}\left(T\right)=0{% endequation %} והנה מצאנו פולינום שמאפס את {% equation %}T{% endequation %} אבל דרגתו היא רק {% equation %}k-1{% endequation %}, כלומר קטנה מדרגת הפולינום המינימלי. זה מסיים את הכל.

בפוסט הבא נגיע כבר למשפט כבד באמת - משפט הפירוק הפרימרי - אבל שימו לב שגם בפוסט הזה כבר כיסינו כברת דרך לא קטנה והצגנו רעיונות שהם חשובים למדי בהקשרים רבים, וכנראה שנפגוש עוד בהמשך הדרך בצורה רצינית כשנדבר על מרחבי מכפלה פנימית. בנוסף, גם ההוכחות כבר הפסיקו להיות טריוויאליות כמו שהיו ברוב העניינים עד כה - אבל לדעתי הן עדיין אלגנטיות ויפות ביותר, במיטב מסורת האלגברה הלינארית.
