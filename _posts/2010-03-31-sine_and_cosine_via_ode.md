---
id: 415
title: "נעים להכיר - סינוס וקוסינוס (גרסת המשוואה הדיפרנציאלית)"
date: 2010-03-31 08:00:05
layout: post
categories: 
  - אנליזה מתמטית
tags: 
  - טריגונומטריה
  - משוואות דיפרנציאליות
  - סינוס
  - קוסינוס
social_media_share: true
---
שרשרת הפוסטים הקודמים שלי, שהחלה ב<a href="http://www.gadial.net/2010/03/14/happy_pi_day/">יום פאי</a>, יועדה למטרה אחת - הגדרה של סינוס וקוסינוס באופן שהוא לחלוטין בלתי קשור לגאומטריה בשום צורה שהיא - ומכאן גם הכנסה של פאי למשחק המתמטי בדרך שהיא לחלוטין בלתי קשורה לגאומטריה בשום צורה שהיא. <a href="http://www.gadial.net/2010/03/27/exponent/">מנת הפתיחה שלי</a> הייתה הגדרת פונקצית האקספוננט באופן בלתי גאומטרי שכזה, כש<a href="http://www.gadial.net/2010/03/26/radiocarbon_dating_and_math/">המוטיבציה מגיעה</a> מפתרון משוואות דיפרנציאליות; ו<a href="http://www.gadial.net/2010/03/29/from_exponent_to_trigo_via_ode/">בפוסט האחרון</a> הגעתי למשוואה דיפרנציאלית שבה האקספוננט הממשי אינו מסוגל להועיל לנו עוד - המשוואה {% equation %}f^{\prime\prime}=-f{% endequation %}. זוהי נקודת המוצא למה שאעשה בפוסט הזה, שיהיה דומה למדי למה שעשיתי בפוסט על האקספוננט - נתחיל מכך שקיימים פתרונות למשוואה הזו, נחקור את תכונותיהם ובסוף נגיע למסקנה שאלו הם הסינוס והקוסינוס המוכרים לנו זה לא מכבר. חשוב להבהיר שמה שנעשה יהיה לצאת להרפתקאה בג'ונגל - זו לא הדרך הקצרה או הפשוטה ביותר, וגם לא רואים בה את הנוף באופן הטוב ביותר, וגם נשרטים כל הזמן מקוצים וענפים וצריך להיזהר מחיות טרף - אבל אני חושב שזו הרפתקאה טובה שכן היא מעניקה לנו נקודת מבט שונה וזרה על הנושא מזו שניתן לראות כאשר פוסעים בשבילים המוכרים.

ובכן, הבה וניגש לעבודה. כפי שאמרתי בפוסט הקודם, למשוואות דיפרנציאליות מסדר שני יש משפט קיום ויחידות שמבטיח למשוואה {% equation %}f^{\prime\prime}=-f{% endequation %} קיים פתרון יחיד אם דורשים גם שני תנאי התחלה מהצורה {% equation %}f\left(0\right)=a,f^{\prime}\left(0\right)=b{% endequation %} עבור {% equation %}a,b{% endequation %} ממשיים כלשהם (תנאי ההתחלה לא חייב להיות באפס, אבל זה יהיה הכי נוח עבורנו). כתמיד, נרצה שתנאי ההתחלה יהיו פשוטים ככל הניתן; תנאי ההתחלה {% equation %}f\left(0\right)=f^{\prime}\left(0\right)=0{% endequation %} מניב בבירור את הפתרון {% equation %}f\left(x\right)=0{% endequation %} שאיננו מעניין, ולכן הנסיון הבא יהיה לקבוע את אחד מתנאי ההתחלה להיות 1. נאמר, {% equation %}f\left(0\right)=0,f^{\prime}\left(0\right)=1{% endequation %}. משפט הקיום והיחידות מבטיח שקיימת פונקציה שעונה על תנאים אלו - בואו נסמן אותה בסימון הבלתי צפוי לחלוטין {% equation %}f{% endequation %}. ומה יקרה אם נבחר דווקא תנאי התחלה שב-{% equation %}0{% endequation %} נותן לפונקציה 1, ולנגזרתה יתן {% equation %}0{% endequation %}? אין שום בעיה - נסמן פתרון זה ב-{% equation %}g{% endequation %}. השלב הראשון בהרפתקאה שלנו יהיה להבין את הקשר שבין {% equation %}f{% endequation %} ו-{% equation %}g{% endequation %}.

הבה ונתבונן רגע על הפונקציה {% equation %}f^{\prime}{% endequation %}. אמנם, הפונקציה הזו היא בראש ובראשונה הנגזרת של {% equation %}f{% endequation %}, אבל יש לה חיים משל עצמה. אם גוזרים אותה מקבלים את {% equation %}f^{\prime\prime}{% endequation %}, שכידוע שווה ל-{% equation %}-f{% endequation %}; ואם גוזרים אותה שוב, מקבלים את {% equation %}-f^{\prime}{% endequation %}. במילים אחרות, גם {% equation %}f^{\prime}{% endequation %} מקיימת את המשוואה הדיפרנציאלית שממנה התחלנו. עם אילו תנאי התחלה היא מקימת אותם? ובכן, {% equation %}f^{\prime}\left(0\right)=1{% endequation %}, כי כך קבענו את {% equation %}f{% endequation %} מלכתחילה; ו-{% equation %}\left(f^{\prime}\right)^{\prime}\left(0\right)=f^{\prime\prime}\left(0\right)=-f\left(0\right)=0{% endequation %} - אבל אלו בדיוק תנאי ההתחלה של {% equation %}g{% endequation %}! מכאן ש-{% equation %}f^{\prime}=g{% endequation %}. כבר צץ הקשר הראשון בין שני הפתרונות ה"מעניינים" של המשוואה עם תנאי ההתחלה הפשוטים ביותר שהצלחנו למצוא.

הצעד הבא פשוט: {% equation %}g^{\prime}=\left(f^{\prime}\right)^{\prime}=f^{\prime\prime}=-f{% endequation %}. כלומר, בעוד ש-{% equation %}g{% endequation %} הייתה הנגזרת של {% equation %}f{% endequation %}, הרי ש-{% equation %}-f{% endequation %} הוא הנגזרת של {% equation %}g{% endequation %}. שימו לב כמה מעט היינו צריכים להניח בשביל לקבל את "חוק הטבע" הזה ואת הא-סימטריה שטבועה בשתי הפונקציות הללו - האחת מניבה את חברתה, ואילו השניה מניבה את <strong>מינוס </strong>חברתה. לכן כל אחת מהפונקציות מעניינת בזכות עצמה ויש מקום לדבר על שתיהן בבת אחת.

עכשיו, משיש לנו מידע יותר מלא על מהן כל הנגזרות של {% equation %}f{% endequation %} ו-{% equation %}g{% endequation %}, ניתן לבצע את אותו ניתוח שביצענו גם עבור אקספוננט - מציאת טורי הטיילור המתאימים לפונקציות. כזכור, עבור {% equation %}f{% endequation %} טור הטיילור יהיה טור מהצורה {% equation %}\sum_{n=0}^{\infty}\frac{f^{\left(n\right)}\left(0\right)}{n!}x^{n}{% endequation %}. החישוב אינו מסובך במיוחד: {% equation %}f^{\left(0\right)}\left(0\right)=0{% endequation %} על פי הגדרה; {% equation %}f^{\left(1\right)}\left(0\right)=g\left(0\right)=1{% endequation %}; {% equation %}f^{\left(2\right)}\left(0\right)=-f\left(0\right)=0{% endequation %}; {% equation %}f^{\left(3\right)}\left(0\right)=-g\left(0\right)=-1{% endequation %}; ואילו {% equation %}f^{\left(4\right)}=f{% endequation %}, ולכן הסדרה תתחיל לחזור על עצמה משם ואילך. במילים אחרות, סדרת הערכים שמתקבלת היא {% equation %}0,1,0,-1,0,1,0,-1,\dots{% endequation %} (להבדיל מאקספוננט, שבה היא הייתה פשוט {% equation %}1,1,1,\dots{% endequation %}). לכן הטור יהיה מהצורה {% equation %}x-\frac{x^{3}}{3!}+\frac{x^{5}}{5!}-\frac{x^{7}}{7!}+\dots{% endequation %}. ניתוח דומה עבור {% equation %}g{% endequation %} מניב את הסדרה {% equation %}1,0,-1,0,1,0,-1,0,\dots{% endequation %} ולכן את הטור{% equation %}1-\frac{x^{2}}{2!}+\frac{x^{4}}{4!}-\frac{x^{6}}{6!}+\dots{% endequation %}. כפי שניתן לראות, שני הטורים "משלימים" זה את זה; בפרט, אם נהפוך את סימני המינוס לפלוס ונחבר את הטורים, נקבל את הטור של {% equation %}e^{x}{% endequation %}. תופעה זו היא שמובילה ל<a href="http://he.wikipedia.org/wiki/%D7%A0%D7%95%D7%A1%D7%97%D7%AA_%D7%90%D7%95%D7%99%D7%9C%D7%A8_%28%D7%90%D7%A0%D7%9C%D7%99%D7%96%D7%94_%D7%9E%D7%A8%D7%95%D7%9B%D7%91%D7%AA%29">נוסחת אוילר</a>, {% equation %}e^{i\theta}=\cos\theta+i\sin\theta{% endequation %}, אך דיה לצרה בשעתה.

כמובן, זה שכתבנו את טור הטיילור של {% equation %}f,g{% endequation %} עדיין לא אומר שהטור אכן מתכנס אליהן - בשביל זה צריך לדבר על גודל השארית, כמו שעשיתי במקרה של אקספוננט. שם הראיתי שדי להצביע על כך שיש חסם על הערך שכל הנגזרות של {% equation %}\exp{% endequation %}יכולות לקבל בתחום {% equation %}\left[0,x_{0}\right]{% endequation %} כדי להוכיח שהטור מתכנס לפונקציה, וכדי לראות זאת פשוט שמנו לב לכך שגם כאשר גוזרים את {% equation %}\exp{% endequation %} מקבלים אותה עצמה, ולכן חסם על {% equation %}\exp{% endequation %} בתחום הזה (שקיים, כי היא רציפה והתחום סגור) מוביל לחסם על כל הנגזרות. אותו שיקול עובד גם כאן - אמנם, הנגזרת של {% equation %}f{% endequation %} היא {% equation %}g{% endequation %} ושל {% equation %}g{% endequation %} היא {% equation %}-f{% endequation %}, אבל ניתן למצוא חסם על {% equation %}g,f{% endequation %} "בו זמנית", ולכן גם על כל נגזרותיהן. מסקנה: שני הטורים שכתבתי לעיל אכן מתארים נכונה את {% equation %}f,g{% endequation %}. לאלו מכם שמכירים את הטורים הללו כבר בתור הטורים של {% equation %}\sin{% endequation %} ו-{% equation %}\cos{% endequation %} כבר הגענו לקרקע יציבה כלשהי. עבור היתר מה שחשוב כאן הוא רק שמצאנו ביטוי "קונקרטי" לפונקציות הללו, שגם מאפשר לנו לחשב אותן אם נרצה.

נחזור כעת לציד תכונות מעניינות בג'ונגל, כשהמוטיבציה שלנו מגיעה ממה שאנחנו כבר יודעים על {% equation %}\sin{% endequation %}ו-{% equation %}\cos{% endequation %}. הבה ונתבונן בפונקציה שמוגדרת על ידי {% equation %}h=f^{2}+g^{2}{% endequation %}. אם נגזור אותה, נקבל את הנגזרת {% equation %}h^{\prime}=2ff^{\prime}+2gg^{\prime}=2fg-2gf=0{% endequation %} - במילים אחרות, {% equation %}h{% endequation %} היא פונקציה שנגזרתה היא זהותית אפס, ולכן היא פונקציה קבועה (זהו אחד מהמשפטים הבסיסיים בחשבון אינפיניטסימלי, וגם משפט ברור אינטואיטיבית - הרי נגזרת היא קצב השינוי של פונקציה, ואם קצב השינוי הזה הוא תמיד אפס, הפונקציה בהכרח קבועה). האם אנחנו יודעים לחשב את הערך הקבוע של {% equation %}h{% endequation %}? ודאי - {% equation %}h\left(0\right)=f^{2}\left(0\right)+g^{2}\left(0\right)=0+1=1{% endequation %}. מכאן ש-{% equation %}f^{2}\left(x\right)+g^{2}\left(x\right)=1{% endequation %} לכל {% equation %}x{% endequation %}. נראה מוכר? זה גם מניב דרך נוספת לבטא את {% equation %}g{% endequation %} באמצעות {% equation %}f{% endequation %}: {% equation %}g=\pm\sqrt{1-f^{2}}{% endequation %}. זוהי דרך הצגה "רמאית" במובן מסויים כי איננו יודעים <strong>באמת</strong> את הערך של {% equation %}g\left(x\right){% endequation %} בהינתן {% equation %}f\left(x\right){% endequation %}; אנחנו יודעים שהוא {% equation %}\pm\sqrt{1-f^{2}\left(x\right)}{% endequation %} אבל איננו יודעים אם זהו הערך החיובי או השלילי. נצטרך לאמץ דרך שונה לתקוף את השאלה הזו.

שימו לב למה שנובע מהתכונה שכרגע ראינו - מכיוון ש-{% equation %}g,f{% endequation %} הן פונקציות ממשיות ומוגדרות לכל {% equation %}x{% endequation %}, נובע מכך בהכרח שהערכים ששתיהן מחזירות מצויים תמיד בתחום {% equation %}\left[-1,1\right]{% endequation %}, כי במספרים ממשיים, {% equation %}f^{2}\left(x\right)+g^{2}\left(x\right)=1{% endequation %} מכריח את {% equation %}f\left(x\right),g\left(x\right){% endequation %} להיות קטנים או שווים ל-1 אחרת אחד מהם יהיה חייב להיות מספר מרוכב. יותר מכך - {% equation %}f,g{% endequation %} רוקדות מעין "ריקוד" יחדיו - כאשר אחת גדולה (בערכה המוחלט), השניה חייבת להיות קטנה. האופן שבו הן משתלבות זו בזו ב"ריקוד" הזה והעובדה שהריקוד הוא מחזורי היא היעד המרכזי שלנו - אבל לצורך כך יש עוד תכונות שעלינו להיווכח בהן.

כל מי שהיה תלמיד תיכון ודאי זוכר את הנוסחאות המפלצתיות עבור {% equation %}\sin\left(x+y\right){% endequation %} ו-{% equation %}\cos\left(x+y\right){% endequation %}. הבה וננסה לגזור נוסחאות שכאלו עבור {% equation %}f,g{% endequation %} באמצעות הכלים שיש לנו עד כה (דהיינו, בלי שום גאומטריה). לצורך כך הבה וניזכר במשהו מהפוסט הקודם - אמרתי שבהינתן משוואה דיפרנציאלית מסדר שני (בלי מקדם חופשי) ושני פתרונות "בלתי תלויים" עבורה, אפשר לבנות כל פתרון אחר כצירוף לינארי של שני הפתרונות הללו, כשהמקדמים נקבעים על פי תנאי ההתחלה. כפי שניתן לנחש, {% equation %}f,g{% endequation %} הם שני פתרונות "בלתי תלויים" שכאלו, ונראה זאת במפורש. נניח אם כן כי {% equation %}h{% endequation %} היא פונקציה אשר מקיימת {% equation %}h^{\prime\prime}=-h{% endequation %} וכמו כן {% equation %}h\left(0\right)=a{% endequation %} ו-{% equation %}h^{\prime}\left(0\right)=b{% endequation %}. כעת נתבונן בפונקציה {% equation %}bf+ag{% endequation %}; בבירור אם נציב בה 0 נקבל {% equation %}a{% endequation %} (כי {% equation %}f{% endequation %} יתאפס ואילו {% equation %}g{% endequation %} יהפוך ל-1). אם נגזור אותה, נקבל {% equation %}bf^{\prime}+ag^{\prime}=bg-af{% endequation %}, וכשמציבים 0 בנגזרת זו מקבלים בבירור את {% equation %}b{% endequation %}. כמו כן ברור כי {% equation %}bf+ag{% endequation %} מקיימת את המשוואה הדיפרנציאלית המקורית שכן היא צירוף לינארי של {% equation %}f,g{% endequation %}. מסקנה ממשפט הקיום והיחידות? {% equation %}h=bf+ag{% endequation %}.

בואו ניקח כעת {% equation %}y{% endequation %} ממשי כלשהו, ונגדיר פונקציה חדשה: {% equation %}h\left(x\right)=f\left(x+y\right){% endequation %}. מכללי הגזירה הסטנדרטיים עולה ש-{% equation %}h^{\prime\prime}\left(x\right)=f^{\prime\prime}\left(x+y\right)=-f\left(x+y\right)=-h\left(x\right){% endequation %}, כך שאת {% equation %}h{% endequation %} אפשר לייצג כצירוף לינארי של {% equation %}f,g{% endequation %}. מהם המקדמים? {% equation %}a=h\left(0\right)=f\left(y\right){% endequation %}, ו-{% equation %}b=h^{\prime}\left(0\right)=f^{\prime}\left(y\right)=g\left(y\right){% endequation %}. מסקנה: {% equation %}f\left(x+y\right)=f\left(x\right)g\left(y\right)+g\left(x\right)f\left(y\right){% endequation %}. נראה מוכר? באופן דומה אפשר להראות כי {% equation %}g\left(x+y\right)=g\left(x\right)g\left(y\right)-f\left(x\right)f\left(y\right){% endequation %}. אני מאוד אוהב את ההוכחה הזו כי היא נותנת תובנה יפה על הנוסחאות הללו - הן לא סתם ערב רב של סינוסים וקוסינוסים שהושלכו באקראי, אלא צירוף לינארי של {% equation %}\sin x,\cos x{% endequation %} כשהמקדמים מבוססים על {% equation %}\sin y,\cos y{% endequation %}.

מכאן הדרך להוכחה ש-{% equation %}f,g{% endequation %} מחזוריות קצרה יחסית, אבל עדיין יש צעד מרכזי אחד שטרם ביצענו - עלינו להראות כי {% equation %}g{% endequation %} מתאפסת היכן שהוא. הבה נניח בשלילה כי {% equation %}g\left(x\right)&gt;0{% endequation %} לכל {% equation %}x\ge0{% endequation %} (עבור {% equation %}x=0{% endequation %} אנו יודעים כי זה נכון: {% equation %}g\left(0\right)=1{% endequation %}). מכיוון ש-{% equation %}f^{\prime}=g{% endequation %}, נובע מכך ש-{% equation %}f{% endequation %} היא מונוטונית עולה עבור {% equation %}x\ge0{% endequation %}, דהיינו {% equation %}f\left(x\right)&gt;0{% endequation %} לכל {% equation %}x&gt;0{% endequation %}. כעת, מכיוון ש-{% equation %}g^{\prime}=-f{% endequation %}, עולה מכך כי {% equation %}g{% endequation %} היא מונוטונית יורדת לכל {% equation %}x&gt;0{% endequation %}. עד כאן, שום דבר מפתיע - זהו בדיוק ה"ריקוד" של {% equation %}f,g{% endequation %} שעליו דיברתי - כשהאחת עולה, השנייה יורדת. האינטואיציה כאן היא שקצב הירידה של {% equation %}g{% endequation %}, אם היא אינה מתאפסת אף פעם, חייב להתמתן עוד ועוד עם הזמן. קצב הירידה הזה הוא נגזרתה של {% equation %}g{% endequation %}, כלומר {% equation %}-f{% endequation %}, ולכן הטענה היא שהערך של {% equation %}-f{% endequation %} חייב <strong>לגדול</strong> עם הזמן (הוא <strong>שלילי</strong> כל הזמן, ולכן כשאני אומר שהוא "גדל", הכוונה היא דווקא לכך שערכו המוחלט קטן - בהתחלה הוא {% equation %}-1{% endequation %}, אחר כך {% equation %}-0.5{% endequation %} וכן הלאה). אלא שהערך של {% equation %}-f{% endequation %} בתחילת ה"ריקוד" היה 0, ולכן הסיטואציה חייבת להיות כזו: ראשית ערכו של {% equation %}-f{% endequation %} <strong>קטן</strong>, ואז פתאום המצב "מתהפך" וערכו מתחיל "לגדול". בפרט זה אומר שיש ל-{% equation %}-f{% endequation %}נקודת מינימום בריקוד הזה, אבל <a href="http://he.wikipedia.org/wiki/%D7%9E%D7%A9%D7%A4%D7%98_%D7%A4%D7%A8%D7%9E%D7%94_%28%D7%9C%D7%A0%D7%A7%D7%95%D7%93%D7%95%D7%AA_%D7%A7%D7%99%D7%A6%D7%95%D7%9F%29">משפט בסיסי</a> מחשבון אינפיניטסימלי אומר שבנקודת המינימום הזו הנגזרת של {% equation %}-f{% endequation %} תתאפס - ונגזרת זו היא בדיוק {% equation %}-g{% endequation %}...

למרות שהטיעון הזה נשמע חצי נפנוף-ידיימי, הוא למעשה מאוד קונקרטי ולא נדרשת הרבה עבודה כדי לפרמל אותו לגמרי. השורה התחתונה היא מה שמעניין אותנו - קיימת נקודה {% equation %}t&gt;0{% endequation %} כך ש-{% equation %}g\left(t\right)=0{% endequation %}, ו-{% equation %}t{% endequation %} הוא הערך הקטן ביותר שגדול מ-0 שמקיים זאת. מהו ערכה של {% equation %}f{% endequation %} בנקודה זו? ובכן, {% equation %}f\left(t\right)=\pm\sqrt{1-g^{2}\left(t\right)}=\pm1{% endequation %}. אלא שלא ייתכן ש-{% equation %}f{% endequation %} שלילי בנקודה זו, כי ב-0 התקיים {% equation %}f\left(0\right)=0{% endequation %} ומאותו רגע והלאה {% equation %}g{% endequation %} - הנגזרת של {% equation %}f{% endequation %} - הייתה חיובית (כי {% equation %}t{% endequation %} הנקודה המינימלית שבה {% equation %}g{% endequation %} מתאפסת), ולכן {% equation %}f{% endequation %} רק <strong>עלתה</strong>. מכאן ש-{% equation %}f\left(t\right)=1{% endequation %}. כעת אפשר להגיע למסקנה מעניינת מאוד: {% equation %}f\left(x+t\right)=f\left(x\right)g\left(t\right)+g\left(x\right)f\left(t\right)=g\left(x\right){% endequation %}. במילים אחרות, {% equation %}g{% endequation %} מתנהגת <strong>בדיוק כמו </strong>{% equation %}f{% endequation %}, פרט לכך שהיא "מקדימה" אותה בדיוק ב-{% equation %}t{% endequation %} "צעדים" (כלומר, אם נזיז את הגרף של {% equation %}f{% endequation %} {% equation %}t{% endequation %} יחידות ימינה, הוא יזדהה עם הגרף של {% equation %}g{% endequation %}).

כעת הניתוח נעשה פשוט בהרבה. מה קורה לפונקציות בקטע {% equation %}\left[t,2t\right]{% endequation %}? בתחילתו, כזכור, {% equation %}g\left(t\right)=0{% endequation %} ואילו {% equation %}f\left(t\right)=1{% endequation %}. מכיוון ש-{% equation %}f{% endequation %} מתנהגת בקטע הזה כמו ש-{% equation %}g{% endequation %} התנהגה בקטע {% equation %}\left[0,t\right]{% endequation %} הרי ש-{% equation %}f{% endequation %} פשוט תרד עד ל-{% equation %}0{% endequation %}: {% equation %}f\left(2t\right)=0{% endequation %}. בזמן הזה {% equation %}g{% endequation %} היא בעלת נגזרת שלילית לכל אורך הדרך (כי הנגזרת שלה היא {% equation %}-f{% endequation %} ו-{% equation %}f{% endequation %} הרי חיובית בקטע זה) ולכן {% equation %}g{% endequation %} תהיה מונוטונית יורדת בכל הקטע. עד להיכן היא תרד? כאן אפשר להשתמש בנוסחת הסכום: {% equation %}g\left(2t\right)=g^{2}\left(t\right)-f^{2}\left(t\right)=-1{% endequation %}. אם כן, הריקוד ממשיך - בקטע מ-{% equation %}t{% endequation %} אל {% equation %}2t{% endequation %}, שתי הפונקציות יורדות מטה מרחק של יחידה אחת.

ומה קורה ב-{% equation %}\left[2t,3t\right]{% endequation %}? ובכן, {% equation %}f{% endequation %} כרגיל מחקה את {% equation %}g{% endequation %}: יורדת עד ל-{% equation %}-1{% endequation %} ({% equation %}f\left(3t\right)=-1{% endequation %}). על כן הנגזרת של {% equation %}g{% endequation %} היא <strong>חיובית</strong> בכל הקטע ולכן {% equation %}g{% endequation %} עולה בכל הקטע ומגיעה עד ל-0, שהרי {% equation %}g\left(3t\right)=g\left(2t\right)g\left(t\right)-f\left(2t\right)f\left(t\right)=0-0=0{% endequation %}.

ולבסוף, בקטע {% equation %}\left[3t,4t\right]{% endequation %} {% equation %}f{% endequation %} ממשיכה לחקות את {% equation %}g{% endequation %} ועולה בעצמה ל-0, ואילו {% equation %}g{% endequation %} ממשיכה לעלות (כי נגזרתה חיובית) ומגיעה עד ל-1: {% equation %}g\left(4t\right)=g^{2}\left(2t\right)-f^{2}\left(2t\right)=1{% endequation %}. זה אומר שב-{% equation %}4t{% endequation %} חזרנו להתחלה - שוב {% equation %}f{% endequation %} מאופסת ו-{% equation %}g{% endequation %} מחזירה 1. מזה נובע מיידית ש-{% equation %}4t{% endequation %} הוא מחזור של שתי הפונקציות הללו: {% equation %}f\left(x+4t\right)=f\left(x\right)g\left(4t\right)+f\left(4t\right)g\left(x\right)=f\left(x\right){% endequation %}, ובדומה {% equation %}g\left(x+4t\right)=g\left(x\right)g\left(4t\right)-f\left(x\right)f\left(4t\right)=g\left(x\right){% endequation %} - וזה נכון <strong>לכל</strong> {% equation %}x{% endequation %}, כולל השליליים. הוכחנו (בלי שום גאומטריה) את המחזוריות של {% equation %}f,g{% endequation %}. יותר מכך - המעקב המדוקדק שלנו אחרי ההתנהגות של {% equation %}f,g{% endequation %} מעלה שהסיטואציה הזו ({% equation %}f{% endequation %} מקבלת 0, {% equation %}g{% endequation %} מקבלת 1) התרחשה <strong>לראשונה</strong> ב-{% equation %}4t{% endequation %} לאחר ההתרחשות שלה ב-0, ומכאן ש-{% equation %}4t{% endequation %} הוא המחזור <strong>המינימלי</strong> של שתי הפונקציות הללו.

זהו - הוכחנו כרגע את התכונה החשובה ביותר של שתי הפונקציות. שימו לב כמה אנחנו כבר יכולים לומר: למשל, מניתוח ההתנהגות שביצענו ל-{% equation %}f{% endequation %} ברור כי היא מתאפסת רק בערכים מהצורה {% equation %}k\cdot2t{% endequation %} עבור {% equation %}k{% endequation %} שלם; לכן אם נשתמש <a href="http://www.gadial.net/2010/03/14/happy_pi_day/">בהוכחה של אוילר</a> לחישוב {% equation %}\sum\frac{1}{n^{2}}{% endequation %} שהצגתי בעבר, נקבל שהסכום הזה הוא {% equation %}\frac{\left(2t\right)^{2}}{6}{% endequation %}. במילים אחרות, הצלחנו לחשב את סכום הטור בלי שום גאומטריה. זו נקודה טובה לעצור ולהודות באמת: {% equation %}f\left(x\right){% endequation %} הוא פשוט שם מיתמם ל-{% equation %}\sin\left(x\right){% endequation %}, {% equation %}g\left(x\right){% endequation %} הוא שם מיתמם ל-{% equation %}\cos\left(x\right){% endequation %}, ואילו {% equation %}\pi=2t{% endequation %}. אך לא ניתן לעשות זאת "סתם", שהרי {% equation %}\sin\left(x\right),\cos\left(x\right),\pi{% endequation %} כולם יצורים גאומטריים ואי אפשר "להשתלט" עליהם ככה בלי להגיד כלום על גאומטריה. לכן, אם מתעקשים, אפשר להיפגש באמצע - עם קצת אנליזה (והגבול {% equation %}\lim_{x\to0}\frac{\sin x}{x}=1{% endequation %} והוכחתו <strong>הגאומטרית</strong> <a href="http://www.gadial.net/2008/01/20/lim_sin_x_over_x/">הידועה לשמצה</a>) אפשר להראות כי {% equation %}\sin^{\prime}\left(x\right)=\cos\left(x\right){% endequation %} ו-{% equation %}\cos^{\prime}\left(x\right)=-\sin\left(x\right){% endequation %} ומכאן חיש קל אפשר להראות ש-{% equation %}\sin,\cos{% endequation %} הם הפתרונות למשוואה הדיפרנציאלית שעליה דיברתי. האם יש דרך אחרת? ובכן, אפשר להגדיר את {% equation %}\sin,\cos{% endequation %} בצורה מעט שונה מהצורות שאנו מכירים - צורה שהיא מעין פשרה בין ההגדרה הגאומטרית ובין ההגדרות האנליטיות, ומשתמשת בפונקציה אנליטית המתארת שטח של עיגול. הניתוח של הפונקציה הזו כולל קצת אינפי "מלוכלך", ואיני רוצה להיכנס אליו כעת; אבל גם בו היעד המרכזי שמגיעים אליו, שהחל ממנו הכל ממשיך כרגיל, הוא נוסחאות הגזירה של סינוס וקוסינוס. דבר זה מראה כי במובן מסויים, הגישה שאני הצגתי היא ה"ישירה" ביותר, שכן ממנה נוסחאות הגזירה נובעות בצורה מיידית לחלוטין.

בפוסט הבא אפרע את החוב מהפוסט הקודם - אראה כיצד נפתרת בעזרת סינוס וקוסינוס המשוואה הדיפרנציאלית הכללית שהצגתי, ואכניס לתמונה סוף סוף את נוסחת אוילר.
