---
id: 3244
title: "משפט מייהיל-נרוד - נקודת מבט נוספת, ואלגוריתמי מינימיזציה"
date: 2015-05-07 09:37:34
layout: post
categories: 
  - תורת הסיבוכיות
tags: 
  - משפט מייהיל-נרוד
  - שפות פורמליות
---
בכל הנושא של תורת השפות הפורמליות, המשפט החביב עלי הוא משפט <a href="http://www.gadial.net/2015/02/11/myhill_nerode_theorem/">מייהיל-נרוד</a>. כל כך חביב עלי, שבפוסט הזה אני הולך להציג אותו שוב, ובצורה שונה מזו שבה הצגתי אותו בפוסט הקודם שלי בנושא. שתי נקודות המבט על המשפט הן דואליות באופיין (הן אומרות את אותו הדבר, אבל כל אחת מסתכלת על הדבר הזה מנקודת מבט שונה ואפילו מנוגדת קצת), וזו שאציג עכשיו תהיה שימושית בהמשך, עם עוד כמה תוצאות יפות שאני רוצה להראות. בפרט, היא תהיה שימושית כדי לטפל בבעיה שעד כה לא התייחסתי אליה - איך אפשר <strong>למצוא</strong> בפועל את האוטומט המינימלי עבור שפה שמשפט מייהיל-נרוד מבטיח את קיומו. אראה שני אלגוריתמים שעושים את זה - הראשון הוא נחמד ואינטואיטיבי יחסית, והשני הוא משהו פסיכי לחלוטין: כשראיתי אותו בפעם הראשונה התגובה שלי הייתה "מה, לעזאזל?!". הטיזר הזה מספיק לכם כדי שיתחשק לכם לראות איך אני מנסח מחדש את כל המונחים של נרוד בלשון אחרת? אחלה.

נתחיל בתזכורת מה הולך במשפט מייהיל-נרוד. בהינתן שפה {% equation %}L{% endequation %} כלשהי מעל {% equation %}\Sigma^{*}{% endequation %}, הגדרנו יחס שקילות {% equation %}R_{L}{% endequation %} מעל {% equation %}\Sigma^{*}{% endequation %}: {% equation %}xR_{L}y{% endequation %} אם ורק אם לא קיימת "סיפא מפרידה" של {% equation %}x,y{% endequation %} ביחס ל-{% equation %}L{% endequation %}, כלומר לכל {% equation %}z\in\Sigma^{*}{% endequation %} מתקיים {% equation %}xz\in L\iff yz\in L{% endequation %}. סימנו את אוסף מחלקות השקילות של היחס הזה ב-{% equation %}\Sigma^{*}/R_{L}{% endequation %}, והמשפט אמר ש-{% equation %}L{% endequation %} רגולרית אם ורק אם מספר מחלקות השקילות של היחס הוא סופי. האינטואיציה היא שניתן לבנות אוטומט (לאו דווקא סופי) עבור {% equation %}L{% endequation %} שמצביו הם בדיוק {% equation %}\Sigma^{*}/R_{L}{% endequation %}, המצב ההתחלתי שלו הוא {% equation %}\left[\varepsilon\right]{% endequation %} (מחלקת השקילות של {% equation %}\varepsilon{% endequation %}), מצביו המקבלים הם מהצורה {% equation %}\left[w\right]{% endequation %} עבור כל {% equation %}w\in L{% endequation %}, ופונקציית המעברים שלו היא {% equation %}\delta\left(\left[w\right],\sigma\right)=\left[w\sigma\right]{% endequation %}. הוכחנו שהאוטומט הזה הוא בעל מספר המצבים <strong>המינימלי</strong> מבין כל האוטומטים עבור {% equation %}L{% endequation %}, ולכן {% equation %}L{% endequation %} הייתה רגולרית אם ורק אם המספר המינימלי הזה היה סופי.

עכשיו בואו נתאר את כל העסק הזה מזווית ראייה אחרת. אני הולך להשתמש במושג שהזכרתי קודם אבל לא קיבל עד כה את הזרקור שמגיע לו - המושג של <strong>חלוקה</strong> של שפות. נתחיל הפעם דווקא עם חלוקה במילה בודדת, ועם סימון חדש כדי להציג את זה. אם {% equation %}w=uv{% endequation %} היא מילה ש-{% equation %}u{% endequation %} היא רישא שלה, אז אסמן {% equation %}u^{-1}w\triangleq v{% endequation %}. כלומר, {% equation %}u^{-1}w{% endequation %} היא מה שמקבלים מ-{% equation %}w{% endequation %} אחרי שמסלקים ממנו את הרישא {% equation %}u{% endequation %}. האינטואיציה לסימון הזה עם החזקה של המינוס 1 מגיעה מתורת החבורות, ולא אכביר עליה מילים. צריך להיזהר קצת עם הסימון - אם {% equation %}u{% endequation %} איננה רישא של {% equation %}w{% endequation %}, אז אין שום משמעות לסימון {% equation %}u^{-1}w{% endequation %} בהקשר שלנו. כמו כן, באופן דומה אפשר גם להגדיר {% equation %}wu^{-1}{% endequation %} אבל לא אזדקק לסימון הזה ולכן לא אציג אותו בהמשך.

עכשיו, אם {% equation %}L{% endequation %} היא שפה כלשהו, אפשר להכליל את פעולת החלוקה עבורה: להגדיר {% equation %}u^{-1}L\triangleq\left\{ u^{-1}w\ |\ w\in L\right\} {% endequation %}, כאשר המוסכמה כאן היא שאם {% equation %}u^{-1}w{% endequation %} אינו מוגדר הוא אינו משתתף בקבוצה (מבחינה פורמלית הסימון שלי לא תקין והייתי צריך להוסיף במפורש את התנאי ש-{% equation %}u{% endequation %} היא רישא של {% equation %}w{% endequation %}, אבל אני בכוונה משתמש פה בסימון לא תקין - מה שנקרא Abuse of notation - כי חשוב לי להדגיש שככה זה עובד במתמטיקה - יותר חשובה לנו נוחות הסימון כל עוד כולם מבינים את הכוונה, מאשר נוקדנות ברמת הסימונים). גם את זה אפשר להכליל ולקבל חלוקה משמאל של שפות כדי שהגדרתי אותה פעם: {% equation %}L_{2}^{-1}L_{1}\triangleq\left\{ u^{-1}w\ |\ u\in L_{2},\in L_{1}\right\} {% endequation %}, אבל לא אזדקק לסימון הזה יותר מדי הפעם.

עכשיו אפשר לנסח את משפט מייהיל-נרוד בטרמינולוגיה החדשה שלנו: שפה {% equation %}L{% endequation %} היא רגולרית אם ורק אם הקבוצה {% equation %}\left\{ u^{-1}L\ |\ u\in\Sigma^{*}\right\} {% endequation %} סופית; וגודל הקבוצה שווה למספר המצבים באוטומט סופי דטרמיניסטי מינימלי עבור {% equation %}L{% endequation %}.

במבט ראשון אולי לא ברור מה הקשר, אבל במבט שני די ברור שזה בדיוק אותו דבר: דרך אחרת ושקולה לנסח את הטענה ש-{% equation %}xR_{L}y{% endequation %} היא לומר ש-{% equation %}x^{-1}L=y^{-1}L{% endequation %} - כלומר, שאוסף כל המילים {% equation %}z{% endequation %} כך ש-{% equation %}xz\in L{% endequation %} שווה לאוסף כל המילים כך ש-{% equation %}yz\in L{% endequation %}. אז עד כה לא עשיתי כלום חוץ מאשר הצבעה על העובדה (הנחמדה) שאפשר לנסח את המשפט בעזרת מושג החלוקה, במקום להזדקק למחלקות שקילות.

עכשיו בואו נכניס אוטומטים לתמונה. ניקח אוטומט סופי דטרמיניסטי כלשהו {% equation %}A=\left(Q,\Sigma,q_{0},\delta,F\right){% endequation %}. עכשיו, לכל מצב {% equation %}q\in Q{% endequation %} בואו נסמן ב-{% equation %}L_{q}{% endequation %} את שפת כל המילים שאם אנחנו נמצאים ב-{% equation %}q{% endequation %} וקוראים אותן, נגיע למצב מקבל: {% equation %}L_{q}\triangleq\left\{ w\in\Sigma^{*}\ |\ \hat{\delta}\left(q,w\right)\in F\right\} {% endequation %}. בבירור {% equation %}L\left(A\right)=L_{q_{0}}{% endequation %} (אם זה לא ברור נסו להסביר לעצמכם את ההגדרה). עכשיו, לפני שנמשיך, אני רוצה להציג סימון שיחסוך לי את הצורך לכתוב {% equation %}\hat{\delta}{% endequation %} עם סוגריים כל הזמן: במקום לכתוב {% equation %}\hat{\delta}\left(q,w\right){% endequation %} אני אכתוב {% equation %}q\cdot w{% endequation %}. פורמלית, אפשר לחשוב על זה כאילו {% equation %}w{% endequation %} <strong>פועלת</strong> על {% equation %}q{% endequation %}, למי שמכיר את המושג הזה (כאן זו פעולה של המונואיד {% equation %}\Sigma^{*}{% endequation %} על הקבוצה {% equation %}Q{% endequation %}, למי שמכיר את ההגדרות). התכונה שמעניינת אותנו כאן היא ש-{% equation %}q\cdot\left(uv\right)=\left(q\cdot u\right)\cdot v{% endequation %} (מה שהוכחתי בעבר בתור {% equation %}\hat{\delta}\left(q_{0},uv\right)=\hat{\delta}\left(\hat{\delta}\left(q_{0},u\right),v\right){% endequation %}) ובגללה בחרתי את הסימון בצורה שבה בחרתי (נראה לי בהתחלה יותר טבעי לסמן {% equation %}w\cdot q{% endequation %}, אבל אני רוצה להימנע מזוועות כמו {% equation %}\left(uv\right)\cdot q=v\cdot\left(u\cdot q\right){% endequation %}). בסימון הזה, {% equation %}L_{q}\triangleq\left\{ w\in\Sigma^{*}\ |\ q\cdot w\in F\right\} {% endequation %}

בואו נניח שכל המצבים ב-{% equation %}A{% endequation %} ישיגים (לאוטומט כזה אקרא <strong>נגיש</strong>), כי קל להעיף מאוטומט מצבים לא ישיגים ומקבלים אוטומט שקול. זה אומר שלכל {% equation %}q{% endequation %} קיימת מילה {% equation %}u{% endequation %} כך ש-{% equation %}q=q_{0}\cdot u{% endequation %}. אני טוען ש-{% equation %}L_{q}=u^{-1}L{% endequation %}, ודי קל לראות את זה: {% equation %}w\in u^{-1}L{% endequation %} אם ורק אם {% equation %}uw\in L{% endequation %}, אם ורק אם {% equation %}q_{0}\cdot uw\in F{% endequation %}, אם ורק אם {% equation %}\left(q_{0}\cdot u\right)\cdot w=q\cdot w\in F{% endequation %}, אם ורק אם {% equation %}w\in L_{q}{% endequation %}. באופן דומה, אם {% equation %}q=q_{0}\cdot v{% endequation %} עבור {% equation %}v\ne u{% endequation %} אז נקבל ש-{% equation %}L_{q}=v^{-1}L{% endequation %} ולכן בפרט {% equation %}u^{-1}L=v^{-1}L{% endequation %}. המסקנה היא שהפונקציה {% equation %}f\left(q\right)=L_{q}{% endequation %} היא פונקציה מ-{% equation %}Q{% endequation %} <strong>על</strong> הקבוצה {% equation %}\left\{ u^{-1}L\ |\ u\in\Sigma^{*}\right\} {% endequation %}, כלומר הגודל של {% equation %}Q{% endequation %} הוא לפחות כגודל הקבוצה הזו, ומכאן שמספר המצבים באוטומט שבונים בהוכחת מייהיל-נרוד הוא אכן מינימלי (כי מספר מצביו שווה לגודל הקבוצה {% equation %}\left\{ u^{-1}L\ |\ u\in\Sigma^{*}\right\} {% endequation %}).

עכשיו, נניח שיש לנו שני מצבים {% equation %}q,p{% endequation %} כך ש-{% equation %}L_{q}=L_{p}{% endequation %}. מה זה אומר? זה אומר ששני חישובים, שאחד מהם הגיע אל {% equation %}q{% endequation %} והשני הגיע אל {% equation %}p{% endequation %}, יהיו משם והלאה שקולים במובן מסויים; אם נמשיך את שני החישובים על אותה מילה, או ששניהם יסתיימו בקבלה או ששניהם יסתיימו בדחיה (אבל זה ממש לא אומר שהחישובים יגיעו לאותם מצבים - ייתכן שלא יהיו להם מצבים משותפים בכלל). אינטואיטיבית זה אומר שאין לנו צורך בשני מצבים שונים עבור {% equation %}q,p{% endequation %}; אם החישוב מכאן והלאה הוא אותו הדבר, למה לא לאחד את שניהם למצב אחד?

בואו נחדד את מה שאני עושה. אגדיר יחס שקילות {% equation %}\equiv{% endequation %} על {% equation %}Q{% endequation %} באופן הבא: {% equation %}q\equiv p{% endequation %} אם ורק אם {% equation %}L_{q}=L_{p}{% endequation %}. די קל לראות שזה יחס שקילות (כל יחס על קבוצה {% equation %}A{% endequation %} שמוגדר באמצעות פונקציה {% equation %}f:A\to B{% endequation %} כלשהי כך ש-{% equation %}a\equiv a^{\prime}{% endequation %} אם ורק אם {% equation %}f\left(a\right)=f\left(a^{\prime}\right){% endequation %} הוא יחס שקילות). כעת אני טוען שקבוצת המנה {% equation %}Q/\equiv{% endequation %} <strong>איזומורפית</strong> לקבוצת המנה {% equation %}\Sigma^{*}/R_{L}{% endequation %}, כאשר האיזומורפיזם נתון על ידי {% equation %}\left[w\right]_{R_{L}}\mapsto\left[q_{0}\cdot w\right]_{\equiv}{% endequation %}. להוכיח את זה - זה קצת סיפור. צריך להוכיח שהאיזומורפיזם הזה הוא באמת פונקציה; ושהיא חח"ע ועל.

כדי להוכיח שזו פונקציה צריך להוכיח שאין בהגדרה שלה תלות בנציג, כלומר שאם {% equation %}uR_{L}v{% endequation %} אז {% equation %}q_{0}\cdot u\equiv q_{0}\cdot v{% endequation %}, כלומר ש-{% equation %}L_{q_{0}\cdot u}=L_{q_{0}\cdot v}{% endequation %}. נניח בשלילה שקיים {% equation %}z{% endequation %} כך ש-{% equation %}z\in L_{q_{0}\cdot u}{% endequation %} אבל {% equation %}z\notin L_{q_{0}\cdot v}{% endequation %}, אז {% equation %}\left(q_{0}\cdot u\right)\cdot z\in F{% endequation %}, כלומר {% equation %}uz\in L{% endequation %}, אבל {% equation %}vz\notin L{% endequation %}, בסתירה לכך ש-{% equation %}uR_{L}v{% endequation %}.

כדי להוכיח שהפונקציה היא חח"ע צריך להוכיח את הכיוון ההפוך - שאם {% equation %}L_{q_{0}\cdot u}=L_{q_{0}\cdot v}{% endequation %} אז {% equation %}uR_{L}v{% endequation %} - זה פשוט היפוך של הטיעון שנתתי קודם.

כדי להראות שהפונקציה היא על, ניקח מחלקת שקילות {% equation %}\left[q\right]_{\equiv}{% endequation %} כלשהי. מכיוון שהנחתי שכל מצבי האוטומט ישיגים (בדיוק בשביל השלב הזה) הרי שקיים {% equation %}w{% endequation %} כך ש-{% equation %}q=q_{0}\cdot w{% endequation %}, ולכן {% equation %}\left[w\right]_{R_{L}}{% endequation %} הוא מקור של {% equation %}\left[q\right]_{\equiv}{% endequation %}, וסיימנו.

המסקנה היא שכדי לחשב את האוטומט המינימלי, מספיק לנו למצוא את מחלקות השקילות של {% equation %}\equiv{% endequation %}. אחרי שעשינו זאת, עדיין צריך להסביר מה יהיה המצב ההתחלתי שלנו, מי יהיו המצבים המקבלים ומה תהיה פונקציית המעברים. נלך על פי האיזומורפיזם שהצעתי: המצב ההתחלתי יהיה התמונה של {% equation %}\left[\varepsilon\right]_{R_{L}}{% endequation %}, כלומר {% equation %}\left[q_{0}\right]_{\equiv}{% endequation %}; התמונה של כל מצב מקבל {% equation %}\left[w\right]_{R_{L}}{% endequation %} (כאשר {% equation %}w\in L{% endequation %}) תהיה {% equation %}\left[q_{0}\cdot w\right]_{\equiv}{% endequation %}, ואנחנו יודעים ש-{% equation %}q_{0}\cdot w\in F{% endequation %}, כלומר המצבים המקבלים באוטומט שלנו יהיו מחלקות השקילות של מצבים מקבלים ב-{% equation %}Q{% endequation %}; ופונקציית המעברים תוגדר בתור {% equation %}\delta\left(\left[q\right]_{\equiv},\sigma\right)=\left[q\cdot\sigma\right]_{\equiv}{% endequation %}. זה נותן לנו את האוטומט האופטימלי של מייהיל-נרוד. כל מה שנשאר להסביר הוא איך מוצאים את מחלקות השקילות של {% equation %}\equiv{% endequation %}.

הדרך שבה אעשה זאת היא איטרטיבית - אני אתחיל מיחס שקילות שגוי, שהוא <strong>גס מדי</strong> - כלומר, כל מי ש<strong>אמור</strong> להיות שקול אכן שקול, אבל יש גם איברים לא שקולים ב-{% equation %}\equiv{% endequation %} שיהיו שקולים ביחס שלי. לאט לאט אני אלך ו<strong>אעדן</strong> את היחס - כלומר, אם שני איברים לא היו שקולים, הם ימשיכו להיות כאלו, אבל בכל איטרציה אני אקח כמה איברים שהיו שקולים קודם ואפריד אותם זה מזה. נמשיך לבצע את זה עד שנגיע לאיטרציה שבה היחס לא השתנה, ואני אטען שאז הגעתי אל {% equation %}\equiv{% endequation %}. פורמלית, אבנה סדרה של יחסי שקילות {% equation %}\mathcal{Q}_{0},\mathcal{Q}_{1},\dots{% endequation %} עד שאגיע למצב שבו {% equation %}\mathcal{Q}_{k}=\mathcal{Q}_{k+1}{% endequation %}, והטענה תהיה שאז {% equation %}\mathcal{Q}_{k}{% endequation %} הוא בדיוק {% equation %}\equiv{% endequation %}, כלומר ש-{% equation %}q\mathcal{Q}_{k}p{% endequation %} אם ורק אם {% equation %}L_{q}=L_{p}{% endequation %}.

הנה הצעה לגבי האופן שבו כדאי לאתחל:{% equation %}\mathcal{Q}_{0}=\left\{ Q\right\} {% endequation %} (אני מתאר כאן את יחס השקילות בתור <strong>חלוקה</strong> של {% equation %}Q{% endequation %}), כלומר כל האיברים יהיו שקולים זה לזה. מכאן והלאה אנחנו "מתקנים" כשאנחנו מוצאים דוגמאות נגדיות לכך שזוגות של מצבים הם שקולים. הדוגמה הנגדית הראשונה היא {% equation %}\varepsilon{% endequation %}. מן הסתם היא מפרידה בדיוק את אותם מצבים שהם מקבלים מאלו שאינם מקבלים (למה?) ולכן יותר הגיוני לאתחל {% equation %}\mathcal{Q}_{0}=\left\{ Q\backslash F,F\right\} {% endequation %} במקום לאתחל עם קבוצה אחת. מכאן והלאה נפעל איטרטיבית: בהינתן {% equation %}\mathcal{Q}_{k}{% endequation %} נחשב מתוכה את {% equation %}\mathcal{Q}_{k+1}{% endequation %} שהיא קצת יותר מדוייקת מ-{% equation %}\mathcal{Q}_{k}{% endequation %}, עד שנגיע למצב שבו אין יותר שינויים.

עכשיו, בהינתן {% equation %}p,q{% endequation %} שהם שקולים ב-{% equation %}\mathcal{Q}_{k}{% endequation %}, אני אבדוק אם קיים {% equation %}a{% endequation %} כך ש-{% equation %}q\cdot a,p\cdot a{% endequation %} <strong>לא שקולים</strong> ש-{% equation %}\mathcal{Q}_{k}{% endequation %}. אם קיים כזה, אני מפריד את {% equation %}p,q{% endequation %} ב-{% equation %}\mathcal{Q}_{k+1}{% endequation %}. אם {% equation %}p,q{% endequation %} היו שקולים ב-{% equation %}\mathcal{Q}_{k}{% endequation %} ולא מצאתי {% equation %}a{% endequation %} מפריד שכזה, אני ממשך לסמן אותם כשקולים. הניסוח המילולי הזה מסתיר מאחוריו סכנה כלשהי לסיטואציה לא מוגדרת היטב - שיהיו לי שלושה מצבים {% equation %}p,q,r{% endequation %} כך ש-{% equation %}p,q{% endequation %} אמורים להיות לא שקולים אבל {% equation %}p,r{% endequation %} אמורים להיות שקולים וגם {% equation %}q,r{% endequation %} אמורים להיות שקולים. אם זה מטריד אתכם קחו רגע כדי להוכיח שזה לא יכול לקרות, ולכן אנחנו מקבלים שגם {% equation %}\mathcal{Q}_{k+1}{% endequation %} הוא יחס שקילות, וכזה שמעדן את {% equation %}\mathcal{Q}_{k}{% endequation %}. מכיוון שאלו יחס שקילות על קבוצה סופית וכל אחד מהם מעדן את קודמו, מתישהו בהכרח נגיע לנקודת שבת - {% equation %}\mathcal{Q}_{k}=\mathcal{Q}_{k+1}{% endequation %}, מה שמוכיח שהאלגוריתם תמיד מסתיים. נותר להוכיח שהתוצאה היא אכן יחס השקילות שאנחנו רוצים.

כיוון אחד קל. נוכיח באינדוקציה על {% equation %}t{% endequation %} שאם עבור זוג מצבים כלשהו {% equation %}p,q{% endequation %} מתקיים ש-{% equation %}L_{p}=L_{q}{% endequation %} אז {% equation %}q\mathcal{Q}_{t}p{% endequation %}. עבור {% equation %}t=0{% endequation %} זה בבירור עובד, כי אם {% equation %}q{% endequation %} לא שקול ל-{% equation %}p{% endequation %} ב-{% equation %}\mathcal{Q}_{0}{% endequation %} אז בלי הגבלת הכלליות {% equation %}p\in F{% endequation %} ו-{% equation %}q\notin F{% endequation %}, מה שאומר ש-{% equation %}\varepsilon\in L_{p}{% endequation %} אבל {% equation %}\varepsilon\notin L_{q}{% endequation %}. כעת, נניח שזה עובד עבור {% equation %}t{% endequation %} ונוכיח ל-{% equation %}t+1{% endequation %}: אם {% equation %}L_{p}=L_{q}{% endequation %} אבל {% equation %}p,q{% endequation %} לא שקולים ב-{% equation %}\mathcal{Q}_{t+1}{% endequation %}. הנחת האינדוקציה שלנו אומרת ש-{% equation %}p,q{% endequation %} כן היו שקולים ב-{% equation %}\mathcal{Q}_{t}{% endequation %}, ולכן על פי אופן פעולת האלגוריתם, זה אומר שקיים {% equation %}a{% endequation %} כך ש-{% equation %}p\cdot a{% endequation %} ו-{% equation %}q\cdot a{% endequation %} לא שקולים ב-{% equation %}\mathcal{Q}_{t}{% endequation %}; מכאן שבהכרח {% equation %}L_{q\cdot a}\ne L_{p\cdot a}{% endequation %} (למה?). בלי הגבלת הכלליות נובע מכך שקיים {% equation %}z{% endequation %} כך ש-{% equation %}z\in L_{q\cdot a}{% endequation %} אבל {% equation %}z\notin L_{p\cdot a}{% endequation %} - מכאן נובע ש-{% equation %}az\in L_{q}{% endequation %} אבל {% equation %}az\notin L_{p}{% endequation %}, בסתירה לכך ש-{% equation %}L_{q}=L_{p}{% endequation %}, מה שמסיים את הכיוון הזה.

בכיוון השני, אני רוצה להוכיח שאם {% equation %}p\mathcal{Q}_{k}q{% endequation %} אז {% equation %}L_{p}=L_{q}{% endequation %}. נניח שזה לא המצב, אז תהיה לי לפחות דוגמה נגדית אחת. דוגמה נגדית מורכבת משלושה דברים: זוג מצבים {% equation %}p,q{% endequation %} כך ש-{% equation %}p\mathcal{Q}_{k}q{% endequation %}, וכמו כן מילה {% equation %}z{% endequation %} כך ש-{% equation %}z\in L_{p}{% endequation %} אבל {% equation %}z\notin L_{q}{% endequation %}. כדי שההוכחה תעבוד, אני לא סתם אסתכל על דוגמה נגדית אקראית, אלא אקח כזו שבה {% equation %}z{% endequation %} הוא הקצר ביותר האפשרי - כלומר, שכל מילה קצרה יותר מ-{% equation %}z{% endequation %} לא מופיעה באף דוגמה נגדית.

עכשיו אפשר לפרק את {% equation %}z{% endequation %} באופן הבא: {% equation %}z=az^{\prime}{% endequation %} (אני מניח ש-{% equation %}z{% endequation %} הוא מאורך לפחות 1 - למה זה אפשרי?). נקבל ש-{% equation %}z^{\prime}\in L_{p\cdot a}{% endequation %} אבל {% equation %}z^{\prime}\notin L_{q\cdot a}{% endequation %}. אני חותר לכך שזו סתירה למינימליות של האורך של {% equation %}z{% endequation %}; לצורך כך צריך להשתכנע שהשלשה {% equation %}p\cdot a,q\cdot a{% endequation %}ו-{% equation %}z^{\prime}{% endequation %} גם היא דוגמה נגדית, כלומר ש-{% equation %}p\cdot a\mathcal{Q}_{k}q\cdot a{% endequation %}. הסיבה שזה נכון היא שאם לא היה מתקיים ש-{% equation %}p\cdot a\mathcal{Q}_{k}q\cdot a{% endequation %} אז האלגוריתם שלנו היה מפריד את {% equation %}p,q{% endequation %} ב-{% equation %}\mathcal{Q}_{k+1}{% endequation %} ובוודאי שלא היינו מקבלים {% equation %}\mathcal{Q}_{k}=\mathcal{Q}_{k+1}{% endequation %}. זה מסיים את הוכחת הנכונות של האלגוריתם. עכשיו לכו לתכנת אותו!

חזרתם? יופי. בואו נעבור לחלק המוזר של הפוסט - עוד אלגוריתם מינימזציה שלא ברור בכלל מאיפה הוא הגיע ולמה הוא עובד.

כדי שנוכל לתאר את האלגוריתם בצורה פשוטה, כמה סימונים חדשים. נסמן ב-{% equation %}A{% endequation %} אוטומט סופי כלשהו (לאו דווקא דטרמיניסטי, אבל בלי מסעי-{% equation %}\varepsilon{% endequation %}). נסמן ב-{% equation %}A_{\mbox{det}}{% endequation %} את ה<strong>דטרמיניזציה</strong> של {% equation %}A{% endequation %} - האוטומט שמתקבל מאוטומט החזקה של {% equation %}A{% endequation %} על ידי הסרת מצבים לא ישיגים (אסביר את זה בפירוט בהמשך). נסמן ב-{% equation %}A^{R}{% endequation %} את <strong>ההיפוך</strong> של {% equation %}A{% endequation %} - אוטומט שמתקבל מ-{% equation %}A{% endequation %} על ידי היפוך כל כיווני הקשתות והחלפת תפקידי המצבים ההתחלתיים והמקבלים (כזכור, {% equation %}L\left(A^{R}\right)=\left(L\left(A\right)\right)^{R}{% endequation %} כאשר {% equation %}L^{R}{% endequation %} היא היפוך כל המילים ב-{% equation %}L{% endequation %}), ונסמן ב-{% equation %}A_{\mbox{min}}{% endequation %} את האוטומט הדטרמיניסטי המינימלי ששקול ל-{% equation %}A{% endequation %}. אז אני טוען שמתקיים:

{% equation %}A_{\mbox{min}}=\left(\left(\left(A^{R}\right)_{\mbox{det}}\right)^{R}\right)_{\mbox{det}}{% endequation %}

במילים: כדי לקבל את האוטומט הדטרמיניסטי המינימלי ששקול ל-{% equation %}A{% endequation %}, פעלו כך: קודם כל הפכו את {% equation %}A{% endequation %}. בצעו דטרמיניזציה לתוצאה. הפכו את התוצאה ובצעו למה שקיבלתם דטרמיניזציה. הופס! קיבלתם את האוטומט המינימלי.

לא יודע מה אתכם, אני עדיין מרגיש שמשהו מאוד מוזר הולך פה גם בזמן שבו אני כותב את השורות הללו. בתקווה עד שאסיים לכתוב את הפוסט תהיה לכולנו אינטואיציה יותר טובה למה זה עובד, ולא סתם הוכחה פורמלית.

סיבה עיקרית לקושי שאני מרגיש ללא ספק נובעת מכך שאני רגיל לחשוב על דטרמיניזציה של אוטומט בתור משהו ש"מנפח" אותו, ולכן לא ייתכן ששתי דטרמיניזציות יקטינו את מספר המצבים ויתנו לנו אוטומט מינימלי. לכן חשוב להסביר מה זו בעצם הדטרמיניזציה הזו. <a href="http://www.gadial.net/2014/11/19/nondeterministic_automata/">בפוסט</a> על אוטומט אי דטרמיניסטי הצגתי את ההוכחה שקיים לו אוטומט דטרמיניסטי שקול - מה שנקרא <strong>אוטומט חזקה</strong>. כל מצב של אוטומט החזקה הוא קבוצה של מצבים של האוטומט המקורי - אחרי קריאת {% equation %}w{% endequation %} אנחנו מגיעים לקבוצת כל המצבים שיש ריצה על {% equation %}w{% endequation %} באוטומט המקורי שמביאה אותו אליהם.

באופן הזה, הרבה פעמים אנחנו מקבלים מצבים מיותרים. דוגמה טריוויאלית היא מה שנקבל אם נבצע את הבניה הזו על אוטומט שהוא כבר דטרמיניסטי, המצבים היחידים שנזדקק להם בפועל הם קבוצות שהן סינגלטונים (למה?). כל שאר המצבים פשוט יהיו לא ישיגים מהמצב ההתחלתי. אז כשרוצים לבצע דטרמיניזציה בפועל של אוטומט, לא מתחילים מבניה של כל המצבים האפשריים (יש המון כאלו - 2 בחזקת מספר המצבים של האוטומט המקורי). פשוט מבצעים DFS מהמצב ההתחלתי, שהוא {% equation %}\left\{ q_{0}\right\} {% endequation %}. לכל אות מחשבים לאיזה מצב של אוטומט החזקה עוברים ממנו, ולכל מצב כזה מבצעים את אותו חישוב, וכדומה. התוצאה <strong>עשויה</strong> להיות אוטומט החזקה המלא, במקרה שבו כל המצבים שלו הם ישיגים; אבל לרוב היא תהיה הרבה יותר קטנה ולכן העניין הזה פרקטי בפועל. כאמור, אם {% equation %}A{% endequation %} הוא אוטומט, אז אסמן ב-{% equation %}A_{\mbox{det}}{% endequation %} את הדטרמיניזציה הזו שלו.

כדי לקבל אינטואיציה כלשהי לכך שזה עובד, בואו נראה דוגמת צעצוע. אני אקח אוטומט עבור שפת כל המילים מאורך אי-זוגי מעל {% equation %}\left\{ a,b\right\} {% endequation %} ובכוונה האוטומט הזה יהיה לא מינימלי - במקום שני מצבים יהיו לו שלושה, כשבבירור אפשר לאחד את המצב הראשון והשלישי:

<strong><a href="{{site.baseurl}}{{site.post_images}}/2015/05/diagram005.png"><img class="aligncenter size-full wp-image-3245" alt="diagram005" src="{{site.baseurl}}{{site.post_images}}/2015/05/diagram005.png" width="448" height="75" /></a></strong>

הדבר הראשון שנעשה יהיה היפוך של האוטומט הזה. אני הופך את כיווני הקשתות, הופך כל מצב התחלתי למקבל, וכל מצב מקבל להתחלתי. כאן יש רק מצב מקבל אחד אז אני לא מקבל תופעה מוזרה של אוטומט עם כמה מצבים התחלתיים (כבר ראינו שאוטומט כזה הוא לגיטימי ושקול למודל הדטרמיניסטי):

<strong><a href="{{site.baseurl}}{{site.post_images}}/2015/05/diagram006.png"><img class="aligncenter size-full wp-image-3246" alt="diagram006" src="{{site.baseurl}}{{site.post_images}}/2015/05/diagram006.png" width="322" height="162" /></a></strong>

ועכשיו אני מבצע דטרמיניזציה:

<a href="{{site.baseurl}}{{site.post_images}}/2015/05/diagram007.png"><img class="aligncenter size-full wp-image-3247" alt="diagram007" src="{{site.baseurl}}{{site.post_images}}/2015/05/diagram007.png" width="398" height="129" /></a>הופס! קיבלנו רק שני מצבים במקום שלושה - איכשהו הדטרמיניזציה זיהתה ש-{% equation %}q_{0},q_{2}{% endequation %} הם אותו הדבר מבחינתנו והם נדחסו למצב יחיד. למעשה, מה שקיבלנו הוא כבר אוטומט עבור השפה שלנו - לא צריך את ההיפוך והדטרמיניזציה הנוספים, והם גם לא משנים את האוטומט כלל (למה?).

כדי להבין למה כאן הספיק לנו רק "חצי" מהאלגוריתם, הנה המשפט הכללי שעליו אני מסתמך באלגוריתם. לפני כן, הגדרה אחרונה: נאמר שאוטומט {% equation %}A{% endequation %} הוא <strong>קו-בלהבלה</strong>, כאשר במקום "בלהבלה" קחו את התכונה החביבה עליכם, אם {% equation %}A^{R}{% endequation %} מקיים את בלהבלה. למשל, {% equation %}A{% endequation %} הוא קו-דטרמיניסטי אם {% equation %}A^{R}{% endequation %} הוא דטרמיניסטי; והוא קו-נגיש אם {% equation %}A^{R}{% endequation %} נגיש, כלומר כל מצבי {% equation %}A^{R}{% endequation %} ישיגים. הנה המשפט: אם {% equation %}A{% endequation %} הוא קו-דטרמיניסטי וקו-נגיש, אז {% equation %}A_{\mbox{min}}=A_{\mbox{det}}{% endequation %}. מכאן יותר קל להבין מה קרה בנוסחה {% equation %}A_{\mbox{min}}=\left(\left(\left(A^{R}\right)_{\mbox{det}}\right)^{R}\right)_{\mbox{det}}{% endequation %}: החלק הפנימי, {% equation %}\left(\left(A^{R}\right)_{\mbox{det}}\right)^{R}{% endequation %}, הוא פשוט מה שצריך לעשות כדי לקבל מ-{% equation %}A{% endequation %} שהתחלנו ממנו אוטומט שקול שהוא קו-דטרמיניסטי וקו-נגיש (שתי התכונות הללו מושגות בו זמנית על ידי ביצוע דטרמיניזציה). בדוגמת הצעצוע שנתתי, {% equation %}A{% endequation %} שלי <strong>לא</strong> היה קו-דטרמיניסטי, אבל מה שכן היה נכון הוא ש-{% equation %}A^{R}{% endequation %} קיבל את אותה שפה כמו {% equation %}A{% endequation %} (כי מילה היא מאורך אי זוגי אם ורק אם ההיפוך שלה כזה), ואותו {% equation %}A^{R}{% endequation %} דווקא <strong>כן</strong> מקיים את התכונה שהוא קו-דטרמיניסטי וקו-נגיש (כי {% equation %}A{% endequation %} היה דטרמיניסטי ונגיש). לכן כשביצענו את הדטרמיניזציה של {% equation %}A^{R}{% endequation %} קיבלנו אוטומט מינימלי עבור השפה של {% equation %}A^{R}{% endequation %}, ובמקרה שלנו זו הייתה השפה שאנחנו מחפשים.

אז הקסם הוא בכך שדטרמיניזציה של אוטומט עשויה, בתנאים נחמדים מסויימים, לבנות ממנו את האוטומט המינימלי. זה לא באמת מופרך, אם חושבים על זה לרגע. דטרמיניזציה בונה אוטומט חדש, שמצביו הם <strong>קבוצות</strong> של מצבים של האוטומט המקורי - זה בדיוק גם מה שעשינו באלגוריתם הקודם שהצגנו. אבל הסיטואציה בכל זאת שונה - הקבוצות שנקבל <strong>לא</strong> יהיו מחלקות השקילות של היחס {% equation %}\equiv{% endequation %} (למשל, בדוגמה שלי, {% equation %}q_{0}{% endequation %} מתקבץ יחד עם {% equation %}q_{2}{% endequation %} למרות שאחד הוא מצב מקבל והשני איננו). יש בעיה מהותית לדבר בכלל על היחס {% equation %}\equiv{% endequation %} כי הוא הוגדר עבור אוטומטים דטרמיניסטיים, אבל {% equation %}A{% endequation %} שלנו עשוי להיות אי-דטרמיניסטי. לכן בואו נחזור לתיאור האוטומט המינימלי שנתתי בתחילת הפוסט - מצבי האוטומט הם השפות {% equation %}u^{-1}L{% endequation %}. כלומר, אני אראה התאמה חח"ע ועל בין מצבי {% equation %}A_{\mbox{det}}{% endequation %} ובין השפות {% equation %}u^{-1}L{% endequation %}. האינטואיציה ברורה - לכל {% equation %}u\in\Sigma^{*}{% endequation %}, נעביר את המצב שאליו מגיעים על ידי קריאת {% equation %}u{% endequation %} ב-{% equation %}A_{\mbox{det}}{% endequation %} אל {% equation %}u^{-1}L{% endequation %} (דהיינו, אם {% equation %}S=\hat{\delta}\left(q_{0},u\right){% endequation %}, אז מבצעים {% equation %}S\mapsto u^{-1}L{% endequation %}). כדי להיווכח בכך שההתאמה הזו היא בכלל פונקציה ושהיא חח"ע צריך להראות שלכל זוג מילים {% equation %}u,v{% endequation %} מתקיים ש-{% equation %}\hat{\delta}\left(q_{0},u\right)=\hat{\delta}\left(q_{0},v\right){% endequation %} אם ורק אם {% equation %}u^{-1}L=v^{-1}L{% endequation %} - אנחנו מקבלים את אותו הפלט. מרגע שהראיתי את זה, סיימתי, כי ההתאמה היא בבירור על (הרי התחלנו עם {% equation %}u\in\Sigma^{*}{% endequation %} כלשהי, זה מבטיח שנוכל לכסות את כל ה-{% equation %}u^{-1}L{% endequation %}-ים)

בכיוון אחד, אם {% equation %}\hat{\delta}\left(q_{0},u\right)=\hat{\delta}\left(q_{0},v\right){% endequation %} אז מן הסתם לכל הרחבה של החישוב באמצעות {% equation %}z{% endequation %}, אם יהיה חישוב מקבל באחד האוטומטים יהיה גם בשני. לכן {% equation %}uz\in L\iff vz\in L{% endequation %} מה שמראה ש-{% equation %}u^{-1}L=v^{-1}L{% endequation %}. הכיוון המעניין הוא השני: אנו מניחים ש-{% equation %}u^{-1}L=v^{-1}L{% endequation %} וצריכים להראות שהמצבים שאליהם {% equation %}A{% endequation %} יכול להגיע על ידי קריאת {% equation %}u{% endequation %} הם בדיוק המצבים שאליהם {% equation %}A{% endequation %} יכול להגיע על ידי קריאת {% equation %}v{% endequation %}. כאן מן הסתם ייכנסו לפעולה התכונות שמאפיינות את {% equation %}A^{R}{% endequation %}.

בואו ניקח {% equation %}p{% endequation %} כך שקיימת ריצה של {% equation %}A{% endequation %} על {% equation %}u{% endequation %} שמסתיימת ב-{% equation %}p{% endequation %}. האבחנה הראשונה שלנו היא שאפשר להמשיך את הריצה הזו ולהגיע למצב מקבל; זה נובע מכך ש-{% equation %}A^{R}{% endequation %} הוא אוטומט ישיג, ולכן {% equation %}p{% endequation %} ישיג ממצב התחלתי של {% equation %}A^{R}{% endequation %} - כלומר, ב-{% equation %}A{% endequation %} העסק מתהפך ואנחנו מקבלים שיש מצב מקבל של {% equation %}A{% endequation %} שישיג מ-{% equation %}p{% endequation %}. כלומר, קיים {% equation %}z{% endequation %} כך ש-{% equation %}uz\in L{% endequation %}, דהיינו {% equation %}z\in u^{-1}L=v^{-1}L{% endequation %}, ולכן גם {% equation %}vz\in L{% endequation %}. כלומר: קיימת ריצה של {% equation %}A{% endequation %} על {% equation %}vz{% endequation %} שמסתיימת במצב מקבל. עכשיו נכניס לתמונה את העובדה ש-{% equation %}A^{R}{% endequation %} הוא דטרמיניסטי; בפרט זה אומר שקיים לו מצב התחלתי <strong>יחיד</strong> ולכן ל-{% equation %}A{% endequation %} יש מצב מקבל יחיד, כלומר הריצה של {% equation %}A{% endequation %} על {% equation %}vz{% endequation %} מסתיימת באותו מצב כמו הריצה של {% equation %}A{% endequation %} על {% equation %}uz{% endequation %}. בואו נסמן ב-{% equation %}p^{\prime}{% endequation %} את המצב שאליו הריצה הזו מגיעה אחרי סיום קריאת {% equation %}v{% endequation %}.

מה למדנו? שב-{% equation %}A{% endequation %} קיימים שני מצבים, {% equation %}p,p^{\prime}{% endequation %}, שעל ידי קריאת {% equation %}z{% endequation %} ניתן לעבור <strong>מכל אחד מהם</strong> אל המצב המקבל היחיד של {% equation %}A{% endequation %}. זה אומר שב-{% equation %}A^{R}{% endequation %}, על ידי קריאת {% equation %}z^{R}{% endequation %}, אפשר להגיע גם ל-{% equation %}p{% endequation %} וגם ל-{% equation %}p^{\prime}{% endequation %}. אבל הרי {% equation %}A^{R}{% endequation %} הוא דטרמיניסטי, ולכן זה אפשרי רק אם {% equation %}p=p^{\prime}{% endequation %}. המסקנה: קיימת ריצה של {% equation %}A{% endequation %} על {% equation %}v{% endequation %} שמסתיימת ב-{% equation %}p{% endequation %}, ולכן {% equation %}\hat{\delta}\left(q_{0},u\right)\subseteq\hat{\delta}\left(q_{0},v\right){% endequation %}. ההוכחה בכיוון השני זהה, וקיבלנו שהאיזומורפיזם שהגדרתי בין מצבי {% equation %}A_{\mbox{det}}{% endequation %} ובין השפות {% equation %}u^{-1}L{% endequation %} עובד. עדיין צריך להשתכנע ש-{% equation %}A_{\mbox{det}}{% endequation %} זהה לאוטומט שבונים מתוך {% equation %}u^{-1}L{% endequation %}, אבל קל למדי לוודא את זה. סיימנו את הבניה הזו!

כמובן, נשאלת השאלה איזה מבין שני האלגוריתמים הוא עדיף. בשניהם זמן הריצה עשוי להיות אקספוננציאלי במספר המצבים (נסו למצוא דוגמאות נגדיות!) ולכן אין לי תשובה טובה - כנראה שכדאי לנסות להריץ אחד, ואם לא עובד מהר, לנסות את השני. יש גם שאלה של מה בעצם הקלט שלנו - אם נתון לנו אוטומט דטרמיניסטי, כנראה עדיף להפעיל את האלגוריתם הראשון; אם נתון אוטומט אי-דטרמיניסטי, אז כדי להפעיל את האלגוריתם הראשון ממילא יהיה צורך לבצע דטרמיניזציה, אז אפשר כבר לנסות ולהפעיל את האלגוריתם השני (ולבדוק אם יש לנו מזל והוא קו-נגיש וקו-דטרמיניסטי מראש). אבל אם אם זמן הריצה של האלגוריתם השני היה נחות מזה של הראשון זה לא היה כל כך אכפת לי - פשוט כי זה כל כך מגניב.
