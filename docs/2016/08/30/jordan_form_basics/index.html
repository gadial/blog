<!DOCTYPE html>
<html lang="he" dir="rtl">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>צורת ז&#39;ורדן, התכל&#39;ס - לא מדויק</title>
    <link rel="icon" type="image/x-icon" href="/blog/favicon.ico">
    
    
    <!-- KaTeX for math rendering -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css">
    <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js"></script>
    <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js"></script>

    
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }
        
        body {
            font-family: 'Arial', 'David', 'Tahoma', sans-serif;
            line-height: 1.6;
            color: #333;
            background-color: #f5f5f5;
        }
        
        /* Top navigation bar */
        .top-nav {
            background: #2c3e50;
            padding: 15px 20px;
            box-shadow: 0 2px 5px rgba(0,0,0,0.1);
        }
        
        .top-nav .nav-container {
            max-width: 1200px;
            margin: 0 auto;
            display: flex;
            align-items: center;
            justify-content: space-between;
            gap: 20px;
        }
        
        .top-nav .site-title {
            font-size: 1.5em;
            font-weight: bold;
            color: white;
            text-decoration: none;
            white-space: nowrap;
        }
        
        .top-nav .nav-links {
            display: flex;
            gap: 20px;
            align-items: center;
            flex-wrap: wrap;
        }
        
        .top-nav .nav-links a {
            color: #ecf0f1;
            text-decoration: none;
            padding: 5px 10px;
            border-radius: 4px;
            transition: background 0.2s;
            white-space: nowrap;
        }
        
        .top-nav .nav-links a:hover {
            background: #34495e;
        }
        
        .top-nav .search-box {
            display: flex;
            gap: 5px;
        }
        
        .top-nav .search-box input {
            padding: 5px 10px;
            border: none;
            border-radius: 4px;
            font-size: 0.9em;
            min-width: 150px;
        }
        
        .top-nav .search-box button {
            padding: 5px 15px;
            background: #3498db;
            color: white;
            border: none;
            border-radius: 4px;
            cursor: pointer;
            transition: background 0.2s;
        }
        
        .top-nav .search-box button:hover {
            background: #2980b9;
        }
        
        /* Hamburger menu button */
        .menu-toggle {
            display: none;
            background: none;
            border: none;
            font-size: 1.8em;
            color: white;
            cursor: pointer;
            padding: 0;
            line-height: 1;
        }
        
        .menu-toggle:hover {
            opacity: 0.8;
        }
        
        /* Mobile responsive */
        @media (max-width: 768px) {
            .top-nav .nav-container {
                flex-direction: column;
                align-items: stretch;
            }
            
            .top-nav .site-title {
                display: flex;
                justify-content: space-between;
                align-items: center;
                margin-bottom: 0;
                padding: 10px 0;
            }
            
            .menu-toggle {
                display: block;
            }
            
            /* Hide nav links by default on mobile */
            .top-nav .nav-links {
                display: none;
                flex-direction: column;
                width: 100%;
                margin-top: 10px;
            }
            
            /* Show when expanded */
            .top-nav .nav-links.expanded {
                display: flex;
            }
            
            .top-nav .nav-links > a {
                text-align: center;
                padding: 12px;
                border-top: 1px solid rgba(255, 255, 255, 0.2);
            }
            
            .top-nav .search-box {
                width: 100%;
                flex-direction: column;
                margin-top: 10px;
                padding-top: 10px;
                border-top: 1px solid rgba(255, 255, 255, 0.2);
            }
            
            .top-nav .search-box input {
                width: 100%;
                margin-bottom: 5px;
                min-width: 0;
            }
            
            .top-nav .search-box button {
                width: 100%;
            }
        }
        
        /* Blockquote styling */
        blockquote {
            background: #f9f9f9;
            border-right: 5px solid #ccc;
            margin: 1.5em 10px;
            padding: 0.75em 16px;
            position: relative;
            font-style: italic;
        }
        
        blockquote:before {
            content: '"';
            position: absolute;
            top: -10px;
            right: 8px;
            font-size: 3.5em;
            color: #ccc;
            line-height: 1;
        }
        
        blockquote p {
            display: block;
            margin: 0 0 0.75em 0;
        }
        
        blockquote p:last-child {
            margin-bottom: 0;
        }
        
        
        body {
            line-height: 1.8;
        }
        
        .container {
            max-width: 800px;
            margin: 20px auto;
            background: white;
            padding: 40px;
            box-shadow: 0 2px 10px rgba(0,0,0,0.1);
            border-radius: 8px;
        }
        
        header {
            margin-bottom: 40px;
            border-bottom: 2px solid #e0e0e0;
            padding-bottom: 20px;
        }
        
        h1 {
            font-size: 2.5em;
            margin-bottom: 10px;
            color: #2c3e50;
        }
        
        .post-meta {
            color: #7f8c8d;
            font-size: 0.9em;
        }
        
        .post-meta .date {
            margin-left: 15px;
        }
        
        .post-meta .categories,
        .post-meta .tags {
            display: inline;
        }
        
        .post-meta .categories a,
        .post-meta .tags a {
            color: #3498db;
            text-decoration: none;
            margin: 0 5px;
        }
        
        .post-meta .categories a:hover,
        .post-meta .tags a:hover {
            text-decoration: underline;
        }
        
        article {
            font-size: 1.1em;
        }
        
        article h2 {
            margin-top: 30px;
            margin-bottom: 15px;
            color: #34495e;
            font-size: 1.8em;
        }
        
        article h3 {
            margin-top: 25px;
            margin-bottom: 12px;
            color: #34495e;
            font-size: 1.4em;
        }
        
        article p {
            margin-bottom: 15px;
            text-align: justify;
        }
        
        article ul, article ol {
            margin-right: 30px;
            margin-bottom: 15px;
        }
        
        article li {
            margin-bottom: 8px;
        }
        
        article code {
            background-color: #f4f4f4;
            padding: 2px 6px;
            border-radius: 3px;
            font-family: 'Courier New', monospace;
            font-size: 0.9em;
        }
        
        article pre {
            background-color: #2d2d2d;
            color: #f8f8f2;
            padding: 15px;
            border-radius: 5px;
            overflow-x: auto;
            margin-bottom: 20px;
            direction: ltr;
            text-align: left;
        }
        
        article pre code {
            background-color: transparent;
            padding: 0;
            color: inherit;
        }
        
        /* Image styles - responsive and contained */
        article img {
            max-width: 100%;
            height: auto;
            display: block;
            margin: 20px auto;
        }
        
        /* Math rendering styles */
        .math {
            direction: ltr;
        }
        
        span.math {
            direction: ltr;
        }
        
        /* Override RTL for KaTeX */
        .katex {
            direction: ltr;
            unicode-bidi: embed;
        }
        
        /* Force KaTeX content to wrap by overriding its internal structure */
        .katex-html {
            display: inline !important;
            white-space: normal !important;
        }
        
        .katex .base {
            display: inline !important;
            white-space: normal !important;
        }
        
        .katex .mord,
        .katex .mbin,
        .katex .mrel,
        .katex .mopen,
        .katex .mclose,
        .katex .mpunct,
        .katex .minner {
            display: inline !important;
            white-space: normal !important;
        }
        
        div.math {
            display: block;
            text-align: center;
            padding: 15px 0;
            direction: ltr;
        }
        
        /* RTL adjustments for code blocks */
        .highlight {
            direction: ltr;
            text-align: left;
        }
        
        footer {
            margin-top: 60px;
            padding-top: 20px;
            border-top: 1px solid #e0e0e0;
            text-align: center;
            color: #95a5a6;
            font-size: 0.9em;
        }
        
        /* Responsive design */
        @media (max-width: 768px) {
            .container {
                padding: 20px;
            }
            
            h1 {
                font-size: 2em;
            }
            
            article {
                font-size: 1em;
            }
            
            /* Hide post navigation on mobile */
            .post-navigation {
                display: none;
            }
        }
        
        /* Post navigation */
        .post-navigation {
            display: flex;
            justify-content: space-between;
            margin-bottom: 30px;
            padding-bottom: 20px;
            border-bottom: 2px solid #e0e0e0;
            gap: 20px;
        }
        
        .post-navigation .nav-link {
            flex: 1;
            text-decoration: none;
            color: #2c3e50;
            padding: 15px;
            background: #f8f9fa;
            border-radius: 5px;
            transition: background 0.2s;
        }
        
        .post-navigation .nav-link:hover {
            background: #e9ecef;
        }
        
        .post-navigation .nav-prev {
            text-align: right;
        }
        
        .post-navigation .nav-next {
            text-align: left;
        }
        
        .post-navigation .nav-label {
            font-size: 0.85em;
            color: #7f8c8d;
            display: block;
            margin-bottom: 5px;
        }
        
        .post-navigation .nav-title {
            font-weight: bold;
            font-size: 1.1em;
        }

    </style>
</head>
<body>
    <nav class="top-nav">
        <div class="nav-container">
            <div class="site-title">
                <a href="/blog/" style="color: white; text-decoration: none;">לא מדויק</a>
                <button class="menu-toggle" onclick="toggleMobileMenu()" aria-label="תפריט">
                    ☰
                </button>
            </div>
            <div class="nav-links" id="navLinks">
                <a href="/blog/">דף הבית</a>
                <a href="/blog/random.html">פוסט אקראי</a>
                <a href="/blog/post_list.html">כל הפוסטים</a>
                <div class="search-box">
                    <input type="text" id="searchInput" placeholder="חיפוש...">
                    <button onclick="searchPosts()">חפש</button>
                </div>
            </div>
        </div>
    </nav>
    
    
    <div class="container">
        <!-- Post Navigation -->
        
        <nav class="post-navigation">
            
            <a href="/blog/2016/08/21/stokes_theorem_overview/" class="nav-link nav-prev">
                <span class="nav-label">פוסט ישן יותר →</span>
                <span class="nav-title">על יריעות ותבניות (מה משפט סטוקס אומר, בגדול)</span>
            </a>
            

            
            <a href="/blog/2016/09/29/cyclic_decomposition_theorem/" class="nav-link nav-next">
                <span class="nav-label">← פוסט חדש יותר</span>
                <span class="nav-title">משפט הפירוק הציקלי</span>
            </a>
            
        </nav>
        
        
        <header>
            <h1>צורת ז&#39;ורדן, התכל&#39;ס</h1>
            <div class="post-meta">
                <span class="date">2016-08-30</span>
                
                <span class="categories">
                    | קטגוריות:
                    
                    <a href="/categories/אלגברה לינארית.html">אלגברה לינארית</a>
                    
                </span>
                
                
                <span class="tags">
                    | תגיות:
                    
                    <a href="/tags/אלגברה לינארית.html">אלגברה לינארית</a>
                    
                    <a href="/tags/צורת ז&#39;ורדן.html">צורת ז&#39;ורדן</a>
                    
                </span>
                
            </div>
        </header>
        
        <article>
            <p><strong>מבוא ובו סיפור חיים מרגש ומטריצות, הרבה מטריצות</strong></p>
<p>בזמנו כתבתי סדרת פוסטים על אלגברה לינארית, ששיאה היה אמור להיות פוסט על צורת ז'ורדן. בפועל הגעתי עד ל<a href="http://www.gadial.net/2012/01/09/primary_decomposition_theorem/">משפט הפירוק הפרימרי</a> (גם זה סוג של שיא) ושם נתקעתי, כי את צורת ז'ורדן לא הצלחתי להציג בצורה משביעת רצון, אפילו לא לעצמי, ולמרות שזה נושא שכבר הכרתי מכמה נקודות התבוננות שונות. כיום אני חושב שאני יודע להצביע על הבעיה המרכזית שלי; הדרך ה"נכונה" להציג את צורת ז'ורדן, זו שכוללת את כל התיאוריה שמובילה אליה, היא מאוד עמוסה ברעיונות שנראים קצת לא קשורים בהתחלה ופתאום הכל מסתדר. זה יפה בצורה בלתי רגילה. זה גם לא בדיוק פרקטי לקרוא את זה כשכל מה שרוצים באותו הרגע הוא להבין איך מוצאים את צורת ז'ורדן הארורה הזו ו"מה האלגוריתם". אז בואו נעשה את הדבר הבא: אתחיל מהצגה של התכל'ס - מה זה, מה התכונות הבסיסיות של זה, איך מוצאים את זה, וזהו. ארמוז קצת לגבי <strong>למה</strong> זה עובד ומאיפה דברים מגיעים, אבל לא אכנס לפרטים. אחר כך, כשהרעיון הכללי כבר יושב לנו טוב, נוכל ללכת ולהסתכל על התיאוריה הכללית שמסביב, ולהתלהב מכמה שזה יפה.</p>
<p>נתחיל עם תיאור של מה זה בכלל. ההקשר הכללי שלנו הוא אלגברה לינארית, שאני מניח שכולכם מכירים; ההקשר הפרטני יותר הוא זה של צורות קנוניות של מטריצות/טרנספורמציות לינאריות, שגם אותו אני מניח שאתם מכירים. לכל הפחות, צריך להכיר את הנושא של <a href="http://www.gadial.net/2011/12/03/eigenvalues_main/">לכסון מטריצות</a>, כי זה בדיוק מה שצורת ז'ורדן באה להכליל. השורה התחתונה של מהי צורת ז'ורדן היא פשוטה להדהים. בלכסון מטריצות, הרעיון היה שאפשר למצוא עבור מטריצות <span class="math">\(A\)</span> מסויימות מטריצה <span class="math">\(D\)</span> אלכסונית ומטריצה <span class="math">\(P\)</span> הפיכה, כך ש-<span class="math">\(D=P^{-1}AP\)</span>. בניסוח אחר: לטרנספורמציות לינאריות מסויימות היה אפשר למצוא בסיס שבו הן מיוצגות על ידי מטריצה <span class="math">\(D\)</span> אלכסונית. הדגש היה על <strong>מסויימות</strong>; לא כל מטריצה/טרנספורמציה הייתה "לכסינה" בצורה הזו. צורת ז'ורדן באה לתת משהו שמתקיים לכל מטריצה או טרנספורמציה, בתנאי אחד: שהשדה שמעליו אנחנו עובדים הוא סגור אלגברית (אסביר את זה בהמשך). התוצאה היא כמעט אותה תוצאה, רק שבמקום <span class="math">\(D\)</span> <strong>אלכסונית</strong> יש לנו <span class="math">\(J\)</span> שהיא "כמעט אלכסונית" - פרט לאיברים על האלכסון, עשויים להופיע 1-ים במקומות שונים ומשונים על גבי האלכסון המשני שמעל האלכסון הראשי. זה הכל.</p>
<p>בשביל שתהיה לנו כל הזמן דוגמה כלשהי מול העיניים, הנה משהו קונקרטי:</p>
<p><span class="math">\(A=\left(\begin{array}{rrrrrr}3 & 0 & 0 & 0 & 0 & 0\\0 & 2 & 0 & 0 & -1 & 0\\0 & 0 & 2 & 0 & 1 & 0\\0 & 0 & 0 & 2 & 0 & 1\\0 & 1 & 1 & 0 & 2 & 0\\0 & 0 & 0 & 0 & 0 & 2\end{array}\right)\)</span></p>
<p><span class="math">\(J=\left(\begin{array}{rrrrrr}3 & 0 & 0 & 0 & 0 & 0\\0 & 2 & 1 & 0 & 0 & 0\\0 & 0 & 2 & 1 & 0 & 0\\0 & 0 & 0 & 2 & 0 & 0\\0 & 0 & 0 & 0 & 2 & 1\\0 & 0 & 0 & 0 & 0 & 2\end{array}\right)\)</span></p>
<p><span class="math">\(P=\left(\begin{array}{rrrrrr}1 & 0 & 0 & 0 & 0 & 0\\0 & -1 & 0 & 1 & 0 & 0\\0 & 1 & 0 & 0 & 0 & 0\\0 & 0 & 0 & 0 & 1 & 0\\0 & 0 & 1 & 0 & 0 & 0\\0 & 0 & 0 & 0 & 0 & 1\end{array}\right)\)</span></p>
<p>שימו לב לצורה של <span class="math">\(J\)</span>. זה מה שנקרא <strong>מטריצת בלוקים</strong>. רובה אפסים, פרט לשלוש תת-מטריצות שהאלכסון הראשי שלהן נח על האלכסון הראשי של המטריצה: המטריצה <span class="math">\(\left(\begin{array}{c}3\end{array}\right)\)</span> (מטריצה מסדר <span class="math">\(1\times1\)</span>), המטריצה <span class="math">\(\left(\begin{array}{ccc}2 & 1 & 0\\0 & 2 & 1\\0 & 0 & 2\end{array}\right)\)</span> והמטריצה <span class="math">\(\left(\begin{array}{cc}2 & 1\\0 & 2\end{array}\right)\)</span>. על מטריצה כזו אומרים שהיא מורכבת משלושה <strong>בלוקי ז'ורדן</strong>, שאחד מהם הוא מגודל 1 ומתאים לערך העצמי 3, השני הוא מגודל 3 ומתאים לערך העצמי 2, והשלישי הוא מגודל 2 ומתאים לערך העצמי 2. כלומר, בלוק ז'ורדן הוא בסך הכל מטריצה סקלרית (כלומר, כזו שבה על האלכסון הראשי יש ערך סקלרי קבוע כלשהו) ועוד מטריצה שבה על האלכסון המשני העליון יש 1-ים. כל צורת ז'ורדן היא משהו כזה: מטריצת בלוקים שבה הבלוקים הם בלוקי ז'ורדן. לב הרעיון הוא שכל מטריצה דומה למטריצת ז'ורדן <strong>יחידה</strong>, עד כדי זה שאפשר לשחק עם הסדר של העמודות. כלומר, אם נמיין את הבלוקים (למשל) על פי גודל הערך העצמי ואז על פי גדלי הבלוקים, נקבל ייצוג יחיד.</p>
<p>השאלה שלנו, אם כן, היא זו: בהינתן <span class="math">\(A\)</span> כמו זו, איך מוצאים את <span class="math">\(J\)</span>? ואיך מוצאים את <span class="math">\(P\)</span>? זה מה שנטפל בו בפוסט הזה. לא ניכנס להוכחות של קיום ויחידות צורת ז'ורדן או כל דבר דומה.</p>
<p><strong>פרק ראשון, ובו נוסטלגיה לימים הטובים שבהם פולינומים היו פולינומים, ריבוי אלגברי היה ריבוי גאומטרי, ומטריצות היו לכסינות</strong></p>
<p>נתחיל מלהזכיר את המושגים שרלוונטיים לנו. צורת ז'ורדן היא סוג של הכללה של לכסון מטריצות, ולכן לא פלא שהמושגים שצצו בלכסון מטריצות הם בעלי תפקיד מרכזי גם כאן, אז נזכיר אותם. המושג הבסיסי הוא <strong>ערך עצמי</strong> של <span class="math">\(A\)</span>: <span class="math">\(\lambda\)</span> הוא ערך עצמי אם קיים וקטור <span class="math">\(v\ne0\)</span> כך ש-<span class="math">\(Av=\lambda v\)</span>. על <span class="math">\(v\)</span> אומרים שהוא <strong>וקטור עצמי</strong> של <span class="math">\(A\)</span>.</p>
<p>מציאת ערכים עצמיים זה עניין פשוט יחסית. נניח ש-<span class="math">\(A\)</span> היא מטריצה מסדר <span class="math">\(n\times n\)</span> מעל שדה <span class="math">\(\mathbb{F}\)</span>. אם <span class="math">\(Av=\lambda v\)</span> אז על ידי העברת אגפים מקבלים ש-<span class="math">\(\left(A-\lambda I\right)v=0\)</span>, כלומר <span class="math">\(v\in\ker\left(A-\lambda I\right)\)</span>. בפרט, זה אומר שהגרעין של המטריצה <span class="math">\(A-\lambda I\)</span> אינו טריוויאלי, ולכן המטריצה הזו אינה הפיכה, ולכן הדטרמיננטה שלה היא אפס: <span class="math">\(\det\left(A-\lambda I\right)=0\)</span>. זה מוביל להגדרה הבאה של <strong>הפולינום האופייני</strong> של מטריצה <span class="math">\(A\)</span>: <span class="math">\(p_{A}\left(x\right)=\det\left(xI-A\right)\)</span>. כאן <span class="math">\(xI-A\)</span> היא מטריצה שהכניסות שלה לא שייכות סתם לאיזה שדה <span class="math">\(\mathbb{F}\)</span> אלא ל-<span class="math">\(\mathbb{F}\left[x\right]\)</span> - חוג הפולינומים מעל <span class="math">\(\mathbb{F}\)</span>. חישוב הדטרמיננטה עדיין מתבצע באותו האופן. מקבלים תמיד פולינום מתוקן (כלומר, כזה שבו המקדם המוביל הוא 1; זו הסיבה שלוקחים דטרמיננטה של <span class="math">\(xI-A\)</span> ולא של <span class="math">\(A-xI\)</span>) ממעלה <span class="math">\(n\)</span>. למשל, עבור המטריצה <span class="math">\(A\)</span> בדוגמה שלנו, חישוב ישיר נותן <span class="math">\(p_{A}\left(x\right)=\left(x-3\right)\left(x-2\right)^{5}\)</span>. הפואנטה בפולינום האופייני הוא שהערכים העצמיים של <span class="math">\(A\)</span> הם בדיוק השורשים של הפולינום הזה.</p>
<p>בדוגמה שלנו, הפולינום התפרק למכפלה של גורמים לינאריים, כלומר גורמים מהצורה <span class="math">\(\left(x-\lambda\right)\)</span>. חלק מהגורמים חזרו על עצמם - <span class="math">\(\left(x-2\right)\)</span> הופיע 5 פעמים - אבל זו לא בעיה. מתי יש בעיה? אם יש לנו גורם שאנחנו לא יכולים לפרק יותר מעל השדה הנוכחי שלנו. נראה את הדוגמה הקלאסית לכך. נניח שאנחנו מעל השדה <span class="math">\(\mathbb{R}\)</span> ונתבונן על המטריצה <span class="math">\(\left(\begin{array}{cc}0 & 1\\-1 & 0\end{array}\right)\)</span>. הפולינום האופייני שלה הוא <span class="math">\(\det\left(\begin{array}{cc}x & -1\\1 & x\end{array}\right)=x^{2}+1\)</span>. מעל <span class="math">\(\mathbb{R}\)</span> אי אפשר לפרק את הפולינום הזה לגורמים לינאריים. אם נעבור אל <span class="math">\(\mathbb{C}\)</span> הפולינום יתפרק ל-<span class="math">\(\left(x-i\right)\left(x+i\right)\)</span>, ואלו אכן הערכים העצמיים של המטריצה הזו; אבל מעל <span class="math">\(\mathbb{R}\)</span> אנחנו "תקועים". כאן זה החיסרון היחיד של צורת ז'ורדן: אם הפולינום האופייני לא מתפרק לגורמים לינאריים, צורת ז'ורדן לא עובדת. אם <strong>נרחיב את השדה</strong> שמעליו אנחנו עובדים לשדה שבו הפולינום הזה מתפרק לגורמים לינאריים, אז מעל השדה המורחב הזה נוכל למצוא צורת ז'ורדן והכל יהיה טוב ויפה, אבל בלי זה אין על מה לדבר. לכן בכל הדיון על צורות ז'ורדן מניחים שהפולינום האופייני של המטריצה שלנו כן מתפרק לגורמים לינאריים (לפעמים פשוט מניחים שעובדים מעל השדה <span class="math">\(\mathbb{C}\)</span> שכל פולינום מעליו מתפרק לגורמים לינאריים וחסל; זהו <strong>המשפט היסודי של האלגברה</strong>).</p>
<p>לכל שורש <span class="math">\(\lambda\)</span> של הפולינום האופייני מגדירים את <strong>הריבוי האלגברי</strong> שלו להיות מספר הפעמים שבהן הגורם <span class="math">\(x-\lambda\)</span> מופיע בפולינום האופייני. בדוגמה שלנו הריבוי האלגברי של 3 הוא 1 והריבוי האלגברי של 2 הוא 5. כמו כן, מגדירים את <strong>הריבוי הגאומטרי</strong> של <span class="math">\(\lambda\)</span> בתור <span class="math">\(\dim\ker\left(A-\lambda I\right)\)</span>, שזו דרך אחרת לומר "המימד של תת-המרחב של הוקטורים העצמיים שמתאימים לערך <span class="math">\(\lambda\)</span>".</p>
<p>לבסוף, המשפט הבסיסי על לכסון מטריצות אומר שמטריצה היא לכסינה אם ורק אם הריבוי האלגברי של כל ערך עצמי שווה לריבוי הגיאומטרי שלו (אפשר לראות שתמיד הריבוי האלגברי <strong>גדול או שווה</strong>). במקרה הזה, אפשר למצוא למרחב כולו בסיס שכולו בנוי מוקטורים עצמיים של <span class="math">\(A\)</span>. כעת הטרנספורמציה הלינארית ש-<span class="math">\(A\)</span> מייצג תהיה מיוצגת על ידי מטריצה אלכסונית בבסיס הזה; ואם נגדיר את <span class="math">\(P\)</span> להיות המטריצה שעמודותיה הם הוקטורים העצמיים הללו, אז נקבל ש-<span class="math">\(P^{-1}AP=D\)</span> כאשר <span class="math">\(D\)</span> אלכסונית ועל האלכסון שלה מופיעים הערכים העצמיים של <span class="math">\(A\)</span>.</p>
<p>צורת ז'ורדן באה לטפל בסיטואציה שבה הריבוי הגיאומטרי <strong>קטן</strong> מהריבוי האלגברי. במצב הזה, אין לנו "מספיק" וקטורים עצמיים כדי לקבל בסיס, אז אנחנו מתחילים לחפש וקטורים במקומות נוספים. הנה הרעיון: אם עבור וקטורים עצמיים עבור <span class="math">\(\lambda\)</span> חיפשנו איברים של <span class="math">\(\ker\left(A-\lambda I\right)\)</span>, הרי שעכשיו אנחנו נחפש איברים של <span class="math">\(\ker\left(A-\lambda I\right)^{k}\)</span> עבור <span class="math">\(k\ge1\)</span>. אבל לא מספיק לבחור "סתם" איברים של המרחבים הללו; צריך לבצע את הבחירה הזו בצורה זהירה למדי כדי לוודא שאנחנו אכן תופסים את כל מה שצריך לתפוס. אני אתן כבר עכשיו את הרעיון על קצה המזלג:</p>
<ol>
    <li>בכל שלב, אנחנו מחפשים וקטורים ב-<span class="math">\(\ker\left(A-\lambda I\right)^{k}\)</span> <strong>שאינם</strong> שייכים ל-<span class="math">\(\ker\left(A-\lambda I\right)^{k-1}\)</span> (ועוד תכונה יותר מסובכת שאסביר בהמשך, <strong>אל תחשבו</strong> שהתיאור הזה שלם).</li>
    <li>בכל שלב, אם בחרנו וקטור <span class="math">\(v\)</span> כלשהו, אנחנו צריכים לקחת את כל ה<strong>שרשרת</strong> שהוא יוצר על ידי הפעלות חוזרות ונשנות של <span class="math">\(\left(A-\lambda I\right)\)</span> עליו. דהיינו, אם לקחנו את <span class="math">\(v\)</span> לקבוצת הוקטורים שאנחנו בונים, ניקח גם את <span class="math">\(\left(A-\lambda I\right)v\)</span>, גם את <span class="math">\(\left(A-\lambda I\right)^{2}v\)</span> וכן הלאה עד אשר מגיעים אל 0.</li>
</ol>
<p>זה, על רגל אחת, האלגוריתם שלנו. הוא לא שונה כל כך ממה שקרה בסיטואציה של לכסון מטריצות: שם התחלנו מ-<span class="math">\(k=1\)</span>, ולכן בסך הכל חיפשנו כמה שיותר וקטורים ב-<span class="math">\(\ker\left(A-\lambda I\right)\)</span> כאשר תנאי ה"אינם שייכים" היה בדיוק התנאי שהוקטורים העצמיים שונים מ-0.</p>
<p><b>פרק שני, שבו הפולינום המינימלי מראה שאת מה שהוא הספיק לשכוח על בלוקי ז'ורדן אנחנו עוד לא למדנו</b></p>
<p>דבר אחד עדיין בבירור חסר ב"אלגוריתם" שאני מציע כאן - איך יודעים מאיזה <span class="math">\(k\)</span> להתחיל את החיפוש? בשביל זה נכניס לתמונה עוד מושג מוכר מהעבר: <strong>פולינום מינימלי</strong>.</p>
<p>בהינתן מטריצה <span class="math">\(A\)</span>, <strong>הפולינום המינימלי</strong> <span class="math">\(m_{A}\left(x\right)\)</span> שלה הוא פולינום מתוקן שמקיים <span class="math">\(m_{A}\left(A\right)=0\)</span> והוא מחלק כל פולינום אחר שמאפס את <span class="math">\(A\)</span> - במילים יותר פורמליות, <span class="math">\(m_{A}\left(x\right)\)</span> הוא <strong>היוצר</strong> של אידאל הפולינומים שמאפסים את <span class="math">\(A\)</span> בחוג <span class="math">\(\mathbb{F}\left[x\right]\)</span>. העובדה שקיים כזה פולינום מובטחת מכך ש-<span class="math">\(\mathbb{F}\left[x\right]\)</span> הוא תחום ראשי; לא אכנס כאן לפרטים. כלי מועיל מאוד בדרך למציאת הפולינום המינימלי הוא <strong>משפט קיילי המילטון</strong> שאומר ש-<span class="math">\(p_{A}\left(A\right)=0\)</span>, כלומר הפולינום האופייני של מטריצה מאפס אותה, ולכן הפולינום המינימלי מחלק אותו; אפשר להראות שהפולינום המינימלי הוא בעל אותם גורמים לינאריים בדיוק כמו הפולינום האופייני, רק שהריבוי שלהם עשוי להיות קטן יותר (כלומר, מקטינים חלק מהחזקות, אבל לא מורידים חזקה כלשהי ל-0). לכן אפשר פשוט להציב את <span class="math">\(A\)</span> בכל מני מועמדים אפשריים ולראות מה קורה (בהמשך נראה שיש דרך חכמה יותר למצוא את הפולינום המינימלי). בדוגמה שלנו, <span class="math">\(m_{A}\left(x\right)=\left(x-3\right)\left(x-2\right)^{3}\)</span>, כלומר הגורם <span class="math">\(\left(x-3\right)\)</span> לא נעלם (אסור לו להיעלם) והגורם <span class="math">\(\left(x-2\right)^{5}\)</span> איבד 2 ממעריך החזקה שלו והפך להיות <span class="math">\(\left(x-2\right)^{3}\)</span>.</p>
<p>מה שיפה הוא שהפולינומים האופייני והמינימלי של <span class="math">\(A\)</span> מספקים לנו המון מידע על צורת ז'ורדן של המטריצה. לפעמים מספיק מידע כדי לקבוע מהי בצורה יחידה (אבל לא תמיד). הנה סיכום זריז:</p>
<ul>
    <li>לכל ערך עצמי <span class="math">\(\lambda\)</span>, הריבוי האלגברי של <span class="math">\(\lambda\)</span> (הדרגה של <span class="math">\(\left(x-\lambda\right)\)</span> בפולינום האופייני) שווה ל<strong>סכום גדלי</strong> בלוקי ז'ורדן המתאימים ל-<span class="math">\(\lambda\)</span>.</li>
    <li>לכל ערך עצמי <span class="math">\(\lambda\)</span>, הריבוי הגאומטרי של <span class="math">\(\lambda\)</span> שווה ל<strong>מספר</strong> בלוקי ז'ורדן המתאימים ל-<span class="math">\(\lambda\)</span>.</li>
    <li>לכל ערך עצמי <span class="math">\(\lambda\)</span>, הריבוי של <span class="math">\(\lambda\)</span> <strong>בפולינום המינימלי</strong> שווה לגודל בלוק הז'ורדן הגדול ביותר המתאים ל-<span class="math">\(\lambda\)</span>.</li>
</ul>
<p>בואו נראה מה שלושת אלו אומרים בדוגמה שלנו. עבור <span class="math">\(\lambda=3\)</span> קיים בפולינום האופייני הגורם <span class="math">\(\left(x-3\right)\)</span> שהוא ממעלה 1, כלומר הריבוי האלגברי הוא 1 ולכן גם הריבוי הגאומטרי הוא 1. המסקנה היא שב-<span class="math">\(J\)</span> יהיה בלוק ז'ורדן יחיד שמתאים ל-<span class="math">\(\lambda=3\)</span> ושהגודל שלו יהיה 1. זה אכן מה שקורה.</p>
<p>לגבי הערך העצמי <span class="math">\(\lambda=2\)</span>, הריבוי האלגברי שלו הוא 5, ולכן סכום גדלי כל הבלוקים שלו יהיה 5. כמה בלוקים כאלו יהיו? בשביל זה צריך להפשיל שרוולים ולמצוא את הריבוי הגיאומטרי, כלומר לחשב את <span class="math">\(\dim\ker\left(A-2I\right)\)</span>, מה שאפשר לעשות על ידי דירוג מטריצות סטנדרטי. מקבלים ריבוי גיאומטרי 2, ולכן יהיו שני בלוקי ז'ורדן. זה זמן לא רע לעצור ולחשוב מה הם יכולים להיות. סכום הגדלים שלהם יהיה 5; בכמה דרכים אפשר לכתוב את 5 בתור סכום של שני מספרים טבעיים חיוביים? או <span class="math">\(5=1+4\)</span> או <span class="math">\(5=2+3\)</span>. אלא שהמקרה הראשון נפסל בשל הפולינום המינימלי; הריבוי של <span class="math">\(\lambda=2\)</span> בפולינום המינימלי הוא 3 ולכן לא ייתכן שיש בלוק מגודל 4. לכן בהכרח האפשרות הנוספת היא הנכונה - יהיה לנו בלוק אחד מגודל 3 ובלוק אחר מגודל 2, וזה בדיוק מה שיש לנו. הנה כי כן, רק מהיכרות עם הפולינום האופייני והמינימלי של <span class="math">\(A\)</span> כבר הבנו בדיוק איך צורת ז'ורדן שלה תיראה. אם אנחנו רוצים למצוא את <span class="math">\(P\)</span> המז'רדנת, נצטרך לעבוד עוד קצת.</p>
<p>האם המידע שכתבתי למעלה זה כל המידע שאפשר לחלץ על צורת ז'ורדן מבלי לחשב את <span class="math">\(P\)</span> במפורש? ובכן, לא. שמרתי את הדבר המסובך ביותר לסוף:</p>
<ul>
    <li>לכל ערך עצמי <span class="math">\(\lambda\)</span>, מספר בלוקי ז'ורדן המתאימים ל-<span class="math">\(\lambda\)</span> מגודל <span class="math">\(k\)</span> <strong>לפחות</strong> הוא ההפרש <span class="math">\(\dim\ker\left(A-\lambda I\right)^{k}-\dim\ker\left(A-\lambda I\right)^{k-1}\)</span>.</li>
</ul>
<p>עוד רגע אסביר את ההגיון מאחורי התכונה הזו, ויש בהחלט הגיון, אבל לפני כן בואו נעזור קצת למי שה"לפחות" הזה מציק לו ורוצה לדעת מה המספר <strong>בדיוק</strong>. הטיעון הוא קצת חמקמק, אז הנה דוגמה: נניח שאני יודע שיש בדיוק 5 בלוקים מגודל שהוא <strong>לפחות</strong> 3, ואני יודע שיש 2 בלוקים מגודל שהוא <strong>לפחות</strong> 4, כמה בלוקים מגודל <strong>בדיוק</strong> 3 יש? אני מקווה שאתם צועקים עלי "שלושה!". איך ידעתם? כי אפשר לראות שבמעבר בין בלוקים מגודל <strong>לפחות</strong> 3 אל גודל <strong>לפחות</strong> 4 "איבדנו" 3 בלוקים; אלו חייבים להיות הבלוקים שגודלם הוא <strong>בדיוק</strong> 3.</p>
<p>מכאן שכדי לקבל את מספר הבלוקים מגודל <span class="math">\(k\)</span> <strong>בדיוק</strong> אנחנו צריכים לחשב את מספר הבלוקים מגודל <span class="math">\(k\)</span> <strong>לפחות</strong>, פחות מספר הבלוקים מגודל <span class="math">\(k+1\)</span> <strong>לפחות</strong>. אפשר לעשות את זה על ידי שתי הפעלות של הנוסחה לעיל. נקבל:</p>
<ul>
    <li>לכל ערך עצמי <span class="math">\(\lambda\)</span>, מספר בלוקי ז'ורדן המתאימים ל-<span class="math">\(\lambda\)</span> מגודל <span class="math">\(k\)</span> <strong>בדיוק</strong> הוא ההפרש <span class="math">\(2\dim\ker\left(A-\lambda I\right)^{k}-\dim\ker\left(A-\lambda I\right)^{k+1}-\dim\ker\left(A-\lambda I\right)^{k-1}\)</span>.</li>
</ul>
<p>תעשו לעצמכם את החשבון ותראו שאכן זה מה שיוצא.</p>
<p><strong>פרק שלישי, שבו אנחנו מז'רדנים סוף סוף בעזרת וקטורים ציקליים שזה סוג מיוחד של וקטור עצמי מוכלל וזה לא נשמע גס בכלל</strong></p>
<p>עכשיו אני רוצה לעבור לדבר על האופן שבו מוצאים את <span class="math">\(P\)</span>, מה שישתלב יפה עם הסבר לגבי המקום שממנו כל התכונות הללו מגיעות מלכתחילה. כשמדברים על <span class="math">\(P\)</span> קצת יותר קל לדעתי לחשוב על <span class="math">\(A\)</span> לא בתור מטריצה שרוצים למצוא אחת שדומה לה, אלא בתור טרנספורמציה לינארית שאנחנו מחפשים בסיס <span class="math">\(P\)</span> למרחב שבו היא מיוצגת על ידי מטריצה נחמדה - מטריצת בלוקים. מה הרעיון של מטריצת בלוקים שמייצגת טרנספורמציה לינארית? שכל בלוק מייצג <strong>תת-מרחב אינוריאנטי</strong> של הטרנספורמציה. אם <span class="math">\(T:V\to V\)</span> היא טרנספורמציה ו-<span class="math">\(W\)</span> הוא תת-מרחב של <span class="math">\(V\)</span>, אז <span class="math">\(W\)</span> הוא <span class="math">\(T\)</span>-אינוריאנטי אם <span class="math">\(T\left(W\right)\subseteq W\)</span>. זה אומר שאם כחלק מהבסיס <span class="math">\(P\)</span> שלנו יש בסיס ל-<span class="math">\(W\)</span>, ושאר אברי <span class="math">\(P\)</span> לא שייכים ל-<span class="math">\(W\)</span>, אז כשמייצגים את <span class="math">\(T\)</span> באמצעות <span class="math">\(P\)</span> נקבל בלוק שמתאים בדיוק ל-<span class="math">\(W\)</span>. בואו נראה את זה עם דוגמה פשוטה. נניח ש-<span class="math">\(V=W\oplus U\)</span> כך ש-<span class="math">\(W,U\)</span> הם <span class="math">\(T\)</span>-אינוריאנטים, וניקח בסיס <span class="math">\(P=\left\{ w_{1},w_{2},u_{1},u_{2}\right\} \)</span> שמורכב מאיחוד בסיסים של <span class="math">\(W,U\)</span>. לצורך הקונקרטיות נניח ש-<span class="math">\(T\left(w_{1}\right)=w_{1}+w_{2}\)</span> ו-<span class="math">\(T\left(w_{2}\right)=2w_{1}-w_{2}\)</span>, וש-<span class="math">\(T\left(u_{1}\right)=3u_{2}\)</span>, <span class="math">\(T\left(u_{2}\right)=u_{1}-u_{2}\)</span>. אם נשב ונחשב את המטריצה המייצגת של <span class="math">\(T\)</span> על פי <span class="math">\(P\)</span> נקבל את המטריצה הבאה:</p>
<p><span class="math">\(\left(\begin{array}{cccc}1 & 2 & 0 & 0\\1 & -1 & 0 & 0\\0 & 0 & 0 & 1\\0 & 0 & 3 & -1\end{array}\right)\)</span></p>
<p>האינטואיציה: כל וקטור עמודה במטריצה המייצגת שווה לתוצאת ההפעלה של <span class="math">\(T\)</span> על אחד מאברי הבסיס, כשמה שנכתב בעמודה הוא <strong>וקטור הקואורדינטות</strong> שלו על פי הבסיס. העמודה הראשונה היא וקטור ששייך ל-<span class="math">\(W\)</span> ולכן גם הפלט שלו יהיה ב-<span class="math">\(W\)</span> ולכן וקטור הקואורדינטות שלו יתאפס על השורות שמתאימות לאברי בסיס שאינם ב-<span class="math">\(W\)</span>, וכדומה.</p>
<p>אם כן, זה מה שקורה גם בצורת ז'ורדן. איכשהו מצליחים לפרק את <span class="math">\(V\)</span> לתת-מרחבים אינוריאנטים, שכל אחד מהם מתאים לבלוק ז'ורדן מסויים. לב-לבו של הרעיון בצורת ז'ורדן הוא שכל תת-מרחב כזה הוא <strong>ציקלי</strong>: הוא מתקבל מכך שלוקחים וקטור בודד ב-<span class="math">\(V\)</span>, שנקרא לו <strong>וקטור ציקלי</strong>, ואז מפעילים עליו את כל החזקות האפשריות של <span class="math">\(T\)</span> (כולל 0) ולוקחים את כל הצירופים הלינאריים האפשריים. אבל הרעיון הזה לבדו לא מספיק - כדי שנקבל בלוק ז'ורדן צריך לבחור בצורה זהירה את הוקטורים שיהיו בבסיס. בואו ננסה לעשות הינדוס לאחור כדי להבין מה צריך. ניקח בלוק ז'ורדן תמים, נאמר מסדר <span class="math">\(3\times3\)</span>:</p>
<p><span class="math">\(\left(\begin{array}{ccc}\lambda & 1 & 0\\0 & \lambda & 1\\0 & 0 & \lambda\end{array}\right)\)</span></p>
<p>בואו נאמר שהבסיס שיצר אותו הוא <span class="math">\(\left\{ w_{1},w_{2},w_{3}\right\} \)</span>. עכשיו אנחנו מבינים את המשמעות של בלוק כזה - הוא אומר שהטרנספורמציה פועלת באופן הבא:</p>
<p><span class="math">\(T\left(w_{1}\right)=\lambda w_{1}\)</span></p>
<p><span class="math">\(T\left(w_{2}\right)=w_{1}+\lambda w_{2}\)</span></p>
<p><span class="math">\(T\left(w_{3}\right)=w_{2}+\lambda w_{3}\)</span></p>
<p>נסתכל למשל על המשוואה האחרונה. אפשר לכתוב אותה גם בתור <span class="math">\(T\left(w_{3}\right)=w_{2}+\lambda I\left(w_{3}\right)\)</span> כאשר <span class="math">\(I\)</span> היא פונקצית הזהות. העברת אגפים תיתן <span class="math">\(w_{2}=\left(T-\lambda I\right)w_{3}\)</span> (כן, אני קצת משנה את תפקידי הסוגריים, אתם חזקים, תתמודדו). באופן דומה, <span class="math">\(w_{1}=\left(T-\lambda I\right)w_{2}\)</span> ואילו <span class="math">\(\left(T-\lambda I\right)w_{1}=0\)</span>. מה שזה אומר בפועל הוא שתת-המרחב האינוריאנטי שנותן לו את בלוק הז'ורדן הזה נבנה מתוך וקטור <span class="math">\(w_{3}\)</span> שאנחנו מוצאים בדרך קסם כלשהי (שעוד מעט תוסבר), ועליו אנחנו מפעילים שוב ושוב את <span class="math">\(\left(T-\lambda I\right)\)</span> עד שלבסוף אנחנו מגיעים אל 0 (או, אם תרצו, עד שאנחנו מגיעים אל וקטור עצמי של <span class="math">\(T\)</span> המתאים לערך העצמי <span class="math">\(\lambda\)</span>). <span class="math">\(w_{3}\)</span> הוא אותו <strong>וקטור ציקלי</strong> שהזכרתי קודם. שימו לב שכדי שהצורה היפה של בלוק ז'ורדן תתקבל אנחנו צריכים להקפיד על הסדר שבו הוקטורים מופיעים בבסיס: הוקטור הציקלי מופיע <strong>אחרון</strong>, והוקטורים שמתקבלים ממנו מופיעים לפניו, כשהסדר הוא מההפעלה האחרונה אל ההפעלה הראשונה.</p>
<p>זה מה שתיארתי קודם במה שקראתי לו "הרעיון על קצה המזלג"; עכשיו אנחנו גם מבינים למה צריך לעשות את זה. רק נשאר להבין איפה מוצאים את הוקטורים הציקליים המדוברים. ובכן, בואו נמשיך עוד קצת עם הדוגמה הנוכחית שלנו. ראינו ש-<span class="math">\(\left(T-\lambda I\right)w_{1}=0\)</span>. דרך אחרת לכתוב את זה היא <span class="math">\(w_{1}\in\ker\left(T-\lambda I\right)\)</span>. ראינו גם ש-<span class="math">\(w_{1}=\left(T-\lambda I\right)w_{2}\)</span>, ולכן אם נפעיל את <span class="math">\(\left(T-\lambda I\right)\)</span> על שני האגפים נקבל ש-<span class="math">\(\left(T-\lambda I\right)^{2}w_{2}=0\)</span>, כלומר <span class="math">\(w_{2}\in\ker\left(T-\lambda I\right)^{2}\)</span>. בדומה <span class="math">\(w_{3}\in\ker\left(T-\lambda I\right)^{3}\)</span>. העיקרון הזה נכון באופן כללי: לכל ערך עצמי <span class="math">\(\lambda\)</span> של <span class="math">\(T\)</span>, וקטור ציקלי שיוצר תת-מרחב מגודל <span class="math">\(k\)</span> עשוי להסתתר לנו בתוך <span class="math">\(\ker\left(T-\lambda I\right)^{k}\)</span>. אז אלו המקומות שבהם אנחנו מחפשים את הוקטורים הציקליים שלנו. בואו נדבר שניה טרמינולוגיה: <strong>וקטור עצמי</strong> היה וקטור <span class="math">\(w\in\ker\left(T-\lambda I\right)\)</span>; לכן שם סביר לוקטור <span class="math">\(w\in\ker\left(T-\lambda I\right)^{k}\)</span> הוא <strong>וקטור עצמי מוכלל</strong>. אם כדי ללכסן מטריצה חיפשנו בסיס שמורכב מוקטורים עצמיים שלה, כאן אנחנו מחפשים בסיס שמורכב מוקטורים עצמיים מוכללים שלה. הקושי הוא שלא כל "סתם" בסיס של וקטורים עצמיים מוכללים יעבוד; חייבים כזה שנבנה מתוך וקטורים עצמיים מוכללים ציקליים.</p>
<p>מבחינה חישובית, בינתיים הכל מאוד קל: למצוא איברים ב-<span class="math">\(\ker\left(T-\lambda I\right)^{k}\)</span> זה בפועל לחשב חזקה של מטריצה סקלרית ולדרג אותה. להפעיל את <span class="math">\(\left(T-\lambda I\right)\)</span> על וקטורים זה קל מאוד. אבל עדיין יש דברים לא ברורים. בתור התחלה, מאיפה מתחילים? נניח שאני יודע ש-<span class="math">\(\lambda\)</span> הוא ערך עצמי של <span class="math">\(T\)</span>, אז אני הולך לחפש וקטור ציקלי ב-<span class="math">\(\ker\left(T-\lambda I\right)^{k}\)</span>. אבל עבור איזה <span class="math">\(k\)</span>? שאני אקח באקראי <span class="math">\(k=1,000\)</span>? ובכן, כמובן שלא. ככל שמגדילים את <span class="math">\(k\)</span>, כך גם המרחב <span class="math">\(\ker\left(T-\lambda I\right)^{k}\)</span> גדל, עד שמגיעים לנקודת שבת. אפשר להתחיל את החיפושים ממנה. לא קשה לראות שה-<span class="math">\(k\)</span> שמתאים לנקודת השבת הזו הוא בדיוק החזקה <span class="math">\(k\)</span> של הגורם <span class="math">\(\left(x-\lambda\right)\)</span> בפולינום המינימלי של <span class="math">\(T\)</span>, מה שמחזיר אותנו לתכונות שראינו קודם. וקטור ציקלי שנמצא ב-<span class="math">\(\ker\left(T-\lambda I\right)^{k}\)</span> יוצר בלוק מגודל <strong>לכל היותר</strong> <span class="math">\(k\)</span>; לכל היותר, כי הוא עשוי להיות שייך גם ל-<span class="math">\(\ker\left(T-\lambda I\right)^{k-1}\)</span> ואז הסדרה שהוא ייצור תהיה מאורך קטן מ-<span class="math">\(k\)</span>. לעומת זאת, אם הוא שייך ל-<span class="math">\(\ker\left(T-\lambda I\right)^{k}\)</span> אבל לא שייך ל-<span class="math">\(\ker\left(T-\lambda I\right)^{k-1}\)</span> מובטח לנו שגודל הבלוק שהוא ייצור הוא <strong>בדיוק</strong> <span class="math">\(k\)</span>. זה מסביר לנו באופן מלא את התכונה של "גודל הבלוק המקסימלי שווה לחזקה של הגורם בפולינום המינימלי" וגם את התכונות המסובכות אחר כך שהתבססו על המימדים של <span class="math">\(\ker\left(T-\lambda I\right)^{k}\)</span>. כמו כן, מכיוון שהסדרה שיוצר וקטור ציקלי מסתיימת תמיד בוקטור עצמי, הרי שמספר הסדרות של וקטורים ציקליים בלתי תלויים - שהוא בדיוק מספר הבלוקים - יהיה שווה למספר הוקטורים העצמיים הבלתי תלויים, כלומר לריבוי הגיאומטרי של <span class="math">\(\lambda\)</span>. הכל מתחבר!</p>
<p>נשאר רק להבין מה זה אומר למצוא וקטורים ציקליים "בלתי תלויים". לצורך כך בואו ניקח דוגמת צעצוע. נניח שאנחנו מחפשים וקטורים ציקליים עבור המטריצה</p>
<p><span class="math">\(\left(\begin{array}{ccccc}2 & 1 & 0 & 0 & 0\\0 & 2 & 0 & 0 & 0\\0 & 0 & 2 & 1 & 0\\0 & 0 & 0 & 2 & 0\\0 & 0 & 0 & 0 & 2\end{array}\right)\)</span></p>
<p>זה אווילי, כי המטריצה הזו כבר נמצאת בצורת ז'ורדן. יש לנו שלושה בלוקים שכולם מתאימים לערך העצמי 2: שניים מגודל 2 ואחד מגודל 1. עדיין, בואו נראה מה קורה כשלוקחים את הפרוצדורה ומפעילים אותה על המקרה הזה. לא קשה לבדוק ולראות ש-<span class="math">\(\left(A-2I\right)^{2}\)</span> היא מטריצת האפס, ולכן <span class="math">\(\ker\left(A-2I\right)^{2}=\mathbb{C}^{5}\)</span> - המרחב כולו. יש לנו לכאורה חופש בחירה מוחלט לוקטורים שמתחשק לנו לקחת. אבל בפועל יש לנו שתי מגבלות. ראשית, אנחנו רוצים וקטורים ש<strong>לא</strong> שייכים ל-<span class="math">\(\ker\left(A-2I\right)\)</span>, כי וקטורים כאלו יוצרים לנו בלוק מגודל 1 (כלומר, הסדרה שהם יוצרים תהיה מאורך 1 ותכיל רק את עצמם). זה מצמצם את חופש הבחירה שלנו: <span class="math">\(\ker\left(A-2I\right)=\left\{ \left(x,0,y,0,z\right)\ |\ x,y,z\in\mathbb{C}\right\} \)</span> ולכן כל וקטור שניקח יהיה חייב להיות מהצורה <span class="math">\(\left(a_{1},a_{2},a_{3},a_{4},a_{5}\right)\)</span> כך ש-<span class="math">\(a_{2}\ne0\)</span> או <span class="math">\(a_{4}\ne0\)</span>.</p>
<p>יודעים מה? זה לא נשמע כמו מגבלה כל כך רצינית. לכאורה עדיין יש לנו המון וקטורים שאפשר לקחת. אבל האתגר הוא לקחת וקטורים שהשרשראות שהם יוצרים לא "יתנגשו". בואו נראה מקרה שבו זה כן קורה. בתור וקטור אחד ניקח את <span class="math">\(v=\left(0,1,0,0,0\right)\)</span>, אבל בתור הוקטור השני, במקום לקחת את <span class="math">\(\left(0,0,0,1,0\right)\)</span> המתבקש, אני אקח לצורך הדוגמה דווקא את <span class="math">\(u=\left(1,1,0,0,0\right)\)</span>. למה לא? שני הוקטורים הללו, <span class="math">\(v,u\)</span>, הם בלתי תלויים לינארית; המרחב שהם פורשים הוא ממימד 2. מה אמור לרמוז לנו ש"אסור" לקחת את <span class="math">\(u\)</span>?</p>
<p>ובכן, בואו נסתכל על השרשרת ששני אלו מייצרים: <span class="math">\(\left(A-2I\right)v=\left(A-2I\right)u=\left(1,0,0,0,0\right)\)</span>. קיבלנו התנגשות באיבר השני בשרשרת. מה שזה אומר לנו בפועל הוא ששני הוקטורים הציקליים <span class="math">\(u,v\)</span> מתאימים שניהם <strong>לאותו הבלוק</strong>. אני יכול להחליף את אחד מהם בשני ובסופו של דבר עדיין נקבל בסיס שנותן לנו את אותה צורת ז'ורדן. אבל אני לא יכול לדחוף ל-<span class="math">\(P\)</span> את שניהם ביחד. כי כזכור, כדי שהעסק יעבוד אנחנו צריכים לדחוף כל וקטור ציקלי ואת כל מי שהוא יוצר. אז מה נעשה עם <span class="math">\(\left(1,0,0,0,0\right)\)</span>? נדחוף אותו פעמיים? ככה נקבל מטריצה <span class="math">\(P\)</span> לא הפיכה; "בסיס" <span class="math">\(P\)</span> שהוא תלוי לינארית כי אותו איבר מופיע בו פעמיים. אז אולי נוסיף את <span class="math">\(\left(1,0,0,0,0\right)\)</span> רק פעם אחת? אבל אז נקבל <strong>מעט מדי</strong> וקטורים עצמיים מוכללים מכדי לקבל בסיס. בקיצור, אסור באיסור חמור לקבל התנגשות. האופןש בו יכלנו לזהות ש-<span class="math">\(u\)</span> הוא רע הוא על ידי כך שהיינו מזהים שאי שם בהמשך הוא ייתן לנו התנגשות עם <span class="math">\(v\)</span>.</p>
<p>מה הסיבה שבגללה קיבלנו התנגשות שכזו? ובכן, אם תחשבו על זה רגע, <span class="math">\(u=v+\left(1,0,0,0,0\right)\)</span>. כלומר, אפשר לחשוב על <span class="math">\(u\)</span> הרע שלנו בתור <span class="math">\(v\)</span> הטוב ועוד "תוספת". עכשיו, אם נפעיל את <span class="math">\(\left(A-\lambda I\right)\)</span> על <span class="math">\(u\)</span>, אז בזכות הלינאריות של טרנספורמציות לינאריות נקבל ש-<span class="math">\(\left(A-\lambda I\right)u=\left(A-\lambda I\right)v+\left(A-\lambda I\right)\left(1,0,0,0,0\right)\)</span>. אלא ש-<span class="math">\(\left(1,0,0,0,0\right)\in\ker\left(A-\lambda I\right)\)</span> ולכן התוספת "תתבטל". ונקבל התנגשות.</p>
<p>זה הרעיון שמתאר את הבעיה באופן כללי: שני וקטורים <span class="math">\(u,v\in\ker\left(A-\lambda I\right)^{k}\)</span> הם "בעייתיים" אם מתקיים ש-<span class="math">\(u-v\in\ker\left(A-\lambda I\right)^{k-1}\)</span>. פירוש הדבר הוא שאם נפעיל את <span class="math">\(\left(A-\lambda I\right)\)</span> עליהם <span class="math">\(k-1\)</span> פעמים, מתישהו נקבל התנגשות - לכן לא נצליח לקבל <span class="math">\(k\)</span> וקטורים שונים. לתכונה הזו של ה"בעייתיות" יש טרמינולוגיה מאוד סטנדרטית במתמטיקה שבאה לתאר אותה, אם כי ייתכן שלרובכם היא לא מוכרת בהקשר של מרחבים וקטוריים: אומרים ש-<span class="math">\(u,v\)</span> הם <strong>שקולים מודולו</strong> <span class="math">\(\ker\left(A-\lambda I\right)^{k-1}\)</span>. הטרמינולוגיה הזו מאפשרת לנו לנסח מאוד באלגנטיות את מה שצריך לעשות כדי למצוא את הוקטורים הציקליים של <span class="math">\(\ker\left(A-\lambda I\right)^{k}\)</span>: אנחנו צריכים למצוא <strong>בסיס</strong> עבור <strong>מרחב המנה</strong> <span class="math">\(\ker\left(A-\lambda I\right)^{k}/\ker\left(A-\lambda I\right)^{k-1}\)</span>, ואז להעביר את הבסיס הזה לקבוצת וקטורים ב-<span class="math">\(\ker\left(A-\lambda I\right)^{k}\)</span>. אני אסביר את הטרמינולוגיה הזו בהמשך, כי לטעמי זו הדרך הנכונה לתאר את מה שצריך לעשות, אבל כדי לא לכפות אותה עליכם אני אציג קודם כל את האלגוריתם הכללי עם הניסוחים המסורבלים שכופה עלינו ההתעלמות מהטרמינולוגיה הזו.</p>
<p>בואו רק נשלים את דוגמת הצעצוע שלנו. אני מניח שאנחנו מסכימים ששני הוקטורים הציקליים שעלינו לבחור ב-<span class="math">\(\ker\left(A-2I\right)^{2}\)</span> הם הוקטורים <span class="math">\(v_{2}=\left(0,1,0,0,0,0\right)\)</span> ו-<span class="math">\(u_{2}=\left(0,0,0,1,0\right)\)</span>. סימנתי אותם עם אינדקס 2, כי כזכור, בבסיס הסדור <span class="math">\(P\)</span> שאני בונה הם מופיעים <strong>אחרי</strong> מי שמתקבלים מהם. ומי מתקבלים מהם?</p>
<p><span class="math">\(v_{1}=\left(A-2I\right)v_{2}=\left(1,0,0,0,0\right)\)</span></p>
<p><span class="math">\(u_{1}=\left(A-2I\right)u_{2}=\left(0,0,1,0,0\right)\)</span></p>
<p>אם כן, כרגע הבסיס הסדור שלי כולל את האיברים <span class="math">\(\left\{ v_{1},v_{2},u_{1},u_{2}\right\} \)</span>. עדיין חסר לי וקטור עצמי מוכלל אחד. האם פספסתי מישהו ב-<span class="math">\(\ker\left(A-2I\right)^{2}\)</span>? התשובה היא לא. דרך פשוטה להיות בטוחים בכך: <span class="math">\(\dim\ker\left(A-2I\right)^{2}-\dim\ker\left(A-2I\right)=2\)</span> ולכן אני מצפה למצוא רק 2 וקטורים ציקליים "בלתי תלויים" שם. אם כן, מה נשאר? כרגע יש לי שני וקטורים בלתי תלויים ב-<span class="math">\(\ker\left(A-2I\right)\)</span>, אבל <span class="math">\(\dim\ker\left(A-2I\right)=3\)</span>, כך שחסר לי וקטור. אז מה שאני אעשה הוא לקחת את הקבוצה <span class="math">\(\left\{ u_{1},v_{1}\right\} \)</span>, ו<strong>להשלים אותה לבסיס</strong> של <span class="math">\(\ker\left(A-2I\right)\)</span>. זה יניב לי את הוקטור <span class="math">\(\left(0,0,0,0,1\right)\)</span>, וכך קיבלנו לבסוף את <span class="math">\(P\)</span> שלנו, שהיא פשוט הבסיס הסטנדרטי (מה שהוא לחלוטין לא מפתיע, כמובן, שהרי המטריצה שהתחלתי ממנה כבר הייתה בצורת ז'ורדן). ומה היה קורה אם הייתי בוחר, למשל, <span class="math">\(v_{2}=\left(1,1,0,0,0\right)\)</span>? הייתי מקבל <span class="math">\(v_{1}=\left(1,0,0,0,0\right)\)</span> ולכן שאר הבסיס שלי לא היה משתנה. אז הייתי מקבל בסיס קצת שונה, אבל הייצוג של המטריצה בבסיס הזה היה עדיין אותו ייצוג. באופן כללי בהינתן מטריצה <span class="math">\(A\)</span>, <strong>יש הרבה</strong> מטריצות מז'רדנות <span class="math">\(P\)</span>, כלומר הרבה מטריצות <span class="math">\(P\)</span> שונות שעבורן <span class="math">\(P^{-1}AP=J\)</span> כאשר <span class="math">\(J\)</span> היא אותה צורת ז'ורדן של <span class="math">\(A\)</span>. אין עם זה בעיה.</p>
<p><strong>פרק רביעי, ובו אלגוריתם שהוא התכל'ס של התכל'ס ודוגמה שהיא התכל'ס של התכל'ס של התכל'ס</strong></p>
<p>מה שנעשה עכשיו הוא זה: ראשית אציג את האלגוריתם המלא למציאת צורת ז'ורדן של מטריצה כללית <span class="math">\(A\)</span>; שנית אראה איך הוא עובד במקרה של ה-<span class="math">\(A\)</span> שהצגתי בתחילת הפוסט, בתור דוגמה; ולבסוף אנסח מחדש את האלגוריתם בטרמינולוגיה שאני אוהב של מרחבי מנה, אחרי שאסביר מהם בכלל.</p>
<p>נתחיל עם האלגוריתם הכללי. נתונה מטריצה <span class="math">\(A\)</span> ואנחנו רוצים למצוא את צורת ז'ורדן שלה ומטריצה מז'רדנת. מה עושים?</p>
<ol>
    <li>נחשב את הפולינום האופייני <span class="math">\(p_{A}\left(x\right)=\det\left(xI-A\right)\)</span> ונפרק אותו לגורמים לינאריים <span class="math">\(p_{A}\left(x\right)=\left(x-\lambda_{1}\right)^{k_{1}}\cdots\left(x-\lambda_{n}\right)^{k_{n}}\)</span>. אם הפולינום לא מתפרק לגורמים לינאריים מעל השדה אפשר לשכוח מצורת ז'ורדן. השורשים של הפולינום האופייני נקראים <strong>ערכים עצמיים</strong> של <span class="math">\(A\)</span>.</li>
    <li>לכל ערך עצמי <span class="math">\(\lambda\)</span> נסמן לצורך נוחות ב-<span class="math">\(B_{\lambda}\)</span> את המטריצה <span class="math">\(B_{\lambda}\triangleq A-\lambda I\)</span>, וכעת:
<ol>
    <li>נחשב את <span class="math">\(\dim\ker B_{\lambda}^{k}\)</span> עבור <span class="math">\(k=1,2,\dots\)</span> עד אשר נמצא <span class="math">\(k\)</span> כך ש-<span class="math">\(\dim\ker B_{\lambda}^{k+1}=\dim\ker B_{\lambda}^{k}\)</span> (באופן שקול, אפשר למצוא את הפולינום המינימלי של <span class="math">\(A\)</span> בדרך אחרת; <span class="math">\(k\)</span> המבוקש היא החזקה של הגורם <span class="math">\(\left(x-\lambda\right)\)</span>).</li>
    <li>נבנה באופן אינדוקטיבי סדרה של קבוצות <span class="math">\(P_{k}^{\lambda},P_{k-1}^{\lambda},P_{k-2}^{\lambda},\dots,P_{1}^{\lambda}\)</span> באופן הבא: בתחילה, <span class="math">\(P_{k}^{\lambda}=\emptyset\)</span>. כעת, לכל <span class="math">\(t=k,k-1,\dots,1\)</span>:
<ol>
    <li>נוסיף ל-<span class="math">\(P_{t}^{\lambda}\)</span> איברים עד שיהיו בה <span class="math">\(\dim\ker B_{\lambda}^{t}-\dim\ker B_{\lambda}^{t-1}\)</span> איברים בסך הכל, כך שאין שני איברים <strong>שונים</strong> <span class="math">\(v,u\in P_{t}^{\lambda}\)</span> עבורם <span class="math">\(v-u\in\ker B_{\lambda}^{t-1}\)</span>. לאיברים שמתווספים בשלב הזה נקרא <strong>וקטורים ציקליים</strong>.</li>
    <li>לכל <span class="math">\(v\in P_{t}^{\lambda}\)</span> נוסיף ל-<span class="math">\(P_{t-1}^{\lambda}\)</span> את <span class="math">\(B_{\lambda}\cdot v\)</span> (לוקטורים הללו לא נקרא וקטורים ציקליים).</li>
</ol>
</li>
    <li>נגדיר <span class="math">\(P^{\lambda}=\bigcup_{t=1}^{k}P_{t}^{\lambda}\)</span>.</li>
</ol>
</li>
    <li>נגדיר <span class="math">\(P=\bigcup_{\lambda}P^{\lambda}\)</span>.</li>
    <li>נסדר את איברי ב-<span class="math">\(P\)</span> באופן הבא: נגדיר סדר כלשהו על הערכים העצמיים וכל הוקטורים שהתקבלו מערך עצמי <span class="math">\(\lambda\)</span> יופיעו ביחד בהתאם לסדר הזה, ונגדיר סדר כלשהו על הוקטורים הציקליים שהתגלו במהלך האלגוריתם. אם <span class="math">\(v\)</span> הוא וקטור ציקלי ששייך ל-<span class="math">\(P_{t}^{\lambda}\)</span> אז נסדר את האיברים <span class="math">\(B^{t}v,B^{t-1}v,\dots,Bv,v\)</span> בסדר הזה (כך ש-<span class="math">\(B^{t}v\)</span> ראשון ו-<span class="math">\(v\)</span> אחרון).</li>
</ol>
<p>זה האופן הכי טוב שבו אני מסוגל לכתוב את האלגוריתם. נתקלתי בשלל ניסוחים שונים ומשונים שלו במקומות שונים ומשונים ואת כולם היה לי קשה מאוד להבין. אני מקווה שהניסוח הזה בהיר למדי. מה שכנראה לא ברור הוא <strong>איך</strong> מבצעים חלק מהשלבים של האלגוריתם. הרי מה שכתבתי לעיל הוא עדיין לא משהו שאפשר לתת למחשב לעשות. בעיה אחת, שקיימת כבר בלכסון מטריצות, היא איך לפרק את הפולינום האופייני לגורמים לינאריים - או באופן שקול, איך למצוא את השורשים שלו. מה אני אגיד לכם, זה עניין בעייתי. יש אלגוריתמים כמו ניוטון-רפסון שמוצאים שורשים של פולינומים (לפחות באופן מקורב) וכדומה, אבל באופן כללי זה יכול להיות מסובך. זה נושא ששייך לאנליזה נומרית ובדרך כלל לא רלוונטי לסטודנטים שלומדים את הנושא, כי עבורם יש תרגילים פשוטים שבהם לרוב אפשר לנחש בצורה חכמה את השורשים או שהם נתונים במפורש.</p>
<p>החלק היותר מעניין הוא זה שבו צריך לקחת את <span class="math">\(P_{t}^{\lambda}\)</span>, שאולי כבר יש בה כמה וקטורים שהגיעו מהשלב הקודם, ולהרחיב אותה כך שיהיו בה <span class="math">\(\dim\ker B_{\lambda}^{t}-\dim\ker B_{\lambda}^{t-1}\)</span> וקטורים שהם "בלתי תלויים" במובן שאמרתי קודם - לא מתקיים <span class="math">\(v-u\in\ker B_{\lambda}^{t-1}\)</span> לאף זוג וקטורים בתוכה. התשובה הפשוטה ביותר שאני מכיר היא זו: קחו בסיס ל-<span class="math">\(\ker B_{\lambda}^{t-1}\)</span>. הוסיפו לו את איברי <span class="math">\(P_{t}^{\lambda}\)</span> הנוכחיים. קיבלתם קבוצה של וקטורים ב-<span class="math">\(\ker B_{\lambda}^{t}\)</span> ואפשר להוכיח שהם תמיד יהיו בלתי תלויים לינארית. הרחיבו אותה לבסיס של <span class="math">\(\ker B_{\lambda}^{t}\)</span>. אברי הבסיס החדשים הם בדיוק האיברים שאתם רוצים להוסיף ל-<span class="math">\(P_{t}^{\lambda}\)</span>. כמובן, אני מניח שאתם כבר יודעים לפתור את בעיית ה"השלמה של קבוצת וקטורים לבסיס" - אבל זו בעיה הרבה יותר סטנדרטית באלגברה לינארית ולא אדבר עליה כאן.</p>
<p>למה זה עובד? פשוט מאוד: כי אם עבור <span class="math">\(v,u\in P_{t}^{\lambda}\)</span> מתקיים ש-<span class="math">\(v-u\in\ker B_{\lambda}^{t-1}\)</span>, אז אפשר לכתוב את <span class="math">\(v-u\)</span> כצירוף לינארי של הבסיס של <span class="math">\(\ker B_{\lambda}^{t-1}\)</span>, כלומר <span class="math">\(v-u=\sum\rho_{i}b_{i}\)</span>. נעביר אגפים והופס, <span class="math">\(v-u-\sum\rho_{i}b_{i}=0\)</span>, קיבלנו צירוף לינארי של אברי בסיס של <span class="math">\(\ker B_{\lambda}^{t}\)</span> שנותן 0. זה אפשרי רק אם כל המקדמים בצירוף הלינארי הזה הם 0, כלומר בפרט <span class="math">\(v-u=0\)</span>, כלומר <span class="math">\(v=u\)</span>. אז רק רגע, אם זה כל כך פשוט, למה לא כתבתי את זה באלגוריתם מלכתחילה? ובכן, בגלל שאם <strong>אני</strong> הייתי קורא את זה באלגוריתם מלכתחילה, לא הייתי מבין מה לעזאזל הרעיון שמאחורי השלב הזה. אני מעדיף שהאלגוריתם יציג את הרעיון ולא את הפרטים של הביצוע הטכני שלו. פרט לכך, אל תדאגו - בניסוח עם מרחבי מנה, יופיע שם בדיוק הדבר הזה.</p>
<p>בואו נעבור, אם כן, לפתרון של הדוגמה מתחילת הפוסט. אקפוץ על השלב של חישוב הפולינום האופייני של <span class="math">\(A\)</span>: כפי שאמרתי קודם, מקבלים <span class="math">\(p_{A}\left(x\right)=\left(x-3\right)\left(x-2\right)^{5}\)</span>. סביר להתחיל עם הערך העצמי 3. עבורו, המטריצה <span class="math">\(B=\left(A-3I\right)\)</span> יוצאת</p>
<p><span class="math">\(B=\left(\begin{array}{rrrrrr}0 & 0 & 0 & 0 & 0 & 0\\0 & -1 & 0 & 0 & -1 & 0\\0 & 0 & -1 & 0 & 1 & 0\\0 & 0 & 0 & -1 & 0 & 1\\0 & 1 & 1 & 0 & -1 & 0\\0 & 0 & 0 & 0 & 0 & -1\end{array}\right)\)</span></p>
<p>דירוג מטריצות סטנדרטי יעביר אותנו למטריצה הבאה:</p>
<p><span class="math">\(\left(\begin{array}{rrrrrr}0 & 0 & 0 & 0 & 0 & 0\\0 & 1 & 0 & 0 & 0 & 0\\0 & 0 & 1 & 0 & 0 & 0\\0 & 0 & 0 & 1 & 0 & 0\\0 & 0 & 0 & 0 & 1 & 0\\0 & 0 & 0 & 0 & 0 & 1\end{array}\right)\)</span></p>
<p>ולכן <span class="math">\(\ker B=\text{span}\left\{ e_{1}\right\} \)</span> כאשר <span class="math">\(e_{1}=\left(1,0,0,0,0,0\right)\)</span> הוא וקטור של הבסיס הסטנדרטי. אם נחזור על התעלול עבור <span class="math">\(B^{2}\)</span> נגלה שנקבל את אותו הדבר בדיוק - <span class="math">\(\ker B^{2}=\ker B^{1}\)</span>. זה כמובן לא אמור להפתיע אותנו בשום צורה - אנחנו יודעים שהגורם של <span class="math">\(\left(x-3\right)\)</span> בפולינום האופייני הוא 1, ולכן זה גם הגורם בפולינום המינימלי, ולכן המרחב <span class="math">\(\ker B^{2}\)</span> ממילא לא רלוונטי עבורנו. אם כן, אין לנו כמעט מה לעשות כאן: ב-<span class="math">\(P\)</span> הסופי שלנו יהיה את <span class="math">\(e_{1}\)</span>, ואפשר לעבור לטפל בערך העצמי האחר, <span class="math">\(\lambda=2\)</span>.</p>
<p>נגדיר אם כן <span class="math">\(B=\left(A-2I\right)\)</span>, נחשב חזקות של <span class="math">\(B\)</span> ונקבל את המטריצות</p>
<p><span class="math">\(B=\left(\begin{array}{rrrrrr}1 & 0 & 0 & 0 & 0 & 0\\0 & 0 & 0 & 0 & -1 & 0\\0 & 0 & 0 & 0 & 1 & 0\\0 & 0 & 0 & 0 & 0 & 1\\0 & 1 & 1 & 0 & 0 & 0\\0 & 0 & 0 & 0 & 0 & 0\end{array}\right),B^{2}=\left(\begin{array}{rrrrrr}1 & 0 & 0 & 0 & 0 & 0\\0 & -1 & -1 & 0 & 0 & 0\\0 & 1 & 1 & 0 & 0 & 0\\0 & 0 & 0 & 0 & 0 & 0\\0 & 0 & 0 & 0 & 0 & 0\\0 & 0 & 0 & 0 & 0 & 0\end{array}\right),B^{3}=\left(\begin{array}{rrrrrr}1 & 0 & 0 & 0 & 0 & 0\\0 & 0 & 0 & 0 & 0 & 0\\0 & 0 & 0 & 0 & 0 & 0\\0 & 0 & 0 & 0 & 0 & 0\\0 & 0 & 0 & 0 & 0 & 0\\0 & 0 & 0 & 0 & 0 & 0\end{array}\right)\)</span></p>
<p>ובבירור <span class="math">\(B^{4}=B^{3}\)</span> ולכן הסיפור ייתקע ב-<span class="math">\(B^{3}\)</span> ומשם אנחנו צריכים להתחיל לחפש את הוקטורים הציקליים שלנו.</p>
<p>נפתח, אם כן, במציאת וקטורים ציקליים ב-<span class="math">\(\ker B^{3}\)</span>. אמרנו שהדרך לעשות זאת בפועל היא למצוא בסיס ל-<span class="math">\(\ker B^{2}\)</span> ואז להשלים אותו לבסיס של <span class="math">\(\ker B^{3}\)</span>. מה יניב לנו דירוג מטריצות של <span class="math">\(B^{2}\)</span>? את המטריצה הבאה:</p>
<p><span class="math">\(\left(\begin{array}{rrrrrr}1 & 0 & 0 & 0 & 0 & 0\\0 & 1 & 1 & 0 & 0 & 0\\0 & 0 & 0 & 0 & 0 & 0\\0 & 0 & 0 & 0 & 0 & 0\\0 & 0 & 0 & 0 & 0 & 0\\0 & 0 & 0 & 0 & 0 & 0\end{array}\right)\)</span></p>
<p>כלומר, <span class="math">\(\ker B^{2}=\left\{ \left(0,a,-a,b,c,d\right)\ |\ a,b,c,d\in\mathbb{C}\right\} \)</span> - מרחב 4-ממדי. בתור בסיס שלו אפשר לקחת למשל את <span class="math">\(\left\{ e_{2}-e_{3},e_{4},e_{5},e_{6}\right\} \)</span>.</p>
<p>את <span class="math">\(B^{3}\)</span> אין צורך לדרג - היא כבר מדורגת, ובבירור <span class="math">\(\ker B^{3}=\left\{ \left(0,a,f,b,c,d\right)\ |\ a,b,c,d,f\in\mathbb{C}\right\} \)</span>. כלומר, הוסרה המגבלה על הקואורדינטה השלישית להיות נגדית של השניה. אם כן, את מי אפשר להוסיף לבסיס <span class="math">\(\left\{ e_{2}-e_{3},e_{4},e_{5},e_{6}\right\} \)</span>? אפשר להוסיף את <span class="math">\(e_{2}\)</span> בלי לדאוג יותר מדי. קל לבדוק שהוא אכן בלתי תלוי בשאר הוקטורים. אם כן, <span class="math">\(e_{2}\)</span> יהיה הוקטור הציקלי הראשון שלנו, זה שיצור בלוק ז'ורדן מסדר 3. בסימונים שלי, <span class="math">\(P_{3}=\left\{ e_{2}\right\} \)</span>.</p>
<p>עכשיו, נחשב את <span class="math">\(B\cdot e_{2}=e_{5}\)</span> (זכרו - מטריצה כפול וקטור בסיס סטנדרטי זה פשוט לקחת את העמודה המתאימה). רעיונית אני יכול להמשיך עם זה, לחשב גם את <span class="math">\(B^{2}\cdot e_{2}=-e_{2}+e_{3}\)</span> וכבר להגיד שאני מוסיף לבסיס שאני בונה את שלושת הוקטורים הללו, אבל בואו נרגיע רגע עם זה ונעבוד על פי האלגוריתם שלי. בסימונים שלי, <span class="math">\(P_{2}=\left\{ e_{5}\right\} \)</span> בשלב הזה ואני צריך להרחיב אותה עוד קצת. מתחילים בלמצוא את <span class="math">\(\ker B\)</span> על ידי דירוג של <span class="math">\(B\)</span>. מקבלים את המטריצה המדורגת</p>
<p><span class="math">\(\left(\begin{array}{rrrrrr}1 & 0 & 0 & 0 & 0 & 0\\0 & 1 & 1 & 0 & 0 & 0\\0 & 0 & 0 & 0 & 1 & 0\\0 & 0 & 0 & 0 & 0 & 1\\0 & 0 & 0 & 0 & 0 & 0\\0 & 0 & 0 & 0 & 0 & 0\end{array}\right)\)</span></p>
<p>כלומר, <span class="math">\(\ker B=\left\{ \left(0,a,-a,b,0,0\right)\ |\ a,b\in\mathbb{C}\right\} \)</span> וזהו בבירור מרחב ממימד 2. לכן אנחנו רוצים להרחיב את <span class="math">\(P_{2}\)</span> כך שיהיו בה <span class="math">\(\dim\ker B^{2}-\dim\ker B=4-2=2\)</span> וקטורים. נפעל כמו קודם: ניקח בסיס ל-<span class="math">\(\ker B\)</span>, נוסיף אליו את מי שכבר ב-<span class="math">\(P_{2}\)</span>, ואז נרחיב לבסיס של <span class="math">\(\ker B^{2}\)</span>. בסיס ל-<span class="math">\(\ker B\)</span> הוא <span class="math">\(\left\{ e_{2}-e_{3},e_{4}\right\} \)</span>, ולכן אנחנו רוצים להרחיב את הקבוצה <span class="math">\(\left\{ e_{2}-e_{3},e_{4},e_{5}\right\} \)</span> לבסיס עבור <span class="math">\(\ker B^{2}\)</span>. היי, זה בדיוק כמו הבסיס של <span class="math">\(\ker B^{2}\)</span> שכבר מצאנו קודם חוץ מ-<span class="math">\(e_{6}\)</span> שלא בפנים! איזה יופי, גילינו ש-<span class="math">\(e_{6}\)</span> הוא הוקטור הציקלי השני שלנו. בסך הכל, <span class="math">\(P_{2}=\left\{ e_{5},e_{6}\right\} \)</span> בסוף השלב הזה.</p>
<p>כעת אנו מחשבים את <span class="math">\(B\cdot e_{5}=-e_{2}+e_{3}\)</span> ואת <span class="math">\(B\cdot e_{6}=e_{4}\)</span> ומקבלים <span class="math">\(P_{1}=\left\{ -e_{2}+e_{3},e_{4}\right\} \)</span>. מכיוון ש-<span class="math">\(\dim\ker B=2\)</span> אין לנו עוד וקטורים שאנחנו רוצים להוסיף לקבוצה הזו - סיימנו. על ידי איחוד כל ה-<span class="math">\(P\)</span>-ים שמצאנו וסידור על פי שיטת הסידור שבחרתי קודם, אני מקבל בסוף את הבסיס הסדור <span class="math">\(P=\left\{ e_{1},-e_{2}+e_{3},e_{5},e_{2},e_{4},e_{6}\right\} \)</span>. אם תסתכלו על המטריצה מתחילת הפוסט, זו בדיוק המטריצה הזו. סיימנו!</p>
<p>כמובן, מה שהיה פה הוא קסם. איך קרה הנס הזה שהיו קיימים לנו וקטורים ציקליים, ושקיבלנו קבוצה בלתי תלויה של וקטורים? מה שמבטיח לנו את זה הוא משפט עמוק שלא הוכחתי ולא הראיתי במפורש, אבל זה, כאמור, יהיה שייך לפוסט אחר.</p>
<p><strong>פרק חמישי ואחרון שבו האלגוריתם מקבל מנה אחת אפיים ואוי ואבוי טוב שזה נגמר נשבר לי מבדיחות הקרש הללו</strong></p>
<p>הבטחתי להציג את הטרמינולוגיה שלטעמי היא הנכונה ביותר לתיאור כל הסיפור הזה - <strong>מרחבי מנה</strong>. מרחבי מנה באלגברה הם נושא נפוץ ביותר - בהקשר של חבורות וחוגים אנחנו רואים אותם כל הזמן. איכשהו יצא שעבור מרחבים וקטוריים אותו מושג הוא הרבה פחות פופולרי ושימושי, אבל כאן הוא בהחלט מתאים. אז אני אתאר את ההגדרות הבסיסיות - שוב, תחת הנחה שאתם יודעים קצת אלגברה.</p>
<p>ובכן, יהא <span class="math">\(V\)</span> מרחב וקטורי ו-<span class="math">\(W\subseteq V\)</span> תת-מרחב שלו. נגדיר <strong>יחס שקילות</strong> על הוקטורים של <span class="math">\(V\)</span>: <span class="math">\(v\equiv_{W}u\)</span> אם ורק אם <span class="math">\(v-u\in W\)</span>. זה בבירור יחס שקילות בגלל תכונות סטנדרטיות של תת-מרחבים וקטוריים: <span class="math">\(0\in W\)</span> ולכן רפלקסיביות; אם <span class="math">\(v\in W\)</span> גם <span class="math">\(-v\in W\)</span> ולכן סימטריה; ו-<span class="math">\(W\)</span> סגור לחיבור ולכן טרנזיטיביות (<span class="math">\(\left(v-w\right)=\left(v-u\right)+\left(u-w\right)\)</span>). <strong>מחלקת השקילות</strong> של <span class="math">\(v\)</span> היא אוסף כל האיברים השקולים לו: <span class="math">\(\left[v\right]_{W}\triangleq\left\{ u\in V\ |\ v\equiv_{W}u\right\} =\left\{ v+w\ |\ w\in W\right\} \)</span>. השוויון האחרון מצדיק את הסימון המקובל יותר, <span class="math">\(v+W\)</span>, עבור מחלקת השקילות הזו, שגם נקראת לפעמים <strong>קוסט</strong> של <span class="math">\(W\)</span>. כעת אנחנו מגדירים את <strong>מרחב המנה</strong> <span class="math">\(V/W\)</span> בתור מרחב המנה של היחס - אוסף הקוסטים שלו. דהיינו, <span class="math">\(V/W\triangleq\left\{ v+W\ |\ v\in V\right\} \)</span>.</p>
<p>שימו לב לכך ש-<span class="math">\(V/W\)</span> הוא <strong>לא</strong> תת-מרחב של <span class="math">\(V\)</span>. זה לא ייתכן כבר ברמה הסינטקטית: אברי <span class="math">\(V/W\)</span> הם לא איברים של <span class="math">\(V\)</span> אלא <strong>קבוצות</strong> של איברים של <span class="math">\(V\)</span>. אז איך נכון לחשוב על <span class="math">\(V/W\)</span>? בתור מרחב שמתקבל מכך ש"מדביקים ביחד" איברים שונים של <span class="math">\(V\)</span>. הדוגמה הקלאסית היא עבור <span class="math">\(V=\mathbb{R}^{2}\)</span> ו-<span class="math">\(W\)</span> שהוא תת-מרחב ממימד 1, כלומר קו ישר ב-<span class="math">\(\mathbb{R}^{2}\)</span>. במקרה הזה, מחלקות השקילות של <span class="math">\(V/W\)</span> יהיו בדיוק הישרים שמקבילים ל-<span class="math">\(V/W\)</span>. המרחב הזה איזומורפי ל-<span class="math">\(\mathbb{R}^{1}\)</span> - תחשבו, למשל, שמעבירים כל ישר ב-<span class="math">\(V/W\)</span> לנקודה שהוא חותך על ציר <span class="math">\(x\)</span> (או, אם <span class="math">\(W\)</span> הוא ציר <span class="math">\(x\)</span>, לנקודה שהוא חותך על ציר <span class="math">\(y\)</span>).</p>
<p>דרך קצת יותר כללית להבין מרחבי מנה היא באמצעות משפט האיזומורפיזם הראשון, כשהוא מנוסח עבור מרחבים וקטוריים: אם <span class="math">\(T:V\to U\)</span> היא טרנספורמציה לינארית כלשהי, אז <span class="math">\(V/\ker T\cong\text{Im}T\)</span>. כלומר, כדי להבין מרחב מנה <span class="math">\(V/W\)</span> אפשר לחשוב על טרנספורמציה לינארית שמעבירה את אברי <span class="math">\(V\)</span> למרחב כלשהו שנוח לנו לדמיין כך שהגרעין יוצא בדיוק <span class="math">\(W\)</span>. בעזרת המשפט הזה קל לראות שלמשל, אם <span class="math">\(V=W\oplus U\)</span> אז <span class="math">\(V/W\cong U\)</span> (עם ההעתקה <span class="math">\(T\left(v\right)=T\left(w+u\right)=u\)</span>, כאשר <span class="math">\(v=w+u\)</span> היא ההצגה היחידה של <span class="math">\(v\)</span> כצירוף לינארי של איבר מ-<span class="math">\(W\)</span> ואיבר מ-<span class="math">\(U\)</span>). באופן מפורש, האיזומורפיזם שולח את <span class="math">\(u\in U\)</span> אל <span class="math">\(u+W\in V/W\)</span> (ולהיפך: משפט האיזומורפיזם הראשון מראה שכל קוסט של <span class="math">\(W\)</span> ניתן לכתיבה באופן יחיד בתור <span class="math">\(u+W\)</span> עם <span class="math">\(u\in U\)</span> ואז האיזומורפיזם מעביר את הקוסט אל <span class="math">\(u\)</span>).</p>
<p>התוצאה האחרונה הזו גם מראה לנו כיצד ניתן למצוא בסיס ל-<span class="math">\(V/W\)</span>: אם נתון לנו כבר בסיס <span class="math">\(\left\{ w_{1},\dots,w_{k}\right\} \)</span> עבור <span class="math">\(W\)</span>, אנחנו משלימים אותו לבסיס עבור <span class="math">\(V\)</span>, שנסמן <span class="math">\(\left\{ w_{1},\dots,w_{k},u_{1},\dots,u_{t}\right\} \)</span>. כעת נגדיר <span class="math">\(U=\text{span}\left\{ u_{1},\dots,u_{t}\right\} \)</span> וקיבלנו ש-<span class="math">\(V=W\oplus U\)</span>. לכן <span class="math">\(U\cong V/W\)</span>, ולכן <span class="math">\(u_{1}+W,\dots,u_{t}+W\)</span> הוא בסיס של <span class="math">\(V/W\)</span> (התמונה של בסיס על ידי איזומורפיזם היא בסיס).</p>
<p>עכשיו, עם הטרמינולוגיה החדשה הזו, הנה ניסוח מחודש של האלגוריתם למציאת צורת ז'ורדן של <span class="math">\(A\)</span>:</p>
<ol>
    <li>נחשב את הפולינום האופייני <span class="math">\(p_{A}\left(x\right)=\det\left(xI-A\right)\)</span> ונפרק אותו לגורמים לינאריים <span class="math">\(p_{A}\left(x\right)=\left(x-\lambda_{1}\right)^{k_{1}}\cdots\left(x-\lambda_{n}\right)^{k_{n}}\)</span>. אם הפולינום לא מתפרק לגורמים לינאריים מעל השדה אפשר לשכוח מצורת ז'ורדן. השורשים של הפולינום האופייני נקראים <strong>ערכים עצמיים</strong> של <span class="math">\(A\)</span>.</li>
    <li>לכל ערך עצמי <span class="math">\(\lambda\)</span> נסמן לצורך נוחות ב-<span class="math">\(B_{\lambda}\)</span> את המטריצה <span class="math">\(B_{\lambda}\triangleq A-\lambda I\)</span>, ונסמן ב-<span class="math">\(V_{\lambda}^{k}\)</span> את תת-המרחב <span class="math">\(V_{\lambda}^{k}\triangleq\ker B_{\lambda}^{k}\)</span>. כעת:
<ol>
    <li>נחשב את <span class="math">\(\dim\left(V_{\lambda}^{k+1}/V_{\lambda}^{k}\right)\)</span> עבור <span class="math">\(k=1,2,\dots\)</span> עד אשר נמצא <span class="math">\(k\)</span> שהמימד שווה ל-0 עבורו.</li>
    <li>נבנה באופן אינדוקטיבי סדרה של קבוצות <span class="math">\(P_{k}^{\lambda},P_{k-1}^{\lambda},P_{k-2}^{\lambda},\dots,P_{1}^{\lambda}\)</span> באופן הבא: בתחילה, <span class="math">\(P_{k}^{\lambda}=\emptyset\)</span>. כעת, לכל <span class="math">\(t=k,k-1,\dots,1\)</span>:
<ol>
    <li>ניקח את קבוצת הקוסטים <span class="math">\(\left\{ v+V_{\lambda}^{t-1}\ |\ v\in P_{t}^{\lambda}\right\} \)</span> ונרחיב אותה לבסיס של <span class="math">\(V_{\lambda}^{t}/V_{\lambda}^{t-1}\)</span>.</li>
    <li>נוסיף ל-<span class="math">\(P_{t}^{\lambda}\)</span> את הנציגים של הקוסטים שהתווספו בשלב ההרחבה הזה. לאיברים הללו נקרא <strong>וקטורים ציקליים</strong>.</li>
    <li>לכל <span class="math">\(v\in P_{t}^{\lambda}\)</span> נוסיף ל-<span class="math">\(P_{t-1}^{\lambda}\)</span> את <span class="math">\(B_{\lambda}\cdot v\)</span> (לוקטורים הללו לא נקרא וקטורים ציקליים).</li>
</ol>
</li>
    <li>נגדיר <span class="math">\(P^{\lambda}=\bigcup_{t=1}^{k}P_{t}^{\lambda}\)</span>.</li>
</ol>
</li>
    <li>נגדיר <span class="math">\(P=\bigcup_{\lambda}P^{\lambda}\)</span>.</li>
    <li>נסדר את איברי ב-<span class="math">\(P\)</span> באופן הבא: נגדיר סדר כלשהו על הערכים העצמיים וכל הוקטורים שהתקבלו מערך עצמי <span class="math">\(\lambda\)</span> יופיעו ביחד בהתאם לסדר הזה, ונגדיר סדר כלשהו על הוקטורים הציקליים שהתגלו במהלך האלגוריתם. אם <span class="math">\(v\)</span> הוא וקטור ציקלי ששייך ל-<span class="math">\(P_{t}^{\lambda}\)</span> אז נסדר את האיברים <span class="math">\(B^{t}v,B^{t-1}v,\dots,Bv,v\)</span> בסדר הזה (כך ש-<span class="math">\(B^{t}v\)</span> ראשון ו-<span class="math">\(v\)</span> אחרון).</li>
</ol>
<p>זו הגרסה הפשוטה ביותר של האלגוריתם שאני מסוגל לתאר. האם תוכלו לתת ניסוח טוב יותר? אשמח לשמוע.</p>
        </article>
        
        <footer>
            <p>© כל הזכויות שמורות לגדי אלכסנדרוביץ'</p>
        </footer>
    </div>

    
    <script>
        function toggleMobileMenu() {
            const navLinks = document.getElementById('navLinks');
            navLinks.classList.toggle('expanded');
        }
        
        function searchPosts() {
            const searchTerm = document.getElementById('searchInput').value;
            if (searchTerm.trim()) {
                window.location.href = '/blog/post_list.html?search=' + encodeURIComponent(searchTerm);
            }
        }
        
        document.getElementById('searchInput').addEventListener('keypress', function(e) {
            if (e.key === 'Enter') {
                searchPosts();
            }
        });
    </script>
    
    
    <!-- Auto-render KaTeX math -->
    <script>
        document.addEventListener("DOMContentLoaded", function() {
            renderMathInElement(document.body, {
                delimiters: [
                    {left: "\\[", right: "\\]", display: true},
                    {left: "\\(", right: "\\)", display: false}
                ],
                throwOnError: false
            });
        });
    </script>

</body>
</html>