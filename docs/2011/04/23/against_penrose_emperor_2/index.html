<!DOCTYPE html>
<html lang="he" dir="rtl"><head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1"><!-- Begin Jekyll SEO tag v2.6.1 -->
<title>המותר האדם מן האלגוריתם, חלק 2 - הנקמה? | לא מדויק</title>
<meta name="generator" content="Jekyll v3.9.0" />
<meta property="og:title" content="המותר האדם מן האלגוריתם, חלק 2 - הנקמה?" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="לא מדויק - בלוג על מתמטיקה ומדעי המחשב" />
<meta property="og:description" content="לא מדויק - בלוג על מתמטיקה ומדעי המחשב" />
<link rel="canonical" href="http://gadial.net/2011/04/23/against_penrose_emperor_2/" />
<meta property="og:url" content="http://gadial.net/2011/04/23/against_penrose_emperor_2/" />
<meta property="og:site_name" content="לא מדויק" />
<meta property="og:image" content="http://gadial.net/assets/img/main/default-card.png" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2011-04-23T09:55:22+00:00" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:image" content="http://gadial.net/assets/img/main/default-card.png" />
<meta property="twitter:title" content="המותר האדם מן האלגוריתם, חלק 2 - הנקמה?" />
<meta name="twitter:site" content="@" />
<script type="application/ld+json">
{"mainEntityOfPage":{"@type":"WebPage","@id":"http://gadial.net/2011/04/23/against_penrose_emperor_2/"},"url":"http://gadial.net/2011/04/23/against_penrose_emperor_2/","@type":"BlogPosting","description":"לא מדויק - בלוג על מתמטיקה ומדעי המחשב","headline":"המותר האדם מן האלגוריתם, חלק 2 - הנקמה?","dateModified":"2011-04-23T09:55:22+00:00","datePublished":"2011-04-23T09:55:22+00:00","image":"http://gadial.net/assets/img/main/default-card.png","@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->
<link href="/assets/css/bootstrap.min.css" rel="stylesheet" integrity="sha384-ggOyR0iXCbMQv3Xipma34MD+dH/1fQ784/j6cY/iJTQUOhcWr7x9JvoRxT2MZw1T" crossorigin="anonymous">
  <link rel="stylesheet" href="/assets/css/main.css">
  <link rel="shortcut icon" href="/favicon.ico" type="image/x-icon">
  <link rel="icon" href="/favicon.ico" type="image/x-icon"><link type="application/atom+xml" rel="alternate" href="http://gadial.net/feed.xml" title="לא מדויק" /><script>
if(!(window.doNotTrack === "1" || navigator.doNotTrack === "1" || navigator.doNotTrack === "yes" || navigator.msDoNotTrack === "1")) {
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-3924539-2', 'auto');
  ga('send', 'pageview');
}
</script>
  
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
      tex2jax: {
        processEscapes: true
      },
      TeX: {extensions: ["AMSmath.js","AMSsymbols.js"]},
      "HTML-CSS": { 
        linebreaks: { automatic: true }
      },
      SVG: { 
        linebreaks: { automatic: true } 
      }
    });
  </script>
  <!-- "https://www.gadial.net/wp-includes/js/xypic.js" -->

  <script type="text/javascript" async
    src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML">
  </script>

</head>
<body><header>
  <nav class="navbar navbar-expand-md navbar-dark fixed-top bg-dark">
    <a class="navbar-brand" href="/">לא מדויק</a>
    <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation">
      <span class="navbar-toggler-icon"></span>
    </button>
    <div class="collapse navbar-collapse" id="navbarCollapse">
      <ul class="navbar-nav mr-auto">
        
            
            <li class="nav-item">
                <a class="nav-link" href="/">דף הבית</a>
            </li>
            
        
            
            <li class="nav-item">
                <a class="nav-link" href="/post_list">רשימת הפוסטים</a>
            </li>
            
        
            
            <li class="nav-item">
                <a class="nav-link" href="/categories">קטגוריות</a>
            </li>
            
        
            
            <li class="nav-item">
                <a class="nav-link" href="/random">פוסטים אקראיים</a>
            </li>
            
        
            
            <li class="nav-item">
                <a class="nav-link" href="/lecture_notes">סיכומי הרצאות</a>
            </li>
            
        
            
            <li class="nav-item">
                <a class="nav-link" href="/about/">אודות</a>
            </li>
            
        
      </ul>
      <form class="form-inline mt-2 mt-md-0" action="/post_list/" method="get">
        <input class="form-control mr-sm-2" type="text" placeholder="חיפוש" aria-label="חיפוש" name="s">
        <button class="btn btn-outline-success my-2 my-sm-0" type="submit">חיפוש</button>
      </form>
    </div>
  </nav>
</header><main class="page-content" aria-label="Content" role="main">
      <div class="wrapper text-right">
        <article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting"><div class="PageNavigation">
    
      <a class="prev" href="/2011/04/21/against_penrose_emperor_1/">&laquo; המותר האדם מן האלגוריתם?</a>
    
    
      <a class="next" href="/2011/05/02/damn_stupid_equation/">מה האסוציאציה שלכם ל-?=(1+2)2÷6? &raquo;</a>
    
  </div><header class="post-header">
    <h1 class="post-title p-name" itemprop="name headline">המותר האדם מן האלגוריתם, חלק 2 - הנקמה?</h1>
    <p class="post-meta">
      <time class="dt-published" datetime="2011-04-23T09:55:22+00:00" itemprop="datePublished">Apr 23, 2011
      </time></p>
  </header>

  <div class="post-content e-content" itemprop="articleBody">
    <p>כפי שקיוויתי, <a href="http://www.gadial.net/2011/04/21/against_penrose_emperor_1/">הפוסט הקודם שלי</a> על הספר של רוג’ר פנרוז עורר כמה תגובות מעניינות (לאו דווקא כתגובות לפוסט עצמו) והייתי רוצה להקדיש פוסט למחשבה עליהן. מחשבה, כי גם אני עצמי לא יודע מה נכון ומה לא בכל העניין הזה.</p>

<p>בראש ובראשונה, טענו כי אני מרמה לקראת הסוף, כאשר אני מדבר על כך ש”אם האדם יחוייב להשתתף במשחק ולענות, אז הוא יפסיד מייד כי אפשר יהיה לבנות מכונה ששואלת אותו שאלות ו…”. זו אכן רמאות ותיקנתי קצת את הפוסט כדי להבהיר זאת, אבל אולי כדאי לחדד את הנקודה ולמה זו אולי לא באמת רמאות. לפני כן אני רוצה לחדד קצת את הנקודה של פנרוז.</p>

<p>כזכור, לב הטיעון של פנרוז היה כזה: בהינתן <span>\( H \)</span> שמנסה לפתור את בעיית העצירה (אם היא עוצרת היא עונה נכון, אבל לפעמים היא לא עוצרת) אפשר להציג מכונה <span>\( Q \)</span> שכאשר <span>\( H \)</span> רצה “עליה”, <span>\( H \)</span> לא יכולה לענות תשובה נכונה ולכן חייבת לא לעצור, ומכך נובע שהיא “לא מכריעה” את בעיית העצירה על <span>\( Q \)</span>, אבל אנחנו בני האדם יודעים ש-<span>\( Q \)</span> בהכרח לא עוצרת (כי חלק ממה ש-<span>\( Q \)</span> עושה הוא להריץ את <span>\( H \)</span> “על עצמה”).</p>

<p>פנרוז תיאר את העסק בצורה יותר מסובכת עם ביטויים כמו <span>\( M_{k}\left(k\right)=1+M_{k}\left(k\right)\times H\left(k,k\right) \)</span>, אבל זה מיותר לגמרי, כפי שאמרתי בפוסט הקודם; לצורך פשטות מספיק לתאר את <span>\( Q \)</span> באופן הבא: <span>\( Q \)</span> מריצה את <span>\( H \)</span> על הקוד של <span>\( Q \)</span> (<span>\( Q \)</span> יכולה לדעת מה הקוד של <span>\( Q \)</span>; זהו משפט הרקורסיה של קלייני) ואם <span>\( H \)</span> אמרה ש-<span>\( Q \)</span> עוצרת, אז <span>\( Q \)</span> לא עוצרת; ואם <span>\( H \)</span> אמרה ש-<span>\( Q \)</span> לא עוצרת, אז <span>\( Q \)</span> עוצרת. זהו. שימו לב שכאן אין התייחסות בכלל לקלט של <span>\( Q \)</span>; אפשר לחשוב עליה כעל מכונה שלא מקבלת קלט, או שההתנהגות שלה לכל הקלטים היא אותו דבר ו-<span>\( H \)</span> נשאלת על ההתנהגות של <span>\( Q \)</span> על קלט ספציפי, וכדומה. אני חושב שדרך ההצגה שלי מזקקת את לב הבעיה.</p>

<p>איפה הטיעון שלי נכשל? בואו נניח ש-<span>\( P \)</span> הוא בן אדם שמנסה לפתור את בעיית העצירה (האות <span>\( H \)</span> מתאימה יותר כאן, כמובן, אבל פנרוז כבר תפס לנו אותה; כמו כן, במהלך הפוסט <span>\( P \)</span> יהיה זכר בעוד שמכונות טיורינג יהיו נקבות; אתם מוזמנים להאשים אותי בשוביניזם ואמונה בעליונות החישובית של גברים על נשים-שהן-רובוטים). אני אומר - אם <span>\( P \)</span> עונה, אז אפשר לבנות <span>\( Q \)</span> ששואלת את האדם על הקוד של עצמה ומתנהגת הפוך. הבעיה היא של-<span>\( Q \)</span> אין את <span>\( P \)</span> זמין לידה לשאלות בכל פעם שהיא רצה; היא צריכה <strong>לסמלץ</strong> אותו איכשהו. גם קודם, בבניה המקורית, <span>\( Q \)</span> ביצעה סימולציה של <span>\( H \)</span>. לכן כדי שהבניה שלי תעבוד אני צריך להניח, לכל הפחות, ש-<span>\( Q \)</span> מסוגלת לגלות איכשהו מה תהיה התשובה של <span>\( P \)</span> על הקוד של <span>\( Q \)</span>. אם <span>\( Q \)</span> כזו קיימת, אז <span>\( P \)</span> “הפסיד”, כי אפשר לבנות מכונת טיורינג שעל אותו <span>\( Q \)</span> ספציפי עונה נכון, ואז היא הביסה את <span>\( P \)</span> לפחות על קלט אחד.</p>

<p>הכוונה שלי בטיעון (כוונה שלא הועברה טוב בפוסט) היא זו: אם <span>\( Q \)</span> <strong>לא</strong> מסוגלת לגלות מה תהיה התשובה של <span>\( P \)</span> על הקוד של <span>\( Q \)</span>, הנה מצאנו מטלה חישובית ש-<span>\( P \)</span> מסוגל לבצע ו-<span>\( Q \)</span> לא; ומכיוון שהיינו יכולים לבנות את <span>\( Q \)</span> כרצוננו, בעצם הטענה היא זו: <strong>קיים</strong> <span>\( P \)</span> אנושי כך ש<strong>לכל</strong> מכונת טיורינג <span>\( Q \)</span>, <strong>קיים</strong> קלט ש-<span>\( P \)</span> אומר את התשובה עליו ו-<span>\( Q \)</span> לא. זה טיעון חזק; לטעמי טיעון כזה כבר אומר מפורשות שהאדם, כמודל חישובי, חזק יותר ממכונת טיורינג. במילים אחרות, כדי שהטיעון “שלי” ייכשל, צריך להניח מראש שהאדם חזק חישובית ממכונת טיורינג. לכן אמרתי בפוסט שהטיעון של פנרוז, כשמקלפים ממנו את כל הקליפות, הוא למעשה “אם האדם חזק מהמכונה, אז האדם חזק מהמכונה”. אבל פנרוז צריך להוכיח שהאדם חזק מהמכונה <strong>בלי</strong> שום הנחות מוקדמות!</p>

<p>אם אכן מישהו יצליח למצוא הוכחה לטענה שנתתי למעלה, זה יהיה ממש נפלא לדעתי. הוכחה מתמטית טהורה לכך שהאדם הוא מודל חישובי חזק ממכונת טיורינג? זה יהיה פנטסטי, בעיקר עבור מישהו כמוני שמאמין (ללא הוכחה, כמובן) בכך שכמודל חישובי האדם אינו חזק יותר. אבל כפי שאנו רואים, הטענה הזו שונה למדי ממה שפנרוז ניסה בכלל לעשות באותו פרק בספר: פנרוז הראה רק ש<strong>לכל</strong> מכונת טיורינג <span>\( Q \)</span>, <strong>קיים</strong> <span>\( P \)</span> אנושי ו<strong>קיים</strong> קלט ש-<span>\( P \)</span> אומר (“יודע”) את התשובה הנכונה עליו ו-<span>\( Q \)</span> לא. יש כאן מה שנקרא “היפוך של סדר הכמתים” - במקום “קיים-לכל-קיים”, פנרוז מראה “לכל-קיים-קיים” שהיא טענה <strong>חלשה</strong> הרבה יותר (מה חזק יותר? “לכל מספר טבעי <span>\( a \)</span> קיים מספר טבעי <span>\( b \)</span> הגדול ממנו” שהיא טענה שכל ילד יודע, או “קיים מספר טבעי <span>\( b \)</span> הגדול מכל מספר טבעי <span>\( a \)</span>” שהיא כמובן שגויה?). בלבול דומה קיים הרבה פעמים גם בניסוח משפט אי השלמות הראשון של גדל: במקום לומר “<strong>לכל</strong> תורה פורמלית שמקיימת כך-וכך <strong>קיים</strong> פסוק שאותה תורה לא יכולה להוכיח או להפריך” אומרים “<strong>קיים</strong> פסוק כך ש<strong>כל</strong> תורה פורמלית לא יכולה להוכיח או להפריך אותו”. אגב, מהבלבול הזה פנרוז דווקא נמנע (וטוב שכך, אחרת הייתם צריכים לסבול פוסט נוסף שבו אני מקטר על העניין הזה).</p>

<p>אם כן, היפוך סדר הכמתים פה ממחיש שפנרוז לא באמת הראה את עליונות האדם על המכונה עם הטיעון שלו. פנרוז גם לא מנסה לטעון שם דבר שכזה באופן חד משמעי - הניסוח שלו לגבי המסקנה מהטיעון שלו הוא מעורפל למדי וכבר ציטטתי אותו בפוסט הקודם.</p>

<p>אבל רגע, למה הטיעון של פנרוז הופך את הכמתים? על פניו, נראה שאותו <span>\( P \)</span> “מנצח” את כל המכונות <span>\( H \)</span>. זו עוד נקודה שלא הבהרתי מספיק בפוסט הקודם. פנרוז בונה את <span>\( P \)</span> הזה בנפנופי ידיים לא מתמטיים (קצת אבסורדי, בהתחשב בכך שהוא מקדיש קודם לכן עמודים על גבי עמודים לבניות פורמליות מתישות של מכונות עבור מטלות חישוביות זוטרות), וכשיש כל הזמן איזו <span>\( H \)</span> ספציפית ברקע, וכל הייעוד של <span>\( P \)</span> הוא לנצח את <span>\( H \)</span> על קלט אחד מסויים. אם באמת רוצים לבנות <span>\( P \)</span> שטוב מכל מכונה, צריך להגיד מה היא עושה על כל קלט, בלי התייחסות לאף <span>\( H \)</span> ספציפית, ו<strong>אחרי</strong> ש-<span>\( P \)</span> נבנתה, להראות שלכל <span>\( H \)</span> ספציפית, <span>\( P \)</span> מביסה אותה. אבל האם לא ניתן לבנות <span>\( P \)</span> שכזו?</p>

<p>בואו ננסה לעשות את הבניה הטבעית ביותר: <span>\( P \)</span> על מכונה <span>\( M \)</span> בודקת קודם כל אם <span>\( M \)</span> יכולה להתקבל כ-<span>\( Q \)</span> של <strong>איזו</strong> מכונה <span>\( H \)</span>, ואם היא יכולה, אז <span>\( P \)</span> אומרת ש-<span>\( M \)</span> לא עוצרת… רגע, רגע, הויסה. יש לנו שתי טעויות גסות בשורה האחרונה.</p>

<p>ראשית, יש אינסוף מכונות <span>\( H \)</span>, אז רק שלב הבדיקה אם <span>\( M \)</span> היא <span>\( Q \)</span> של <span>\( H \)</span> <strong>כלשהי</strong> יכול להימשך לנצח. אם <span>\( M \)</span> אינה מתאימה לאף <span>\( H \)</span>, אז החיפוש הזה לא יסתיים אף פעם. אפשר לנסות ולעקוף את הבעיה הזו כך - במקביל לביצוע החיפוש, <span>\( P \)</span> גם יבצע הרצה של <span>\( M \)</span>. אם <span>\( M \)</span> עוצרת, אז <span>\( P \)</span> תענה ש-<span>\( M \)</span> כן עוצרת. אפשר גם לזרוק פנימה בדיקות קצת יותר מחוכמות האם <span>\( M \)</span> עוצרת או לא. הנקודה היא שהבדיקה אם <span>\( M \)</span> היא “מכונה שמכשילה <span>\( H \)</span> כלשהו” יכולה להתבצע במקביל ובאופן בלתי תלוי לשאר הבדיקות; זה סתם עוד כלי נשק של <span>\( P \)</span>. אם כן, לכל מכונה <span>\( H \)</span> שפותרת את בעיית העצירה באופן חלקי, <span>\( P \)</span> בריצתו על <span>\( Q \)</span> יגיד בודאות ש-<span>\( Q \)</span> לא עוצרת (כי הוא יגלה ש-<span>\( Q \)</span> היא המכונה שמכשילה את <span>\( H \)</span> הספציפי הזה; הוא יגיע אל <span>\( H \)</span> במהלך הבדיקה שלה).</p>

<p>אז מה הבעיה כאן? ובכן, הטעות הגסה השניה שעוד לא ציינתי, שהיא כנראה לב העניין: <span>\( P \)</span> בכלל לא פותר חלקית את בעיית העצירה. <span>\( P \)</span>, חד משמעית, <strong>טועה</strong> על קלטים מסויימים, וזה בדיוק מה שאסור לו לעשות. על אילו קלטים הוא טועה? על <span>\( M \)</span> שהם <span>\( Q \)</span> של איזו מכונה <span>\( H \)</span>, כאשר אותה <span>\( H \)</span> <strong>לא</strong> פותרת את בעיית העצירה.</p>

<p>בואו ניקח כדוגמה <span>\( H \)</span> שעוצרת תמיד עם הפלט 0. אז ה-<span>\( Q \)</span> המתאימה לה (שכזכור, מריצה את <span>\( H \)</span> ועושה הפוך ממה שהיא אומרת) תעצור מייד. זה מראה ש-<span>\( H \)</span> לא פותרת את בעיית העצירה כי היא טועה על הקלט <span>\( Q \)</span>; אבל גם <span>\( P \)</span> לא פותר את בעיית העצירה כי גם הוא יגיד ש-<span>\( Q \)</span> אינה עוצרת, ולכן יטעה. כדי ש-<span>\( P \)</span> יעבוד בהצלחה, הוא חייב לבדוק האם <span>\( M \)</span> היא <span>\( Q \)</span> של איזו מכונה <span>\( H \)</span> רק עבור מכונות <span>\( H \)</span> ש<strong>פותרות חלקית את בעיית העצירה</strong>. אבל, וזו הנקודה המרכזית, למיטב ידיעתנו אין ל-<span>\( P \)</span> יכולת לעשות זאת! לא קשה להוכיח שהבעיה של “זיהוי האם <span>\( H \)</span> פותרת חלקית את בעיית העצירה” היא קשה עוד יותר מפתרון בעיית העצירה (פורמלית, זו בעיה שאפילו אינה ב-RE). לכן, רק להראות ש-<span>\( P \)</span> מסוגלת לבצע את אותו שלב בדיקה כבר דורש מאיתנו להראות ש-<span>\( P \)</span> חזקה יותר מכל מכונת טיורינג. שוב - “אם האדם חזק מהמכונה, אז האדם חזק מהמכונה”.</p>

<p>סיכום קצר למי שאיבד אותי בים הסימונים: ניסיתי להציע בניה שנראתה לי טבעית ומבוססת על הרעיונות של פנרוז. היא נכשלה באופן חרוץ. זה לא אומר שאין בניה שעובדת - אשמח מאוד לשמוע הצעות - אבל אני לא חושב שמה שפנרוז מציע מקדם אותנו לקראת בניה שעובדת. כל מה שפנרוז מציע הוא טענת “לכל-קיים-קיים”, שהיא כאמור חלשה למדי.</p>

<p>למעשה, לא ברור איפה פנרוז משתמשת ביכולותיו של האדם בכל הסיפור הזה - כפי שכבר ראינו, את <span>\( Q \)</span> אפשר לבנות מ-<span>\( H \)</span> באופן אלגוריתמי. כך שאפשר לנסח את מה שפנרוז מראה גם בתור “לכל <span>\( H \)</span> שמנסה לפתור את בעיית העצירה קיימת <span>\( H^{\prime} \)</span> שפותרת את בעיית העצירה יותר טוב ממנה”. אז איפה מותר האדם מן המכונה פה?</p>

<p>פנרוז מציין במפורש שאותה <span>\( H^{\prime} \)</span> משופרת קיימת, אבל הוא מעיר בהערת שוליים שגם אותה אפשר להביס עם טיעון דומה (והוא צודק), ושגם את <span>\( H^{\prime} \)</span> אפשר יהיה לשפר עם איזו <span>\( H^{\prime\prime} \)</span> (והוא צודק), ושהוא ידון ב”סוג השיקולים שהתהליך האיטרטיבי הזה מוביל אותנו אליו” בפרק שעוסק במשפטי גדל. הוא אכן עושה זאת שם, אבל רק בהקשר של תורות פורמליות ולא של מכונות טיורינג, והוא לא נכנס לעובי הקורה; הוא מתאר קצת איך אפשר להמשיך עוד ועוד את הבניה (ומערב בתמונה אורדינלים) ממלמל משהו על כך שתהליך הבניה האיטרטיבי מוביל אותנו ל”שיקולים מתמטיים קשים שלא ניתן להיכנס לפרטיהם כאן” ומפנה למאמר (מרתק ובלתי קריא) של טיורינג בנושאים הללו. אנסה כנראה להקדיש פוסט לאותו מאמר מתישהו; אבל עבור פנרוז העיסוק בנושא נגמר כאן פחות או יותר (אלא אם הוא חוזר אליו בפרקים מאוחרים יותר) מבלי שהוא הסיק מתמטית שום מסקנה חד משמעית. בהמשך הוא מציג עוד מושגים יפים מחישוביות וכמה בעיות לא כריעות מפורסמות (הבעיה העשירית של הילברט, בעיית המילה, בעיית הריצוף) אבל לחזור מתמטית לכל עניין ה”האדם יודע לפתור את בעיית העצירה יותר טוב מכל מכונה”? לא.</p>

<p>לסיכום, אני לא שולל את הרעיונות של פנרוז. הם נשמעים מרתקים למדי. אבל אני ממש לא רואה איך מה שהוא כותב בפרקים אותם קראתי בספר מוביל לעליונות האדם על המכונה. יותר מכך, אני לא רואה איך הבניות הפורמליות תקפות לאדם אך <strong>לא</strong> למכונות; ובקיצור, אני לא חושב שיש תוכן כלשהו למה שהוא כותב שם, והסיבה שנראה שיש היא הניסוחים המילוליים המעורפלים שלו שבאים אחרי התוכן המתמטי.</p>

<p>זה מוביל אותי לנקודה האחרונה - הדיבורים שלי בפוסט הקודם על ההבדל בין “יודעת” ו”אומרת”. כשניסיתי להבין איפה בטיעון של פנרוז נכנס ההבדל בין אדם ומכונה (כי אם בשום מקום לא נכנס הבדל כזה, פנרוז מוכיח כי המכונה חזקה מהמכונה), ההבדל היחיד שראיתי הוא בין הדרישה שלו שהמכונה “תכריע” את בעיית העצירה, ושהאדם רק “ידע” את התשובה. טענתי ש-<span>\( H \)</span>, כשהיא רצה על <span>\( Q \)</span>, יכולה לדעת מייד ש-<span>\( Q \)</span> היא “מכונה רמאית”, שתתנהג הפוך ממה ש-<span>\( H \)</span> תאמר בסוף. לא הגדרתי במפורש את ה”יודעת” הזו כי גם פנרוז לא הגדיר מה זה “לדעת” והנחתי שניתן להסתמך כאן על האינטואיציה. אבל בטיעון שלי יש כשל מהותי: לא משנה איך אני אגדיר “לדעת” באופן פורמלי, מכיוון ש-<span>\( Q \)</span> מסוגלת לבצע סימולציה אחד-לאחד של <span>\( H \)</span> (ממש ברמה של לדעת כל צעד ש-<span>\( H \)</span> מבצעת, את תוכן תאי הזכרון שלה וכדומה), אז <span>\( Q \)</span> תוכל לזהות את הרגע המדוייק שבו מתגשמת ב-<span>\( H \)</span> ה”ידיעה” ש-<span>\( Q \)</span> אינה עוצרת - ואז כמובן ש-<span>\( Q \)</span> תעצור ותראה שאפילו הידיעה ההיא של <span>\( H \)</span> הייתה טעות.</p>

<p>האדם יכול לחמוק מהפסד כאן אם נוכל להראות שלא ניתן לסמלץ את המוח שלו בצורה כזו ש”ידיעה” תהיה ניתנת לזיהוי (זה כבר משהו הרבה יותר סביר מאשר ההתאמה בין קלט לפלט שדיברתי עליה קודם; בהתאמה כזו לא חייבים לסמלץ אחד-לאחד את המוח, אולי יש דרך אחרת לדעת איזה פלט האדם יענה על קלט נתון). אבל כרגיל, זה בדיוק מה שאנחנו רוצים להוכיח.</p>

<p>מה שאי אפשר לקחת מ-<span>\( H \)</span>, לדעתי, הוא את הידיעה ש-<span>\( Q \)</span> מנסה להכשיל אותה - כאמור, <span>\( H \)</span> יכולה לגלות זאת על ידי משחק עם הקידוד שלה עצמה. במילים אחרות, <span>\( H \)</span> לא יכולה לדעת מה <span>\( Q \)</span> תעשה, אבל <strong>היא יכולה לדעת שהיא לא יכולה לדעת</strong> מה <span>\( Q \)</span> תעשה. בשלב הזה בוודאי מדגדג לחלקכם לבנות <span>\( Q \)</span> שדווקא <strong>כן</strong> מתנהגת כמו ש-<span>\( H \)</span> מצפה שהיא תתנהג, ובכך מראה ש-<span>\( H \)</span> לא באמת יודעת שהיא לא יכולה לדעת מה <span>\( Q \)</span> תעשה; וזה בדיוק השלב שבו אני חש שאין טעם להמשיך עם הכיוון הזה בלי לתת הגדרות מדוייקות של “לדעת” ולראות מה יוצא מהן, אבל אני לא חושב שיצא מהן משהו מעניין במיוחד ולא אנסה ללכת בכיוון הזה.</p>

<p>אני מקווה שבכך אפשר לסגור את הדיון על הטיעון הספציפי הזה של פנרוז; אשמח מאוד לקיים דיונים על טיעונים אחרים שפנרוז מעלה (בחלקים אחרים של הספר/בספר ההמשך/במקום אחר כלשהו) או על ניסוחים יותר פורמליים ומדוייקים של הטיעון של פנרוז שמהם כן עולה שהאדם חזק מהמכונה.</p>

  </div>

  <hr />
  <p>
    נהניתם? התעניינתם? אם תרצו, אתם מוזמנים לתת טיפ:
  </p>
  <a href='https://ko-fi.com/H2H5XFBQ' target='_blank'><img height='36' style='border:0px;height:36px;' src='https://az743702.vo.msecnd.net/cdn/kofi2.png?v=2' border='0' alt='Buy Me a Coffee at ko-fi.com' /></a><div class="PageNavigation">
    
      <a class="prev" href="/2011/04/21/against_penrose_emperor_1/">&laquo; המותר האדם מן האלגוריתם?</a>
    
    
      <a class="next" href="/2011/05/02/damn_stupid_equation/">מה האסוציאציה שלכם ל-?=(1+2)2÷6? &raquo;</a>
    
  </div><div id="disqus_thread"></div>
  <script>
    var disqus_config = function () {
      this.page.url = 'http://gadial.net/2011/04/23/against_penrose_emperor_2/';
      this.page.identifier = 'http://gadial.net/2011/04/23/against_penrose_emperor_2/';
    };

    (function() {
      var d = document, s = d.createElement('script');

      s.src = 'https://not-precise.disqus.com/embed.js';

      s.setAttribute('data-timestamp', +new Date());
      (d.head || d.body).appendChild(s);
    })();
  </script>
  <noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript" rel="nofollow">comments powered by Disqus.</a></noscript><a class="u-url" href="/2011/04/23/against_penrose_emperor_2/" hidden></a>
</article>

      </div>
    </main><footer class="site-footer h-card">
  <data class="u-url" href="/"></data>

  <div class="wrapper">

    <h2 class="footer-heading">לא מדויק</h2>

    <div class="footer-col-wrapper">
      <div class="footer-col footer-col-1">
        <ul class="contact-list">
          <li class="p-name">לא מדויק</li><li><a class="u-email" href="mailto:gadial@gmail.com">gadial@gmail.com</a></li><li>&copy; כל הזכויות שמורות לגדי אלכסנדרוביץ'</li>
        </ul>
      </div>

      <div class="footer-col footer-col-2"><ul class="social-media-list"><li><a href="https://www.facebook.com/%D7%9C%D7%90-%D7%9E%D7%93%D7%95%D7%99%D7%A7-163347110378474"><svg class="svg-icon"><use xlink:href="/assets/minima-social-icons.svg#facebook"></use></svg> <span class="username">לא מדויק</span></a></li><li><a href="/feed.xml"><svg class="svg-icon"><use xlink:href="/assets/minima-social-icons.svg#rss"></use></svg> <span>RSS</span></a></li></ul>
</div>

      <div class="footer-col footer-col-3">
        <p>בלוג על מתמטיקה ומדעי המחשב</p>
      </div>
    </div>

  </div>

</footer><script src="https://code.jquery.com/jquery-3.3.1.slim.min.js" integrity="sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo" crossorigin="anonymous"></script>
<script>window.jQuery || document.write('<script src="assets/js/jquery-slim.min.js"><\/script>')</script><script src="/assets/js/bootstrap.bundle.js"></script><script src="https://code.jquery.com/jquery-3.3.1.slim.min.js" integrity="sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo" crossorigin="anonymous"></script>
<script>window.jQuery || document.write('<script src="assets/js/jquery-slim.min.js"><\/script>')</script><script src="/assets/js/bootstrap.bundle.js"></script>

<!-- Default Statcounter code for New blog
http://www.gadial.net/ -->
<script type="text/javascript">
  var sc_project=5444342; 
  var sc_invisible=1; 
  var sc_security="4a89cbe4"; 
  </script>
  <script type="text/javascript"
  src="https://www.statcounter.com/counter/counter.js"
  async></script>
  <noscript><div class="statcounter"><a title="Web Analytics"
  href="https://statcounter.com/" target="_blank"><img
  class="statcounter"
  src="https://c.statcounter.com/5444342/0/4a89cbe4/1/"
  alt="Web Analytics"></a></div></noscript>
  <!-- End of Statcounter Code --></body>

</html>
