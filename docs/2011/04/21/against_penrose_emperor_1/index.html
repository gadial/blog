<!DOCTYPE html>
<html lang="he" dir="rtl"><head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1"><!-- Begin Jekyll SEO tag v2.6.1 -->
<title>המותר האדם מן האלגוריתם? | לא מדויק</title>
<meta name="generator" content="Jekyll v3.8.5" />
<meta property="og:title" content="המותר האדם מן האלגוריתם?" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="לא מדויק - בלוג על מתמטיקה ומדעי המחשב" />
<meta property="og:description" content="לא מדויק - בלוג על מתמטיקה ומדעי המחשב" />
<link rel="canonical" href="http://gadial.net/2011/04/21/against_penrose_emperor_1/" />
<meta property="og:url" content="http://gadial.net/2011/04/21/against_penrose_emperor_1/" />
<meta property="og:site_name" content="לא מדויק" />
<meta property="og:image" content="http://gadial.net/assets/img/main/default-card.png" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2011-04-21T11:39:33+00:00" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:image" content="http://gadial.net/assets/img/main/default-card.png" />
<meta property="twitter:title" content="המותר האדם מן האלגוריתם?" />
<meta name="twitter:site" content="@" />
<script type="application/ld+json">
{"@type":"BlogPosting","url":"http://gadial.net/2011/04/21/against_penrose_emperor_1/","image":"http://gadial.net/assets/img/main/default-card.png","headline":"המותר האדם מן האלגוריתם?","dateModified":"2011-04-21T11:39:33+00:00","datePublished":"2011-04-21T11:39:33+00:00","description":"לא מדויק - בלוג על מתמטיקה ומדעי המחשב","mainEntityOfPage":{"@type":"WebPage","@id":"http://gadial.net/2011/04/21/against_penrose_emperor_1/"},"@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->
<link href="/assets/css/bootstrap.min.css" rel="stylesheet" integrity="sha384-ggOyR0iXCbMQv3Xipma34MD+dH/1fQ784/j6cY/iJTQUOhcWr7x9JvoRxT2MZw1T" crossorigin="anonymous">
  <link rel="stylesheet" href="/assets/css/main.css">
  <link rel="shortcut icon" href="/favicon.ico" type="image/x-icon">
  <link rel="icon" href="/favicon.ico" type="image/x-icon"><link type="application/atom+xml" rel="alternate" href="http://gadial.net/feed.xml" title="לא מדויק" /><script>
if(!(window.doNotTrack === "1" || navigator.doNotTrack === "1" || navigator.doNotTrack === "yes" || navigator.msDoNotTrack === "1")) {
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-3924539-2', 'auto');
  ga('send', 'pageview');
}
</script>
  
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
      tex2jax: {
        processEscapes: true
      },
      TeX: {extensions: ["AMSmath.js","AMSsymbols.js"]},
      "HTML-CSS": { 
        linebreaks: { automatic: true }
      },
      SVG: { 
        linebreaks: { automatic: true } 
      }
    });
  </script>
  <!-- "https://www.gadial.net/wp-includes/js/xypic.js" -->

  <script type="text/javascript" async
    src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML">
  </script>
  
</head>
<body><header>
  <nav class="navbar navbar-expand-md navbar-dark fixed-top bg-dark">
    <a class="navbar-brand" href="/">לא מדויק</a>
    <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation">
      <span class="navbar-toggler-icon"></span>
    </button>
    <div class="collapse navbar-collapse" id="navbarCollapse">
      <ul class="navbar-nav mr-auto">
        
            
            <li class="nav-item">
                <a class="nav-link" href="/whats_going_on">מה הולך פה?</a>
            </li>
            
        
            
            <li class="nav-item">
                <a class="nav-link" href="/">דף הבית</a>
            </li>
            
        
            
            <li class="nav-item">
                <a class="nav-link" href="/categories">קטגוריות</a>
            </li>
            
        
            
            <li class="nav-item">
                <a class="nav-link" href="/random">דף אקראי</a>
            </li>
            
        
            
            <li class="nav-item">
                <a class="nav-link" href="/about/">אודות</a>
            </li>
            
        
      </ul>
      <form class="form-inline mt-2 mt-md-0" action="/post_list/" method="get">
        <input class="form-control mr-sm-2" type="text" placeholder="חיפוש" aria-label="חיפוש" name="s">
        <button class="btn btn-outline-success my-2 my-sm-0" type="submit">חיפוש</button>
      </form>
    </div>
  </nav>
</header><main class="page-content" aria-label="Content" role="main">
      <div class="wrapper text-right">
        <article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting"><div class="PageNavigation">
    
      <a class="prev" href="/2011/04/12/gelfond_schneider_theorem/">&laquo; הוכחה לא קונסטרוקטיבית לכך שרציונלי זה טרנסצנדנטי (טוב, לא בדיוק...)</a>
    
    
      <a class="next" href="/2011/04/23/against_penrose_emperor_2/">המותר האדם מן האלגוריתם, חלק 2 - הנקמה? &raquo;</a>
    
  </div><header class="post-header">
    <h1 class="post-title p-name" itemprop="name headline">המותר האדם מן האלגוריתם?</h1>
    <p class="post-meta">
      <time class="dt-published" datetime="2011-04-21T11:39:33+00:00" itemprop="datePublished">Apr 21, 2011
      </time></p>
  </header>

  <div class="post-content e-content" itemprop="articleBody">
    <p>אחד מהספרים שאני נאבק איתם בקביעות עוד מתחילת הלימודים שלי באוניברסיטה הוא The Emperor’s New Mind (“תודעת המלך החדשה”? על משקל “בגדי המלך החדשים”) של רוג’ר פנרוז. בפשטות, הספר מתעסק באחת השאלות הפילוסופיות המרתקות ביותר שאני, כאדם המתעניין במדעי המחשב, יכול להעלות על הדעת - האם התודעה האנושית היא בסך הכל אלגוריתם שרץ על מחשב ביולוגי מחוכם, או שיש בה “משהו נוסף”. נזכרתי בספר לאחר שמוסף הארץ פרסמו רשימת “שאלות ותשובות” מעניינת, ואחת מהן עסקה ב”<a href="http://www.haaretz.co.il/hasite/spages/1225006.html">למה המוח הוא בסך הכל מכונה?</a>”. האם אתם שמים לב להנחה הסמויה בכותרת?</p>

<p>פנרוז אינו מקבל את ההנחה הסמויה הזו. הספר מוקדש לתיאור מה שהוא מבהיר מראש שהיא דעתו האישית, וכזו שאינה ממש בקונצנזוס, לפיה “יש עוד משהו”. כדי לנמק את עצמו פנרוז נכנס לאלף ואחד תחומים - חישוביות, משפטי גדל, פיזיקה קלאסית ומודרנית, מבנה המוח הביולוגי… כך שאי אפשר לומר שהוא לא מתאמץ, או שהוא סתם זורק קשקושים לאוויר. לפחות בכל הנוגע לתחומים שבהם אני מבין, הוא אינו כותב קשקושים ולמעט אי דיוקים פה ושם, הצגת הדברים <strong>המתמטית</strong> שלו היא נכונה לגמרי ואם יש בעיה היא בפרשנות. כך שעל פניו זה ספר מרתק.</p>

<p>לרוע המזל, אני חושב שהכתיבה של הספר היא טרחנית ומייגעת ביותר. כדי להציג את תורת החישוביות הוא עוסק במשך עמודים על גבי עמודים בתכנות של מכונות טיורינג ובהמוני פרטים קטנים אחרים שאפילו בספרי חישוביות לא טורחים להיכנס אליהם. הספר הוא גם כבד וטכני מכדי להיות ספר מדע פופולרי, אבל גם מפוזר מדי מכדי להיות ספר לימוד. זו אולי הסיבה שבגללה אני כל הזמן נתקע איתו - בשלב כלשהו אני מגלה שאני פוסח על דפים על גבי דפים שכוללים חומר שאני כבר מכיר ומוצג באופן מייגע, ובסוף מרגיש שלא קראתי מספיק מהספר כדי לבקר אותו. יש לספר ספר המשך, שאמור להתמודד עם חלק מהביקורת עליו - Shadows of the Mind. אליו בכלל לא הגעתי. לכן, ברשותכם, אני לא הולך לכתוב מסה הפוסלת את הספר מכל וכל, אלא להתייחס לטיעון שמופיע בשלב מוקדם של הספר, באופן מנותק למדי משאר הספר. אני מקווה שאני לא מפספס משהו מהותי בכך שאני מתרכז לבינתיים רק בטיעון הזה - הקוראים מוזמנים לתקן אותי.</p>

<p>הטיעון עצמו, שמופיע בפרק 2 תחת הכותרת “How to outdo an algorithm”, נראה לי חזק ומשכנע ביותר ממבט ראשון. בפשטות, פנרוז מתאר מטלה חישובית כלשהי שבה אנחנו, בני האדם, נהיה טובים יותר מכל אלגוריתם שמבצע אותה; כלומר, שתמיד יהיה קלט שעליו האלגוריתם כושל באופן מחפיר ועם זאת אנחנו, בני האדם, נדע מה התשובה הנכונה במקרה הזה. זו וריאציה על טיעון דומה שמושמע לעתים קרובות (ומושמע גם בספר על ידי פנרוז עצמו) שמשפט גדל מראה שהחשיבה האנושית “גדולה יותר” מהפורמליסטיקה המתמטית שכן במהלך הוכחת המשפט נבנה פסוק ש”אי אפשר להוכיח אבל אנחנו יודעים שהוא נכון” (אני מגחיך פה את הטענה וכמובן שלא מתאר נכונה את משפט גדל; לזכותי ייאמר ש<a href="http://www.gadial.net/2009/05/03/godel_incompleteness_yes/">יש לי פוסט</a> שכן מנסה לתת תיאור הולם של המשפט).</p>

<p>אז איך הטיעון של פנרוז הולך? לפני כן, חזרה קצרה על חישוביות על רגל אחת - ומי שאינו מכיר את הנושא ולא יצליח לעקוב אחרי החזרה, יש לי <a href="http://www.gadial.net/2007/09/23/turing_machine/">פוסטים</a> בעניין ויש ספרי לימוד טובים וזה נושא מרתק ואלמנטרי לחלוטין מבחינה מתמטית (כלומר, לא נדרש כמעט שום ידע מתמטי קודם עבורו).</p>

<p>המושג של “אלגוריתם” הוא מעורפל. ההגדרה הפורמלית לאלגוריתם היא באמצעות מין מחשב מתמטי אבסטרקטי שמכונה “מכונת טיורינג”. הפרטים הספציפיים של איך המכונה מבצעת חישובים לחלוטין לא רלוונטיים כרגע; הדבר היחיד שחשוב הוא שניתן לקודד את התיאור של מכונת טיורינג באמצעות מחרוזת תווים סופית, ואפשר לקחת את המחרוזת הזו ולסמלץ את ריצת המכונה שהיא מקודדת (ליצור שיודע לבצע סימולציה שכזו קוראים “מכונת טיורינג אוניברסלית”, אבל באותה מידה אפשר גם לעשות את זה במחשב האישי שלכם). התפקיד של מכונת טיורינג בחיים הוא להמיר קלטים לפלטים - אם נותנים לה 7, היא עושה המון חישובים ובסוף כותבת 13, ואז אומרים שהקלט 7 עבר לפלט 13. זה אולי כבר נשמע מוזר לתוהים על סוגיית “האם המוח הוא מכונת טיורינג”, שכן המוח בכלל לא עסוק בתרגום קלטים לפלטים - הוא פשוט קיים! כמובן, כשהמוח מקבל אותות חשמליים מהעיניים, למשל, הוא מתרגם אותם למה שאנחנו מבינים בתור “ראייה” בתודעה שלנו, אבל לחשוב על זה כפלט מספרי זה קצת מוזר. כלומר, יש כאן חוסר התאמה כלשהו כבר ברמת ההגדרות. אבל במקום להסתבך עם הגדרות יותר מחוכמות לאלגוריתמים, אפשר לעשות בדיוק את ההפך - לטעון שהאדם מנצח את מכונת הטיורינג כבר במגרש הביתי שלה; לחשוב על אותו אספקט של המוח שכן עובד עם קלט/פלט. במילים אחרות, לשאול - האם אדם עם עט ונייר, שמקבל מחרוזת על פיסת נייר ובסוף מחזיר מחרוזת חדשה על פיסת נייר, יכול לעשות דברים שמכונות טיורינג לא יכולות?</p>

<p>השלב הראשון הוא כמובן להוכיח שיש בכלל דברים חישוביים שמכונות טיורינג לא מסוגלות לעשות. הדוגמה הקלאסית לכך נקראת “<a href="http://www.gadial.net/2007/09/26/halting_problem/">בעיית העצירה</a>” אבל פנרוז מציג שיטת הוכחה טיפה שונה (לא מהותית) מהמקובלת כדי להתאים יותר לשאר חלקי הספר. לכן אציג את הגישה שלו, שבה מובלט מאוד הדמיון של הוכחת האי-יכולת הזו לשיטת <a href="http://www.gadial.net/2007/08/29/cantor_diagonal/">האלכסון של קנטור</a> הקלאסית. אשנה באופן קל את הסימונים ותו לא.</p>

<p>פנרוז מניח שקיים מספור כלשהו של מכונות הטיורינג הקיימות, <span>\( M_{1},M_{2},M_{3}\dots \)</span> וכמובן שאכן יש כזה - אפשר למספר את כל המחרוזות בעולם, וכל מחרוזת מייצגת מכונת טיורינג כלשהי (גם למחרוזת שנראית כמו ג’יבריש ולא כמו קידוד “חוקי” של מכונת טיורינג אפשר לייחס מכונת טיורינג - למשל, לומר שכל מחרוזות הג’יבריש בעולם מייצגות מכונה שעוצרת מייד על כל קלט ומחזירה פלט 0). מכאן שבהינתן מספר <span>\( n \)</span> אפשר לדעת בקלות מהי <span>\( M_{n} \)</span>, ומעתה ואילך אניח שזה מובן מאליו.</p>

<p>כעת, נסמן ב-<span>\( M_{n}\left(k\right) \)</span> את הפלט של המכונה ה-<span>\( n \)</span>-ית על הקלט שהוא המספר <span>\( k \)</span>. בתיאוריה, הפלט הזה יהיה מספר; בפועל, אף אחד לא מבטיח לנו שהחישוב של <span>\( M_{n} \)</span> על <span>\( k \)</span> חייב להסתיים! זו הבעיה הבסיסית עם מכונות טיורינג וחישובים בכלל; החישוב מורכב ממספר שיכול להיות אינסופי של צעדים, ואם ננסה להגביל את מספר הצעדים שמותר למכונה לבצע, קרוב לוודאי שנצמצם משמעותית את כמות הבעיות שאנחנו יכולים לפתור (כמובן, לא <strong>עד כדי כך</strong> משמעותית; לרובן המוחץ של הבעיות שמתמודדים איתן במדעי המחשב אכן קיימים פתרונות-מוגבלי-צעדים שכאלו). על כל פנים, כשמריצים מכונת טיורינג תמיד קיימת הסכנה שהיא לא תעצור בכל, ואת המקרה הזה פנרוז מסמן ב-<span>\( M_{n}\left(k\right)=\square \)</span>.</p>

<p>האתגר החישובי שמכונות טיורינג לא מסוגלות להתמודד איתו הוא לדעת, בהינתן מכונה וקלט, האם היא עוצרת על הקלט או לא. פנרוז שואל האם קיימת מכונה <span>\( H \)</span> שעל זוג הקלטים <span>\( \left(n,k\right) \)</span> מחזירה 1 אם <span>\( M_{n} \)</span> עוצרת על <span>\( k \)</span>, ו-0 אם <span>\( M_{n} \)</span> לא עוצרת על <span>\( k \)</span> (כלומר, <span>\( M_{n}\left(k\right)=\square \)</span>). התשובה היא “לא” חד משמעי. הסיבה לכך היא שאם <span>\( H \)</span> כזו הייתה קיימת, היינו מנצלים אותה באופן הבא: בונים מכונה <span>\( Q \)</span> (זהו, אין יותר סימונים פרט לכך!) שעל קלט <span>\( n \)</span> עושה את הדבר הבא: מחשבת את <span>\( H\left(n,n\right) \)</span>; אם <span>\( H\left(n,n\right)=0 \)</span> אז <span>\( Q \)</span> פולטת 1; ואם <span>\( H\left(n,n\right)=1 \)</span> אז <span>\( Q \)</span> מחשבת את <span>\( M_{n}\left(n\right) \)</span> (מריצה את המכונה שמקודדת על ידי המספר <span>\( n \)</span>, על הקלט שהוא <span>\( n \)</span> עצמה) ועונה שונה ממנה - למשל, מוסיפה 1 לפלט. באנג! אתם רואים את הסתירה?</p>

<p>אה… כן, אני חייב להודות שבדרך הצגת הדברים הזו של פנרוז די מבלבל לראות את הסתירה. כאמור, יש הגיון כלשהו בגישה שלו, אבל אני חושב שהוא מסתבך יותר מדי. בואו בכל זאת נמשיך לרגע עד הסוף ונראה איך הוא מציג את הדברים. פנרוז מתאר את מה שקרה באמצעות המשוואה <span>\( Q\left(n\right)=1+M_{n}\left(n\right)\times H\left(n,n\right) \)</span>, מה שאכן נכון תחת המוסכמה ש-<span>\( \square\times0=0 \)</span> (זה ממדל את ה”אם <span>\( H\left(n,n\right)=0 \)</span> אז <span>\( Q \)</span> פולטת 1”). כעת טיעון המחץ שלו הוא שגם <span>\( Q \)</span> היא מכונת טיורינג חוקית, ולכן מקודדת על ידי מספר <span>\( k \)</span>. במילים אחרות, <span>\( Q=M_{k} \)</span>. כעת, איך <span>\( Q \)</span> מתנהגת על הקלט <span>\( k \)</span>? קיבלנו את המשוואה <span>\( M_{k}\left(k\right)=1+M_{k}\left(k\right)\times H\left(k,k\right) \)</span>, וקל לראות שהמשוואה הזו תמיד שגויה, בין אם <span>\( H\left(k,k\right)=1 \)</span> (ואז נקבל <span>\( M_{k}\left(k\right)=1+M_{k}\left(k\right) \)</span>) ובין אם <span>\( H\left(k,k\right)=0 \)</span> (ואז נקבל <span>\( \square=1+0 \)</span>). הגענו לסתירה, ולכן ההנחה שלנו ש-<span>\( H \)</span> אכן קיימת ויודעת להגיד לכל מכונה וקלט האם הם עוצרים או לא שגויה - סוף ההוכחה.</p>

<p>אני חושב שפנרוז מסתבך כאן הרבה יותר מדי עם המשוואות הללו. כאמור, אני מבין את הרצון שלו לדמות את כל העסק לאלכסון של קנטור (למרות שבשלב זה של הספר הוא טרם הציג את האלכסון של קנטור - עוד בעיה של הספר היא הסדר המבולבל שבו הוא מציג דברים) אבל לטעמי הוא מפספס קצת את לב הבעיה והורג קוראים. בואו ננסה להבין מה באמת הבעיה עם <span>\( Q \)</span> המדוברת. איך היא רצה על <span>\( k \)</span>? ובכן, זה תהליך דו שלבי. ראשית היא מחשבת את <span>\( H\left(k,k\right) \)</span> - לגיטימי לחלוטין. אם <span>\( H\left(k,k\right)=0 \)</span> אז היא פולטת מייד 1; ואילו אם <span>\( H\left(k,k\right)=1 \)</span> אז היא עוברת להריץ את <span>\( M_{k} \)</span> על הקלט <span>\( k \)</span>. אבל, כפי שאמרנו, <span>\( Q=M_{k} \)</span>. במילים אחרות, <span>\( Q \)</span> על הקלט <span>\( k \)</span> פונה להריץ את <strong>עצמה</strong> על הקלט <span>\( k \)</span>. <span>\( Q \)</span> על <span>\( k \)</span> מריצה את <span>\( Q \)</span> על <span>\( k \)</span>! מבינים את הבעיה? גם באותה ריצה פנימית של <span>\( Q \)</span> על <span>\( k \)</span> היא תתחיל להריץ את <span>\( Q \)</span> על <span>\( k \)</span>, וכן הלאה וכן הלאה עד סוף הדורות. כלומר, <span>\( Q \)</span> <strong>אינה עוצרת</strong> על <span>\( k \)</span>.</p>

<p>מה קיבלנו? אם <span>\( H\left(k,k\right)=0 \)</span>, כלומר <span>\( H \)</span> אומרת “<span>\( M_{k} \)</span> לא תעצור על <span>\( k \)</span>”, אז <span>\( Q \)</span> עוצרת מייד על <span>\( k \)</span> ובכך עושה צחוק מ-<span>\( H \)</span>; ואם <span>\( H\left(k,k\right)=1 \)</span>, כלומר <span>\( H \)</span> אומרת “<span>\( M_{k} \)</span> תעצור על <span>\( k \)</span>” אז <span>\( Q \)</span> נכנסת (בטעות!) ללולאה אינסופית ובכך שוב עושה צחוק מ-<span>\( H \)</span>. הבעיה היא בכלל לא בפלט של <span>\( Q \)</span>; הבעיה היא בכך ש-<span>\( Q \)</span> מתנהגת הפוך ממה ש-<span>\( H \)</span> מנבאת לה.</p>

<p>זה מוביל אותנו לאופן שבו בדרך כלל מנסחים את בעיית העצירה - בונים <span>\( Q \)</span> שעל קלט <span>\( n \)</span> מחשבת את <span>\( H\left(n,n\right) \)</span>; אם <span>\( H\left(n,n\right)=0 \)</span> אז <span>\( Q \)</span> עוצרת מייד, ואם <span>\( H\left(n,n\right)=1 \)</span> אז <span>\( Q \)</span> נכנסת ללולאה אינסופית. בפועל זו גם <strong>בדיוק </strong>הבניה של פנרוז, רק שהוא מעמיס עליה עוד פרטים מיותרים.</p>

<p>חדי העין מביניכם אולי שמים לב שגם בבניה ה”סטנדרטית” הזו יש משהו מיותר - אנחנו ממילא לא מתעניינים ביכולת של <span>\( H \)</span> לענות על קלטים <span>\( \left(n,k\right) \)</span> שבהם <span>\( n\ne k \)</span>; אפשר היה להראות שאפילו בעיה פחות שאפתנית מבעיית העצירה אינה ניתנת לפתרון - הבעיה “בהינתן <span>\( n \)</span>, האם <span>\( M_{n} \)</span> עוצרת על <span>\( n \)</span>?” ואכן, כשאני למדתי קורס בתורת החישוביות זו הייתה הבעיה הראשונה שאת אי הפתירות שלה הוכחנו (עם זאת, בהצגות פופולריות של הבעיה עדיין מעדיפים את הניסוח הכללי יותר של בעיית העצירה שכן הוא מרגיש “טבעי” יותר לקוראים; אבל פנרוז <strong>לא</strong> כותב הצגה פופולרית, הוא נכנס הרבה יותר מדי לפרטים טכניים).</p>

<p>אם כן, הראינו שמכונות טיורינג לא יודעות לפתור את בעיית העצירה. אם היינו יודעים שבני אדם <strong>כן</strong> יכולים לפתור את בעיית העצירה (כלומר, <strong>לכל</strong> זוג <span>\( \left(n,k\right) \)</span> לומר אם <span>\( M_{n} \)</span> עוצרת על <span>\( k \)</span> או לא) זה היה מוכיח מייד שבני אדם הם אכן יותר ממכונות טיורינג גם מבחינה חישובית טהורה. לרוע המזל, אנחנו לא יודעים שבני אדם יכולים לפתור את בעיית העצירה, ואני מאמין בכל לבי שהם לא. פנרוז מסתפק בטיעון הרבה יותר צנוע כדי לשכנע אותנו שבני אדם הם בכל זאת “קצת יותר” (בשלב זה של הספר; אני משער שבהמשך מגיעים טיעונים חזקים בהרבה). כאמור, הטיעון נשמע מאוד משכנע ממבט ראשון - אני ממליץ לכם לחשוב עליו קצת ולחפש בו בעיות.</p>

<p>פנרוז אומר - “אז נכון שראינו שבעיית העצירה לא פתירה, אבל בינתיים לא ממש ראינו אף מכונה <strong>ספציפית</strong> שאיננו יכולים לדעת אם היא עוצרת או לא; למעשה, השיטה שראינו קודם אומרת לנו במובלע האם המכונה שנבנית בה עוצרת או לא”. כדי להבהיר את המשפט הזה פנרוז מסתכל כעת על מכונה <span>\( H \)</span> ש<strong>מנסה</strong> לפתור את בעיית העצירה. הדרישה שלנו מ-<span>\( H \)</span> היא שהיא לא תטעה - אם <span>\( H \)</span> עוצרת על קלט <span>\( \left(n,k\right) \)</span> עם תשובה, התשובה חייבת להיות נכונה. מצד שני, אנחנו מרשים ל-<span>\( H \)</span> לא לעצור על חלק מהקלטים - אלו קלטים ש-<span>\( H \)</span> “נכשלת” עליהם. מכונות כאלו קיימות בודאות; הנה דוגמה לאחת כזו - <span>\( H \)</span> שעל קלט <span>\( n,k \)</span> מריצה את <span>\( M_{n} \)</span> על <span>\( k \)</span> ומחזירה 1 אם <span>\( M_{n} \)</span> עצרה. זו כמובן מכונה מטופשת למדי (היא לא עונה 0 אף פעם) אבל היא מתאימה לגמרי להגדרה שלנו. בנוסף, כמובן שאפשר לחשוב על שיפורים פשוטים ל-<span>\( H \)</span> שיאפשרו לה לגלות לפעמים אם <span>\( M_{n} \)</span> לא עוצרת על <span>\( k \)</span> (שיפורים כאלו כבר תלויים בהגדרה המדוייקת של מכונת טיורינג והאופן שבו היא מבצעת חישובים - אתם לא חייבים לשבור את הראש בחיפוש אחריהם).</p>

<p>כעת פנרוז טוען שבהינתן <span>\( H \)</span> כזה, אנחנו מסוגלים למצוא מכונה <span>\( M_{k} \)</span> כך ש-<span>\( H \)</span> נכשל ולא עוצר על <span>\( \left(k,k\right) \)</span> אבל אנחנו יודעים את התשובה הנכונה על <span>\( \left(k,k\right) \)</span>. הבניה היא בדיוק אותה בניה כמו קודם - בונים מכונה <span>\( Q \)</span> שמחשבת את <span>\( Q\left(n\right)=1+M_{n}\left(n\right)\times H\left(n,n\right) \)</span>. וכמו קודם, <span>\( Q \)</span> היא חוקית לחלוטין ולכן <span>\( Q=M_{k} \)</span> עבור <span>\( k \)</span> מסויים; וכמו קודם, אם <span>\( H\left(k,k\right)=0 \)</span> או <span>\( H\left(k,k\right)=1 \)</span> המשוואה <span>\( M_{k}\left(k\right)=1+M_{k}\left(k\right)\times H\left(k,k\right) \)</span> מובילה לסתירה ולכן לא ייתכן שהמקרים הללו מתרחשים; אבל לא הגענו לסתירה במתמטיקה כי כעת ייתכן גם ש-<span>\( H\left(k,k\right)=\square \)</span> ואז נקבל משוואה מהצורה <span>\( \square=\square \)</span> שהיא בסדר. במילים - הדבר היחיד שיכול לקרות הוא ש-<span>\( H \)</span> כלל לא תעצור על <span>\( \left(k,k\right) \)</span>, ולכן גם <span>\( Q \)</span>, שמריצה אותה, לא תעצור על <span>\( k \)</span>. כלומר, <span>\( H \)</span> נכשלת בנסיון שלה לדעת אם <span>\( Q \)</span> עוצרת על <span>\( k \)</span>, אבל אנחנו כן יודעים זאת - אנחנו יודעים בודאות ש-<span>\( Q \)</span> אינה עוצרת על <span>\( k \)</span>. זה מראה שאנחנו יותר טובים מ-<span>\( H \)</span> - כי כל דבר ש-<span>\( H \)</span> יכולה לדעת גם אנחנו יכולים (כי נסמלץ את הריצה של <span>\( H \)</span> - אפשר לעשות זאת עם נייר ועט וסבלנות), ובנוסף אנחנו יודעים משהו ש-<span>\( H \)</span> לא יכולה לדעת.</p>

<p>ועכשיו, ברשותכם, נזרוק את המתמטיקה לפח ונעבור לתמהיל מוזר של פילוסופיה ומתמטיקה. זו ארץ לא נודעת בשבילי ולכן הקוראים הזועמים מוזמנים לקרוע אותי בתגובות. שורש העניין שעליו צריך לדבר כאן הוא המושג של “לדעת”, שאינו מוגדר מתמטית (בשלב זה של הספר; אני חושב שבספר ההמשך פנרוז מנסה לתת הגדרה כלשהי), ולדעתי לא ניתן להגדיר אותו בצורה מיישבת דעת שעדיין מאפשרת לאדם לנצח את המכונה. אני חושב שמה שפנרוז עושה בתעלול שהצגתי זה עתה, באמצעות המניפולציה הזו של המילה “לדעת”, משהו ששקול לכל דבר ועניין לאמירה “אם האדם אינו מכונת טיורינג, אז האדם אינו מכונת טיורינג”. וכעת אסביר.</p>

<p>פנרוז מצביע בעצמו על כך שהתהליך שבו הפקנו מ-<span>\( H \)</span> את <span>\( Q \)</span> היה <strong>אלגוריתמי</strong>. כלומר, יש אלגוריתם שבהינתן הקידוד של המכונה <span>\( H \)</span> פולט את הקידוד של המכונה <span>\( Q \)</span> שעבורה <span>\( H \)</span> “לא יודעת” את התשובה, ואילו אנחנו בני האדם כן יודעים. פנרוז גם מתייחס לכך שהאלגוריתם הזה יכול בעצמו “לשפר את <span>\( H \)</span>” על ידי כך שהוא ידע לענות פרטנית ש-<span>\( Q \)</span> אינה עוצרת. רק מה, פנרוז גם ממשיך ואומר שגם את האלגוריתם המשופר הזה אפשר לתקוף באותה דרך וכן הלאה. זה סוף ההתייחסות של פנרוז לעניין בפרק זה של הספר. אני חושב שכדאי להביא את הדברים בשם אומרם כדי להסתכן כמה שפחות בהוצאה מהקשר:</p>
<blockquote>
<p dir="ltr">In fact the procedure is so well defined that we could find an algorithm for generating k, given H. So, before we get too complacent, we have to realize that this algorithm can improve on H since, in effect, it 'knows' that <span>\( M_{k}\left(k\right)=\square \)</span> — or does it? It has been helpful in the above description to use the anthropomorphic term 'know' in reference to an algorithm. However, is it not we who are doing the 'knowing', while the algorithm just follows the rules we have told it to follow? Or are we ourselves merely following rules that we have been programmed to follow from the construction of our brains and from our environment? The issue is not really simply one of algorithms, but also question of how judges what is true and what is not true.</p>
</blockquote>
<p>אני לא יכול לומר שאני מבין עד הסוף את מה שפנרוז אומר כאן על “לדעת”, וזה נראה לי כמו התחמקות. אבל זה לא חשוב; פנרוז מפספס משום מה את הבעיה העיקרית כאן - גם <span>\( H \)</span> יכולה “לדעת” ש-<span>\( Q \)</span> לא עוצרת; היא פשוט לא יכולה <strong>להגיד את זה</strong>.</p>

<p>האס שאני שולף מהשרוול כאן (ואני <strong>בטוח</strong> שפנרוז מכיר אותו - פנרוז מפגין בקיאות רבה בחומר שהוא כותב עליו; לכן חורה לי שהוא בכלל לא מתייחס לזה) הוא מה שנקרא “משפט הרקורסיה של קלייני”, שתיארתי כבר (לא בשם זה) ב<a href="http://www.gadial.net/2009/11/27/quine_and_recursion_theorem/">פוסט</a> בעבר. משפט הרקורסיה הוא תוצאה אלגנטית ויפהפיה, שמראה שכאשר בונים מכונת טיורינג, אפשר להניח שהיא יודעת את הקידוד שלה עצמה; היא מסוגלת איכשהו לבצע בתחילת הריצה שלה חישוב ולייצר את הקידוד הזה יש מאין - “נס” מתמטי שכזה, שכמובן מעוגן היטב במציאות (לא קשה לכתוב בפועל תוכניות מחשב שמבצעות את הנס הזה). מכיוון שפנרוז מנסה לתקוף <strong>כל</strong> <span>\( H \)</span> שמנסה לפתור את בעיית העצירה, בפרט הוא צריך לתקוף גם <span>\( H \)</span> כזו שכחלק ממה שהיא עושה היא מחשבת את <span>\( Q \)</span> מתוך הקידוד שלה עצמה, ואז בודקת האם <span>\( Q=M_{n} \)</span>, כאשר <span>\( \left(n,n\right) \)</span> הוא הקלט שלה. אם התשובה חיובית, אז <span>\( H \)</span> <strong>יודעת</strong> שהקלט שהיא מטפלת בו כרגע הוא מה שאכנה “הנודניק של פנרוז”. היא יודעת שהקלט הנוכחי היא מכונה שמנסה להכשיל אותה. ו-<span>\( H \)</span>, גיבורה טרגית אמיתית, גם יודעת שאין לה שום דרך לענות נכון על הקלט <span>\( n \)</span>; אם <span>\( H \)</span> תענה 1 (“המכונה <span>\( M_{n} \)</span> עוצרת על <span>\( n \)</span>”) אז אותה <span>\( M_{n} \)</span> זדונית לא תעצור על <span>\( n \)</span>; ואם היא תענה 0, אז <span>\( M_{n} \)</span> המרשעת כן תעצור על <span>\( n \)</span>. הנקודה המהותית כאן היא שהפרדוקסליות לא נובעת ממה ש-<span>\( H \)</span> <strong>יודעת</strong> אלא ממה ש-<span>\( H \)</span> <strong>אומרת</strong>: <span>\( Q \)</span> לוקחת את התשובה של <span>\( H \)</span> ועושה ממנה חוכא ואיטלולא. זה לא אומר ש-<span>\( H \)</span> לא מבינה מראש שזה מה שהולך לקרות. אם <span>\( H \)</span> תענה תשובה כלשהי, <span>\( Q \)</span> תגרום לתשובה הזו להיות שקר, ולכן <span>\( H \)</span> חייבת לא לעצור, ובכך לגרום גם ל-<span>\( Q \)</span> לא לעצור. וכאשר <span>\( H \)</span> תרוץ ותרוץ עוד ועוד אל הנצח, היא תדע כל הזמן שהקלט הנוכחי שלה לא הולך לעצור. היא פשוט לא תוכל לעצור ולהגיד את זה.</p>

<p>אם כן, אם אנחנו מבצעים הפרדה פילוסופית בין “מה שהמכונה יודעת” ובין “מה שהמכונה אומרת”, אין ספק שהדוגמה של פנרוז קורסת לחלוטין. אנחנו בני האדם, חד משמעית, <strong>לא</strong> יודעים יותר מאשר המכונה <span>\( H \)</span>. אבל, האם פנרוז מרשה את זה? נניח שלא. נניח שהמכונה <strong>חייבת</strong> לומר את מה שהיא חושבת כדי שנדע שהיא חושבת אותו; במקרה זה אכן <span>\( H \)</span> “לא יודעת” ש-<span>\( Q \)</span> לא תעצור, אבל אנחנו כן. במילותיו של פנרוז:</p>
<blockquote>
<p dir="ltr">Let us see how this comes about. Suppose we have some algorithm which is sometimes effective for telling us when a Turing machine will not stop. Turing's procedure, as outlined above, will explicitly exhibit a Turing machine calculation for which that particular algorithm is not able to decide whether or not the calculation stops. However, in doing so, it actually enables us to see the answer in this case! The particular Turing machine calculation that we exhibit will indeed not stop.</p>
</blockquote>
<p>וכאן אנחנו מגיעים לנקודה המרכזית, ה”שקר” שאני רואה אצל פנרוז. המשחק שהוא דורש שנשחק כאן הוא לא הוגן - הוא דורש מהמכונה “להכריע” (Decide) האם החישוב עוצר או לא, כש”הכרעה” שכזו חייבת לבוא לידי ביטוי בסיום החישוב והוצאת פלט; אבל מבני האדם הוא דורש רק שהם “יראו” (See) האם התשובה נכונה או לא. בשום מקום הוא לא דורש מבני האדם להשתתף באותו מבחן כמו המכונות ולטרוח לכתוב את התשובה על דף!</p>

<p>ומה יקרה אם בני האדם יחוייבו להשתתף במשחק? אם הם יחוייבו לכתוב על דף, או לומר בקול, או משהו, את מה שהם “רואים”? כמובן, הם יפסידו מייד; כי אז נבנה מכונה <span>\( Q \)</span> באותו אופן כמו קודם, רק שבמקום להריץ את <span>\( H \)</span> על <span>\( \left(n,n\right) \)</span> המכונה <span>\( Q \)</span> תשאל את האדם “תגיד, מה יש לך לומר על <span>\( \left(n,n\right) \)</span>?” והאדם יהיה באותה בעיה שבה <span>\( H \)</span> הייתה קודם - אם הוא מזהה ש-<span>\( M_{n}=Q \)</span> הוא יודע בודאות ש-<span>\( M_{n} \)</span> מנסה להכשיל אותו, אבל <strong>הוא לא יכול להגיד זאת</strong>. הוא יהיה חייב לשתוק לנצח, ואז רובוט-פנרוז יכתוב עליו בספר “The Emperor’s New Algorithm”, תחת הכותרת “How to outdo a human’’. בעסה לאדם.</p>

<p>בפסקה הקודמת אני טיפה מרמה, כי הרעיון הוא ש-<span>\( Q \)</span> תוכל להסתדר בעצמה, בלי אדם בכלל - שהיא תוכל <strong>לסמלץ</strong> את האדם במובן זה שהיא תדע מה הפלט שהוא יוציא לכל קלט שהיא נותנת. אם זה לא נכון, כמובן שהאדם חזק מהמכונה - אבל זו תהיה בדיוק הנחת המבוקש של פנרוז; מה שקראתי לו קודם “אם האדם חזק מהמכונה, אז האדם חזק מהמכונה”. כל עוד האדם אינו חזק <strong>חישובית</strong> מהמכונה - כלומר, כל עוד לכל קלט שנותנים לאדם, גם המכונה יכולה לדעת מה יהיה הפלט, אז גם היתרון של ה”ידיעה” שפנרוז מנסה להצביע עליו לא קיים, כי המכונה יכולה “לדעת” דברים שהאדם לא יכול לומר במפורש.</p>

<p>השורה התחתונה פשוטה - פנרוז מראש מארגן משחק מכור של אדם-נגד-מכונה, ותובע מהאדם הרבה פחות; פלא שהאדם מנצח? כמובן, ייתכן שבהמשך פנרוז מתייחס בהרחבה לכל הנקודות הללו ומציע משחק יותר הוגן; אבל אין לכך שום רמז בחלק שבו הוא מציג את הטיעון לראשונה. הקוראים מוזמנים לתקן אותי אם אני מפספס משהו.</p>

<p>אני חושב שכל העניין הזה מצביע יפה על הבעייתיות הגדולה שבנסיון להסיק מסקנות פילוסופיות מתוצאות מתמטיות. המעבר ממתמטיקה - מוגדרת היטב, חד משמעית, מדויקת - לפילוסופיה, שהיא הרבה יותר מילולית ומסתמכת על אינטואיציות שלנו - הוא מאוד מסוכן. אפשר “להחביא” בתוך המעבר הזה (ואפילו בטעות) מעין רמאויות שהופכות את כל התוצאות המתמטיות המדוייקות לחסרות משמעות. שימו לב לכך בפעם הבאה שמישהו ישכנע אתכם בטיעון פילוסופי כלשהו באמצעות מתמטיקה.</p>

  </div>

  <hr />
  <p>
    נהניתם? התעניינתם? אם תרצו, אתם מוזמנים לתת טיפ:
  </p>
  <a href='https://ko-fi.com/H2H5XFBQ' target='_blank'><img height='36' style='border:0px;height:36px;' src='https://az743702.vo.msecnd.net/cdn/kofi2.png?v=2' border='0' alt='Buy Me a Coffee at ko-fi.com' /></a><div class="PageNavigation">
    
      <a class="prev" href="/2011/04/12/gelfond_schneider_theorem/">&laquo; הוכחה לא קונסטרוקטיבית לכך שרציונלי זה טרנסצנדנטי (טוב, לא בדיוק...)</a>
    
    
      <a class="next" href="/2011/04/23/against_penrose_emperor_2/">המותר האדם מן האלגוריתם, חלק 2 - הנקמה? &raquo;</a>
    
  </div><div id="disqus_thread"></div>
  <script>
    var disqus_config = function () {
      this.page.url = 'http://gadial.net/2011/04/21/against_penrose_emperor_1/';
      this.page.identifier = 'http://gadial.net/2011/04/21/against_penrose_emperor_1/';
    };

    (function() {
      var d = document, s = d.createElement('script');

      s.src = 'https://not-precise.disqus.com/embed.js';

      s.setAttribute('data-timestamp', +new Date());
      (d.head || d.body).appendChild(s);
    })();
  </script>
  <noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript" rel="nofollow">comments powered by Disqus.</a></noscript><a class="u-url" href="/2011/04/21/against_penrose_emperor_1/" hidden></a>
</article>

      </div>
    </main><footer class="site-footer h-card">
  <data class="u-url" href="/"></data>

  <div class="wrapper">

    <h2 class="footer-heading">לא מדויק</h2>

    <div class="footer-col-wrapper">
      <div class="footer-col footer-col-1">
        <ul class="contact-list">
          <li class="p-name">לא מדויק</li><li><a class="u-email" href="mailto:gadial@gmail.com">gadial@gmail.com</a></li><li>&copy; כל הזכויות שמורות לגדי אלכסנדרוביץ'</li>
        </ul>
      </div>

      <div class="footer-col footer-col-2"><ul class="social-media-list"><li><a href="https://www.facebook.com/%D7%9C%D7%90-%D7%9E%D7%93%D7%95%D7%99%D7%A7-163347110378474"><svg class="svg-icon"><use xlink:href="/assets/minima-social-icons.svg#facebook"></use></svg> <span class="username">לא מדויק</span></a></li><li><a href="/feed.xml"><svg class="svg-icon"><use xlink:href="/assets/minima-social-icons.svg#rss"></use></svg> <span>RSS</span></a></li></ul>
</div>

      <div class="footer-col footer-col-3">
        <p>בלוג על מתמטיקה ומדעי המחשב</p>
      </div>
    </div>

  </div>

</footer><script src="https://code.jquery.com/jquery-3.3.1.slim.min.js" integrity="sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo" crossorigin="anonymous"></script>
<script>window.jQuery || document.write('<script src="assets/js/jquery-slim.min.js"><\/script>')</script><script src="/assets/js/bootstrap.bundle.js"></script><!-- Default Statcounter code for New blog
http://www.gadial.net/ -->
<script type="text/javascript">
  var sc_project=5444342; 
  var sc_invisible=1; 
  var sc_security="4a89cbe4"; 
  </script>
  <script type="text/javascript"
  src="https://www.statcounter.com/counter/counter.js"
  async></script>
  <noscript><div class="statcounter"><a title="Web Analytics"
  href="https://statcounter.com/" target="_blank"><img
  class="statcounter"
  src="https://c.statcounter.com/5444342/0/4a89cbe4/1/"
  alt="Web Analytics"></a></div></noscript>
  <!-- End of Statcounter Code --></body>

</html>
