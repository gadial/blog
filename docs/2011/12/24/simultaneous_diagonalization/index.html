<!DOCTYPE html>
<html lang="he" dir="rtl">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>להטיל לכסון סימולטני בתת-מרחב שמור, בערך - לא מדויק</title>
    <link rel="icon" type="image/x-icon" href="/favicon.ico">
    
    
    <!-- KaTeX for math rendering -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css">
    <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js"></script>
    <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js"></script>

    
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }
        
        body {
            font-family: 'Arial', 'David', 'Tahoma', sans-serif;
            line-height: 1.6;
            color: #333;
            background-color: #f5f5f5;
        }
        
        /* Top navigation bar */
        .top-nav {
            background: #2c3e50;
            padding: 15px 20px;
            box-shadow: 0 2px 5px rgba(0,0,0,0.1);
        }
        
        .top-nav .nav-container {
            max-width: 1200px;
            margin: 0 auto;
            display: flex;
            align-items: center;
            justify-content: space-between;
            gap: 20px;
        }
        
        .top-nav .site-title {
            font-size: 1.5em;
            font-weight: bold;
            color: white;
            text-decoration: none;
            white-space: nowrap;
        }
        
        .top-nav .nav-links {
            display: flex;
            gap: 20px;
            align-items: center;
            flex-wrap: wrap;
        }
        
        .top-nav .nav-links a {
            color: #ecf0f1;
            text-decoration: none;
            padding: 5px 10px;
            border-radius: 4px;
            transition: background 0.2s;
            white-space: nowrap;
        }
        
        .top-nav .nav-links a:hover {
            background: #34495e;
        }
        
        .top-nav .search-box {
            display: flex;
            gap: 5px;
        }
        
        .top-nav .search-box input {
            padding: 5px 10px;
            border: none;
            border-radius: 4px;
            font-size: 0.9em;
            min-width: 150px;
        }
        
        .top-nav .search-box button {
            padding: 5px 15px;
            background: #3498db;
            color: white;
            border: none;
            border-radius: 4px;
            cursor: pointer;
            transition: background 0.2s;
        }
        
        .top-nav .search-box button:hover {
            background: #2980b9;
        }
        
        /* Blockquote styling */
        blockquote {
            background: #f9f9f9;
            border-right: 5px solid #ccc;
            margin: 1.5em 10px;
            padding: 0.75em 16px;
            position: relative;
            font-style: italic;
        }
        
        blockquote:before {
            content: '"';
            position: absolute;
            top: -10px;
            right: 8px;
            font-size: 3.5em;
            color: #ccc;
            line-height: 1;
        }
        
        blockquote p {
            display: block;
            margin: 0 0 0.75em 0;
        }
        
        blockquote p:last-child {
            margin-bottom: 0;
        }
        
        
        body {
            line-height: 1.8;
        }
        
        .container {
            max-width: 800px;
            margin: 20px auto;
            background: white;
            padding: 40px;
            box-shadow: 0 2px 10px rgba(0,0,0,0.1);
            border-radius: 8px;
        }
        
        header {
            margin-bottom: 40px;
            border-bottom: 2px solid #e0e0e0;
            padding-bottom: 20px;
        }
        
        h1 {
            font-size: 2.5em;
            margin-bottom: 10px;
            color: #2c3e50;
        }
        
        .post-meta {
            color: #7f8c8d;
            font-size: 0.9em;
        }
        
        .post-meta .date {
            margin-left: 15px;
        }
        
        .post-meta .categories,
        .post-meta .tags {
            display: inline;
        }
        
        .post-meta .categories a,
        .post-meta .tags a {
            color: #3498db;
            text-decoration: none;
            margin: 0 5px;
        }
        
        .post-meta .categories a:hover,
        .post-meta .tags a:hover {
            text-decoration: underline;
        }
        
        article {
            font-size: 1.1em;
        }
        
        article h2 {
            margin-top: 30px;
            margin-bottom: 15px;
            color: #34495e;
            font-size: 1.8em;
        }
        
        article h3 {
            margin-top: 25px;
            margin-bottom: 12px;
            color: #34495e;
            font-size: 1.4em;
        }
        
        article p {
            margin-bottom: 15px;
            text-align: justify;
        }
        
        article ul, article ol {
            margin-right: 30px;
            margin-bottom: 15px;
        }
        
        article li {
            margin-bottom: 8px;
        }
        
        article code {
            background-color: #f4f4f4;
            padding: 2px 6px;
            border-radius: 3px;
            font-family: 'Courier New', monospace;
            font-size: 0.9em;
        }
        
        article pre {
            background-color: #2d2d2d;
            color: #f8f8f2;
            padding: 15px;
            border-radius: 5px;
            overflow-x: auto;
            margin-bottom: 20px;
            direction: ltr;
            text-align: left;
        }
        
        article pre code {
            background-color: transparent;
            padding: 0;
            color: inherit;
        }
        
        /* Image styles - responsive and contained */
        article img {
            max-width: 100%;
            height: auto;
            display: block;
            margin: 20px auto;
        }
        
        /* Math rendering styles */
        .math {
            direction: ltr;
        }
        
        span.math {
            direction: ltr;
        }
        
        /* Override RTL for KaTeX */
        .katex {
            direction: ltr;
            unicode-bidi: embed;
        }
        
        div.math {
            display: block;
            text-align: center;
            padding: 15px 0;
            direction: ltr;
        }
        
        /* RTL adjustments for code blocks */
        .highlight {
            direction: ltr;
            text-align: left;
        }
        
        footer {
            margin-top: 60px;
            padding-top: 20px;
            border-top: 1px solid #e0e0e0;
            text-align: center;
            color: #95a5a6;
            font-size: 0.9em;
        }
        
        /* Responsive design */
        @media (max-width: 768px) {
            .container {
                padding: 20px;
            }
            
            h1 {
                font-size: 2em;
            }
            
            article {
                font-size: 1em;
            }
        }
        
        /* Post navigation */
        .post-navigation {
            display: flex;
            justify-content: space-between;
            margin-bottom: 30px;
            padding-bottom: 20px;
            border-bottom: 2px solid #e0e0e0;
            gap: 20px;
        }
        
        .post-navigation .nav-link {
            flex: 1;
            text-decoration: none;
            color: #2c3e50;
            padding: 15px;
            background: #f8f9fa;
            border-radius: 5px;
            transition: background 0.2s;
        }
        
        .post-navigation .nav-link:hover {
            background: #e9ecef;
        }
        
        .post-navigation .nav-prev {
            text-align: right;
        }
        
        .post-navigation .nav-next {
            text-align: left;
        }
        
        .post-navigation .nav-label {
            font-size: 0.85em;
            color: #7f8c8d;
            display: block;
            margin-bottom: 5px;
        }
        
        .post-navigation .nav-title {
            font-weight: bold;
            font-size: 1.1em;
        }

    </style>
</head>
<body>
    <nav class="top-nav">
        <div class="nav-container">
            <a href="/" class="site-title">לא מדויק</a>
            <div class="nav-links">
                <a href="/">דף הבית</a>
                <a href="/random.html">פוסט אקראי</a>
                <a href="/post_list.html">כל הפוסטים</a>
                <div class="search-box">
                    <input type="text" id="searchInput" placeholder="חיפוש...">
                    <button onclick="searchPosts()">חפש</button>
                </div>
            </div>
        </div>
    </nav>
    
    
    <div class="container">
        <!-- Post Navigation -->
        
        <nav class="post-navigation">
            
            <a href="/2011/12/11/gauss_circle_problem/" class="nav-link nav-prev">
                <span class="nav-label">פוסט ישן יותר →</span>
                <span class="nav-title">בעיית המעגל של גאוס (וגם קצת על טרחנות)</span>
            </a>
            

            
            <a href="/2011/12/31/inclusion_exclusion_principle/" class="nav-link nav-next">
                <span class="nav-label">← פוסט חדש יותר</span>
                <span class="nav-title">עקרון ההכלה וההפרדה, ואז הכללה והפחדה</span>
            </a>
            
        </nav>
        
        
        <header>
            <h1>להטיל לכסון סימולטני בתת-מרחב שמור, בערך</h1>
            <div class="post-meta">
                <span class="date">2011-12-24</span>
                
                <span class="categories">
                    | קטגוריות:
                    
                    <a href="/categories/אלגברה לינארית.html">אלגברה לינארית</a>
                    
                </span>
                
                
                <span class="tags">
                    | תגיות:
                    
                    <a href="/tags/אלגברה לינארית.html">אלגברה לינארית</a>
                    
                    <a href="/tags/הטלות.html">הטלות</a>
                    
                    <a href="/tags/לכסון סימולטני.html">לכסון סימולטני</a>
                    
                    <a href="/tags/פולינום מינימלי.html">פולינום מינימלי</a>
                    
                    <a href="/tags/תת מרחב שמור.html">תת מרחב שמור</a>
                    
                </span>
                
            </div>
        </header>
        
        <article>
            <h2><strong>תת-מרחבים שמורים</strong></h2>
<p>כזכור, בסדרת הפוסטים על אלגברה לינארית הגענו להתעסק בשאלה הבאה: נתונה טרנספורמציה לינארית <span class="math">\(T:V\to V\)</span> ואנו רוצים למצוא בסיס שבו המטריצה שמייצגת את <span class="math">\(T\)</span> היא פשוטה. המקרה הטוב ביותר כבר טופל: ראינו כי <span class="math">\(T\)</span> מיוצגת בידי מטריצה אלכסונית אם ורק אם יש ל-<span class="math">\(V\)</span> בסיס שכולו מורכב מוקטורים עצמיים של <span class="math">\(T\)</span>. אני רוצה להתחיל בלהיזכר מה הלך בהוכחה הזו.</p>
<p>מה שעשינו היה להראות שוקטורים עצמיים השייכים לערכים עצמיים שונים הם בלתי תלויים לינארית, במובן זה שאם <span class="math">\(v_{1}+\dots+v_{k}=0\)</span> כשכל <span class="math">\(v_{i}\)</span> הוא וקטור המקיים <span class="math">\(T\left(v_{i}\right)=\lambda_{i}v_{i}\)</span> עבור <span class="math">\(\lambda_{i}\)</span>-ים שונים כולם, אז <span class="math">\(v_{1}=\dots=v_{k}=0\)</span>. ואז בא איזה שלב מזוויע שבו כתבתי צירוף לינארי של אוספי וקטורים שכל אחד מהם הוא בסיס לתת-מרחב עצמי אחר... אבל בעצם, עם קצת יותר סימונים והגדרות, אפשר היה לעשות את זה טיפה פחות מזוויע.</p>
<p>את מה שעשינו אפשר היה לנסח גם כך: לכל ערך עצמי <span class="math">\(\lambda_{i}\)</span> הגדרנו תת-מרחב <span class="math">\(U_{i}\subseteq V\)</span> - "המרחב העצמי של <span class="math">\(\lambda_{i}\)</span>" - של כל הוקטורים המקיימים <span class="math">\(T\left(v\right)=\lambda_{i}v\)</span> (כל הוקטורים העצמיים של <span class="math">\(\lambda_{i}\)</span> בתוספת וקטור האפס), ואז ראינו שמתקיים <span class="math">\(V=U_{1}\oplus\dots\oplus U_{k}\)</span>, כאשר <span class="math">\(U_{1},\dots,U_{k}\)</span> הם כל המרחבים העצמיים של הערכים העצמיים של <span class="math">\(T\)</span>. תזכורת: להגיד ש-<span class="math">\(V=U_{1}\oplus\dots\oplus U_{k}\)</span> ("<span class="math">\(V\)</span> הוא סכום ישר של <span class="math">\(U_{1},\dots,U{}_{k}\)</span>") אומר שכל איבר ב-<span class="math">\(V\)</span> ניתן לכתיבה כסכום <span class="math">\(v_{1}+\dots+v_{k}\)</span> של איברים מ-<span class="math">\(U_{1},\dots,U_{k}\)</span>, ושכל המרחבים הללו זרים זה לזה, במובן זה שאם ניקח ולו אחד מהם ונוריד אותו מהסכום, אז לו וליתר הסכום לא יהיה איבר משותף השונה מ-0 (פורמלית <span class="math">\(U_{i}\cap\left(U_{1}+\dots+U_{i-1}+U_{i+1}+\dots+U_{k}\right)=\left\{ 0\right\} \)</span>; אולי טבעי יותר לדרוש ש-<span class="math">\(U_{i}\cap U_{j}=\left\{ 0\right\} \)</span> וחסל אבל זו לא דרישה חזקה מספיק). זה תרגיל טוב להוכיח שהדרישה השניה שקולה לכך שדרך ההצגה של איבר ב-<span class="math">\(V\)</span> כסכום איברים מתתי-המרחבים תהיה <strong>יחידה</strong>.</p>
<p>עכשיו, לכתוב את <span class="math">\(V\)</span> כסכום ישר של תתי-מרחבים כלשהם זה דבר קל למדי - קחו כל בסיס שתרצו, חלקו את אברי הבסיס לכמה קבוצות שתרצו, ותת-המרחבים שנפרסים על ידי אברי הקבוצות (כל תת-מרחב נפרס על ידי אברי קבוצה אחת) יהוו סכום ישר שנותן את <span class="math">\(V\)</span>. יש אינספור דרכים לפרק את <span class="math">\(V\)</span> כך, ורובן לא אומרות לנו משהו מועיל על הטרנספורמציה הלינארית <span class="math">\(T\)</span>. העסק מתחיל להיות מעניין כאשר יש לנו תת-מרחב <span class="math">\(W\)</span> שמקיים את התכונה "כל מה שקורה ב-<span class="math">\(W\)</span> (על ידי <span class="math">\(T\)</span>) נשאר ב-<span class="math">\(W\)</span>", ופורמלית <span class="math">\(T\left(W\right)\subseteq W\)</span> (התמונה של כל איבר ב-<span class="math">\(W\)</span> על ידי <span class="math">\(T\)</span> נמצאת גם היא ב-<span class="math">\(W\)</span>). תת-מרחב כזה נקרא <strong>תת-מרחב שמור</strong> (ביחס ל-<span class="math">\(T\)</span>).</p>
<p>מכיוון שבמבט ראשון אולי לא ברור למה זו הגדרה מעניינת, בואו ונבין ראשית כל מה ינבע מכך שאני יודע לכתוב את <span class="math">\(V\)</span> בתור סכום ישר <span class="math">\(U\oplus W\)</span> כאשר <span class="math">\(U,W\)</span> שניהם תתי-מרחבים שמורים של <span class="math">\(T\)</span>. ניקח בסיס ל-<span class="math">\(U\)</span> ובסיס ל-<span class="math">\(W\)</span> ואז איחודם הוא בסיס ל-<span class="math">\(V\)</span> ואפשר להסתכל על המטריצה המיצגת של <span class="math">\(T\)</span> בבסיס הזה. אז אני טוען שהמטריצה המייצגת תורכב משני <strong>בלוקים</strong> - תת-מטריצות ריבועיות מסויימות, כך שכל שאר המטריצה שווה לאפס. משהו כזה: <span class="math">\(\left[T\right]_{V}=\left[\begin{array}{cc}\left[T\right]_{U} &amp; 0\\0 &amp; \left[T\right]_{W}\end{array}\right]\)</span> (כאן אני מתעלל בסימונים בצורה נוראית - <span class="math">\(\left[T\right]_{V}\)</span> כאן פירושו "המטריצה המייצגת של <span class="math">\(T\)</span> בבסיס שזה עתה דיברתי עליו של <span class="math">\(V\)</span>; באופן כללי אין לסימון <span class="math">\(\left[T\right]_{V}\)</span> משמעות כי לכל בסיס של <span class="math">\(V\)</span> שניקח נקבל מטריצה מייצגת אחרת). שימו לב ששני הבלוקים של המטריצה אינם כוללים תוכן מקרי, אלא את המטריצה המייצגת של <span class="math">\(T\)</span> לפי הבסיסים של תתי-המרחבים. הסיבה שבגללה זה עובד היא שאם נפעיל את <span class="math">\(T\)</span> על איבר בסיס של <span class="math">\(U\)</span> נקבל איבר ב-<span class="math">\(U\)</span> ולכן הוא יוצג כצירוף לינארי של אברי <span class="math">\(U\)</span> בלבד; אברי <span class="math">\(W\)</span> לא משתתפים בכלל במשחק. לכן על עמודה שמתאימה לאיבר בסיס של <span class="math">\(U\)</span> מכילה אפסים בשורות שמתאימות לבסיס של <span class="math">\(W\)</span>, ואותו הדבר גם עבור העמודות שמתאימות לאברי בסיס של <span class="math">\(W\)</span>. אותיר לכם לכתוב את ההוכחה הפורמלית לעצמכם אם אתם עוד לא משוכנעים.</p>
<p>מכאן ממשיכים באינדוקציה ומקבלים את התוצאה הכללית: אם <span class="math">\(V=V_{1}\oplus\dots\oplus V_{k}\)</span> כך ש-<span class="math">\(V_{i}\)</span> הם תתי-מרחבים שמורים של <span class="math">\(T\)</span>, אז כאשר מייצגים את <span class="math">\(T\)</span> בבסיס שהוא איחוד הבסיסים של אותם תת-מרחבים, <span class="math">\(T\)</span> היא מטריצה בת <span class="math">\(k\)</span> בלוקים. מה שמעניין אותנו עכשיו הוא אם אפשר להגיד עוד משהו על האופן שבו <span class="math">\(T\)</span> מתפרקת בין כל תתי-המרחבים השמורים, וכמובן לשאול את עצמנו האם פירוק כזה קיים בכלל.</p>
<p>תתי-מרחבים שמורים הם הכללה ברורה של מרחבים עצמיים. אם <span class="math">\(U\)</span> הוא מרחב עצמי של טרנספורמציה <span class="math">\(T\)</span> הוא בוודאי יהיה תת-מרחב שמור שלה, כי כל מה שהפעלת <span class="math">\(T\)</span> על איבר ב-<span class="math">\(U\)</span> עושה היא לכפול אותו בסקלר, וזו פעולה שמשאירה את התוצאה בתוך התת-מרחב מעצם הההגדרה של תת-מרחב. למעשה, אם <span class="math">\(v\)</span> הוא וקטור עצמי אז תת-המרחב שנפרש על ידו בלבד הוא תת-מרחב שמור. זה מבהיר לנו מייד מדוע אם יש למרחב בסיס של וקטורים עצמיים אז <span class="math">\(T\)</span> לכסינה בבסיס זה - במקרה זה אפשר לפרק את <span class="math">\(V\)</span> לסכום ישר של <span class="math">\(n\)</span> תתי-מרחבים שכל אחד מהם ממימד 1, ולכן המטריצה שמייצגת את <span class="math">\(T\)</span> היא מטריצת "בלוקים" שבה כל בלוק הוא מטריצה מסדר <span class="math">\(1\times1\)</span>. אין כאן שום רעיון חדש - הנימוק שכבר הבאתי לכך שטרנספורמציה היא לכסינה אם יש בסיס של וקטורים עצמיים השתמש באותם נימוקים שבהם השתמשתי כאן כדי להסביר איך מתקבלת מטריצת בלוקים - אבל זו עדיין דרך מחשבה נחמדה.</p>
<p>אם <span class="math">\(W\subset V\)</span> הוא תת-מרחב שמור של <span class="math">\(T\)</span>, אז אפשר להסתכל על <span class="math">\(T\)</span> כאשר היא מצומצמת רק לתת-מרחב <span class="math">\(W\)</span>. בואו נגדיר את זה פורמלית כדי למנוע בלבול: יש לנו טרנספורמציה <span class="math">\(T:V\to V\)</span>, ואפשר להגדיר טרנספורמציה חדשה <span class="math">\(T_{W}:W\to W\)</span> שפשוט מוגדרת בתור <span class="math">\(T_{W}\left(w\right)=T\left(w\right)\)</span> לכל <span class="math">\(w\in W\)</span>. הנקודה היא שבגלל ש-<span class="math">\(T_{W}\)</span> מוגדרת על מרחב קטן יותר, קל יותר לחקור אותה - למשל, המטריצה המייצגת שלה תהיה קטנה יותר. עוד תכונה מעניינת שתהיה רלוונטית בהמשך היא שהפולינום המינימלי של <span class="math">\(T_{W}\)</span> מחלק את הפולינום המינימלי של <span class="math">\(T\)</span>, אבל הם ממש לא חייבים להיות זהים. למה הוא מחלק? ובכן, אם <span class="math">\(m\left(T\right)\)</span> היא טרנספורמציית האפס על <span class="math">\(V\)</span> זה אומר שהיא מחזירה 0 לכל איבר של <span class="math">\(V\)</span> ולכן בפרט לכל איבר של <span class="math">\(W\)</span>, ולכן <span class="math">\(p\)</span> הוא פולינום שמאפס את <span class="math">\(T_{W}\)</span>; אבל כזכור, הפולינום המינימלי של <span class="math">\(T_{W}\)</span> מחלק כל פולינום אחר שמאפס את <span class="math">\(T_{W}\)</span>.</p>
<h2><strong>לכסון סימולטני</strong></h2>
<p>בואו נעבור להמחשה של השימוש במושג של תת-מרחבים שמורים - לכסון סימולטני של טרנספורמציות (או מטריצות; זכרו שעבורנו זה אותו הדבר). בואו נניח ש-<span class="math">\(S,T\)</span> הם שני אופרטורים לכסינים; זה אומר שקיים בסיס שבו <span class="math">\(T\)</span> מיוצגת על ידי מטריצה אלכסונית, וקיים בסיס שבו <span class="math">\(S\)</span> מיוצגת על ידי מטריצה אלכסונית, אבל האם קיים בסיס שבו <strong>שתיהן גם יחד</strong> מיוצגות על ידי מטריצה אלכסונית? התשובה היא שלא תמיד; קל לראות שהכרחי שהן <strong>יתחלפו</strong>, כלומר שיתקיים <span class="math">\(ST=TS\)</span> (זכרו שטרנספורמציות ומטריצות לא מתחלפות תמיד בכפל - נסו למצוא דוגמאות!). הסיבה לכך היא שמטריצות אלכסוניות כן מתחלפות בכפל, ולכן אם <span class="math">\(S,T\)</span> ניתנות בו זמנית להצגה בידי מטריצות אלכסוניות הן אכן יתחלפו בכפל. זו דוגמה לתנאי הכרחי, אבל מה שמפתיע כאן הוא שהוא גם מספיק: שתי טרנספורמציות לכסינות הן בעלות לכסון משותף אם ורק אם הן מתחלפות בכפל. למעשה, ההוכחה שאציג כעת עובדת גם אם יש יותר משתי טרנספורמציות - אפילו עבור מספר אינסופי שלהן, כל עוד כולן לכסינות וכל זוג טרנספורמציות מתחלפות בכפל.</p>
<p>תכונת ההתחלפות-בכפל תועיל לי באופן הבא: נניח של-<span class="math">\(T\)</span> יש ערך עצמי <span class="math">\(\lambda\)</span>, אז המרחב העצמי השייך לערך העצמי הזה הוא בעצם הגרעין של הטרנספורמציה <span class="math">\(T-\lambda I\)</span>, ואם <span class="math">\(T\)</span> מתחלף עם <span class="math">\(S\)</span> כך גם הטרנספורמציה <span class="math">\(T-\lambda I\)</span>. כעת אני יכול לטעון טענה כללית קצת יותר: אם <span class="math">\(U,S\)</span> טרנספורמציות לינאריות שמתחלפות בכפל, אז הגרעין של <span class="math">\(U\)</span> הוא תת-מרחב שמור של <span class="math">\(S\)</span>, שהרי אם <span class="math">\(u\)</span> נמצא בגרעין הזה נקבל ש-<span class="math">\(US\left(u\right)=SU\left(u\right)=S\left(0\right)=0\)</span>, כלומר גם <span class="math">\(S\left(u\right)\)</span> בגרעין של <span class="math">\(U\)</span>.</p>
<p>מכאן נובע המשפט על לכסינות סימולטנית כמעט מאליו: אם לכל הטרנספורמציות יש רק ערך עצמי אחד אז כל בסיס שנבחר ילכסן את כולן בו זמנית (זכרו שהן לכסינות, כלומר הריבוי הגיאומטרי של הערך העצמי היחיד של כל אחת מהן הוא מימד <span class="math">\(V\)</span>). בואו נניח אם כן שיש <span class="math">\(T\)</span> עם יותר מערך עצמי אחד, <span class="math">\(\lambda_{1},\dots,\lambda_{t}\)</span>. זה מגדיר פירוק של <span class="math">\(V\)</span> לתת-מרחבים עצמיים: <span class="math">\(V=W_{1}\oplus\dots\oplus W_{t}\)</span> כש-<span class="math">\(W_{i}\)</span> הוא המרחב העצמי של <span class="math">\(T\)</span> שמתאים לערך העצמי <span class="math">\(i\)</span>. כעת בואו ניקח טרנספורמציה אחרת <span class="math">\(S\)</span>. אני בהחלט <strong>לא</strong> יכול לומר ש-<span class="math">\(W_{i}\)</span> הוא מרחב עצמי שלה, אבל בגלל שהיא מתחלפת עם <span class="math">\(T\)</span> אני בהחלט <strong>כן</strong> יכול לומר שהוא תת-מרחב שמור שלה, מהנימוק שהבאתי קודם (במקרה הזה, <span class="math">\(U=T-\lambda I\)</span>). מה שנותר עכשיו לשים לב אליו הוא שכל <span class="math">\(S\)</span> היא לכסינה גם כשהיא מצומצמת ל-<span class="math">\(W_{i}\)</span> כי הפולינום המינימלי שלה ב-<span class="math">\(W_{i}\)</span> מחלק את הפולינום המינימלי שלה ב-<span class="math">\(V\)</span> (כאן אני מתבסס על טענה שטרם הוכחתי - שמטריצה היא לכסינה אם ורק אם לפולינום המינימלי שלה אין שורשים מרובים), ולכן אפשר באינדוקציה להניח שכל הצמצומים של הטרנספורמציות על <span class="math">\(W_{i}\)</span> הן לכסינות סימולטנית ולסיים על ידי איחוד כל הבסיסים המלכסנים-סימולטנית של כל ה-<span class="math">\(W_{i}\)</span>.</p>
<p>למי שנראה לו שרימתי עם האינדוקציה בסוף, שימו לב לכך שבמרחב ממימד 1 כל בחירת בסיס "תלכסן סימולטנית" את כל הטרנספורמציות כי מטריצה <span class="math">\(1\times1\)</span> היא תמיד אלכסונית; ושבגלל שבחרתי לעבוד עם <span class="math">\(T\)</span> שיש לה יותר מערך עצמי אחד, יש לה יותר מ-<span class="math">\(W_{i}\)</span> אחד ולכן המימד של כולם קטן יותר מהמימד של <span class="math">\(V\)</span> ואפשר להשתמש באינדוקציה. ההוכחה הזו מבליטה היטב את הכוח שבדיבור על תתי-מרחבים שמורים - הם מאפשרים להוכיח דברים בשיטת הפרד ומשול.</p>
<h2><strong>הטלות</strong></h2>
<p>בואו נשכח לרגע מתתי-מרחבים שמורים ונדבר על פירוק כלשהו לסכום ישר, <span class="math">\(V=W_{1}\oplus\dots\oplus W_{k}\)</span>. בכל פירוק שכזה יש טרנספורמציות לינאריות שמאפיינות את הפירוק בדיוק כשם ש-<span class="math">\(W_{1},\dots,W_{k}\)</span> מאפיינות אותו - <strong>ההטלות</strong> למרחבים <span class="math">\(W_{1},\dots,W_{k}\)</span>. פורמלית נהוג להגדיר באלגברה לינארית <strong>הטלה</strong> בתור כל טרנספורמציה לינארית <span class="math">\(T:V\to V\)</span> המקיימת <span class="math">\(T^{2}=T\)</span>. בואו נבין למה: נסמן <span class="math">\(U=\text{Im}T\)</span>, ניקח בסיס ל-<span class="math">\(U\)</span> ונשלים אותו לבסיס של <span class="math">\(V\)</span> וניקח את אברי הבסיס שאינם של <span class="math">\(U\)</span> ונביט במרחב <span class="math">\(U^{\prime}\)</span> שהם פורשים - נקבל ש-<span class="math">\(V=U\oplus U^{\prime}\)</span>, ושאת <span class="math">\(T\)</span> אפשר לתאר כך: אם <span class="math">\(v=u+u^{\prime}\)</span> כאשר <span class="math">\(u\in U\)</span> ו-<span class="math">\(u^{\prime}\in U^{\prime}\)</span> (קיימת בדיוק דרך אחת להציג כך את <span class="math">\(v\)</span>) אז <span class="math">\(T\left(v\right)=u\)</span>, כלומר <span class="math">\(T\)</span> לוקחת את הרכיב של <span class="math">\(v\)</span> שנמצא בתוך <span class="math">\(U\)</span> ומוחקת את היתר. זה מתאים לאינטואיציה שיש לנו לגבי הטלות "קלאסיות" (הטלות כאלו הן בדרך כלל ביחס למערכת צירים שבה הצירים מאונכים זה לזה; גם לכך נגיע בסדרת הפוסטים הזו, אבל עוד חזון למועד).</p>
<p>את הרעיון הזה אפשר להכליל למקרה של <span class="math">\(V=W_{1}\oplus\dots\oplus W_{k}\)</span>. במקרה הזה, כל וקטור <span class="math">\(v\)</span> ניתן להציג בצורה יחידה כ-<span class="math">\(v=w_{1}+\dots+w_{k}\)</span> כאשר <span class="math">\(w_{i}\in W_{i}\)</span>; נגדיר טרנספורמציה לינארית <span class="math">\(E_{i}:V\to V\)</span> על ידי <span class="math">\(E_{i}\left(v\right)=w_{i}\)</span>. קל לראות שזוהי הטלה, כלומר <span class="math">\(E_{i}^{2}=E_{i}\)</span>וקל לראות ש=<span class="math">\(\text{Im}E_{i}=W_{i}\)</span>. מההגדרה נובע גם כמעט מייד ש-<span class="math">\(E_{i}E_{j}=0\)</span> אם <span class="math">\(i\ne j\)</span>, ועם עוד טיפה עבודה אפשר לראות ש-<span class="math">\(I=\sum E_{i}\)</span>, כלומר הסכום של כל ההטלות הללו נותן לנו את טרנספורמציית הזהות.</p>
<p>מה שבאמת מעניין הוא שכל קבוצה של <span class="math">\(k\)</span> הטלות <span class="math">\(E_{1},\dots,E_{k}\)</span> שמקיימות את התכונה שהרכבה של שתיים מהן היא אפס וסכום כולן הוא הזהות מגדירות פירוק של <span class="math">\(V\)</span> לסכום ישר של מרחבים שהם התמונות של ההטלות. גם זו טענה קלה יחסית אבל אוכיח אותה כאן כי היא לא מיידית כמו הכיוון השני. לפני כן רק אסביר לאן אני חותר עם זה - לב האתגר במשפט הפירוק הפרימרי (שהוא המטרה העיקרית של הפוסט הזה ואחד מה"גביעים הקדושים" בסדרת הפוסטים כולה באופן כללי) הוא למצוא הטלות שמקיימות תכונות מסויימות, ואז הפירוק נובע מהן בדיוק על פי המשפט שזה עתה אוכיח.</p>
<p>טוב, אז מה עושים? ראשית מגדירים <span class="math">\(W_{i}=\text{Im}E_{i}\)</span>. עכשיו צריך להראות גם שכל איבר ב-<span class="math">\(V\)</span> ניתן לכתיבה כסכום של איברים ב-<span class="math">\(W_{i}\)</span>-ים הללו, וגם שדרך ההצגה הזו היא יחידה. התכונה הראשונה נובעת מכך ש-<span class="math">\(I=\sum E_{i}\)</span>: פשוט נשים לב לכך ש-<span class="math">\(v=I\left(v\right)=\sum E_{i}\left(v\right)\)</span> והנה קיבלנו הצגה של <span class="math">\(v\)</span> כסכום של איברים ב-<span class="math">\(W_{i}\)</span>. כדי לראות שדרך ההצגה הזו היא יחידה, בואו קודם כל נשים לב לכך שאם <span class="math">\(v\in W_{i}\)</span> אז <span class="math">\(E_{i}\left(v\right)=v\)</span> ואילו <span class="math">\(E_{j}\left(v\right)=0\)</span>. למה? כי אם <span class="math">\(v\in W_{i}\)</span> זה אומר ש-<span class="math">\(v\)</span> הוא בתמונה של <span class="math">\(E_{i}\)</span>, כלומר <span class="math">\(v=E_{i}\left(u\right)\)</span>, ולכן <span class="math">\(E_{i}\left(v\right)=E_{i}^{2}\left(u\right)=E_{i}\left(u\right)=v\)</span> ובדומה, <span class="math">\(E_{j}\left(v\right)=E_{j}E_{i}\left(u\right)=0\)</span>.</p>
<p>כעת, אם <span class="math">\(v=w_{1}+\dots+w_{k}\)</span> אז מהתכונות לעיל נובע ש-<span class="math">\(E_{i}\left(v\right)=w_{i}\)</span> - אבל הערך של <span class="math">\(E_{i}\left(v\right)\)</span> ודאי אינו תלוי באופן שבו אנו בוחרים לפרק את <span class="math">\(v\)</span> לסכום! במילים אחרות, גם אם היינו כותבים <span class="math">\(v=\alpha_{1}+\dots+\alpha_{k}\)</span> כך ש-<span class="math">\(\alpha_{i}\in W_{i}\)</span> היינו מקבלים <span class="math">\(E_{i}\left(v\right)=\alpha_{i}\)</span> ולכן <span class="math">\(w_{i}=\alpha_{i}\)</span> ודרך ההצגה הזו היא יחידה.</p>
<p>עכשיו אפשר לחזור למרחבים שמורים. מה שמעניין אותנו הוא השאלה הבאה: נתון פירוק <span class="math">\(V=W_{1}\oplus\dots\oplus W_{k}\)</span> ונתונה טרנספורמציה <span class="math">\(T\)</span> - מתי כל המרחבים <span class="math">\(W_{i}\)</span> הם תתי-מרחבים שמורים של <span class="math">\(T\)</span>? התשובה מקסימה, לטעמי, באלגנטיות שלה: אם ורק אם <span class="math">\(T\)</span> מתחלפת עם ההטלות <span class="math">\(E_{i}\)</span> המתאימות למרחבים.</p>
<p>כיוון אחד הוא קלי קלות: אם <span class="math">\(T\)</span> מתחלפת עם <span class="math">\(E_{i}\)</span> ו-<span class="math">\(w\in W_{i}\)</span> אז <span class="math">\(T\left(w\right)=TE_{i}\left(w\right)=E_{i}T\left(w\right)\in W\)</span> כשסימן השייכות בסוף נובע מכך ש-<span class="math">\(W_{i}\)</span> הוא תמונת <span class="math">\(E_{i}\)</span>. מה שמעניין הוא הכיוון השני, להראות ש-<span class="math">\(T\)</span> מתחלפת עם <span class="math">\(E_{i}\)</span>.</p>
<p>אם כן, הבה וניקח <span class="math">\(v\in V\)</span> כלשהו ונפרק אותו לרכיביו, <span class="math">\(v=\sum w_{i}\)</span>. אז <span class="math">\(T\left(v\right)=\sum T\left(w_{i}\right)=\sum u_{i}\)</span> כאשר <span class="math">\(u_{i}\in W_{i}\)</span> - זה נובע מכך שמדובר על תתי-מרחבים שמורים של <span class="math">\(T\)</span>. כעת הבה ונפעיל על כל זה הטלה: <span class="math">\(E_{i}T\left(v\right)=u_{i}\)</span> (מאותן סיבות שכבר ראינו עד כה). מצד שני, <span class="math">\(TE_{i}\left(v\right)=T\left(w_{i}\right)=u_{i}=E_{i}T\left(v\right)\)</span>, והנה קיבלנו ש-<span class="math">\(TE_{i}=ET_{i}\)</span> (כי ההוכחה הייתה על <span class="math">\(v\)</span> כלשהו).</p>
<p>הדבר הבא שאני רוצה להראות הוא אפיון אלטרנטיבי ללכסינות, שבכלל לא מדבר על ערכים עצמיים, בסיסים, ריבוי אלגברי וגאומטרי ושום דבר דומה לזה, אלא רק על הטלות. בואו נתחיל מכך שאם <span class="math">\(T\)</span> לכסינה עם ערכים עצמיים <span class="math">\(\lambda_{1},\dots,\lambda_{k}\)</span> אז כפי שכבר אמרתי מאות פעמים, אפשר לפרק את <span class="math">\(V\)</span> לסכום של מרחבים עצמיים. בואו ניקח את <span class="math">\(E_{1},\dots,E_{k}\)</span> להיות ההטלות על אותם מרחבים עצמיים, אז כמו תמיד הן יקיימו <span class="math">\(I=\sum E_{i}\)</span> ו-<span class="math">\(E_{i}E_{j}=0\)</span> לכל <span class="math">\(i\ne j\)</span>. יופי. רק שהן יקיימו הפעם תכונה נוספת: <span class="math">\(T=\sum\lambda_{i}E_{i}\)</span>. למה? ובכן, קחו <span class="math">\(v\in V\)</span> כלשהו, אז כמקודם <span class="math">\(v=I\left(v\right)=\sum E_{i}\left(v\right)\)</span>, ומכיוון ש-<span class="math">\(E_{i}\left(v\right)\)</span> נמצא במרחב העצמי <span class="math">\(W_{i}\)</span> אז <span class="math">\(T\left(E_{i}\left(v\right)\right)=\lambda_{i}E_{i}\left(v\right)\)</span>, כלומר <span class="math">\(T\left(v\right)=\sum\lambda_{i}E_{i}\left(v\right)\)</span> לכל <span class="math">\(v\)</span>, ולכן <span class="math">\(T=\sum\lambda_{i}E_{i}\)</span>.</p>
<p>מסתבר שהתכונה הזו היא גם מספיקה כדי ש-<span class="math">\(T\)</span> תהיה לכסינה. במילים אחרות, <span class="math">\(T\)</span> לכסינה אם קיימים סקלרים שונים <span class="math">\(\lambda_{1},\dots,\lambda_{k}\)</span> וטרנספורמציות לינאריות <span class="math">\(E_{1},\dots,E_{k}\)</span> שונות מאפס כך ש-<span class="math">\(T=\sum\lambda_{i}E_{i}\)</span> ו-<span class="math">\(I=\sum E_{i}\)</span> ו-<span class="math">\(E_{i}E_{j}=0\)</span> (ובאופן צפוי, <span class="math">\(\lambda_{i}\)</span> הם הערכים העצמיים שלה, ו-<span class="math">\(E_{i}^{2}=E_{i}\)</span> כך ש-<span class="math">\(E_{i}\)</span> הן הטלות). ההוכחה היא תרגיל טוב ולא שונה כל כך ממה שכבר ראינו אז אוותר עליה. במקום זה בואו נראה שימוש מיידי של התוצאה הזו: אם <span class="math">\(T=\sum\lambda_{i}E_{i}\)</span>, מהו <span class="math">\(T^{2}\)</span>? לכאורה על פי חוקי הכפל נקבל <span class="math">\(T^{2}=\sum_{i,j}\lambda_{i}\lambda_{j}E_{i}E_{j}\)</span>, אבל אם נשתמש בכך ש-<span class="math">\(E_{i}E_{j}=0\)</span> ובכך ש-<span class="math">\(E_{i}^{2}=E_{i}\)</span> נקבל ש-<span class="math">\(T^{2}=\sum\lambda_{i}^{2}E_{i}\)</span>, ובאופן כללי לא קשה לראות שאם <span class="math">\(p\)</span> הוא פולינום כלשהו אז <span class="math">\(p\left(T\right)=\sum p\left(\lambda_{i}\right)E_{i}\)</span>. לא רק שהאבחנה הזו תעזור לנו בהמשך, היא כבר כעת מוכיחה מייד שאם יש לנו טרנספורמציה <span class="math">\(T\)</span>, אז הערכים העצמיים של <span class="math">\(p\left(T\right)\)</span> הם בדיוק הפעלת <span class="math">\(p\)</span> על הערכים העצמיים של <span class="math">\(T\)</span> - לא תוצאה טריוויאלית כלל ממבט ראשון.</p>
<p>כעת אוכיח סוף סוף את הקריטריון ללכסינות שמבוסס על הפולינום המינימלי: טרנספורמציה היא לכסינה אם ורק אם לפולינום המינימלי שלה אין שורש מרובה (כלומר, הוא מהצורה <span class="math">\(\left(x-\lambda_{1}\right)\cdots\left(x-\lambda_{k}\right)\)</span> כאשר כל ה-<span class="math">\(\lambda_{i}\)</span> שונים זה מזה).</p>
<p>נתחיל מהכיוון הקל. נניח של-<span class="math">\(T\)</span> יש את הערכים העצמיים <span class="math">\(\lambda_{1},\dots,\lambda_{k}\)</span>, אז <span class="math">\(T=\sum\lambda_{i}E_{i}\)</span>. אם <span class="math">\(p\)</span> פולינום שמאפס את <span class="math">\(T\)</span>, אז בהכרח <span class="math">\(\sum p\left(\lambda_{i}\right)E_{i}=0\)</span>. על ידי הפעלות של <span class="math">\(E_{j}\)</span> על המשוואה הזו רואים שבהכרח נובע ממנה ש-<span class="math">\(p\left(\lambda_{i}\right)=0\)</span> לכל <span class="math">\(\lambda_{i}\)</span>. כלומר: כל פולינום שמאפס את <span class="math">\(T\)</span> חייב להתאפס על ידי כל הערכים העצמיים. כמו כן, הפולינום <span class="math">\(\left(x-\lambda_{1}\right)\cdots\left(x-\lambda_{k}\right)\)</span> מאפס את כל הערכים העצמיים בו זמנית ולכן מאפס את <span class="math">\(T\)</span>, ולכל פולינום שמחלק אותו קיים ערך עצמי שהוא לא מחלק. מסקנה: <span class="math">\(\left(x-\lambda_{1}\right)\cdots\left(x-\lambda_{k}\right)\)</span> הוא הפולינום המינימלי של <span class="math">\(T\)</span>.</p>
<p>הכיוון השני הוא העיקר - נניח ש-<span class="math">\(\left(x-\lambda_{1}\right)\cdots\left(x-\lambda_{k}\right)\)</span> הוא הפולינום המינימלי של טרנספורמציה <span class="math">\(T\)</span> ונוכיח שהיא לכסינה ועם הערכים העצמיים <span class="math">\(\lambda_{1},\dots,\lambda_{k}\)</span>. הרעיון יהיה לבנות הטלות שמקיימות את התכונות של המשפט שלעיל - סכומן הוא <span class="math">\(I\)</span>, סכומן המשוקלל עם <span class="math">\(\lambda_{1},\dots,\lambda_{k}\)</span> הוא <span class="math">\(T\)</span>, וההרכבה של כל זוג מהן היא אפס. האופן שבו מוצאים את ההטלות הללו הוא מקסים למדי ונותן לי תירוץ להציג יותר בפירוט משהו שכבר דיברתי עליו - אינטרפולציית לגראנז'.</p>
<p>הרעיון באינטרפולציית לגראנז' הוא לבנות פולינום בעל ערכים נתונים. נותנים לי סדרת זוגות של נקודות <span class="math">\(\left(x_{0},y_{0}\right),\left(x_{1},y_{1}\right),\dots,\left(x_{d},y_{d}\right)\)</span> ודורשים ממני למצוא פולינום <span class="math">\(g\)</span> ממעלה <span class="math">\(d\)</span> לכל היותר שמקיים <span class="math">\(g\left(x_{i}\right)=y_{i}\)</span> לכל זוג מזוגות הנקודות (לא קשה להוכיח שאם קיים פולינום כזה, הוא יחיד - כל שני פולינומים ממעלה לכל היותר <span class="math">\(d\)</span> שמסכימים על <span class="math">\(d+1\)</span> נקודות הם זהים). הפתרון הוא להשתמש במעין בסיס (לא במובן הסטנדרטי) שמותאם לסדרת ה-<span class="math">\(x_{i}\)</span>-ים הנתונה ומאפשרת, לכל סדרת <span class="math">\(y_{i}\)</span>-ים, לבנות בקלות את <span class="math">\(g\)</span> המתאים. לב העניין הוא בבניה של פולינומים <span class="math">\(p_{0},p_{1},\dots,p_{d}\)</span> שכל אחד מהם מקיים <span class="math">\(p_{i}\left(x_{j}\right)=\delta_{ij}\)</span>, כלומר הוא מתאפס על כל ה-<span class="math">\(x\)</span>-ים פרט לאחד, ועליו הוא מקבל 1. פולינום כזה קל לבנות במפורש: <span class="math">\(p_{i}\left(x\right)=\prod_{j\ne i}\frac{x-x_{j}}{x_{i}-x_{j}}\)</span> (כאשר <span class="math">\(\prod\)</span> כאן מייצג מכפלה). הציבו בפולינום הזה <span class="math">\(x_{i}\)</span> ותראו מה מקבלים, ואחר כך חשבו מה קורה כשמציבים בו <span class="math">\(x_{j}\)</span> אחר.</p>
<p>עכשיו, אם ה-<span class="math">\(p\)</span>-ים הללו נתונים לנו, אז את <span class="math">\(g\)</span> בונים בצורה הבאה: <span class="math">\(g\left(x\right)=\sum y_{i}p_{i}\left(x\right)\)</span>. כשמציבים ב-<span class="math">\(g\)</span> את <span class="math">\(x_{i}\)</span>, מה שנשאר כשהעשן מתפזר הוא <span class="math">\(y_{i}\)</span>. הדבר הזה מאוד דומה להטלות, שבתורן מאוד דומות לבסיסים למרחבים וקטוריים (ובפרט לבסיס אורתונורמליים, אבל עוד חזון למועד...) ולא סתם - הנה לנו דוגמה יפה למקום שבו כל הקשרים הללו באים לידי ביטוי.</p>
<p>איך כל זה קשור לענייננו, תשאלו? פשוט מאוד: ניקח את סדרת ה-<span class="math">\(x\)</span>-ים שלנו להיות <span class="math">\(\lambda_{1},\dots,\lambda_{k}\)</span> ונבנה פולינומים <span class="math">\(p_{1},\dots,p_{k}\)</span> מתאימים. כעת נבצע בעזרתם אינטרפולציה לשני פולינומים: אחד שמחזיר 1 על הכל, ושני שאם הוא מקבל <span class="math">\(x\)</span> הוא מחזיר <span class="math">\(x\)</span>. מנוסחת האינטרפולציה שלנו נקבל:</p>
<p><span class="math">\(1=\sum p_{i}\)</span></p>
<p><span class="math">\(x=\sum\lambda_{i}p_{i}\)</span></p>
<p>(אני מניח כאן באופן סמוי ש-<span class="math">\(k&amp;gt;1\)</span> אבל זה בסדר כי <span class="math">\(k=1\)</span> אומר ש-<span class="math">\(T-\lambda I=0\)</span> (פשוט הצבתי את <span class="math">\(T\)</span> בפולינום המינימלי) ולכן <span class="math">\(T\)</span> בבירור לכסינה).</p>
<p>עכשיו הטוויסט הסופי מגיע: נגדיר את <span class="math">\(E_{i}=p_{i}\left(T\right)\)</span>. הצבנו את <span class="math">\(T\)</span> בפולינומי האינטרפולציה, וקיבלנו מייד שמתקיים:</p>
<p><span class="math">\(I=\sum E_{i}\)</span></p>
<p><span class="math">\(T=\sum\lambda_{i}E_{i}\)</span></p>
<p>טוב ויפה, אבל למה <span class="math">\(E_{i}E_{j}=0\)</span>? או, טוב ששאלתם: כי <span class="math">\(p\)</span> בהכרח מחלק את <span class="math">\(p_{i}p_{j}\)</span>, וזאת מכיוון ש-<span class="math">\(p_{i}p_{j}\)</span> הוא פולינום שמתאפס על כל <span class="math">\(\lambda_{1},\dots,\lambda_{j}\)</span> ולכן בהכרח מכיל בתוכו רכיב מהצורה <span class="math">\(\prod\left(x-\lambda_{i}\right)\)</span> - הפולינום המינימלי בכבודו ובעצמו (כאן השתמשתי בהנחה שאין לפולינום המינימלי שורש מרובה).</p>
<p>הדבר האחרון שעוד צריך להשתכנע בו הוא שכל ה-<span class="math">\(E_{i}\)</span>-ים שונים מאפס (זה תנאי הכרחי של המשפט שאותו לא הוכחתי). גם זה פשוט - אם <span class="math">\(E_{i}=0\)</span> זה אומר ש-<span class="math">\(p_{i}\left(T\right)=0\)</span> והנה מצאנו פולינום שמאפס את <span class="math">\(T\)</span> אבל דרגתו היא רק <span class="math">\(k-1\)</span>, כלומר קטנה מדרגת הפולינום המינימלי. זה מסיים את הכל.</p>
<p>בפוסט הבא נגיע כבר למשפט כבד באמת - משפט הפירוק הפרימרי - אבל שימו לב שגם בפוסט הזה כבר כיסינו כברת דרך לא קטנה והצגנו רעיונות שהם חשובים למדי בהקשרים רבים, וכנראה שנפגוש עוד בהמשך הדרך בצורה רצינית כשנדבר על מרחבי מכפלה פנימית. בנוסף, גם ההוכחות כבר הפסיקו להיות טריוויאליות כמו שהיו ברוב העניינים עד כה - אבל לדעתי הן עדיין אלגנטיות ויפות ביותר, במיטב מסורת האלגברה הלינארית.</p>
        </article>
        
        <footer>
            <p>© כל הזכויות שמורות לגדי אלכסנדרוביץ'</p>
        </footer>
    </div>

    
    <script>
        function searchPosts() {
            const searchTerm = document.getElementById('searchInput').value;
            if (searchTerm.trim()) {
                window.location.href = '/post_list.html?search=' + encodeURIComponent(searchTerm);
            }
        }
        
        document.getElementById('searchInput').addEventListener('keypress', function(e) {
            if (e.key === 'Enter') {
                searchPosts();
            }
        });
    </script>
    
    
    <!-- Auto-render KaTeX math -->
    <script>
        document.addEventListener("DOMContentLoaded", function() {
            renderMathInElement(document.body, {
                delimiters: [
                    {left: "\\[", right: "\\]", display: true},
                    {left: "\\(", right: "\\)", display: false}
                ],
                throwOnError: false
            });
        });
    </script>

</body>
</html>