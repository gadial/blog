<!DOCTYPE html>
<html lang="he" dir="rtl">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>דיון מקרי על אלגוריתמים הסתברותיים - לא מדויק</title>
    <link rel="icon" type="image/x-icon" href="/favicon.ico">
    
    <meta name="description" content="לא מדויק - בלוג על מתמטיקה ומדעי המחשב" />
    <!-- Open Graph / Facebook -->
    <meta property="og:type" content="article">
    <meta property="og:url" content="https://gadial.net/2009/08/18/probablistic_algorithms/">
    <meta property="og:title" content="דיון מקרי על אלגוריתמים הסתברותיים">
    <meta property="og:description" content="לא מדויק - בלוג על מתמטיקה ומדעי המחשב">
    <meta property="og:site_name" content="לא מדויק">
    

<meta property="og:image" content="http://gadial.net/img/main/default-card.png" />


        
    <!-- Twitter -->
    

<meta name="twitter:card" content="summary">


    <meta name="twitter:url" content="https://gadial.net/2009/08/18/probablistic_algorithms/">
    <meta name="twitter:description" content="לא מדויק - בלוג על מתמטיקה ומדעי המחשב">
    <meta name="twitter:site" content="@" />
    <meta property="twitter:title" content="דיון מקרי על אלגוריתמים הסתברותיים">
    

<meta property="twitter:image" content="http://gadial.net/img/main/default-card.png" />


    
    <!-- RSS Feed -->
    <link rel="alternate" type="application/rss+xml" title="לא מדויק - RSS Feed" href="/feed.xml">
       
    
    <!-- KaTeX for math rendering -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css">
    <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js"></script>
    <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js"></script>
    <link rel="stylesheet" href="/css/main.css">

    
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }
        
        body {
            font-family: 'Arial', 'David', 'Tahoma', sans-serif;
            line-height: 1.6;
            color: #333;
            background-color: #f5f5f5;
        }
        
        /* Top navigation bar */
        .top-nav {
            background: #2c3e50;
            padding: 15px 20px;
            box-shadow: 0 2px 5px rgba(0,0,0,0.1);
        }
        
        .top-nav .nav-container {
            max-width: 1200px;
            margin: 0 auto;
            display: flex;
            align-items: center;
            justify-content: space-between;
            gap: 20px;
        }
        
        .top-nav .site-title {
            font-size: 1.5em;
            font-weight: bold;
            color: white;
            text-decoration: none;
            white-space: nowrap;
        }
        
        .top-nav .nav-links {
            display: flex;
            gap: 20px;
            align-items: center;
            flex-wrap: wrap;
        }
        
        .top-nav .nav-links a {
            color: #ecf0f1;
            text-decoration: none;
            padding: 5px 10px;
            border-radius: 4px;
            transition: background 0.2s;
            white-space: nowrap;
        }
        
        .top-nav .nav-links a:hover {
            background: #34495e;
        }
        
        .top-nav .search-box {
            display: flex;
            gap: 5px;
        }
        
        .top-nav .search-box input {
            padding: 5px 10px;
            border: none;
            border-radius: 4px;
            font-size: 0.9em;
            min-width: 150px;
        }
        
        .top-nav .search-box button {
            padding: 5px 15px;
            background: #3498db;
            color: white;
            border: none;
            border-radius: 4px;
            cursor: pointer;
            transition: background 0.2s;
        }
        
        .top-nav .search-box button:hover {
            background: #2980b9;
        }
        
        /* Hamburger menu button */
        .menu-toggle {
            display: none;
            background: none;
            border: none;
            font-size: 1.8em;
            color: white;
            cursor: pointer;
            padding: 0;
            line-height: 1;
        }
        
        .menu-toggle:hover {
            opacity: 0.8;
        }
        
        /* Mobile responsive */
        @media (max-width: 768px) {
            .top-nav .nav-container {
                flex-direction: column;
                align-items: stretch;
            }
            
            .top-nav .site-title {
                display: flex;
                justify-content: space-between;
                align-items: center;
                margin-bottom: 0;
                padding: 10px 0;
            }
            
            .menu-toggle {
                display: block;
            }
            
            /* Hide nav links by default on mobile */
            .top-nav .nav-links {
                display: none;
                flex-direction: column;
                width: 100%;
                margin-top: 10px;
            }
            
            /* Show when expanded */
            .top-nav .nav-links.expanded {
                display: flex;
            }
            
            .top-nav .nav-links > a {
                text-align: center;
                padding: 12px;
                border-top: 1px solid rgba(255, 255, 255, 0.2);
            }
            
            .top-nav .search-box {
                width: 100%;
                flex-direction: column;
                margin-top: 10px;
                padding-top: 10px;
                border-top: 1px solid rgba(255, 255, 255, 0.2);
            }
            
            .top-nav .search-box input {
                width: 100%;
                margin-bottom: 5px;
                min-width: 0;
            }
            
            .top-nav .search-box button {
                width: 100%;
            }
        }
        
        /* Blockquote styling */
        blockquote {
            background: #f9f9f9;
            border-right: 5px solid #ccc;
            margin: 1.5em 10px;
            padding: 0.75em 16px;
            position: relative;
            font-style: italic;
        }
        
        blockquote:before {
            content: '"';
            position: absolute;
            top: -10px;
            right: 8px;
            font-size: 3.5em;
            color: #ccc;
            line-height: 1;
        }
        
        blockquote p {
            display: block;
            margin: 0 0 0.75em 0;
        }
        
        blockquote p:last-child {
            margin-bottom: 0;
        }
        
        
    </style>
</head>
<body>
    <nav class="top-nav">
        <div class="nav-container">
            <div class="site-title">
                <a href="/" style="color: white; text-decoration: none;">לא מדויק</a>
                <button class="menu-toggle" onclick="toggleMobileMenu()" aria-label="תפריט">
                    ☰
                </button>
            </div>
            <div class="nav-links" id="navLinks">
                <a href="/">דף הבית</a>
                <a href="/random.html">פוסט אקראי</a>
                <a href="/post_list.html">כל הפוסטים</a>
                <a href="/categories/">קטגוריות</a>
                <div class="search-box">
                    <input type="text" id="searchInput" placeholder="חיפוש...">
                    <button onclick="searchPosts()">חפש</button>
                </div>
            </div>
        </div>
    </nav>
    
    
    <div class="container">
        <!-- Post Navigation -->
        
        <nav class="post-navigation">
            
            <a href="/2009/08/09/miller_rabin/" class="nav-link nav-prev">
                <span class="nav-label">פוסט ישן יותר →</span>
                <span class="nav-title">אז איך באמת בודקים ראשוניות (בעזרת אלגוריתם מילר-רבין)?</span>
            </a>
            

            
            <a href="/2009/08/30/finite_automata_and_regular_languages/" class="nav-link nav-next">
                <span class="nav-label">← פוסט חדש יותר</span>
                <span class="nav-title">אוטומטים סופיים ושפות רגולריות</span>
            </a>
            
        </nav>
        
        
        <header>
            <h1>דיון מקרי על אלגוריתמים הסתברותיים</h1>
            <div class="post-meta">
                <span class="date">2009-08-18</span>
                
                <span class="categories">
                    | קטגוריות:
                    
                    <a href="/categories/הסתברות.html">הסתברות</a>
                    
                    <a href="/categories/מבני נתונים ואלגוריתמים.html">מבני נתונים ואלגוריתמים</a>
                    
                    <a href="/categories/תורת הסיבוכיות.html">תורת הסיבוכיות</a>
                    
                </span>
                
                
            </div>
        </header>
        
        <article>
            <p>אוהבים להגיד שהחיים האמיתיים זה לא כמו מתמטיקה. שבחיים האמיתיים לא הכל מדויק ודטרמיניסטי ויפה. אלא מה - אפילו במתמטיקה זה לא כך. ההסתברות פולשת לכל חלקה טובה של המתמטיקה ומזהמת אותה, וממש לא מסתפקת בדברים שעוסקים בהסתברות, כמו הסיכוי לזכיה בלוטו (אל תטרחו למלא) - גם בעיות "דטרמיניסטיות" למהדרין <a href="http://www.gadial.net/2007/06/30/nonconstructive_proofs_probablistic_logic/">מותקפות מדי פעם</a> באמצעות טכניקות הסתברותיות (שמניבות פתרון דטרמיניסטי למהדרין). גם מדעי המחשב לא פטורים מהזיהום, ומדי פעם מתגנב אל העולם המסודר והיפה שלהם אלגוריתם הסתברותי נפשע. אבל מה זה בכלל אלגוריתם הסתברותי, ובשביל מה זה טוב?</p>
<p>אלגוריתם, כפי שתיארתי כאן בעבר, הוא שם כללי לתהליך חישובי "מוגדר היטב", שבנוי מסדרת צעדים שכל אחד מהם הוא פשוט דיו כדי שיהיה ברור כיצד ניתן לבצע אותו ("הגדל את המספר הזה ב-1"; "אם שני המספרים הללו שווים, כתוב 'כן'" וכו'). באופן כללי מטרתו של אלגוריתם היא לקחת קלט ולייצר ממנו פלט; לפוסט הזה אצטמצמם לבעיות פשוטות עוד יותר - בעיות שבהן מתקבל קלט, והפלט צריך להיות או "כן" או "לא". אם נמשיך עם אלגוריתם מילר-רבין <a href="http://www.gadial.net/2009/08/09/miller_rabin/">מהפוסט הקודם</a>, דוגמה לכך היא אלגוריתם שמקבל מספר וצריך לומר אם הוא ראשוני או לא.</p>
<p>אלגוריתם הסתברותי הוא אלגוריתם שמבצע הגרלות במהלך ריצתו (יש דרך אחרת לחשוב על כך, שלפעמים היא מועילה יותר - אלגוריתם שמקבל עם תחילת ריצתו אוסף של מספרים אקראיים - אבל לא אכנס לכך כאן). אפשר לחשוב על כך בצורה מאוד פשוטה, כאלגוריתם שלפעמים מטיל מטבע ולפי התוצאה בוחר באחת משתי דרכי פעולה אפשריות. בתכנות "אמיתי" אפשר להשתמש בפונקציה rand (או משהו דומה - לרוב השפות יש פונקציה כזו כחלק מהספריה הסטנדרטית) כדי לקבל מספר אקראי ולהמשיך את החישוב על פיו (איך המספרים האקראיים הללו נוצרים כבר תיארתי <a href="http://www.gadial.net/2009/04/08/random_numbers/">בפוסט קודם</a>). דוגמה אמיתית נתתי בפוסט הקודם - מילר-רבין מגריל מספר <span class="math">\(a\)</span> שקטן מה-<span class="math">\(n\)</span> שאת ראשוניותו הוא בודק, ואז משתעשע עם אותו <span class="math">\(a\)</span> קצת ובסוף פולט תשובה, שתלויה ב-<span class="math">\(a\)</span> שהוגרל. זו דוגמה לאלגוריתם טוב, ואני רוצה גם דוגמה לאלגוריתם גרוע, אז הנה אלגוריתם אקראי גרוע לבדיקת ראשוניות - אלגוריתם שבהינתן מספר <span class="math">\(n\)</span> מטיל מטבע. אם יצא "עץ", האלגוריתם פולט "<span class="math">\(n\)</span> ראשוני", ואחרת הוא פולט "<span class="math">\(n\)</span> פריק". זה נשמע מגוחך ואווילי, כמובן (האלגוריתם לא בדק את <span class="math">\(n\)</span> בשום צורה!) אבל נשאלת השאלה - מדוע מילר-רבין הוא אלגוריתם טוב בעוד שהאלגוריתם שהצעתי גרוע? איך מודדים איכות של אלגוריתמים הסתברותיים?</p>
<p>בואו נבהיר קודם כל על מה אני מדבר. כשמנתחים אלגוריתמים הסתברותיים, <strong>לא</strong> מדברים על התנהגות האלגוריתם על קלט אקראי. <strong>לא</strong> אומרים דברים בסגנון "האלגוריתם ירוץ טוב על רוב הקלטים" ולא שום דבר דומה לזה. זה ההבדל שבין ניתוח של "המקרה הממוצע", ובין ניתוח של אלגוריתם הסתברותי. הדרישה מאלגוריתם הסתברותי היא ש<strong>על כל קלט</strong> האלגוריתם ירוץ טוב, בהסתברות גבוהה. שוב, אמחיש זאת עם דוגמה רעה ודוגמה טובה. הדוגמה הרעה היא האלגוריתם הבא לבדיקת האם מספר הוא ראשוני: "בהינתן מספר <span class="math">\(n\)</span>, פלוט 'המספר פריק'". האלגוריתם הזה נשמע מטומטם לגמרי - הוא תמיד יגיד שהמספר פריק, בלי לבדוק אותו בכלל! אבל בואו נניח שהקלטים לאלגוריתם מתפלגים בצורה אחידה בין כל המספרים הטבעיים שניתנים לייצוג עם 32 סיביכות (אני מדקדק כאן בקטנות כי אין כזה דבר, "התפלגות אחידה" על כל הטבעיים) - מה ההסתברות שהאלגוריתם יענה תשובה נכונה? ובכן, גבוהה למדי; בין המספרים הטבעיים עד <span class="math">\(n\)</span> יש בערך <span class="math">\(\frac{n}{\ln n}\)</span> מספרים ראשוניים, ולכן ההסתברות ליפול על ראשוני היא <span class="math">\(\frac{1}{\ln n}\)</span>, שעבור ערכים גדולים של <span class="math">\(n\)</span> הוא מספר לא גבוה כל כך - נניח, עבור מספרים בני 32 סיביות נקבל <span class="math">\(\ln n\approx22\)</span> ולכן האלגוריתם שלנו יטעה רק בפחות מ-5 אחוז מהמקרים - לא רע, נכון? אבל הבעיה היא שכשהאלגוריתם טועה, הוא טועה <strong>תמיד</strong>. ומכיוון שדווקא חמשת האחוזים של המספרים הראשוניים הם המקרים שמעניינים אותנו ביותר, אסור לנו להרשות לו לטעות תמיד עליהם. אז נחזור שוב על הנקודה - אלגוריתם הסתברותי <strong>חייב</strong> לעבוד טוב (כלומר, בהסתברות גבוהה) <strong>על כל הקלטים</strong>.</p>
<p>הדוגמה השנייה, ה"טובה" שלי היא של אלגוריתם המיון Quicksort ("<a href="http://he.wikipedia.org/wiki/%D7%9E%D7%99%D7%95%D7%9F_%D7%9E%D7%94%D7%99%D7%A8">מיון מהיר</a>"). זמן הריצה של האלגוריתם במקרה הגרוע הוא <span class="math">\(O\left(n^{2}\right)\)</span>, וזהו חסם לא טוב לאלגוריתמי מיון; האלגוריתמים הנאיביים ביותר הם בעלי החסם הזה. עם זאת, ניתוח הסתברותי מראה שבמקרה הממוצע, האלגוריתם רץ בזמן <span class="math">\(O\left(n\log n\right)\)</span> (שהוא זמן "כן טוב") ובפועל הביצועים של האלגוריתם מעולים. למרבה האירוניה, הקלטים שעבורם האלגוריתם (במימוש נאיבי שלו) רץ לאט הם דווקא כאלו שבהם האיברים שאותם רוצים למיין <strong>כבר ממויינים</strong> (או קרובים מאוד לכך). אמנם, במקרה שבו כל האיברים ממויינים אפשר לגלות זאת בקלות רבה יחסית ולהמנע מהרצת אלגוריתם המיון מלכתחילה; אבל זה עדיין לא מבטיח התנהגות טובה של האלגוריתם על כל קלט.</p>
<p>אז מה עושים? הופכים את האלגוריתם להסתברותי בצורה פשוטה מאוד - לפני שהאלגוריתם רץ על האיברים שאותם הוא רוצה למיין, הוא מערבב אותם באופן אקראי (אני קצת משקר כאן מסיבות "פדגוגיות"). לאחר העירבוב, יש הסתברות טובה לקבל קבוצה שעליה האלגוריתם המקורי רץ מהר; ותוצאת הערבוב לא תלויה בכלל בסדר שהיה קיים בקבוצת האיברים לפני הערבוב. כלומר, לכל קבוצת איברים שהאלגוריתם רוצה למיין, יש הסתברות טובה שהערבוב שלו "יצליח" ויאפשר לו למיין את הקבוצה המעורבבת במהירות. זוהי דוגמה קלאסית לאלגוריתם הסתברותי.</p>
<p>מיון מהיר הוא דוגמה לאלגוריתם שעושה כל מני הגרלות במהלך הריצה שלו, אבל בסוף מובטח שיחזיר את הפלט הנכון; ההגרלות נועדות רק כדי לתת לו "קיצורי דרך" שאולי יקצרו את זמן הריצה שלו. לסוג הזה של אלגוריתמים הסתברותיים קוראים "אלגוריתמי לאס-וגאס". למרות שאלו אלגוריתמים מעניינים, הם עדיין לא מהווים שבירה של חוקי המשחק, כי הם מתחייבים להחזיר תמיד את התוצאה הנכונה. השבירה האמיתית מתרחשת כשאנחנו מתירים לאלגוריתם שלנו להחזיר תשובה שגויה, כל עוד ההסתברות לכך (בלי תלות בקלט!) היא נמוכה. אלגוריתם מילר-רבין הוא דוגמה לאלגוריתם כזה; ובאופן כללי, אלגוריתמים שכאלו נקראים "אלגוריתמי מונטה-קרלו".</p>
<p>נזכיר שאני מגביל את עצמי לדיון על אלגוריתמים שעונים "כן/לא" (מיון מהיר היה דוגמה חשובה מכדי להתעלם ממנה, אבל זה היוצא מן הכלל). מה ההסתברות לטעות שאני יכול "להרשות" לאלגוריתם? האבחנה הראשונה היא שאלגוריתמים שההסתברות שלהם לטעות גדולה מחצי ניתנים מיידית להמרה לאלגוריתמים שההסתברות שלהם לטעות היא קטנה מחצי - זהו פשוט אותו אלגוריתם, אבל שעונה תשובה הפוכה. לכן הסתברות טעות של <span class="math">\(\frac{1}{2}\)</span> היא החסם התחתון בכל הנוגע לטעויות של אלגוריתמים הסתברותיים, והיא גם ההסתברות שאומרת שהאלגוריתם לא מוסיף לנו מידע - אלגוריתם "הטל מטבע, אם יצא עץ אמור כן ואחרת לא" שהזכרתי קודם הוא בעל הסתברות הצלחה כזו (לכל בעיית "כן/לא"), וזה אלגוריתם שכלל אינו מתחשב בקלט.</p>
<p>אם כן, אנחנו רוצים שהסתברות ההצלחה של האלגוריתם תהיה גדולה מ-<span class="math">\(\frac{1}{2}\)</span>. כמה גדולה? מסתבר שלא הרבה. בתורת הסיבוכיות יש הפרדה בין שתי מחלקות סיבוכיות עיקריות. הראשונה, PP (מלשון Probablistic Polynomial-time), היא אוסף הבעיות שקיים להן אלגוריתם הסתברותי <strong>יעיל</strong> (כלומר, בעל זמן ריצה פולינומי) שעל כל קלט שעבורו התשובה המתאימה היא "לא" מחזיר את התשובה הנכונה בהסתברות חצי לפחות, ועל כל קלט שהתשובה עליו היא "כן" מחזיר את התשובה הנכונה בהסתברות גדולה מחצי. כמה גדולה? אין שום דרישה על הגודל. רק שיהיה גדול מחצי. אפילו אם ככל שהקלטים הולכים וגדלים, ההסתברות לתשובה נכונה הולכת וקטנה, אבל עדיין נותרת גבוהה מחצי, אין עם זה בעיה.</p>
<p>הנה דוגמה לאלגוריתם PP לבדיקת פריקות של מספר: בהינתן <span class="math">\(n\)</span>, הגרל מספר הקטן מ-<span class="math">\(n\)</span> וגדול מ-1. אם הוא מחלק את <span class="math">\(n\)</span>, פלוט "כן" (המספר פריק), ואחרת הטל מטבע וענה בהתאם (אם יצא "עץ", אז פלוט "כן" ואחרת פלוט "לא"). די ברור שאם <span class="math">\(n\)</span> ראשוני, ההסתברות שהאלגוריתם יפלוט "לא" היא <span class="math">\(\frac{1}{2}\)</span>, בגלל הטלת המטבע; ואם <span class="math">\(n\)</span> פריק, אז יש לנו את ההסתברות <span class="math">\(\frac{1}{2}\)</span> להגיד "כן" שמבטיחה הטלת המטבע, ועוד תוספת קטנה ואומללה להסתברות שנובעת מכך שאולי, במזל, איכשהו, נצליח להגריל מחלק של <span class="math">\(n\)</span> בשלב הראשון של האלגוריתם. כלומר, PP מתארת מקרים שבהם יש לנו ולו סיכוי אפסי ואזוטרי לשפר את האמינות שלנו בעזרת הגרלה.</p>
<p>בפועל, אלגוריתמים כאלו אינם טובים מספיק. אנחנו לא רוצים ודאות של כמעט <span class="math">\(\frac{1}{2}\)</span>. לכן ל-PP יש חשיבות תיאורטית, אבל היא לא באמת נתפסת כמייצגת חישובים הסתברותיים "אמיתיים". בשביל זה ישנה מחלקה אחרת - BPP (ה-B שנתווסף הוא בא לציין Bounded). ההגדרה המקובלת דורשת מאלגוריתם BPP לטעות בהסתברות לכל היותר <span class="math">\(\frac{1}{3}\)</span> על כל קלט, אבל <span class="math">\(\frac{1}{3}\)</span> הוא מספר שרירותי יחסית; כל מספר <span class="math">\(p<\frac{1}{2}\)</span> היה מספיק טוב לצרכנו. אם אתם תוהים מה ההבדל בין זה ובין PP, הוא נעוץ בכך ש-<span class="math">\(p\)</span> הוא קבוע ואינו תלוי בקלט; בעוד שאלגוריתם PP עשוי לטעות בהסתברויות שהולכות ומתקרבות עוד ועוד לחצי, אלגוריתם BPP אף פעם לא יעבור את החסם של <span class="math">\(p\)</span>. ועם זאת, על פניו גם זה לא מועיל לכלום - מה אני צריך אלגוריתם שצודק בהסתברות <span class="math">\(\frac{51}{100}\)</span> בלבד? התשובה לכך היא לב-לבה של הסיבה מדוע אלגוריתמי מונטה-קרלו הם אחלה של דבר: ניפוח.</p>
<p>נדגים זאת על אלגוריתם מילר-רבין תחילה. אם הקלט של מילר-רבין הוא מספר ראשוני, ההסתברות שהאלגוריתם יטעה היא 0. הוא <strong>תמיד</strong> יענה את התשובה הנכונה. אם לעומת זאת הקלט הוא מספר פריק, אז יש הסתברות של <span class="math">\(\frac{1}{4}\)</span> שהאלגוריתם יטעה. לאלגוריתם כמו זה, שיש לו טעות רק על סוג אחד של קלטים (במקרה הזה, אלו שצריך להחזיר עליהם תשובת "לא"), קוראים "אלגוריתם הסתברותי עם טעות חד צדדית" וגם להם יש מחלקות משל עצמם (RP ו-coRP) אבל לא ניכנס לזה - לצורך העניין, מספיק לראות שהאלגוריתם עונה לתנאים של BPP.</p>
<p>כעת, מה קורה אם בהינתן מספר <span class="math">\(n\)</span>, אני פועל באופן הבא: במקום להריץ עליו את מילר-רבין וזהו, אני מריץ עליו את מילר-רבין <strong>פעמיים</strong>. אם בשתי הפעמים מילר-רבין אמר שהמספר ראשוני, אני מקבל זאת ומתייחס למספר כאל ראשוני, אבל אם הוא אמר ולו באחת מהפעמים שהמספר פריק, אני מתייחס למספר כאל פריק. מה ההסתברות שאני טועה?</p>
<p>ובכן, אם המספר ראשוני, אז מילר-רבין <strong>תמיד</strong> יחזיר "ראשוני", לא משנה כמה פעמים נריץ אותו; ולכן ההסתברות שלי לטעות היא 0. אם לעומת זאת המספר פריק, אז ההסתברות של מילר רבין להחזיר "ראשוני" בהרצה הראשונה היא <span class="math">\(\frac{1}{4}\)</span>; וההסתברות שלו להחזיר "ראשוני" בהרצה השנייה היא גם כן <span class="math">\(\frac{1}{4}\)</span>; ושתי ההרצות הללו בלתי תלויות זו בזו; וכדי שאטעה ואחשוב שהמספר ראשוני, שתי ההרצות צריכות להחזיר "ראשוני". לכן ההסתברות שלי לטעות היא מכפלת ההסתברויות הללו - <span class="math">\(\frac{1}{4}\cdot\frac{1}{4}=\frac{1}{16}\)</span>. על ידי הפעלה חוזרת של האלגוריתם הצלחתי לצמצם את הסיכוי לטעות. ולא סתם לצמצם - לצמצם באופן משמעותי. אחרי <span class="math">\(k\)</span> הרצות של האלגוריתם, הסיכוי שלי לטעות יהיה <span class="math">\(\frac{1}{4^{k}}\)</span> - ובג'יבריש מתמטי: די בהגדלה פולינומית של מספר ההפעלות של האלגוריתם, כדי שההסתברות לטעות תדעך אקספוננציאלית. ובמילים פשוטות: בעזרת <strong>מעט</strong> הפעלות חוזרות של האלגוריתם, אני יכול לגרום לצמצום <strong>אדיר</strong> של הטעות. במקרה של מילר-רבין, אחרי ארבע הפעלות שלו ההסתברות לטעות תהיה <span class="math">\(\frac{1}{256}\)</span> - פחות מאחוז אחד. עם זאת, זו עדיין לא טעות שאפשר לחיות איתה, כי היא אומרת שבערך פעם ב-256 בדיקות שאבצע, תהיה לי טעות. לכן עדיף להריץ את האלגוריתם עוד כמה וכמה פעמים - אחרי עשרים הרצות ההסתברות לטעות כבר תהיה אפסית באמת ובתמים: <span class="math">\((1099511627776)^{-1}\)</span>. זה יבטיח לי שגם אם אריץ את האלגוריתם שוב ושוב כל ימי חיי, לא אצפה ממנו לבצע יותר מטעות אחת בכל אותן הרצות. זה גם האופן שבו מילר-רבין ממומש בעולם האמיתי: הוא מורץ מספר פעמים על הקלט, כשהפרנואידים יכולים להגדיל את מספר ההרצות כרצונם.</p>
<p>כשיש לנו אלגוריתם עם הסתברות "דו צדדית" לשגיאה, הניתוח נהיה מסובך בהרבה - במקרה זה צריך להריץ את האלגוריתם מספר רב של פעמים ולהחליט איך לענות על פי "הכרעת הרוב". עם זאת, כדי להוכיח שההסתברות לשגיאה עדיין קטנה בקצב מהיר, כך שניתן לצמצם את השגיאה "ככל שנרצה" מבלי לפגום משמעותית בזמן הריצה של האלגוריתם - כדי לעשות זאת צריך להשתמש בעוד כלים מתמטיים (אי שוויון צ'רנוף) שלא אכנס אליהם כאן. די בכך שאגיד שזה עובד. זו הסיבה שבגללה ה-<span class="math">\(\frac{1}{3}\)</span> בהגדרת BPP הוא שרירותי; אם יש לנו <span class="math">\(p\)</span> אחר, הגדול מ-<span class="math">\(\frac{1}{3}\)</span>, די יהיה במספר לא גדול של הרצות כדי להוריד את הסתברות השגיאה של האלגוריתם אל מתחת ל-<span class="math">\(\frac{1}{3}\)</span> הדרוש. זה לב ההבדל שבין BPP ובין PP; עבור אלגוריתם PP, ניפוח לא תמיד אפשרי - כלומר, הרצות חוזרות ונשנות יקטינו את ההסתברות לשגיאה, אך ייתכן שיהיה צורך ב<strong>יותר מדי הרצות</strong> כדי להקטין את השגיאה אל מתחת לחסם שאנחנו מעוניינים בו, כך שהאלגוריתם ה"מנופח" כבר לא יהיה יעיל.</p>
<p>רק הערה לסיום. השאלה המהותית שמדעני מחשב שואלים את עצמם בכל הנוגע לאלגוריתמים הסתברותיים היא האם אלגוריתמים שכאלו באמת מוסיפים לנו כוח. כלומר, האם לא ניתן לוותר על האקראיות מבלי לפגוע באופן מהותי בזמן הריצה. בעבר, בדיקת ראשוניות היוותה אבן בוחן מעניינת לשאלה הזו, מכיוון שהיו ידועים לה אלגוריתמים הסתברותיים טובים (מילר-רבין הוא רק דוגמה אחת), אך לא היה ידוע אף אלגוריתם לא הסתברותי בעל זמן ריצה סביר שעובד בכל המקרים. בשנת 2002 פרסמו שלושה מדעני מחשב הודים את אלגוריתם AKS (על שם ראשי התיבות של שמם) שענה בדיוק להגדרות הללו והוציא את בדיקת הראשוניות מהמשחק. יתר על כן, הצורה שבה הוא עשה זאת נראית מבטיחה - האלגוריתם במקורו היה הסתברותי, אך החוקרים הצליחו לבצע לו דה-רנדומיזציה - ביטול של הצורך באקראיות על ידי הוכחה שמספיק לבצע "חיפוש ממצה" על חלק מסויים ממרחב האיברים האקראיים האפשריים. אחת מהשאלות המעניינות במדעי המחשב כיום היא האם ניתן לעשות דה-רנדומיזציה דומה לכל האלגוריתמים ה-BPP-ים, והאם קיימות בעיות שניתנות לפתרון יעיל באמצעות אלגוריתם BPP, אך לא קיים להן פתרון דטרמיניסטי יעיל. בדומה לשאלת <span class="math">\(\text{P=NP}\)</span>, הכל עדיין פתוח.</p>
        </article>
        
        <footer>
            <p>© כל הזכויות שמורות לגדי אלכסנדרוביץ'</p>
        </footer>
    </div>

    
    <script>
        function toggleMobileMenu() {
            const navLinks = document.getElementById('navLinks');
            navLinks.classList.toggle('expanded');
        }
        
        function searchPosts() {
            const searchTerm = document.getElementById('searchInput').value;
            if (searchTerm.trim()) {
                window.location.href = '/post_list.html?search=' + encodeURIComponent(searchTerm);
            }
        }
        
        document.getElementById('searchInput').addEventListener('keypress', function(e) {
            if (e.key === 'Enter') {
                searchPosts();
            }
        });
    </script>
    
    
    <!-- Auto-render KaTeX math -->
    <script>
        document.addEventListener("DOMContentLoaded", function() {
            renderMathInElement(document.body, {
                delimiters: [
                    {left: "\\[", right: "\\]", display: true},
                    {left: "\\(", right: "\\)", display: false}
                ],
                throwOnError: false
            });
        });
    </script>

</body>
</html>