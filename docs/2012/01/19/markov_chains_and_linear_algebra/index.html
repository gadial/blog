<!DOCTYPE html>
<html lang="he" dir="rtl"><head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1"><!-- Begin Jekyll SEO tag v2.6.1 -->
<title>איך אלגברה לינארית מתקשרת לשרשראות מרקוב (ואיך כל זה קשור לגוגל) | לא מדויק</title>
<meta name="generator" content="Jekyll v3.8.5" />
<meta property="og:title" content="איך אלגברה לינארית מתקשרת לשרשראות מרקוב (ואיך כל זה קשור לגוגל)" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="לא מדויק - בלוג על מתמטיקה ומדעי המחשב" />
<meta property="og:description" content="לא מדויק - בלוג על מתמטיקה ומדעי המחשב" />
<link rel="canonical" href="http://gadial.net/2012/01/19/markov_chains_and_linear_algebra/" />
<meta property="og:url" content="http://gadial.net/2012/01/19/markov_chains_and_linear_algebra/" />
<meta property="og:site_name" content="לא מדויק" />
<meta property="og:image" content="http://gadial.net/assets/img/main/default-card.png" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2012-01-19T11:18:24+00:00" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:image" content="http://gadial.net/assets/img/main/default-card.png" />
<meta property="twitter:title" content="איך אלגברה לינארית מתקשרת לשרשראות מרקוב (ואיך כל זה קשור לגוגל)" />
<meta name="twitter:site" content="@" />
<script type="application/ld+json">
{"@type":"BlogPosting","url":"http://gadial.net/2012/01/19/markov_chains_and_linear_algebra/","image":"http://gadial.net/assets/img/main/default-card.png","headline":"איך אלגברה לינארית מתקשרת לשרשראות מרקוב (ואיך כל זה קשור לגוגל)","dateModified":"2012-01-19T11:18:24+00:00","datePublished":"2012-01-19T11:18:24+00:00","description":"לא מדויק - בלוג על מתמטיקה ומדעי המחשב","mainEntityOfPage":{"@type":"WebPage","@id":"http://gadial.net/2012/01/19/markov_chains_and_linear_algebra/"},"@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->
<link href="/assets/css/bootstrap.min.css" rel="stylesheet" integrity="sha384-ggOyR0iXCbMQv3Xipma34MD+dH/1fQ784/j6cY/iJTQUOhcWr7x9JvoRxT2MZw1T" crossorigin="anonymous">
  <link rel="stylesheet" href="/assets/css/main.css">
  <link rel="shortcut icon" href="/favicon.ico" type="image/x-icon">
  <link rel="icon" href="/favicon.ico" type="image/x-icon"><link type="application/atom+xml" rel="alternate" href="http://gadial.net/feed.xml" title="לא מדויק" /><script>
if(!(window.doNotTrack === "1" || navigator.doNotTrack === "1" || navigator.doNotTrack === "yes" || navigator.msDoNotTrack === "1")) {
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-3924539-2', 'auto');
  ga('send', 'pageview');
}
</script>
  
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
      tex2jax: {
        processEscapes: true
      },
      TeX: {extensions: ["AMSmath.js","AMSsymbols.js"]},
      "HTML-CSS": { 
        linebreaks: { automatic: true }
      },
      SVG: { 
        linebreaks: { automatic: true } 
      }
    });
  </script>
  <!-- "https://www.gadial.net/wp-includes/js/xypic.js" -->

  <script type="text/javascript" async
    src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML">
  </script>
  
</head>
<body><header>
  <nav class="navbar navbar-expand-md navbar-dark fixed-top bg-dark">
    <a class="navbar-brand" href="/">לא מדויק</a>
    <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation">
      <span class="navbar-toggler-icon"></span>
    </button>
    <div class="collapse navbar-collapse" id="navbarCollapse">
      <ul class="navbar-nav mr-auto">
        
            
            <li class="nav-item">
                <a class="nav-link" href="/lecture_notes">סיכומי הרצאות</a>
            </li>
            
        
            
            <li class="nav-item">
                <a class="nav-link" href="/">דף הבית</a>
            </li>
            
        
            
            <li class="nav-item">
                <a class="nav-link" href="/categories">קטגוריות</a>
            </li>
            
        
            
            <li class="nav-item">
                <a class="nav-link" href="/random">דף אקראי</a>
            </li>
            
        
            
            <li class="nav-item">
                <a class="nav-link" href="/about/">אודות</a>
            </li>
            
        
      </ul>
      <form class="form-inline mt-2 mt-md-0" action="/post_list/" method="get">
        <input class="form-control mr-sm-2" type="text" placeholder="חיפוש" aria-label="חיפוש" name="s">
        <button class="btn btn-outline-success my-2 my-sm-0" type="submit">חיפוש</button>
      </form>
    </div>
  </nav>
</header><main class="page-content" aria-label="Content" role="main">
      <div class="wrapper text-right">
        <article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting"><div class="PageNavigation">
    
      <a class="prev" href="/2012/01/09/primary_decomposition_theorem/">&laquo; משפט הפירוק הפרימרי</a>
    
    
      <a class="next" href="/2012/01/21/cantor_schroeder-_bernstein_theorem/">משפט קנטור-שרדר-ברנשטיין &raquo;</a>
    
  </div><header class="post-header">
    <h1 class="post-title p-name" itemprop="name headline">איך אלגברה לינארית מתקשרת לשרשראות מרקוב (ואיך כל זה קשור לגוגל)</h1>
    <p class="post-meta">
      <time class="dt-published" datetime="2012-01-19T11:18:24+00:00" itemprop="datePublished">Jan 19, 2012
      </time></p>
  </header>

  <div class="post-content e-content" itemprop="articleBody">
    <h2><strong>שרשראות מרקוב</strong></h2>
<p>סדרת הפוסטים על אלגברה לינארית הגיעה במזל טוב לנקודה שבה אפשר לעצור ולעשות סיכומי ביניים לפני שצוללים בחומר הכבד הבא (מכפלות פנימיות), ולכן אני רוצה לנצל את ההזדמנות ולהציג נושא שהזכרתי בחטף קודם ולא דורש ידע באלגברה לינארית שטרם הוצג - שרשראות מרקוב. זה נושא ששייך לתורת ההסתברות ולכן הצגה פורמלית עד הסוף שלו תדרוש ממני לגלוש למונחים בהסתברות שעשויים לחסל קוראים שבסך הכל רוצים לראות שימוש מגניב באלגברה לינארית, ולכן אמנע עד כמה שאפשר מהם. מכיוון שאני עושה רק דברים פשוטים, איכשהו אצא מזה בשלום. או שלא.</p>

<p>שרשרת מרקוב היא מערכת מתמטית שמתארת התפתחות אקראית של תהליך לאורך זמן, בתנאי שלאותו תהליך יש תכונה של “חוסר זכרון” - העתיד של התהליך נקבע (אקראית) רק על פי ההווה, בלי תלות בעבר. ברקע תמיד יש קבוצה (סופית או בת-מניה) של “מצבים” אפשריים שבהם התהליך יכול להימצא בכל רגע נתון, והמצב הבא שאליו התהליך יגיע תלוי אך ורק במצב הנוכחי שלו ולא באופן שבו הוא הגיע למצב זה.</p>

<p>הנה דוגמה פשוטה: נניח שאתם מטילים קוביה שוב ושוב ושוב ולאחר כל הטלה רושמים את הסכום של כל ההטלות עד כה. התהליך הזה הוא שרשרת מרקוב; המצבים מתוארים על ידי הסכום הנוכחי שלכם, כלומר יש מצב לכל מספר טבעי. אם כרגע הסכום שלכם הוא 42, הרי שההסתברות שמכאן תגיעו אל 45 היא <span>\( \frac{1}{6} \)</span> (ההסתברות שיצא לכם בדיוק “3” בהטלת הקוביה), וזה בכלל לא משנה אם הגעתם ל-42 על ידי 7 הטלות רצופות של “6” או על ידי 42 הטלות רצופות של “1” או כל סדרה אחרת של מספרים. מרגע שהגעתם ל-42, ולא משנה איך, המשך התהליך יתנהג (הסתברותית) באותו אופן בדיוק.</p>

<p>ההגדרה נראית פשוטה, אבל היא למעשה חמקמקה למדי כי אפשר למדל באמצעות שרשרת חסרת זכרון גם תהליכים שנראים כאילו הם בעלי זכרון ועוד איך. הנה דוגמה: נניח שאנחנו משנים את חוקי משחק הקוביה שלנו כך שבפעם השניה שבה מוטל “1” הסכום שלנו מתאפס, ולא משנה כמה זמן עבר מאז ההטלה הראשונה של 1 (ואחר כך שוב פעם - אם יוצא 1 ממשיכים כרגיל, אבל אם יוצא 1 לאחר מכן, מאפסים את הסכום וחוזר חלילה). לכאורה יש כאן זכרון ועוד איך; אלא שאפשר למדל את המצבים שלנו בתור <strong>זוגות</strong> מהצורה <span>\( \left(n,a\right) \)</span> כאשר <span>\( n \)</span> הוא מספר טבעי כלשהו - הניקוד שלנו - ו-<span>\( a \)</span> הוא 0 או 1 - משתנה ש”זוכר” אם כבר יצא 1 מאז האיפוס האחרון או לא. די ברור שבהינתן <span>\( \left(n,a\right) \)</span>, המשך התהליך לא תלוי באופן שבו הגענו למצב <span>\( \left(n,a\right) \)</span>, אלא רק במצב זה עצמו. הלקח הוא שעל ידי מידול חכם, אפשר לתאר עם שרשרת מרקוב המון, המון דברים.</p>

<p>יש כמה סוגים שונים של שרשראות מרקוב, כשההבדל המרכזי בתיאוריה הוא בין שרשרת בזמן בדיד - שבה ה”זמן” מתואר על ידי מספרים טבעיים (“הצעד הראשון, הצעד השני, הצעד השלישי…”) לעומת שרשרת בזמן רציף, שבה הזמן הוא מספר ממשי. התיאוריה של המקרה הרציף מורכבת קצת יותר (אם כי דומה לזו של זמן בדיד) ואני לא הולך לדבר עליה בכלל. כמו כן, צריך להבדיל בין שרשראות שמרחב המצבים שלהן סופי, ואלו שמרחב המצבים שלהן אינו סופי (כמו השרשרת של המשחק שהצגתי זה עתה). דוגמה קלאסית לשרשרת עם מרחב מצבים סופי היא משחק “סולמות ונחשים” - המשבצות הן המצבים, ומעבר נקבע בהטלת קוביה (ועל פי הסולמות והנחשים, כמובן).</p>

<p>אני הולך לדבר רק על שרשראות שמרחב המצבים שלהן סופי, כי שרשראות כאלו ניתנות לתיאור באמצעות <strong>מטריצות</strong>. זאת מכיוון שאפשר לחשוב על כל שרשרת מרקוב בזמן בדיד בתור <strong>הילוך בגרף</strong> מכוון, כאשר הצמתים של הגרף הם המצבים של השרשרת, ועל הקשתות יש משקלים שמתאימים להסתברות המעבר בין צומת אחד לשני. לצורך פשטות, מסמנים את המצבים במספרים מ-1 ועד <span>\( n \)</span>, ואז אפשר לתאר את השרשרת בעזרת מטריצה <span>\( P \)</span> מסדר <span>\( n\times n \)</span> כך ש-<span>\( P_{ij} \)</span> היא ההסתברות לעבור מהמצב <span>\( i \)</span> למצב <span>\( j \)</span>. הנה דוגמה לאיך שזה נראה:</p>

<p><strong><a href="/assets/img/2012/01/markov1.png"><img class="alignnone size-full wp-image-1487" title="markov1" alt="" src="/assets/img/2012/01/markov1.png" width="177" height="184" /></a>
</strong></p>

<p>המטריצה המתאימה כאן היא <span>\( P=\left(\begin{array}{ccc}\frac{1}{3} &amp; \frac{1}{3} &amp; \frac{1}{3}\\\frac{1}{2} &amp; 0 &amp; \frac{1}{2}\\1 &amp; 0 &amp; 0\end{array}\right) \)</span>. שימו לב לכך שבמטריצה הזו סכום כל שורה הוא 1. זה לא במקרה; השורה ה-<span>\( i \)</span> מייצגת את ההסתברויות לעבור מ-<span>\( i \)</span> לכל אחד מהמצבים האחרים (או להישאר במקום, מה שממודל בתור מעבר ל-<span>\( i \)</span>). מכיוון שאחד מאלו <strong>חייב</strong> לקרות, סכום כל ההסתברויות הוא בדיוק 1. למטריצה כזו, ששורותיה מסתכמות כולן ל-1, קוראים <strong>מטריצה סטוכסטית</strong>, ועוד נראה חשיבות לתכונה הזו בהמשך.</p>

<p>בפוסט שדיבר על כפל מטריצות הזכרתי את העובדה שאם <span>\( A \)</span> היא מטריצה מייצגת של גרף - כלומר, אם <span>\( A_{ij} \)</span> שווה ל-1 כשיש קשת מ-<span>\( i \)</span> אל <span>\( j \)</span> ו-0 אם אין כזו, אז <span>\( A_{ij}^{k} \)</span> הוא מספר המסלולים מאורך <span>\( k \)</span> מ-<span>\( i \)</span> אל <span>\( j \)</span> בגרף. מאותו נימוק ואותה הוכחה (שלא אכנס לפרטיה כאן אבל היא תרגיל מצויין לספקנים) אפשר לראות ש-<span>\( P_{ij}^{k} \)</span> היא בדיוק ההסתברות לעבור מהמצב <span>\( i \)</span> למצב <span>\( j \)</span> אחרי <span>\( k \)</span> צעדים; כלומר, אם התחלנו את השרשרת שלנו כאשר אנחנו במצב <span>\( i \)</span>, וביצענו <span>\( k \)</span> צעדים, אז ההסתברות שבסוף ההרפתקאה הזו נהיה ב-<span>\( j \)</span> היא בדיוק, אבל בדיוק <span>\( P_{ij}^{k} \)</span>. אני מאוד מקווה שהתוצאה הזו נראית לכם טריוויאלית לחלוטין; עכשיו עצרו לרגע וחשבו שאנחנו חיים בעולם ללא מטריצות וללא כפל מטריצות, וחשבו כיצד בעולם כזה היה נראה התיאור של החישוב של הסתברות המעבר מ-<span>\( i \)</span> אל <span>\( j \)</span> ב-<span>\( k \)</span> צעדים. זו דוגמה נאה לכך שבמתמטיקה ההגדרה הנכונה חשובה לעתים לא פחות מאשר המשפט הנכון - ברגע שרואים משהו מזווית הראייה הנכונה, הכל פתאום פשוט וכל החתיכות נופלות למקום. בדרך כלל אותה זווית ראייה היא משהו שכדי לשלוט בו נדרש קצת מאמץ (לאף אחד מאיתנו כפל מטריצות לא בא בקלות…) ולכן ה<strong>הפשטה</strong> שיש כאן כל כך מועילה - מרגע שהבנו כפל מטריצות, אנחנו מסוגלים באמצעותו להבין המוני בעיות שונות ומשונות שאת כולן ניתן לתרגם לכפל מטריצות, ובכך לחסוך את המאמץ שהיה נדרש מאיתנו להבין כל אחת לחוד.</p>

<p>בואו נניח שאנחנו רוצים לשאול שאלה קצת יותר כללית: “אחרי <span>\( k \)</span> צעדים בשרשרת המרקוב, מה התפלגות המצבים שבהם נהיה?”. למה הכוונה בכך? התשובה הצפויה היא משהו בסגנון “בהסתברות חצי נהיה במצב מס’ 1, בהסתברות שליש במצב 2, ובהסתברות שישית במצב 3”. את זה אפשר לתאר על ידי וקטור עם <span>\( n \)</span> כניסות, <span>\( v \)</span>, כך ש-<span>\( v_{i} \)</span> הוא ההסתברות להיות במצב <span>\( i \)</span>. וקטור כזה יכול לתאר גם את המצב ההתחלתי של השרשרת - אף אחד לא אמר שחייבים להתחיל ממצב אחד ספציפי; אפשר לבחור את המצב שבו מתחילים גם כן באופן מקרי. לכן <span>\( v=\left(\frac{1}{3},\frac{1}{3},\frac{1}{3}\right) \)</span> הוא וקטור שמתאר בחירה של כל מצב בהסתברות אחידה, ו-<span>\( v=\left(0,1,0\right) \)</span> הוא וקטור שמתאר התחלה ודאית במצב 2.</p>

<p>מה שצפוי כעת הוא שיתקיים שאם <span>\( v \)</span> הוא ההתפלגות הנוכחית שלנו בנקודת זמן כלשהי, אז <span>\( Pv \)</span> תהיה ההתפלגות אחרי צעד אחד. רק שזה לא עובד. כדי לראות זאת, בואו נניח ש-<span>\( v=\left(1,0,0\right) \)</span> - התחלה ודאית ממצב 1. נכפול ב-<span>\( P \)</span> שלמעלה, ונקבל <span>\( Pv=\left(1,\frac{1}{2},1\right) \)</span>, שהוא בוודאי לא וקטור שמייצג הסתברות ולא כלום (יש כאן גם עניין לפיו <span>\( v \)</span> הוצג כוקטור שורה ולא עמודה, אבל אני מניח שהפורמליזם הזה לא מפריע לכם). למעשה, אם תחשבו על זה לרגע, לא הייתה שום סיבה להניח שזה יעבוד; האפקט הרצוי מושג דווקא על ידי פעולת כפל מהצד השני, שהיא משהו שפחות ראינו עד היום אבל היא לגיטימית לגמרי לכשעצמה: <span>\( vP=\left(\frac{1}{3},\frac{1}{3},\frac{1}{3}\right) \)</span> - לא במפתיע, השורה הראשונה ב-<span>\( P \)</span> - ולא קשה להוכיח שבאופן כללי כפל משמאל אכן מעביר את ההתפלגות <span>\( v \)</span> להתפלגות הצפויה אחרי צעד אחד. וכמובן, <span>\( vP^{k} \)</span> היא ההתפלגות שאליה מגיעים אחרי <span>\( k \)</span> צעדים אם התחלנו ב-<span>\( v \)</span>.</p>
<h2><strong>ואיך אלגברה לינארית מתקשרת אליהן</strong></h2>
<p>עכשיו בואו נעבור לאקשן. אגנוב דוגמה מהספר של Norris על שרשראות מרקוב פשוט כי היא כל כך מוצלחת. בואו נסתכל על השרשרת הפשוטה הבאה:</p>

<p><strong><a href="/assets/img/2012/01/markov2.png"><img class="alignnone size-full wp-image-1486" title="markov2" alt="" src="/assets/img/2012/01/markov2.png" width="161" height="184" /></a>
</strong></p>

<p>לצורך פשטות לא ציירתי את הקשתות מצומת לעצמו (אפשר להסיק מה הערכים שלהן). המטריצה של השרשרת הזו היא <span>\( P=\left(\begin{array}{ccc}0 &amp; 1 &amp; 0\\0 &amp; \frac{1}{2} &amp; \frac{1}{2}\\\frac{1}{2} &amp; 0 &amp; \frac{1}{2}\end{array}\right) \)</span>. כעת נותנים לנו תרגיל - למצוא נוסחה כללית עבור ההסתברות לפיה אם נתחיל מהמצב <span>\( 1 \)</span>, אז כעבור <span>\( n \)</span> צעדים גם כן נהיה במצב 1. בניסוח מטריציוני, שואלים אותנו מהי <span>\( \left[P^{n}\right]_{11} \)</span>. זוהי שאלת אלגברה לינארית למהדרין, והדרך לפתרון שלה עוברת דרך ערכים עצמיים, אז בואו נתחיל מלמצוא את הערכים העצמיים לפי הספר. כאן יש לנו מזל - המטריצה קטנה, אז קל למצוא את הערכים העצמיים שלה, אבל לפעמים זה יכול להיות קשה למדי. הפולינום האופייני הוא</p>

<p><span>\( \left|\begin{array}{ccc}x &amp; -1 &amp; 0\\0 &amp; x-\frac{1}{2} &amp; -\frac{1}{2}\\-\frac{1}{2} &amp; 0 &amp; x-\frac{1}{2}\end{array}\right|=x\left|\begin{array}{cc}x-\frac{1}{2} &amp; -\frac{1}{2}\\0 &amp; x-\frac{1}{2}\end{array}\right|+\left|\begin{array}{cc}0 &amp; -\frac{1}{2}\\-\frac{1}{2} &amp; x-\frac{1}{2}\end{array}\right| \)</span></p>

<p><span>\( =x\left(x-\frac{1}{2}\right)^{2}-\frac{1}{4}=x^{3}-x^{2}+\frac{1}{4}x-\frac{1}{4}=x^{2}\left(x-1\right)+\frac{1}{4}\left(x-1\right)=\left(x-1\right)\left(x^{2}+\frac{1}{4}\right) \)</span></p>

<p>אם כן, מייד רואים ש-<span>\( 1 \)</span> הוא ערך עצמי, אבל פרט אליו אין ערכים עצמיים ממשיים: שני האחרים הם השורשים של <span>\( x^{2}+\frac{1}{4} \)</span>, כלומר <span>\( \pm\frac{i}{2} \)</span>. הנה צצים לנו מספרים מרוכבים בבעיה ממשית למהדרין, אבל אין כאן שום בעיה.</p>

<p>כעת, שימו לב שכל הערכים העצמיים הם שונים זה מזה, מה שמפשט לנו מאוד את החיים - מכיוון שהפולינום האופייני מתפרק לגורמים לינאריים שונים <span>\( \left(x-1\right)\left(x-\frac{i}{2}\right)\left(x+\frac{i}{2}\right) \)</span> נובע מייד ש-<span>\( P \)</span> לכסינה, כלומר <span>\( P=U^{-1}\left(\begin{array}{ccc}1 &amp; 0 &amp; 0\\0 &amp; \frac{i}{2} &amp; 0\\0 &amp; 0 &amp; -\frac{i}{2}\end{array}\right)U \)</span> עבור איזו <span>\( U \)</span> הפיכה שלא מעניינת אותנו. מכאן נובע מייד ש-<span>\( P^{n}=U^{-1}\left(\begin{array}{ccc}1 &amp; 0 &amp; 0\\0 &amp; \left(\frac{i}{2}\right)^{n} &amp; 0\\0 &amp; 0 &amp; \left(-\frac{i}{2}\right)^{n}\end{array}\right)U \)</span>.</p>

<p>כעת אפשר לחשב ישירות את <span>\( \left[P^{n}\right]_{11} \)</span> על ידי חישוב <span>\( U \)</span> וביצוע הכפל, אבל <span>\( U \)</span> עשויה להיות מכוערת למדי ולא ברור עד כמה זה יוביל אותנו לנוסחה כללית טובה. במקום זאת ננקוט בתעלול אחר: מכיוון ש-<span>\( P^{n} \)</span> מתקבלת על ידי כפל המטריצה האלכסונית מימין ב-<span>\( U \)</span> ומשמאל ב-<span>\( U^{-1} \)</span>, הרי ש-<span>\( \left[P^{n}\right]_{11} \)</span> תהיה צירוף לינארי של הכניסות השונות מאפס של המטריצה האלכסונית (כי זה מה שכפל מטריצות עושה - צירופים לינאריים). לכן <span>\( \left[P^{n}\right]_{11}=\alpha\cdot1+\beta\cdot\left(\frac{i}{2}\right)^{n}+\gamma\left(-\frac{i}{2}\right)^{n} \)</span>. כל שנותר לעשות הוא למצוא את המקדמים <span>\( \alpha,\beta,\gamma \)</span> המתאימים. את זה עושים על ידי חישוב קונקרטי של <span>\( \left[P^{0}\right]_{11},\left[P^{1}\right]_{11},\left[P^{2}\right]_{11} \)</span> והצבה בנוסחה (שאמורה לעבוד לכל <span>\( n \)</span>). קל לראות שהערכים המתאימים הם 1,0,0, כך שקיבלנו את המשוואות:</p>

<p><span>\( \alpha+\beta+\gamma=1 \)</span></p>

<p><span>\( \alpha+\left(\frac{i}{2}\right)\left(\beta-\gamma\right)=0 \)</span></p>

<p><span>\( \alpha-\frac{1}{4}\left(\beta+\gamma\right)=0 \)</span></p>

<p>הפתרון למערכת הזו הוא <span>\( \alpha=\frac{1}{5},\beta=\frac{2}{5}+\frac{1}{5}i,\gamma=\frac{2}{5}-\frac{1}{5}i \)</span>. שימו לב בפרט ש-<span>\( \gamma=\overline{\beta} \)</span> (צמוד מרוכב) וזכרו ש-<span>\( -i=\overline{i} \)</span>, כך שקיבלנו את הפתרון הכללי:</p>

<p><span>\( \left[P^{n}\right]_{11}=\frac{1}{5}+\left(\frac{1}{2}\right)^{n}\left[\beta i^{n}+\overline{\beta i^{n}}\right]=\frac{1}{5}+\left(\frac{1}{2}\right)^{n}\left(2\mbox{Re}\left(\beta i^{n}\right)\right) \)</span></p>

<p>ב-<span>\( i^{n} \)</span> הכי קל לטפל בהצגה קוטבית שלא מצריכה חלוקה למקרים: <span>\( i^{n}=e^{i\frac{\pi}{2}n} \)</span>, ולכן <span>\( \beta i^{n}=\frac{2}{5}e^{i\frac{\pi}{2}n}+\frac{1}{5}ie^{i\frac{\pi}{2}n} \)</span>, ואם זוכרים ש-<span>\( e^{i\theta}=\cos\theta+i\sin\theta \)</span> מקבלים חיש קל ש-<span>\( 2\mbox{Re}\left(\beta i^{n}\right)=\frac{4}{5}\cos\frac{n\pi}{2}-\frac{2}{5}\sin\frac{n\pi}{2} \)</span>, ולכן הפתרון לשאלה הוא:</p>

<p><span>\( \left[P^{n}\right]_{11}=\frac{1}{5}+\left(\frac{1}{2}\right)^{n}\left(\frac{4}{5}\cos\frac{n\pi}{2}-\frac{2}{5}\sin\frac{n\pi}{2}\right) \)</span></p>

<p>השתמשתי כאן בתעלול או שניים כדי לפשט את הפתרון, אבל לא יותר מדי - זו גם שיטת העבודה הכללית. בהערת אגב, אפשר היה לפשט עוד את הפתרון על ידי ביצוע משהו שאולי היה נראה לחלקכם כמו רמאות: כשקיבלתי את נוסחת הנסיגה <span>\( \alpha\cdot1+\beta\cdot\left(\frac{i}{2}\right)^{n}+\gamma\left(-\frac{i}{2}\right)^{n} \)</span> להגיד “בגלל שאנחנו יודעים שהפתרון הוא ממשי, אז אפשר להחליף את הנוסחה הזו בנוסחת הנסיגה <span>\( \alpha+\left(\frac{1}{2}\right)^{n}\left(\beta\cos\frac{n\pi}{2}+\gamma\sin\frac{n\pi}{2}\right) \)</span>”, אבל כמו שאנחנו רואים זה לא משפיע על התוצאה.</p>

<p>טוב, אז מה ראינו כאן? גם אם לא נכנסתם לעובי הפרטים הטכניים, לב העניין כאן היה שהתנהגות המערכת לטווח ארוך - ההסתברות לעבור ממצב <span>\( i \)</span> למצב <span>\( j \)</span> אחרי <span>\( n \)</span> צעדים עבור <span>\( n \)</span> כללי - ניתנה באמצעות צירוף לינארי של חזקות של הערכים העצמיים של המטריצה שמתארת את המערכת. זו המחשה נאה ביותר לאופן שבו הערכים העצמיים של המערכת מתארים אותה, והם בעצם אבן היסוד שמרגע שמגלים אותה, שאר התנהגות המערכת נובעת מאליה. למי שתוהה למה ערכים עצמיים הם מושג כה חשוב ומרכזי - זו התחלה.</p>

<p>בדוגמה שלמעלה היה לנו מזל - המטריצה הייתה <strong>לכסינה</strong>. באופן כללי זה לא כך, ואז התנהגות המערכת שנובעת מהערכים העצמיים מסובכת יותר אבל עדיין ניתנת לתיאור שיטתי באמצעות <strong>צורת ז'ורדן</strong> של מטריצות, שאני מקווה להציג מתישהו. נעזוב את זה לבינתיים.</p>

<p>בואו ננסה עכשיו להבין קצת יותר טוב מה הנוסחה ל-<span>\( \left[P^{n}\right]_{11} \)</span> אומרת: שאחרי <span>\( n \)</span> צעדים, אם התחלנו מהמצב 1, ההסתברות שלנו להיות ב-1 היא חמישית ועוד איזה “גורם כאוטי” שמתואר באמצעות <span>\( \frac{4}{5}\cos\frac{n\pi}{2}-\frac{2}{5}\sin\frac{n\pi}{2} \)</span> (הסינוסים והקוסינוסים מעידים על כך שהגורם הזה הוא <strong>מחזורי</strong>, דבר לא מפתיע בפני עצמו) אבל כזה שההשפעה שלו דועכת אקספוננציאלית עם הזמן, מה שבא לידי ביטוי בכפל ב-<span>\( \left(\frac{1}{2}\right)^{n} \)</span>. פורמלית, בבירור <span>\( \lim_{n\to\infty}\left[P^{n}\right]_{11}=\frac{1}{5} \)</span>, מה שאומר שאנחנו מצפים, אם ניתן למערכת לרוץ זמן ארוך אחרי שהתחילה ממצב 1, להגיע לכך שבכל פרק זמן ההסתברות שהמערכת תהיה במצב 1 היא <span>\( \frac{1}{5} \)</span>, ולכן שבריצה לטווח ארוך המערכת תהיה במצב 1 חמישית מהזמן. עכשיו אני רוצה לדבר על האופן שבו מבצעים ניתוח של “התנהגות לטווח ארוך” שכזו.</p>

<p>לב העניין הוא במה שמכונה “התפלגות אינוריאנטית” (או “שיווי משקל”, או אולי “התפלגות סטציונרית”). בואו נתחיל מלשים לב לכך שהעובדה ש-1 היה ערך עצמי של <span>\( P \)</span> בדוגמה למעלה לא הייתה מקרית. באופן כללי, אם כל השורות של מטריצה מסתכמות לאותו מספר <span>\( a \)</span> (או כל העמודות מסתכמות לאותו מספר <span>\( a \)</span>) אז <span>\( a \)</span> הוא ערך עצמי של המטריצה. דרך אחת לראות זאת היא כך: אם כל השורות של המטריצה <span>\( A \)</span> מסתכמות ל-<span>\( a \)</span> אז <span>\( v=\left(1,1,\dots,1\right) \)</span> הוא וקטור עצמי של המטריצה כי <span>\( Av=\left(a,a,\dots,a\right)=av \)</span> (כי כפל ב-<span>\( v \)</span> פשוט סוכם את כל השורות של <span>\( A \)</span> אחת אחת). אם כל העמודות של <span>\( A \)</span> מסתכמות ל-<span>\( a \)</span> אז מתקיים <span>\( vA=\left(a,a,\dots,a\right) \)</span> אבל לא הגדרנו ערכים עצמיים באמצעות פעולת הכפל משמאל. מצד שני, זה לא משנה כי מתקיים ש-<span>\( vA=\left(Av\right)^{t}=A^{t}v \)</span>, כאשר <span>\( t \)</span> מציין את אופרטור השחלוף: <span>\( \left[A_{ij}^{t}\right]=A_{ji} \)</span> (שיקוף הכניסות של <span>\( A \)</span> ביחס לאלכסון הראשי). לא קשה להוכיח של-<span>\( A \)</span> ול-<span>\( A^{t} \)</span> אותו פולינום אופייני (הפיתוח של הדטרמיננטה יהיה זהה פרט לכך שכאשר מפתחים אחת מהן על פי שורה, את השניה מפתחים על פי עמודה) ולכן אותם ערכים עצמיים.</p>

<p>במקרה שלנו שורות <span>\( P \)</span> מסתכמות ל-1, ולכן תמיד יתקיים ש-<span>\( P\cdot\left(1,\dots,1\right)=\left(1,\dots,1\right) \)</span> ולכן 1 הוא ערך עצמי של <span>\( P \)</span>. מה שזה אומר הוא שקיים וקטור <span>\( v \)</span> שמקיים <span>\( vP=v \)</span> גם בכפל <strong>משמאל</strong>; הוקטור הזה כלל לא צריך להיות דומה ל-<span>\( \left(1,\dots,1\right) \)</span>. בואו נגלה אותו עבור <span>\( P \)</span> של הדוגמה שלנו; אנחנו רוצים לפתור את מערכת המשוואות <span>\( \left(\begin{array}{ccc}-1 &amp; 0 &amp; \frac{1}{2}\\1 &amp; -\frac{1}{2} &amp; 0\\0 &amp; \frac{1}{2} &amp; -\frac{1}{2}\end{array}\right)v=0 \)</span> (שחלפתי את <span>\( P \)</span> והפחתתי 1 מהאלכסון הראשי). קצת דירוג מטריצות ונקבל <span>\( \left(\begin{array}{ccc}1 &amp; 0 &amp; -\frac{1}{2}\\0 &amp; 1 &amp; -1\\0 &amp; 0 &amp; 0\end{array}\right)v=0 \)</span>, כלומר הצורה הכללית של הפתרון <span>\( v \)</span> היא <span>\( v=\left(\frac{1}{2}\alpha,\alpha,\alpha\right) \)</span> עבור פרמטר <span>\( \alpha \)</span> כלשהו.</p>

<p>מבין כל הוקטורים העצמיים <span>\( v \)</span> האפשריים, יש אחד שמעניין אותנו במיוחד: כזה שמייצג <strong>התפלגות מצבים</strong>. כדי שוקטור יקיים את התכונה הזו, הוא צריך להיות <strong>אי שלילי</strong> (כלומר, שכל כניסה בו תהיה גדוהל או שווה מ-0, כי אין אצלנו משמעות להסתברות שלילית), והוא צריך שהכניסות שלו יסתכמו ל-1 (בפועל אפשר לקחת כל וקטור אי שלילי ופשוט לחלק את כל הכניסות שלו בסכום הכניסות). במקרה שלנו מתקבל וקטור התפלגות שכזה עבור <span>\( \alpha=\frac{2}{5} \)</span>: נקבל <span>\( u=\left(\frac{1}{5},\frac{2}{5},\frac{2}{5}\right) \)</span>. ה-<span>\( \frac{1}{5} \)</span> בכניסה הראשונה היא לא מקרית, כפי שאסביר בקרוב.</p>

<p>בואו נבין מה מצאנו כרגע: מצאנו וקטור התפלגויות <span>\( u \)</span> כך ש-<span>\( uP=u \)</span>. כלומר, זוהי התפלגות מצבים שאם השרשרת שלנו הגיעה אליה, היא תישאר בה לעד. כמובן, בכל צעד בשרשרת אנחנו עדיין עוברים ממצב למצב באופן הסתברותי, אבל ההתפלגות הכוללת של כל המצבים שבהם אנו עשויים להיות נותרת ללא שינוי. זה מסביר את התארים של “התפלגות אינוריאנטית/סטציונרית” ו”שיווי משקל”.</p>

<p>התוצאה המעניינת הראשונה על התפלגויות אינוריאנטיות מסבירה את ה-<span>\( \frac{1}{5} \)</span> שקיבלנו ב-<span>\( u \)</span>. אם יש לנו שרשרת מרקוב סופית (הסופיות קריטית פה) כך שעבור מצב <span>\( i \)</span> כלשהו מתקיים ש-<span>\( \lim_{n\to\infty}\left[P_{ij}^{n}\right]=\pi_{j} \)</span> לכל מצב <span>\( j \)</span> (אנו דורשים רק שהגבול יהיה קיים; <span>\( \pi_{j} \)</span> הוא איך אנחנו מסמנים אותו אם הוא קיים) אז הוקטור <span>\( \left(\pi_{1},\pi_{2},\dots,\pi_{k}\right) \)</span> הוא וקטור התפלגות אינוריאנטית. במקרה של <span>\( P \)</span> שלנו אכן מתקיים <span>\( \lim_{n\to\infty}\left[P_{12}^{n}\right]=\lim_{n\to\infty}\left[P_{13}^{n}\right]=\frac{2}{5} \)</span> אבל לא טרחתי לחשב את הנוסחה שלהם כדי לראות זאת.</p>

<p>אם כן, ההתפלגות האינוריאנטית מתארת את ההתנהגות לטווח ארוך של <span>\( P \)</span> אם קיימת כזו - <span>\( P \)</span> “שואפת” להתפלגות האינוריאנטית. השאלה המהותית יותר היא <strong>מתי</strong> התכנסות כזו אכן מובטחת. בואו נראה דוגמה פשוטה ביותר שבה אין התכנסות - שרשרת שבה יש שני מצבים, כך שמכל אחד עוברים לשני בהסתברות אחת. לשרשרת הזו יש את המטריצה <span>\( P=\left(\begin{array}{cc}0 &amp; 1\\1 &amp; 0\end{array}\right) \)</span>. בבירור 1 הוא ערך עצמי של <span>\( P \)</span>. מרחב הוקטורים העצמיים השייכים לערך העצמי 1 נפרש על ידי <span>\( \left(\alpha,\alpha\right) \)</span> ולכן <span>\( \left(\frac{1}{2},\frac{1}{2}\right) \)</span> היא התפלגות אינוריאנטית (חשבו על זה קצת - זה פשוט למדי אחרי שמבינים מה הולך כאן). אלא ש-<span>\( P \)</span> לא מתכנסת לשום מקום; שימו לב ש-<span>\( P^{2}=\left(\begin{array}{cc}1 &amp; 0\\0 &amp; 1\end{array}\right) \)</span> ולכן <span>\( P^{3}=P \)</span>, ובאופן כללי כל כניסה של <span>\( P \)</span> “מזגזגת” בין 0 ו-1 ולכן לא מתכנסת. הבעיה כאן היא בכך שהשרשרת שלנו היא <strong>מחזורית</strong>. אין צורך להסתבך עם הגדרות בעייתיות פה כדי לתאר מחזוריות של תהליך אקראי: די לנו להגדיר ששרשרת היא <strong>לא מחזורית</strong> אם <span>\( \left[P^{n}\right]_{ii}&gt;0 \)</span> עבור <span>\( n \)</span> גדול דיו לכל <span>\( i \)</span> (אפשר לראות שהגדרה זו שקולה לדרישה שהמחלק המשותף הגדול ביותר של קבוצת ה-<span>\( n \)</span>-ים שעבורם <span>\( \left[P^{n}\right]_{ii}&gt;0 \)</span> עבור <span>\( i \)</span> מסויים הוא 1).</p>

<p>אפשר היה אולי לחשוב שמספיק לדרוש שמצב אחד בלבד יהיה לא מחזורי, ואז אי-המחזוריות שלו “תפעפע” לשאר המחרוזת. זה גם נכון, בתנאי שלא ניתן לפרק את המחרוזת ל”רכיבי קשירות” שלא מתקשרים זה עם זה. מבלי להיכנס יותר מדי להגדרות הפורמליות, שרשרת מרקוב היא <strong>בלתי פריקה</strong> אם לכל מצב <span>\( i \)</span> ולכל מצב <span>\( j \)</span>, אם התחלנו מ-<span>\( i \)</span> יש לנו סיכוי להגיע מתישהו ל-<span>\( j \)</span> (קצת יותר פורמלית, <span>\( \left[P^{n}\right]_{ij}&gt;0 \)</span> עבור <span>\( n \)</span> גדול דיו). אפשר להראות ששרשרת מרקוב שיש בה מצב אחד בלבד שהוא אי מחזורי והיא אי פריקה תהיה אי מחזורית בכל המצבים שלה.</p>

<p>כעת אפשר לנסח את מה שהוא כנראה המשפט החשוב ביותר בכל הפוסט: אם נתונה לנו שרשרת מרקוב אי מחזוריות ובלתי פריקה (לא בהכרח סופית!) וקיימת לה התפלגות אינוריאנטית <span>\( \pi=\left(\pi_{1},\dots,\pi_{k}\right) \)</span>, אז בלתי תלות בשאלה מה ההתפלגות שבה מתחילים את ריצת השרשרת, לכל מצב <span>\( j \)</span> ההסתברות שהשרשרת תהיה ב-<span>\( j \)</span> בצעד ה-<span>\( n \)</span> שואפת ל-<span>\( \pi_{j} \)</span> כאשר <span>\( n \)</span> שואף לאינסוף (<span>\( \lim_{n\to\infty}\mbox{P}\left(X_{n}=j\right)=\pi_{j} \)</span> כאשר <span>\( X_{n} \)</span> הוא המשתנה המקרי שמתאים ל”המצב של השרשרת בזמן <span>\( n \)</span>”). בפרט זה אומר ש-<span>\( \lim_{n\to\infty}\left[P^{n}\right]_{ij}=\pi_{j} \)</span> לכל <span>\( i,j \)</span>. פירוש הדבר הוא שבשרשראות אי מחזוריות ובלתי פריקות, ההתפלגות האינוריאנטית של השרשרת מתארת בדיוק את ההתנהגות לטווח ארוך שלה. ההוכחה של המשפט היא מקסימה גם היא אבל אינה פשוטה ולא אציג אותה כעת.</p>
<h2><strong>ואיך כל זה קשור לגוגל</strong></h2>
<p>לסיום הפוסט אני רוצה להסביר איך כל זה קשור לגוגל. בשנת 1998 פרסמו סרגיי ברין ולארי פייג’, מייסדי גוגל, מאמר (שהיה תוצאה של פרוייקט שעשו באוניברסיטת סטנפורד) שהציע שיטת דירוג עמודי אינטרנט שנקראה PageRank (על שם לארי פייג’, לא בגלל ש-Page הוא דף). כמובן, גוגל הוא הרבה יותר מאשר רק השיטה הזו, ומנוע החיפוש האמיתי של גוגל משתמש באינספור הרחבות, וריאציות ותיקונים על השיטה הזו, אבל הרעיון הבסיסי בשיטה הוא חזק לכשעצמו ואציג רק אותו.</p>

<p>אנחנו רוצים לדרג דפים לפי ה”חשיבות” שלהם, אבל איך קובעים מתי דף הוא חשוב? ברין ופייג’ הציעו את ההגדרה המטופשת “דף חשוב הוא דף שהרבה דפים חשובים מקשרים אליו”. מטופשת, כי היא נראית מעגלית וחסרת טעם. אלא שהיא בכלל לא מטופשת.</p>

<p>פורמלית, אצל ברין ופייג’ ה-PageRank של דף הוא סכום על ה-PageRank של הדפים שמקשרים, כאשר לכל דף שמקשר אליו אותו PageRank מחולק במספר הדפים שאליהם אותו דף מקשר. בנוסף לכך יש איזה פרמטר <span>\( d \)</span> שתכף אסביר את חשיבותו. הנוסחה של ברין ופייג’ היא</p>

<p><span>\( \mbox{PR}\left(A\right)=\frac{1-d}{N}+d\sum_{T_{i}}\frac{\mbox{PR}\left(T_{i}\right)}{C\left(T_{i}\right)} \)</span></p>

<p>כאשר <span>\( N \)</span> הוא מספר הדפים הכולל באינטרנט (ליתר דיוק - באוסף הדפים שעבורם מחשבים את PageRank) הסכום רץ על כל הדפים <span>\( T_{i} \)</span> שמקשרים ל-<span>\( A \)</span>, ו-<span>\( C\left(T_{i}\right) \)</span> הוא מספר הלינקים הכולל שיוצא מ-<span>\( T_{i} \)</span>. הגדרה מעגלית, אבל בכלל לא בעייתית. הנקודה היא שזה בדיוק מה שמקבלים אם ממדלים גלישה באינטרנט בתור שרשרת מרקוב.</p>

<p>הרעיון הוא לחשוב על האינטרנט בתור גרף אחד גדול, שבו כל דף הוא צומת, ויש קשת מדף א’ לדף ב’ אם דף א’ מקשר אל דף ב’. כעת אנחנו חושבים על שרשרת מרקוב שבה המשתמש מטייל בגרף. בכל פעם שבה הוא בצומת מסויים, הוא בוחר את הצומת הבא לעבור אליו בהסתברות שווה מבין כל הצמתים שניתן להגיע אליהם מהצומת הנוכחי. כמו כן, בהסתברות <span>\( 1-d \)</span> (אצל ברין ופייג’ <span>\( d \)</span> נקבע ל-<span>\( 0.85 \)</span> בתחילה) המשתמש “ישתעמם” ופשוט יעבור לדף אחר באינטרנט (כולו!) באופן אקראי. אני משאיר לכם לחשוב איך אפשר לתאר את כל זה פורמלית בתור שרשרת מרקוב - זה לא קשה.</p>

<p>אין ספק שיש לנו כאן תיאור נאיבי ביותר של האופן שבו אנשים גולשים באינטרנט, אבל אפשר לשפר אותו אם יש בכך צורך (למשל, שלא כל הלינקים בתוך עמוד יקבלו משקל זהה), וגם בגרסתו הבסיסית התיאור הזה נותן תוצאות מועילות למדי. כעת, שימו לב ששרשרת המרקוב הזו היא אי מחזורית (כי תמיד יש סיכוי שתחזור לדף שהתחלת ממנו - אפילו אחרי צעד אחד אם אתה “משתעמם”) ואי פריקה (שוב, ה”שיעמום” מבטיח שתוכל להגיע לכל דף מכל דף אחר בהסתברות נמוכה כלשהי). לכן היא מתכנסת להתפלגות אינוריאנטית - ומה זו ההתפלגות האינוריאנטית הזו? ניחשתם נכון, קל לראות ש-<span>\( \mbox{PR}\left(A\right) \)</span> היא בדיוק התפלגות אינוריאנטית של השרשרת הזו. המעגליות של ההגדרה נפתרה: זו בדיוק אותה מעגליות שיש בהגדרה בסגנון “<span>\( Av=v \)</span>” - אם <span>\( A \)</span> נתונה, כמובן שזו לא הגדרה מעגלית של <span>\( v \)</span> כלל.</p>

<p>בקיצור, <span>\( \mbox{PR}\left(A\right) \)</span> מתאים בדיוק להתנהגות לטווח ארוך של גולש אקראי במודל הגלישה שהצענו. מבחינה אינטואיטיבית המודל הזה קורץ למדי. עם זאת, עוד לא הבהרנו שתי נקודות חשובות: ראשית, למה בכלל <strong>קיים</strong> וקטור עצמי של 1 שהוא אי-שלילי? כל עוד לא הוכחנו קיום של כזה, לא הוכחנו שיש בכלל פתרון למערכת המשוואות שמגדירה את <span>\( \mbox{PR} \)</span>. שנית, איך מוצאים את הוקטור הזה בפועל? אנחנו מדברים כאן על מטריצות ענקיות (ברין ופייג’ דיברו במאמר על מטריצות מסדר 26 מיליון על 26 מיליון; בפועל כמובן שגוגל מתעסקים עם דברים גדולים יותר).</p>

<p>אלו שאלות טובות והתחום של מציאת ערכים עצמיים למטריצות גדולות הוא חשוב ומעניין ומסובך בפני עצמו ואיני יכול להיכנס אליו יותר מדי כרגע, אבל אני יכול לומר משהו בקיצור: המשפט שמהווה את עמוד השדרה לשיטה של ברין ופייג’ נקרא <strong>משפט פרון-פרובניוס</strong> והוא אחד מעמודי התווך של האלגברה הלינארית. לא אוכל להציג את המשפט בשלמותו (הוא אומר הרבה דברים), אבל אספר את מה שרלוונטי לנו כרגע.</p>

<p>בהינתן מטריצה <span>\( A \)</span> מעל <span>\( \mathbb{R} \)</span> או <span>\( \mathbb{C} \)</span>, <strong>הרדיוס הספקטרלי</strong> שלה <span>\( \rho\left(A\right) \)</span> הוא הערך המוחלט המקסימלי של הערכים העצמיים של <span>\( A \)</span> - אם תרצו, חשבו על זה בתור רדיוס העיגול הקטן ביותר ב-<span>\( \mathbb{C} \)</span> שמרכזו בראשית הצירים ומכיל בתוכו את כל הערכים העצמיים של <span>\( A \)</span> (שהם בסופו של דבר איברים של <span>\( \mathbb{C} \)</span>). שימו לב כי <span>\( \rho\left(A\right) \)</span> הוא תמיד מספר ממשי. כעת, החלק הרלוונטי עבורנו ממשפט פרון-פרובניוס אומר כי אם <span>\( A \)</span> היא מטריצה חיובית (שכל כניסותיה הן מספרים ממשיים גדולים מאפס, כמו במקרה של <span>\( P \)</span> של ברין ופייג’) כך ש-<span>\( r=\rho\left(A\right) \)</span>, אז <span>\( r \)</span> הוא ערך עצמי של <span>\( A \)</span> (זה בפני עצמו לא טריוויאלי; אם <span>\( r=\rho\left(A\right) \)</span> כל מה שאפשר לעשות באופן כללי הוא לומר שקיים ערך עצמי <span>\( \lambda \)</span> - שיכול להיות שלילי או מרוכב - כך ש-<span>\( r=\left|\lambda\right| \)</span>), וכל ערך עצמי אחר של <span>\( A \)</span> הוא קטן ממש בערכו המוחלט מ-<span>\( r \)</span>, וקיים וקטור עצמי של <span>\( r \)</span> (הן מימין והן משמאל) שכל הכניסות שלו חיוביות.</p>

<p>כעת, מה הרדיוס הספקטרלי של מטריצה סטוכסטית כמו אלו שבהן התעסקנו בפוסט הזה? ברור שהוא לפחות 1 כי 1 הוא וקטור עצמי. ממשפט פרון-פרובניוס עולה כי אם 1 הוא לא הרדיוס הספקטרלי אז קיים <span>\( \lambda&gt;1 \)</span> ממשי שגם הוא ערך עצמי, עם וקטור עצמי <span>\( v \)</span> שכל כניסותיו הן ממשיות חיוביות, כלומר <span>\( Av=\lambda v \)</span>. קל מאוד לראות שזה בלתי אפשרי: נניח ש-<span>\( v_{max} \)</span> הוא ערכה של הכניסה הגדולה ביותר ב-<span>\( v \)</span>, אז מכיוון שכל שורה של <span>\( A \)</span> מסתכמת ל-1, רואים מייד שכל כניסה ב-<span>\( Av \)</span> היא לכל היותר <span>\( v_{max} \)</span>, אבל ב-<span>\( \lambda v \)</span> יש כניסה שהיא גדולה ממש מ-<span>\( v_{max} \)</span>. לכן במקרה שלנו הרדיוס הספקטרלי הוא בדיוק 1, ולכן קיים למטריצה וקטור עצמי אי-שלילי עבור הערך העצמי 1, ולכן קיימת התפלגות אינוריאנטית, בדיוק כפי שרצינו (יש עוד דרכים להוכיח את עניין הרדיוס הספקטרלי בלי תותח כבד כמו פרון-פרובניוס, אבל לצרכים שלנו כאן זה הכי התאים).</p>

<p>אם כן, ראינו שהתורה של שרשראות מרקוב (עם מרחב מצבים סופי) קשורה בקשר בל-ינתק לאלגברה לינארית; ראינו איך ערכים עצמיים הם השחקן המרכזי בניתוחים שנובעים מכך; ראינו בחטף משפט מרכזי שעוסק בערכים עצמיים של מטריצות חיוביות - פרון-פרובניוס - ואת האופן שבו הוא, יחד עם התורה של שרשראות מרקוב, משמשים באפליקציות מציאותיות ביותר. זה היה רק קצה הקרחון של השימושים של הנושאים שהזכרתי בפוסט הזה, אבל לטעמי קצה הקרחון הזה לכעצמו מספיק כדי להטביע את הטיטאניק.</p>

  </div>

  <hr />
  <p>
    נהניתם? התעניינתם? אם תרצו, אתם מוזמנים לתת טיפ:
  </p>
  <a href='https://ko-fi.com/H2H5XFBQ' target='_blank'><img height='36' style='border:0px;height:36px;' src='https://az743702.vo.msecnd.net/cdn/kofi2.png?v=2' border='0' alt='Buy Me a Coffee at ko-fi.com' /></a><div class="PageNavigation">
    
      <a class="prev" href="/2012/01/09/primary_decomposition_theorem/">&laquo; משפט הפירוק הפרימרי</a>
    
    
      <a class="next" href="/2012/01/21/cantor_schroeder-_bernstein_theorem/">משפט קנטור-שרדר-ברנשטיין &raquo;</a>
    
  </div><div id="disqus_thread"></div>
  <script>
    var disqus_config = function () {
      this.page.url = 'http://gadial.net/2012/01/19/markov_chains_and_linear_algebra/';
      this.page.identifier = 'http://gadial.net/2012/01/19/markov_chains_and_linear_algebra/';
    };

    (function() {
      var d = document, s = d.createElement('script');

      s.src = 'https://not-precise.disqus.com/embed.js';

      s.setAttribute('data-timestamp', +new Date());
      (d.head || d.body).appendChild(s);
    })();
  </script>
  <noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript" rel="nofollow">comments powered by Disqus.</a></noscript><a class="u-url" href="/2012/01/19/markov_chains_and_linear_algebra/" hidden></a>
</article>

      </div>
    </main><footer class="site-footer h-card">
  <data class="u-url" href="/"></data>

  <div class="wrapper">

    <h2 class="footer-heading">לא מדויק</h2>

    <div class="footer-col-wrapper">
      <div class="footer-col footer-col-1">
        <ul class="contact-list">
          <li class="p-name">לא מדויק</li><li><a class="u-email" href="mailto:gadial@gmail.com">gadial@gmail.com</a></li><li>&copy; כל הזכויות שמורות לגדי אלכסנדרוביץ'</li>
        </ul>
      </div>

      <div class="footer-col footer-col-2"><ul class="social-media-list"><li><a href="https://www.facebook.com/%D7%9C%D7%90-%D7%9E%D7%93%D7%95%D7%99%D7%A7-163347110378474"><svg class="svg-icon"><use xlink:href="/assets/minima-social-icons.svg#facebook"></use></svg> <span class="username">לא מדויק</span></a></li><li><a href="/feed.xml"><svg class="svg-icon"><use xlink:href="/assets/minima-social-icons.svg#rss"></use></svg> <span>RSS</span></a></li></ul>
</div>

      <div class="footer-col footer-col-3">
        <p>בלוג על מתמטיקה ומדעי המחשב</p>
      </div>
    </div>

  </div>

</footer><script src="https://code.jquery.com/jquery-3.3.1.slim.min.js" integrity="sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo" crossorigin="anonymous"></script>
<script>window.jQuery || document.write('<script src="assets/js/jquery-slim.min.js"><\/script>')</script><script src="/assets/js/bootstrap.bundle.js"></script><!-- Default Statcounter code for New blog
http://www.gadial.net/ -->
<script type="text/javascript">
  var sc_project=5444342; 
  var sc_invisible=1; 
  var sc_security="4a89cbe4"; 
  </script>
  <script type="text/javascript"
  src="https://www.statcounter.com/counter/counter.js"
  async></script>
  <noscript><div class="statcounter"><a title="Web Analytics"
  href="https://statcounter.com/" target="_blank"><img
  class="statcounter"
  src="https://c.statcounter.com/5444342/0/4a89cbe4/1/"
  alt="Web Analytics"></a></div></noscript>
  <!-- End of Statcounter Code --></body>

</html>
