<!DOCTYPE html>
<html lang="he" dir="rtl">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>איך אלגברה לינארית מתקשרת לשרשראות מרקוב (ואיך כל זה קשור לגוגל) - לא מדויק</title>
    <link rel="icon" type="image/x-icon" href="/new_blog/favicon.ico">
    
    
    <!-- KaTeX for math rendering -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css">
    <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js"></script>
    <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js"></script>

    
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }
        
        body {
            font-family: 'Arial', 'David', 'Tahoma', sans-serif;
            line-height: 1.6;
            color: #333;
            background-color: #f5f5f5;
        }
        
        /* Top navigation bar */
        .top-nav {
            background: #2c3e50;
            padding: 15px 20px;
            box-shadow: 0 2px 5px rgba(0,0,0,0.1);
        }
        
        .top-nav .nav-container {
            max-width: 1200px;
            margin: 0 auto;
            display: flex;
            align-items: center;
            justify-content: space-between;
            gap: 20px;
        }
        
        .top-nav .site-title {
            font-size: 1.5em;
            font-weight: bold;
            color: white;
            text-decoration: none;
            white-space: nowrap;
        }
        
        .top-nav .nav-links {
            display: flex;
            gap: 20px;
            align-items: center;
            flex-wrap: wrap;
        }
        
        .top-nav .nav-links a {
            color: #ecf0f1;
            text-decoration: none;
            padding: 5px 10px;
            border-radius: 4px;
            transition: background 0.2s;
            white-space: nowrap;
        }
        
        .top-nav .nav-links a:hover {
            background: #34495e;
        }
        
        .top-nav .search-box {
            display: flex;
            gap: 5px;
        }
        
        .top-nav .search-box input {
            padding: 5px 10px;
            border: none;
            border-radius: 4px;
            font-size: 0.9em;
            min-width: 150px;
        }
        
        .top-nav .search-box button {
            padding: 5px 15px;
            background: #3498db;
            color: white;
            border: none;
            border-radius: 4px;
            cursor: pointer;
            transition: background 0.2s;
        }
        
        .top-nav .search-box button:hover {
            background: #2980b9;
        }
        
        /* Hamburger menu button */
        .menu-toggle {
            display: none;
            background: none;
            border: none;
            font-size: 1.8em;
            color: white;
            cursor: pointer;
            padding: 0;
            line-height: 1;
        }
        
        .menu-toggle:hover {
            opacity: 0.8;
        }
        
        /* Mobile responsive */
        @media (max-width: 768px) {
            .top-nav .nav-container {
                flex-direction: column;
                align-items: stretch;
            }
            
            .top-nav .site-title {
                display: flex;
                justify-content: space-between;
                align-items: center;
                margin-bottom: 0;
                padding: 10px 0;
            }
            
            .menu-toggle {
                display: block;
            }
            
            /* Hide nav links by default on mobile */
            .top-nav .nav-links {
                display: none;
                flex-direction: column;
                width: 100%;
                margin-top: 10px;
            }
            
            /* Show when expanded */
            .top-nav .nav-links.expanded {
                display: flex;
            }
            
            .top-nav .nav-links > a {
                text-align: center;
                padding: 12px;
                border-top: 1px solid rgba(255, 255, 255, 0.2);
            }
            
            .top-nav .search-box {
                width: 100%;
                flex-direction: column;
                margin-top: 10px;
                padding-top: 10px;
                border-top: 1px solid rgba(255, 255, 255, 0.2);
            }
            
            .top-nav .search-box input {
                width: 100%;
                margin-bottom: 5px;
                min-width: 0;
            }
            
            .top-nav .search-box button {
                width: 100%;
            }
        }
        
        /* Blockquote styling */
        blockquote {
            background: #f9f9f9;
            border-right: 5px solid #ccc;
            margin: 1.5em 10px;
            padding: 0.75em 16px;
            position: relative;
            font-style: italic;
        }
        
        blockquote:before {
            content: '"';
            position: absolute;
            top: -10px;
            right: 8px;
            font-size: 3.5em;
            color: #ccc;
            line-height: 1;
        }
        
        blockquote p {
            display: block;
            margin: 0 0 0.75em 0;
        }
        
        blockquote p:last-child {
            margin-bottom: 0;
        }
        
        
        body {
            line-height: 1.8;
        }
        
        .container {
            max-width: 800px;
            margin: 20px auto;
            background: white;
            padding: 40px;
            box-shadow: 0 2px 10px rgba(0,0,0,0.1);
            border-radius: 8px;
        }
        
        header {
            margin-bottom: 40px;
            border-bottom: 2px solid #e0e0e0;
            padding-bottom: 20px;
        }
        
        h1 {
            font-size: 2.5em;
            margin-bottom: 10px;
            color: #2c3e50;
        }
        
        .post-meta {
            color: #7f8c8d;
            font-size: 0.9em;
        }
        
        .post-meta .date {
            margin-left: 15px;
        }
        
        .post-meta .categories,
        .post-meta .tags {
            display: inline;
        }
        
        .post-meta .categories a,
        .post-meta .tags a {
            color: #3498db;
            text-decoration: none;
            margin: 0 5px;
        }
        
        .post-meta .categories a:hover,
        .post-meta .tags a:hover {
            text-decoration: underline;
        }
        
        article {
            font-size: 1.1em;
        }
        
        article h2 {
            margin-top: 30px;
            margin-bottom: 15px;
            color: #34495e;
            font-size: 1.8em;
        }
        
        article h3 {
            margin-top: 25px;
            margin-bottom: 12px;
            color: #34495e;
            font-size: 1.4em;
        }
        
        article p {
            margin-bottom: 15px;
            text-align: justify;
        }
        
        article ul, article ol {
            margin-right: 30px;
            margin-bottom: 15px;
        }
        
        article li {
            margin-bottom: 8px;
        }
        
        article code {
            background-color: #f4f4f4;
            padding: 2px 6px;
            border-radius: 3px;
            font-family: 'Courier New', monospace;
            font-size: 0.9em;
        }
        
        article pre {
            background-color: #2d2d2d;
            color: #f8f8f2;
            padding: 15px;
            border-radius: 5px;
            overflow-x: auto;
            margin-bottom: 20px;
            direction: ltr;
            text-align: left;
        }
        
        article pre code {
            background-color: transparent;
            padding: 0;
            color: inherit;
        }
        
        /* Image styles - responsive and contained */
        article img {
            max-width: 100%;
            height: auto;
            display: block;
            margin: 20px auto;
        }
        
        /* Math rendering styles */
        .math {
            direction: ltr;
        }
        
        span.math {
            direction: ltr;
        }
        
        /* Override RTL for KaTeX */
        .katex {
            direction: ltr;
            unicode-bidi: embed;
        }
        
        /* Force KaTeX content to wrap by overriding its internal structure */
        .katex-html {
            display: inline !important;
            white-space: normal !important;
        }
        
        .katex .base {
            display: inline !important;
            white-space: normal !important;
        }
        
        .katex .mord,
        .katex .mbin,
        .katex .mrel,
        .katex .mopen,
        .katex .mclose,
        .katex .mpunct,
        .katex .minner {
            display: inline !important;
            white-space: normal !important;
        }
        
        div.math {
            display: block;
            text-align: center;
            padding: 15px 0;
            direction: ltr;
        }
        
        /* RTL adjustments for code blocks */
        .highlight {
            direction: ltr;
            text-align: left;
        }
        
        footer {
            margin-top: 60px;
            padding-top: 20px;
            border-top: 1px solid #e0e0e0;
            text-align: center;
            color: #95a5a6;
            font-size: 0.9em;
        }
        
        /* Responsive design */
        @media (max-width: 768px) {
            .container {
                padding: 20px;
            }
            
            h1 {
                font-size: 2em;
            }
            
            article {
                font-size: 1em;
            }
            
            /* Hide post navigation on mobile */
            .post-navigation {
                display: none;
            }
        }
        
        /* Post navigation */
        .post-navigation {
            display: flex;
            justify-content: space-between;
            margin-bottom: 30px;
            padding-bottom: 20px;
            border-bottom: 2px solid #e0e0e0;
            gap: 20px;
        }
        
        .post-navigation .nav-link {
            flex: 1;
            text-decoration: none;
            color: #2c3e50;
            padding: 15px;
            background: #f8f9fa;
            border-radius: 5px;
            transition: background 0.2s;
        }
        
        .post-navigation .nav-link:hover {
            background: #e9ecef;
        }
        
        .post-navigation .nav-prev {
            text-align: right;
        }
        
        .post-navigation .nav-next {
            text-align: left;
        }
        
        .post-navigation .nav-label {
            font-size: 0.85em;
            color: #7f8c8d;
            display: block;
            margin-bottom: 5px;
        }
        
        .post-navigation .nav-title {
            font-weight: bold;
            font-size: 1.1em;
        }

    </style>
</head>
<body>
    <nav class="top-nav">
        <div class="nav-container">
            <div class="site-title">
                <a href="/new_blog/" style="color: white; text-decoration: none;">לא מדויק</a>
                <button class="menu-toggle" onclick="toggleMobileMenu()" aria-label="תפריט">
                    ☰
                </button>
            </div>
            <div class="nav-links" id="navLinks">
                <a href="/new_blog/">דף הבית</a>
                <a href="/new_blog/random.html">פוסט אקראי</a>
                <a href="/new_blog/post_list.html">כל הפוסטים</a>
                <div class="search-box">
                    <input type="text" id="searchInput" placeholder="חיפוש...">
                    <button onclick="searchPosts()">חפש</button>
                </div>
            </div>
        </div>
    </nav>
    
    
    <div class="container">
        <!-- Post Navigation -->
        
        <nav class="post-navigation">
            
            <a href="/new_blog/2012/01/09/primary_decomposition_theorem/" class="nav-link nav-prev">
                <span class="nav-label">פוסט ישן יותר →</span>
                <span class="nav-title">משפט הפירוק הפרימרי</span>
            </a>
            

            
            <a href="/new_blog/2012/01/21/cantor_schroeder-_bernstein_theorem/" class="nav-link nav-next">
                <span class="nav-label">← פוסט חדש יותר</span>
                <span class="nav-title">משפט קנטור-שרדר-ברנשטיין</span>
            </a>
            
        </nav>
        
        
        <header>
            <h1>איך אלגברה לינארית מתקשרת לשרשראות מרקוב (ואיך כל זה קשור לגוגל)</h1>
            <div class="post-meta">
                <span class="date">2012-01-19</span>
                
                <span class="categories">
                    | קטגוריות:
                    
                    <a href="/categories/אלגברה לינארית.html">אלגברה לינארית</a>
                    
                    <a href="/categories/הסתברות.html">הסתברות</a>
                    
                </span>
                
                
                <span class="tags">
                    | תגיות:
                    
                    <a href="/tags/PageRank.html">PageRank</a>
                    
                    <a href="/tags/אלגברה לינארית.html">אלגברה לינארית</a>
                    
                    <a href="/tags/המתמטיקה למען האנושות.html">המתמטיקה למען האנושות</a>
                    
                    <a href="/tags/הסתברות.html">הסתברות</a>
                    
                    <a href="/tags/משפט פרון-פרובניוס.html">משפט פרון-פרובניוס</a>
                    
                    <a href="/tags/ערכים עצמיים.html">ערכים עצמיים</a>
                    
                    <a href="/tags/שרשראות מרקוב.html">שרשראות מרקוב</a>
                    
                </span>
                
            </div>
        </header>
        
        <article>
            <h2><strong>שרשראות מרקוב</strong></h2>
<p>סדרת הפוסטים על אלגברה לינארית הגיעה במזל טוב לנקודה שבה אפשר לעצור ולעשות סיכומי ביניים לפני שצוללים בחומר הכבד הבא (מכפלות פנימיות), ולכן אני רוצה לנצל את ההזדמנות ולהציג נושא שהזכרתי בחטף קודם ולא דורש ידע באלגברה לינארית שטרם הוצג - שרשראות מרקוב. זה נושא ששייך לתורת ההסתברות ולכן הצגה פורמלית עד הסוף שלו תדרוש ממני לגלוש למונחים בהסתברות שעשויים לחסל קוראים שבסך הכל רוצים לראות שימוש מגניב באלגברה לינארית, ולכן אמנע עד כמה שאפשר מהם. מכיוון שאני עושה רק דברים פשוטים, איכשהו אצא מזה בשלום. או שלא.</p>
<p>שרשרת מרקוב היא מערכת מתמטית שמתארת התפתחות אקראית של תהליך לאורך זמן, בתנאי שלאותו תהליך יש תכונה של "חוסר זכרון" - העתיד של התהליך נקבע (אקראית) רק על פי ההווה, בלי תלות בעבר. ברקע תמיד יש קבוצה (סופית או בת-מניה) של "מצבים" אפשריים שבהם התהליך יכול להימצא בכל רגע נתון, והמצב הבא שאליו התהליך יגיע תלוי אך ורק במצב הנוכחי שלו ולא באופן שבו הוא הגיע למצב זה.</p>
<p>הנה דוגמה פשוטה: נניח שאתם מטילים קוביה שוב ושוב ושוב ולאחר כל הטלה רושמים את הסכום של כל ההטלות עד כה. התהליך הזה הוא שרשרת מרקוב; המצבים מתוארים על ידי הסכום הנוכחי שלכם, כלומר יש מצב לכל מספר טבעי. אם כרגע הסכום שלכם הוא 42, הרי שההסתברות שמכאן תגיעו אל 45 היא <span class="math">\(\frac{1}{6}\)</span> (ההסתברות שיצא לכם בדיוק "3" בהטלת הקוביה), וזה בכלל לא משנה אם הגעתם ל-42 על ידי 7 הטלות רצופות של "6" או על ידי 42 הטלות רצופות של "1" או כל סדרה אחרת של מספרים. מרגע שהגעתם ל-42, ולא משנה איך, המשך התהליך יתנהג (הסתברותית) באותו אופן בדיוק.</p>
<p>ההגדרה נראית פשוטה, אבל היא למעשה חמקמקה למדי כי אפשר למדל באמצעות שרשרת חסרת זכרון גם תהליכים שנראים כאילו הם בעלי זכרון ועוד איך. הנה דוגמה: נניח שאנחנו משנים את חוקי משחק הקוביה שלנו כך שבפעם השניה שבה מוטל "1" הסכום שלנו מתאפס, ולא משנה כמה זמן עבר מאז ההטלה הראשונה של 1 (ואחר כך שוב פעם - אם יוצא 1 ממשיכים כרגיל, אבל אם יוצא 1 לאחר מכן, מאפסים את הסכום וחוזר חלילה). לכאורה יש כאן זכרון ועוד איך; אלא שאפשר למדל את המצבים שלנו בתור <strong>זוגות</strong> מהצורה <span class="math">\(\left(n,a\right)\)</span> כאשר <span class="math">\(n\)</span> הוא מספר טבעי כלשהו - הניקוד שלנו - ו-<span class="math">\(a\)</span> הוא 0 או 1 - משתנה ש"זוכר" אם כבר יצא 1 מאז האיפוס האחרון או לא. די ברור שבהינתן <span class="math">\(\left(n,a\right)\)</span>, המשך התהליך לא תלוי באופן שבו הגענו למצב <span class="math">\(\left(n,a\right)\)</span>, אלא רק במצב זה עצמו. הלקח הוא שעל ידי מידול חכם, אפשר לתאר עם שרשרת מרקוב המון, המון דברים.</p>
<p>יש כמה סוגים שונים של שרשראות מרקוב, כשההבדל המרכזי בתיאוריה הוא בין שרשרת בזמן בדיד - שבה ה"זמן" מתואר על ידי מספרים טבעיים ("הצעד הראשון, הצעד השני, הצעד השלישי...") לעומת שרשרת בזמן רציף, שבה הזמן הוא מספר ממשי. התיאוריה של המקרה הרציף מורכבת קצת יותר (אם כי דומה לזו של זמן בדיד) ואני לא הולך לדבר עליה בכלל. כמו כן, צריך להבדיל בין שרשראות שמרחב המצבים שלהן סופי, ואלו שמרחב המצבים שלהן אינו סופי (כמו השרשרת של המשחק שהצגתי זה עתה). דוגמה קלאסית לשרשרת עם מרחב מצבים סופי היא משחק "סולמות ונחשים" - המשבצות הן המצבים, ומעבר נקבע בהטלת קוביה (ועל פי הסולמות והנחשים, כמובן).</p>
<p>אני הולך לדבר רק על שרשראות שמרחב המצבים שלהן סופי, כי שרשראות כאלו ניתנות לתיאור באמצעות <strong>מטריצות</strong>. זאת מכיוון שאפשר לחשוב על כל שרשרת מרקוב בזמן בדיד בתור <strong>הילוך בגרף</strong> מכוון, כאשר הצמתים של הגרף הם המצבים של השרשרת, ועל הקשתות יש משקלים שמתאימים להסתברות המעבר בין צומת אחד לשני. לצורך פשטות, מסמנים את המצבים במספרים מ-1 ועד <span class="math">\(n\)</span>, ואז אפשר לתאר את השרשרת בעזרת מטריצה <span class="math">\(P\)</span> מסדר <span class="math">\(n\times n\)</span> כך ש-<span class="math">\(P_{ij}\)</span> היא ההסתברות לעבור מהמצב <span class="math">\(i\)</span> למצב <span class="math">\(j\)</span>. הנה דוגמה לאיך שזה נראה:</p>
<p><strong><a href="/new_blog/img/2012/01/markov1.png"><img class="alignnone size-full wp-image-1487" title="markov1" alt="" src="/new_blog/img/2012/01/markov1.png" width="177" height="184" /></a><br />
</strong></p>
<p>המטריצה המתאימה כאן היא <span class="math">\(P=\left(\begin{array}{ccc}\frac{1}{3} &amp; \frac{1}{3} &amp; \frac{1}{3}\\\frac{1}{2} &amp; 0 &amp; \frac{1}{2}\\1 &amp; 0 &amp; 0\end{array}\right)\)</span>. שימו לב לכך שבמטריצה הזו סכום כל שורה הוא 1. זה לא במקרה; השורה ה-<span class="math">\(i\)</span> מייצגת את ההסתברויות לעבור מ-<span class="math">\(i\)</span> לכל אחד מהמצבים האחרים (או להישאר במקום, מה שממודל בתור מעבר ל-<span class="math">\(i\)</span>). מכיוון שאחד מאלו <strong>חייב</strong> לקרות, סכום כל ההסתברויות הוא בדיוק 1. למטריצה כזו, ששורותיה מסתכמות כולן ל-1, קוראים <strong>מטריצה סטוכסטית</strong>, ועוד נראה חשיבות לתכונה הזו בהמשך.</p>
<p>בפוסט שדיבר על כפל מטריצות הזכרתי את העובדה שאם <span class="math">\(A\)</span> היא מטריצה מייצגת של גרף - כלומר, אם <span class="math">\(A_{ij}\)</span> שווה ל-1 כשיש קשת מ-<span class="math">\(i\)</span> אל <span class="math">\(j\)</span> ו-0 אם אין כזו, אז <span class="math">\(A_{ij}^{k}\)</span> הוא מספר המסלולים מאורך <span class="math">\(k\)</span> מ-<span class="math">\(i\)</span> אל <span class="math">\(j\)</span> בגרף. מאותו נימוק ואותה הוכחה (שלא אכנס לפרטיה כאן אבל היא תרגיל מצויין לספקנים) אפשר לראות ש-<span class="math">\(P_{ij}^{k}\)</span> היא בדיוק ההסתברות לעבור מהמצב <span class="math">\(i\)</span> למצב <span class="math">\(j\)</span> אחרי <span class="math">\(k\)</span> צעדים; כלומר, אם התחלנו את השרשרת שלנו כאשר אנחנו במצב <span class="math">\(i\)</span>, וביצענו <span class="math">\(k\)</span> צעדים, אז ההסתברות שבסוף ההרפתקאה הזו נהיה ב-<span class="math">\(j\)</span> היא בדיוק, אבל בדיוק <span class="math">\(P_{ij}^{k}\)</span>. אני מאוד מקווה שהתוצאה הזו נראית לכם טריוויאלית לחלוטין; עכשיו עצרו לרגע וחשבו שאנחנו חיים בעולם ללא מטריצות וללא כפל מטריצות, וחשבו כיצד בעולם כזה היה נראה התיאור של החישוב של הסתברות המעבר מ-<span class="math">\(i\)</span> אל <span class="math">\(j\)</span> ב-<span class="math">\(k\)</span> צעדים. זו דוגמה נאה לכך שבמתמטיקה ההגדרה הנכונה חשובה לעתים לא פחות מאשר המשפט הנכון - ברגע שרואים משהו מזווית הראייה הנכונה, הכל פתאום פשוט וכל החתיכות נופלות למקום. בדרך כלל אותה זווית ראייה היא משהו שכדי לשלוט בו נדרש קצת מאמץ (לאף אחד מאיתנו כפל מטריצות לא בא בקלות...) ולכן ה<strong>הפשטה</strong> שיש כאן כל כך מועילה - מרגע שהבנו כפל מטריצות, אנחנו מסוגלים באמצעותו להבין המוני בעיות שונות ומשונות שאת כולן ניתן לתרגם לכפל מטריצות, ובכך לחסוך את המאמץ שהיה נדרש מאיתנו להבין כל אחת לחוד.</p>
<p>בואו נניח שאנחנו רוצים לשאול שאלה קצת יותר כללית: "אחרי <span class="math">\(k\)</span> צעדים בשרשרת המרקוב, מה התפלגות המצבים שבהם נהיה?". למה הכוונה בכך? התשובה הצפויה היא משהו בסגנון "בהסתברות חצי נהיה במצב מס' 1, בהסתברות שליש במצב 2, ובהסתברות שישית במצב 3". את זה אפשר לתאר על ידי וקטור עם <span class="math">\(n\)</span> כניסות, <span class="math">\(v\)</span>, כך ש-<span class="math">\(v_{i}\)</span> הוא ההסתברות להיות במצב <span class="math">\(i\)</span>. וקטור כזה יכול לתאר גם את המצב ההתחלתי של השרשרת - אף אחד לא אמר שחייבים להתחיל ממצב אחד ספציפי; אפשר לבחור את המצב שבו מתחילים גם כן באופן מקרי. לכן <span class="math">\(v=\left(\frac{1}{3},\frac{1}{3},\frac{1}{3}\right)\)</span> הוא וקטור שמתאר בחירה של כל מצב בהסתברות אחידה, ו-<span class="math">\(v=\left(0,1,0\right)\)</span> הוא וקטור שמתאר התחלה ודאית במצב 2.</p>
<p>מה שצפוי כעת הוא שיתקיים שאם <span class="math">\(v\)</span> הוא ההתפלגות הנוכחית שלנו בנקודת זמן כלשהי, אז <span class="math">\(Pv\)</span> תהיה ההתפלגות אחרי צעד אחד. רק שזה לא עובד. כדי לראות זאת, בואו נניח ש-<span class="math">\(v=\left(1,0,0\right)\)</span> - התחלה ודאית ממצב 1. נכפול ב-<span class="math">\(P\)</span> שלמעלה, ונקבל <span class="math">\(Pv=\left(1,\frac{1}{2},1\right)\)</span>, שהוא בוודאי לא וקטור שמייצג הסתברות ולא כלום (יש כאן גם עניין לפיו <span class="math">\(v\)</span> הוצג כוקטור שורה ולא עמודה, אבל אני מניח שהפורמליזם הזה לא מפריע לכם). למעשה, אם תחשבו על זה לרגע, לא הייתה שום סיבה להניח שזה יעבוד; האפקט הרצוי מושג דווקא על ידי פעולת כפל מהצד השני, שהיא משהו שפחות ראינו עד היום אבל היא לגיטימית לגמרי לכשעצמה: <span class="math">\(vP=\left(\frac{1}{3},\frac{1}{3},\frac{1}{3}\right)\)</span> - לא במפתיע, השורה הראשונה ב-<span class="math">\(P\)</span> - ולא קשה להוכיח שבאופן כללי כפל משמאל אכן מעביר את ההתפלגות <span class="math">\(v\)</span> להתפלגות הצפויה אחרי צעד אחד. וכמובן, <span class="math">\(vP^{k}\)</span> היא ההתפלגות שאליה מגיעים אחרי <span class="math">\(k\)</span> צעדים אם התחלנו ב-<span class="math">\(v\)</span>.</p>
<h2><strong>ואיך אלגברה לינארית מתקשרת אליהן</strong></h2>
<p>עכשיו בואו נעבור לאקשן. אגנוב דוגמה מהספר של Norris על שרשראות מרקוב פשוט כי היא כל כך מוצלחת. בואו נסתכל על השרשרת הפשוטה הבאה:</p>
<p><strong><a href="/new_blog/img/2012/01/markov2.png"><img class="alignnone size-full wp-image-1486" title="markov2" alt="" src="/new_blog/img/2012/01/markov2.png" width="161" height="184" /></a><br />
</strong></p>
<p>לצורך פשטות לא ציירתי את הקשתות מצומת לעצמו (אפשר להסיק מה הערכים שלהן). המטריצה של השרשרת הזו היא <span class="math">\(P=\left(\begin{array}{ccc}0 &amp; 1 &amp; 0\\0 &amp; \frac{1}{2} &amp; \frac{1}{2}\\\frac{1}{2} &amp; 0 &amp; \frac{1}{2}\end{array}\right)\)</span>. כעת נותנים לנו תרגיל - למצוא נוסחה כללית עבור ההסתברות לפיה אם נתחיל מהמצב <span class="math">\(1\)</span>, אז כעבור <span class="math">\(n\)</span> צעדים גם כן נהיה במצב 1. בניסוח מטריציוני, שואלים אותנו מהי <span class="math">\(\left[P^{n}\right]_{11}\)</span>. זוהי שאלת אלגברה לינארית למהדרין, והדרך לפתרון שלה עוברת דרך ערכים עצמיים, אז בואו נתחיל מלמצוא את הערכים העצמיים לפי הספר. כאן יש לנו מזל - המטריצה קטנה, אז קל למצוא את הערכים העצמיים שלה, אבל לפעמים זה יכול להיות קשה למדי. הפולינום האופייני הוא</p>
<p><span class="math">\(\left|\begin{array}{ccc}x &amp; -1 &amp; 0\\0 &amp; x-\frac{1}{2} &amp; -\frac{1}{2}\\-\frac{1}{2} &amp; 0 &amp; x-\frac{1}{2}\end{array}\right|=x\left|\begin{array}{cc}x-\frac{1}{2} &amp; -\frac{1}{2}\\0 &amp; x-\frac{1}{2}\end{array}\right|+\left|\begin{array}{cc}0 &amp; -\frac{1}{2}\\-\frac{1}{2} &amp; x-\frac{1}{2}\end{array}\right|\)</span></p>
<p><span class="math">\(=x\left(x-\frac{1}{2}\right)^{2}-\frac{1}{4}=x^{3}-x^{2}+\frac{1}{4}x-\frac{1}{4}=x^{2}\left(x-1\right)+\frac{1}{4}\left(x-1\right)=\left(x-1\right)\left(x^{2}+\frac{1}{4}\right)\)</span></p>
<p>אם כן, מייד רואים ש-<span class="math">\(1\)</span> הוא ערך עצמי, אבל פרט אליו אין ערכים עצמיים ממשיים: שני האחרים הם השורשים של <span class="math">\(x^{2}+\frac{1}{4}\)</span>, כלומר <span class="math">\(\pm\frac{i}{2}\)</span>. הנה צצים לנו מספרים מרוכבים בבעיה ממשית למהדרין, אבל אין כאן שום בעיה.</p>
<p>כעת, שימו לב שכל הערכים העצמיים הם שונים זה מזה, מה שמפשט לנו מאוד את החיים - מכיוון שהפולינום האופייני מתפרק לגורמים לינאריים שונים <span class="math">\(\left(x-1\right)\left(x-\frac{i}{2}\right)\left(x+\frac{i}{2}\right)\)</span> נובע מייד ש-<span class="math">\(P\)</span> לכסינה, כלומר <span class="math">\(P=U^{-1}\left(\begin{array}{ccc}1 &amp; 0 &amp; 0\\0 &amp; \frac{i}{2} &amp; 0\\0 &amp; 0 &amp; -\frac{i}{2}\end{array}\right)U\)</span> עבור איזו <span class="math">\(U\)</span> הפיכה שלא מעניינת אותנו. מכאן נובע מייד ש-<span class="math">\(P^{n}=U^{-1}\left(\begin{array}{ccc}1 &amp; 0 &amp; 0\\0 &amp; \left(\frac{i}{2}\right)^{n} &amp; 0\\0 &amp; 0 &amp; \left(-\frac{i}{2}\right)^{n}\end{array}\right)U\)</span>.</p>
<p>כעת אפשר לחשב ישירות את <span class="math">\(\left[P^{n}\right]_{11}\)</span> על ידי חישוב <span class="math">\(U\)</span> וביצוע הכפל, אבל <span class="math">\(U\)</span> עשויה להיות מכוערת למדי ולא ברור עד כמה זה יוביל אותנו לנוסחה כללית טובה. במקום זאת ננקוט בתעלול אחר: מכיוון ש-<span class="math">\(P^{n}\)</span> מתקבלת על ידי כפל המטריצה האלכסונית מימין ב-<span class="math">\(U\)</span> ומשמאל ב-<span class="math">\(U^{-1}\)</span>, הרי ש-<span class="math">\(\left[P^{n}\right]_{11}\)</span> תהיה צירוף לינארי של הכניסות השונות מאפס של המטריצה האלכסונית (כי זה מה שכפל מטריצות עושה - צירופים לינאריים). לכן <span class="math">\(\left[P^{n}\right]_{11}=\alpha\cdot1+\beta\cdot\left(\frac{i}{2}\right)^{n}+\gamma\left(-\frac{i}{2}\right)^{n}\)</span>. כל שנותר לעשות הוא למצוא את המקדמים <span class="math">\(\alpha,\beta,\gamma\)</span> המתאימים. את זה עושים על ידי חישוב קונקרטי של <span class="math">\(\left[P^{0}\right]_{11},\left[P^{1}\right]_{11},\left[P^{2}\right]_{11}\)</span> והצבה בנוסחה (שאמורה לעבוד לכל <span class="math">\(n\)</span>). קל לראות שהערכים המתאימים הם 1,0,0, כך שקיבלנו את המשוואות:</p>
<p><span class="math">\(\alpha+\beta+\gamma=1\)</span></p>
<p><span class="math">\(\alpha+\left(\frac{i}{2}\right)\left(\beta-\gamma\right)=0\)</span></p>
<p><span class="math">\(\alpha-\frac{1}{4}\left(\beta+\gamma\right)=0\)</span></p>
<p>הפתרון למערכת הזו הוא <span class="math">\(\alpha=\frac{1}{5},\beta=\frac{2}{5}+\frac{1}{5}i,\gamma=\frac{2}{5}-\frac{1}{5}i\)</span>. שימו לב בפרט ש-<span class="math">\(\gamma=\overline{\beta}\)</span> (צמוד מרוכב) וזכרו ש-<span class="math">\(-i=\overline{i}\)</span>, כך שקיבלנו את הפתרון הכללי:</p>
<p><span class="math">\(\left[P^{n}\right]_{11}=\frac{1}{5}+\left(\frac{1}{2}\right)^{n}\left[\beta i^{n}+\overline{\beta i^{n}}\right]=\frac{1}{5}+\left(\frac{1}{2}\right)^{n}\left(2\text{Re}\left(\beta i^{n}\right)\right)\)</span></p>
<p>ב-<span class="math">\(i^{n}\)</span> הכי קל לטפל בהצגה קוטבית שלא מצריכה חלוקה למקרים: <span class="math">\(i^{n}=e^{i\frac{\pi}{2}n}\)</span>, ולכן <span class="math">\(\beta i^{n}=\frac{2}{5}e^{i\frac{\pi}{2}n}+\frac{1}{5}ie^{i\frac{\pi}{2}n}\)</span>, ואם זוכרים ש-<span class="math">\(e^{i\theta}=\cos\theta+i\sin\theta\)</span> מקבלים חיש קל ש-<span class="math">\(2\text{Re}\left(\beta i^{n}\right)=\frac{4}{5}\cos\frac{n\pi}{2}-\frac{2}{5}\sin\frac{n\pi}{2}\)</span>, ולכן הפתרון לשאלה הוא:</p>
<p><span class="math">\(\left[P^{n}\right]_{11}=\frac{1}{5}+\left(\frac{1}{2}\right)^{n}\left(\frac{4}{5}\cos\frac{n\pi}{2}-\frac{2}{5}\sin\frac{n\pi}{2}\right)\)</span></p>
<p>השתמשתי כאן בתעלול או שניים כדי לפשט את הפתרון, אבל לא יותר מדי - זו גם שיטת העבודה הכללית. בהערת אגב, אפשר היה לפשט עוד את הפתרון על ידי ביצוע משהו שאולי היה נראה לחלקכם כמו רמאות: כשקיבלתי את נוסחת הנסיגה <span class="math">\(\alpha\cdot1+\beta\cdot\left(\frac{i}{2}\right)^{n}+\gamma\left(-\frac{i}{2}\right)^{n}\)</span> להגיד "בגלל שאנחנו יודעים שהפתרון הוא ממשי, אז אפשר להחליף את הנוסחה הזו בנוסחת הנסיגה <span class="math">\(\alpha+\left(\frac{1}{2}\right)^{n}\left(\beta\cos\frac{n\pi}{2}+\gamma\sin\frac{n\pi}{2}\right)\)</span>", אבל כמו שאנחנו רואים זה לא משפיע על התוצאה.</p>
<p>טוב, אז מה ראינו כאן? גם אם לא נכנסתם לעובי הפרטים הטכניים, לב העניין כאן היה שהתנהגות המערכת לטווח ארוך - ההסתברות לעבור ממצב <span class="math">\(i\)</span> למצב <span class="math">\(j\)</span> אחרי <span class="math">\(n\)</span> צעדים עבור <span class="math">\(n\)</span> כללי - ניתנה באמצעות צירוף לינארי של חזקות של הערכים העצמיים של המטריצה שמתארת את המערכת. זו המחשה נאה ביותר לאופן שבו הערכים העצמיים של המערכת מתארים אותה, והם בעצם אבן היסוד שמרגע שמגלים אותה, שאר התנהגות המערכת נובעת מאליה. למי שתוהה למה ערכים עצמיים הם מושג כה חשוב ומרכזי - זו התחלה.</p>
<p>בדוגמה שלמעלה היה לנו מזל - המטריצה הייתה <strong>לכסינה</strong>. באופן כללי זה לא כך, ואז התנהגות המערכת שנובעת מהערכים העצמיים מסובכת יותר אבל עדיין ניתנת לתיאור שיטתי באמצעות <strong>צורת ז'ורדן</strong> של מטריצות, שאני מקווה להציג מתישהו. נעזוב את זה לבינתיים.</p>
<p>בואו ננסה עכשיו להבין קצת יותר טוב מה הנוסחה ל-<span class="math">\(\left[P^{n}\right]_{11}\)</span> אומרת: שאחרי <span class="math">\(n\)</span> צעדים, אם התחלנו מהמצב 1, ההסתברות שלנו להיות ב-1 היא חמישית ועוד איזה "גורם כאוטי" שמתואר באמצעות <span class="math">\(\frac{4}{5}\cos\frac{n\pi}{2}-\frac{2}{5}\sin\frac{n\pi}{2}\)</span> (הסינוסים והקוסינוסים מעידים על כך שהגורם הזה הוא <strong>מחזורי</strong>, דבר לא מפתיע בפני עצמו) אבל כזה שההשפעה שלו דועכת אקספוננציאלית עם הזמן, מה שבא לידי ביטוי בכפל ב-<span class="math">\(\left(\frac{1}{2}\right)^{n}\)</span>. פורמלית, בבירור <span class="math">\(\lim_{n\to\infty}\left[P^{n}\right]_{11}=\frac{1}{5}\)</span>, מה שאומר שאנחנו מצפים, אם ניתן למערכת לרוץ זמן ארוך אחרי שהתחילה ממצב 1, להגיע לכך שבכל פרק זמן ההסתברות שהמערכת תהיה במצב 1 היא <span class="math">\(\frac{1}{5}\)</span>, ולכן שבריצה לטווח ארוך המערכת תהיה במצב 1 חמישית מהזמן. עכשיו אני רוצה לדבר על האופן שבו מבצעים ניתוח של "התנהגות לטווח ארוך" שכזו.</p>
<p>לב העניין הוא במה שמכונה "התפלגות אינוריאנטית" (או "שיווי משקל", או אולי "התפלגות סטציונרית"). בואו נתחיל מלשים לב לכך שהעובדה ש-1 היה ערך עצמי של <span class="math">\(P\)</span> בדוגמה למעלה לא הייתה מקרית. באופן כללי, אם כל השורות של מטריצה מסתכמות לאותו מספר <span class="math">\(a\)</span> (או כל העמודות מסתכמות לאותו מספר <span class="math">\(a\)</span>) אז <span class="math">\(a\)</span> הוא ערך עצמי של המטריצה. דרך אחת לראות זאת היא כך: אם כל השורות של המטריצה <span class="math">\(A\)</span> מסתכמות ל-<span class="math">\(a\)</span> אז <span class="math">\(v=\left(1,1,\dots,1\right)\)</span> הוא וקטור עצמי של המטריצה כי <span class="math">\(Av=\left(a,a,\dots,a\right)=av\)</span> (כי כפל ב-<span class="math">\(v\)</span> פשוט סוכם את כל השורות של <span class="math">\(A\)</span> אחת אחת). אם כל העמודות של <span class="math">\(A\)</span> מסתכמות ל-<span class="math">\(a\)</span> אז מתקיים <span class="math">\(vA=\left(a,a,\dots,a\right)\)</span> אבל לא הגדרנו ערכים עצמיים באמצעות פעולת הכפל משמאל. מצד שני, זה לא משנה כי מתקיים ש-<span class="math">\(vA=\left(Av\right)^{t}=A^{t}v\)</span>, כאשר <span class="math">\(t\)</span> מציין את אופרטור השחלוף: <span class="math">\(\left[A_{ij}^{t}\right]=A_{ji}\)</span> (שיקוף הכניסות של <span class="math">\(A\)</span> ביחס לאלכסון הראשי). לא קשה להוכיח של-<span class="math">\(A\)</span> ול-<span class="math">\(A^{t}\)</span> אותו פולינום אופייני (הפיתוח של הדטרמיננטה יהיה זהה פרט לכך שכאשר מפתחים אחת מהן על פי שורה, את השניה מפתחים על פי עמודה) ולכן אותם ערכים עצמיים.</p>
<p>במקרה שלנו שורות <span class="math">\(P\)</span> מסתכמות ל-1, ולכן תמיד יתקיים ש-<span class="math">\(P\cdot\left(1,\dots,1\right)=\left(1,\dots,1\right)\)</span> ולכן 1 הוא ערך עצמי של <span class="math">\(P\)</span>. מה שזה אומר הוא שקיים וקטור <span class="math">\(v\)</span> שמקיים <span class="math">\(vP=v\)</span> גם בכפל <strong>משמאל</strong>; הוקטור הזה כלל לא צריך להיות דומה ל-<span class="math">\(\left(1,\dots,1\right)\)</span>. בואו נגלה אותו עבור <span class="math">\(P\)</span> של הדוגמה שלנו; אנחנו רוצים לפתור את מערכת המשוואות <span class="math">\(\left(\begin{array}{ccc}-1 &amp; 0 &amp; \frac{1}{2}\\1 &amp; -\frac{1}{2} &amp; 0\\0 &amp; \frac{1}{2} &amp; -\frac{1}{2}\end{array}\right)v=0\)</span> (שחלפתי את <span class="math">\(P\)</span> והפחתתי 1 מהאלכסון הראשי). קצת דירוג מטריצות ונקבל <span class="math">\(\left(\begin{array}{ccc}1 &amp; 0 &amp; -\frac{1}{2}\\0 &amp; 1 &amp; -1\\0 &amp; 0 &amp; 0\end{array}\right)v=0\)</span>, כלומר הצורה הכללית של הפתרון <span class="math">\(v\)</span> היא <span class="math">\(v=\left(\frac{1}{2}\alpha,\alpha,\alpha\right)\)</span> עבור פרמטר <span class="math">\(\alpha\)</span> כלשהו.</p>
<p>מבין כל הוקטורים העצמיים <span class="math">\(v\)</span> האפשריים, יש אחד שמעניין אותנו במיוחד: כזה שמייצג <strong>התפלגות מצבים</strong>. כדי שוקטור יקיים את התכונה הזו, הוא צריך להיות <strong>אי שלילי</strong> (כלומר, שכל כניסה בו תהיה גדוהל או שווה מ-0, כי אין אצלנו משמעות להסתברות שלילית), והוא צריך שהכניסות שלו יסתכמו ל-1 (בפועל אפשר לקחת כל וקטור אי שלילי ופשוט לחלק את כל הכניסות שלו בסכום הכניסות). במקרה שלנו מתקבל וקטור התפלגות שכזה עבור <span class="math">\(\alpha=\frac{2}{5}\)</span>: נקבל <span class="math">\(u=\left(\frac{1}{5},\frac{2}{5},\frac{2}{5}\right)\)</span>. ה-<span class="math">\(\frac{1}{5}\)</span> בכניסה הראשונה היא לא מקרית, כפי שאסביר בקרוב.</p>
<p>בואו נבין מה מצאנו כרגע: מצאנו וקטור התפלגויות <span class="math">\(u\)</span> כך ש-<span class="math">\(uP=u\)</span>. כלומר, זוהי התפלגות מצבים שאם השרשרת שלנו הגיעה אליה, היא תישאר בה לעד. כמובן, בכל צעד בשרשרת אנחנו עדיין עוברים ממצב למצב באופן הסתברותי, אבל ההתפלגות הכוללת של כל המצבים שבהם אנו עשויים להיות נותרת ללא שינוי. זה מסביר את התארים של "התפלגות אינוריאנטית/סטציונרית" ו"שיווי משקל".</p>
<p>התוצאה המעניינת הראשונה על התפלגויות אינוריאנטיות מסבירה את ה-<span class="math">\(\frac{1}{5}\)</span> שקיבלנו ב-<span class="math">\(u\)</span>. אם יש לנו שרשרת מרקוב סופית (הסופיות קריטית פה) כך שעבור מצב <span class="math">\(i\)</span> כלשהו מתקיים ש-<span class="math">\(\lim_{n\to\infty}\left[P_{ij}^{n}\right]=\pi_{j}\)</span> לכל מצב <span class="math">\(j\)</span> (אנו דורשים רק שהגבול יהיה קיים; <span class="math">\(\pi_{j}\)</span> הוא איך אנחנו מסמנים אותו אם הוא קיים) אז הוקטור <span class="math">\(\left(\pi_{1},\pi_{2},\dots,\pi_{k}\right)\)</span> הוא וקטור התפלגות אינוריאנטית. במקרה של <span class="math">\(P\)</span> שלנו אכן מתקיים <span class="math">\(\lim_{n\to\infty}\left[P_{12}^{n}\right]=\lim_{n\to\infty}\left[P_{13}^{n}\right]=\frac{2}{5}\)</span> אבל לא טרחתי לחשב את הנוסחה שלהם כדי לראות זאת.</p>
<p>אם כן, ההתפלגות האינוריאנטית מתארת את ההתנהגות לטווח ארוך של <span class="math">\(P\)</span> אם קיימת כזו - <span class="math">\(P\)</span> "שואפת" להתפלגות האינוריאנטית. השאלה המהותית יותר היא <strong>מתי</strong> התכנסות כזו אכן מובטחת. בואו נראה דוגמה פשוטה ביותר שבה אין התכנסות - שרשרת שבה יש שני מצבים, כך שמכל אחד עוברים לשני בהסתברות אחת. לשרשרת הזו יש את המטריצה <span class="math">\(P=\left(\begin{array}{cc}0 &amp; 1\\1 &amp; 0\end{array}\right)\)</span>. בבירור 1 הוא ערך עצמי של <span class="math">\(P\)</span>. מרחב הוקטורים העצמיים השייכים לערך העצמי 1 נפרש על ידי <span class="math">\(\left(\alpha,\alpha\right)\)</span> ולכן <span class="math">\(\left(\frac{1}{2},\frac{1}{2}\right)\)</span> היא התפלגות אינוריאנטית (חשבו על זה קצת - זה פשוט למדי אחרי שמבינים מה הולך כאן). אלא ש-<span class="math">\(P\)</span> לא מתכנסת לשום מקום; שימו לב ש-<span class="math">\(P^{2}=\left(\begin{array}{cc}1 &amp; 0\\0 &amp; 1\end{array}\right)\)</span> ולכן <span class="math">\(P^{3}=P\)</span>, ובאופן כללי כל כניסה של <span class="math">\(P\)</span> "מזגזגת" בין 0 ו-1 ולכן לא מתכנסת. הבעיה כאן היא בכך שהשרשרת שלנו היא <strong>מחזורית</strong>. אין צורך להסתבך עם הגדרות בעייתיות פה כדי לתאר מחזוריות של תהליך אקראי: די לנו להגדיר ששרשרת היא <strong>לא מחזורית</strong> אם <span class="math">\(\left[P^{n}\right]_{ii}&amp;gt;0\)</span> עבור <span class="math">\(n\)</span> גדול דיו לכל <span class="math">\(i\)</span> (אפשר לראות שהגדרה זו שקולה לדרישה שהמחלק המשותף הגדול ביותר של קבוצת ה-<span class="math">\(n\)</span>-ים שעבורם <span class="math">\(\left[P^{n}\right]_{ii}&amp;gt;0\)</span> עבור <span class="math">\(i\)</span> מסויים הוא 1).</p>
<p>אפשר היה אולי לחשוב שמספיק לדרוש שמצב אחד בלבד יהיה לא מחזורי, ואז אי-המחזוריות שלו "תפעפע" לשאר המחרוזת. זה גם נכון, בתנאי שלא ניתן לפרק את המחרוזת ל"רכיבי קשירות" שלא מתקשרים זה עם זה. מבלי להיכנס יותר מדי להגדרות הפורמליות, שרשרת מרקוב היא <strong>בלתי פריקה</strong> אם לכל מצב <span class="math">\(i\)</span> ולכל מצב <span class="math">\(j\)</span>, אם התחלנו מ-<span class="math">\(i\)</span> יש לנו סיכוי להגיע מתישהו ל-<span class="math">\(j\)</span> (קצת יותר פורמלית, <span class="math">\(\left[P^{n}\right]_{ij}&amp;gt;0\)</span> עבור <span class="math">\(n\)</span> גדול דיו). אפשר להראות ששרשרת מרקוב שיש בה מצב אחד בלבד שהוא אי מחזורי והיא אי פריקה תהיה אי מחזורית בכל המצבים שלה.</p>
<p>כעת אפשר לנסח את מה שהוא כנראה המשפט החשוב ביותר בכל הפוסט: אם נתונה לנו שרשרת מרקוב אי מחזוריות ובלתי פריקה (לא בהכרח סופית!) וקיימת לה התפלגות אינוריאנטית <span class="math">\(\pi=\left(\pi_{1},\dots,\pi_{k}\right)\)</span>, אז בלתי תלות בשאלה מה ההתפלגות שבה מתחילים את ריצת השרשרת, לכל מצב <span class="math">\(j\)</span> ההסתברות שהשרשרת תהיה ב-<span class="math">\(j\)</span> בצעד ה-<span class="math">\(n\)</span> שואפת ל-<span class="math">\(\pi_{j}\)</span> כאשר <span class="math">\(n\)</span> שואף לאינסוף (<span class="math">\(\lim_{n\to\infty}\text{P}\left(X_{n}=j\right)=\pi_{j}\)</span> כאשר <span class="math">\(X_{n}\)</span> הוא המשתנה המקרי שמתאים ל"המצב של השרשרת בזמן <span class="math">\(n\)</span>"). בפרט זה אומר ש-<span class="math">\(\lim_{n\to\infty}\left[P^{n}\right]_{ij}=\pi_{j}\)</span> לכל <span class="math">\(i,j\)</span>. פירוש הדבר הוא שבשרשראות אי מחזוריות ובלתי פריקות, ההתפלגות האינוריאנטית של השרשרת מתארת בדיוק את ההתנהגות לטווח ארוך שלה. ההוכחה של המשפט היא מקסימה גם היא אבל אינה פשוטה ולא אציג אותה כעת.</p>
<h2><strong>ואיך כל זה קשור לגוגל</strong></h2>
<p>לסיום הפוסט אני רוצה להסביר איך כל זה קשור לגוגל. בשנת 1998 פרסמו סרגיי ברין ולארי פייג', מייסדי גוגל, מאמר (שהיה תוצאה של פרוייקט שעשו באוניברסיטת סטנפורד) שהציע שיטת דירוג עמודי אינטרנט שנקראה PageRank (על שם לארי פייג', לא בגלל ש-Page הוא דף). כמובן, גוגל הוא הרבה יותר מאשר רק השיטה הזו, ומנוע החיפוש האמיתי של גוגל משתמש באינספור הרחבות, וריאציות ותיקונים על השיטה הזו, אבל הרעיון הבסיסי בשיטה הוא חזק לכשעצמו ואציג רק אותו.</p>
<p>אנחנו רוצים לדרג דפים לפי ה"חשיבות" שלהם, אבל איך קובעים מתי דף הוא חשוב? ברין ופייג' הציעו את ההגדרה המטופשת "דף חשוב הוא דף שהרבה דפים חשובים מקשרים אליו". מטופשת, כי היא נראית מעגלית וחסרת טעם. אלא שהיא בכלל לא מטופשת.</p>
<p>פורמלית, אצל ברין ופייג' ה-PageRank של דף הוא סכום על ה-PageRank של הדפים שמקשרים, כאשר לכל דף שמקשר אליו אותו PageRank מחולק במספר הדפים שאליהם אותו דף מקשר. בנוסף לכך יש איזה פרמטר <span class="math">\(d\)</span> שתכף אסביר את חשיבותו. הנוסחה של ברין ופייג' היא</p>
<p><span class="math">\(\text{PR}\left(A\right)=\frac{1-d}{N}+d\sum_{T_{i}}\frac{\text{PR}\left(T_{i}\right)}{C\left(T_{i}\right)}\)</span></p>
<p>כאשר <span class="math">\(N\)</span> הוא מספר הדפים הכולל באינטרנט (ליתר דיוק - באוסף הדפים שעבורם מחשבים את PageRank) הסכום רץ על כל הדפים <span class="math">\(T_{i}\)</span> שמקשרים ל-<span class="math">\(A\)</span>, ו-<span class="math">\(C\left(T_{i}\right)\)</span> הוא מספר הלינקים הכולל שיוצא מ-<span class="math">\(T_{i}\)</span>. הגדרה מעגלית, אבל בכלל לא בעייתית. הנקודה היא שזה בדיוק מה שמקבלים אם ממדלים גלישה באינטרנט בתור שרשרת מרקוב.</p>
<p>הרעיון הוא לחשוב על האינטרנט בתור גרף אחד גדול, שבו כל דף הוא צומת, ויש קשת מדף א' לדף ב' אם דף א' מקשר אל דף ב'. כעת אנחנו חושבים על שרשרת מרקוב שבה המשתמש מטייל בגרף. בכל פעם שבה הוא בצומת מסויים, הוא בוחר את הצומת הבא לעבור אליו בהסתברות שווה מבין כל הצמתים שניתן להגיע אליהם מהצומת הנוכחי. כמו כן, בהסתברות <span class="math">\(1-d\)</span> (אצל ברין ופייג' <span class="math">\(d\)</span> נקבע ל-<span class="math">\(0.85\)</span> בתחילה) המשתמש "ישתעמם" ופשוט יעבור לדף אחר באינטרנט (כולו!) באופן אקראי. אני משאיר לכם לחשוב איך אפשר לתאר את כל זה פורמלית בתור שרשרת מרקוב - זה לא קשה.</p>
<p>אין ספק שיש לנו כאן תיאור נאיבי ביותר של האופן שבו אנשים גולשים באינטרנט, אבל אפשר לשפר אותו אם יש בכך צורך (למשל, שלא כל הלינקים בתוך עמוד יקבלו משקל זהה), וגם בגרסתו הבסיסית התיאור הזה נותן תוצאות מועילות למדי. כעת, שימו לב ששרשרת המרקוב הזו היא אי מחזורית (כי תמיד יש סיכוי שתחזור לדף שהתחלת ממנו - אפילו אחרי צעד אחד אם אתה "משתעמם") ואי פריקה (שוב, ה"שיעמום" מבטיח שתוכל להגיע לכל דף מכל דף אחר בהסתברות נמוכה כלשהי). לכן היא מתכנסת להתפלגות אינוריאנטית - ומה זו ההתפלגות האינוריאנטית הזו? ניחשתם נכון, קל לראות ש-<span class="math">\(\text{PR}\left(A\right)\)</span> היא בדיוק התפלגות אינוריאנטית של השרשרת הזו. המעגליות של ההגדרה נפתרה: זו בדיוק אותה מעגליות שיש בהגדרה בסגנון "<span class="math">\(Av=v\)</span>" - אם <span class="math">\(A\)</span> נתונה, כמובן שזו לא הגדרה מעגלית של <span class="math">\(v\)</span> כלל.</p>
<p>בקיצור, <span class="math">\(\text{PR}\left(A\right)\)</span> מתאים בדיוק להתנהגות לטווח ארוך של גולש אקראי במודל הגלישה שהצענו. מבחינה אינטואיטיבית המודל הזה קורץ למדי. עם זאת, עוד לא הבהרנו שתי נקודות חשובות: ראשית, למה בכלל <strong>קיים</strong> וקטור עצמי של 1 שהוא אי-שלילי? כל עוד לא הוכחנו קיום של כזה, לא הוכחנו שיש בכלל פתרון למערכת המשוואות שמגדירה את <span class="math">\(\text{PR}\)</span>. שנית, איך מוצאים את הוקטור הזה בפועל? אנחנו מדברים כאן על מטריצות ענקיות (ברין ופייג' דיברו במאמר על מטריצות מסדר 26 מיליון על 26 מיליון; בפועל כמובן שגוגל מתעסקים עם דברים גדולים יותר).</p>
<p>אלו שאלות טובות והתחום של מציאת ערכים עצמיים למטריצות גדולות הוא חשוב ומעניין ומסובך בפני עצמו ואיני יכול להיכנס אליו יותר מדי כרגע, אבל אני יכול לומר משהו בקיצור: המשפט שמהווה את עמוד השדרה לשיטה של ברין ופייג' נקרא <strong>משפט פרון-פרובניוס</strong> והוא אחד מעמודי התווך של האלגברה הלינארית. לא אוכל להציג את המשפט בשלמותו (הוא אומר הרבה דברים), אבל אספר את מה שרלוונטי לנו כרגע.</p>
<p>בהינתן מטריצה <span class="math">\(A\)</span> מעל <span class="math">\(\mathbb{R}\)</span> או <span class="math">\(\mathbb{C}\)</span>, <strong>הרדיוס הספקטרלי</strong> שלה <span class="math">\(\rho\left(A\right)\)</span> הוא הערך המוחלט המקסימלי של הערכים העצמיים של <span class="math">\(A\)</span> - אם תרצו, חשבו על זה בתור רדיוס העיגול הקטן ביותר ב-<span class="math">\(\mathbb{C}\)</span> שמרכזו בראשית הצירים ומכיל בתוכו את כל הערכים העצמיים של <span class="math">\(A\)</span> (שהם בסופו של דבר איברים של <span class="math">\(\mathbb{C}\)</span>). שימו לב כי <span class="math">\(\rho\left(A\right)\)</span> הוא תמיד מספר ממשי. כעת, החלק הרלוונטי עבורנו ממשפט פרון-פרובניוס אומר כי אם <span class="math">\(A\)</span> היא מטריצה חיובית (שכל כניסותיה הן מספרים ממשיים גדולים מאפס, כמו במקרה של <span class="math">\(P\)</span> של ברין ופייג') כך ש-<span class="math">\(r=\rho\left(A\right)\)</span>, אז <span class="math">\(r\)</span> הוא ערך עצמי של <span class="math">\(A\)</span> (זה בפני עצמו לא טריוויאלי; אם <span class="math">\(r=\rho\left(A\right)\)</span> כל מה שאפשר לעשות באופן כללי הוא לומר שקיים ערך עצמי <span class="math">\(\lambda\)</span> - שיכול להיות שלילי או מרוכב - כך ש-<span class="math">\(r=\left|\lambda\right|\)</span>), וכל ערך עצמי אחר של <span class="math">\(A\)</span> הוא קטן ממש בערכו המוחלט מ-<span class="math">\(r\)</span>, וקיים וקטור עצמי של <span class="math">\(r\)</span> (הן מימין והן משמאל) שכל הכניסות שלו חיוביות.</p>
<p>כעת, מה הרדיוס הספקטרלי של מטריצה סטוכסטית כמו אלו שבהן התעסקנו בפוסט הזה? ברור שהוא לפחות 1 כי 1 הוא וקטור עצמי. ממשפט פרון-פרובניוס עולה כי אם 1 הוא לא הרדיוס הספקטרלי אז קיים <span class="math">\(\lambda&gt;1\)</span> ממשי שגם הוא ערך עצמי, עם וקטור עצמי <span class="math">\(v\)</span> שכל כניסותיו הן ממשיות חיוביות, כלומר <span class="math">\(Av=\lambda v\)</span>. קל מאוד לראות שזה בלתי אפשרי: נניח ש-<span class="math">\(v_{max}\)</span> הוא ערכה של הכניסה הגדולה ביותר ב-<span class="math">\(v\)</span>, אז מכיוון שכל שורה של <span class="math">\(A\)</span> מסתכמת ל-1, רואים מייד שכל כניסה ב-<span class="math">\(Av\)</span> היא לכל היותר <span class="math">\(v_{max}\)</span>, אבל ב-<span class="math">\(\lambda v\)</span> יש כניסה שהיא גדולה ממש מ-<span class="math">\(v_{max}\)</span>. לכן במקרה שלנו הרדיוס הספקטרלי הוא בדיוק 1, ולכן קיים למטריצה וקטור עצמי אי-שלילי עבור הערך העצמי 1, ולכן קיימת התפלגות אינוריאנטית, בדיוק כפי שרצינו (יש עוד דרכים להוכיח את עניין הרדיוס הספקטרלי בלי תותח כבד כמו פרון-פרובניוס, אבל לצרכים שלנו כאן זה הכי התאים).</p>
<p>אם כן, ראינו שהתורה של שרשראות מרקוב (עם מרחב מצבים סופי) קשורה בקשר בל-ינתק לאלגברה לינארית; ראינו איך ערכים עצמיים הם השחקן המרכזי בניתוחים שנובעים מכך; ראינו בחטף משפט מרכזי שעוסק בערכים עצמיים של מטריצות חיוביות - פרון-פרובניוס - ואת האופן שבו הוא, יחד עם התורה של שרשראות מרקוב, משמשים באפליקציות מציאותיות ביותר. זה היה רק קצה הקרחון של השימושים של הנושאים שהזכרתי בפוסט הזה, אבל לטעמי קצה הקרחון הזה לכעצמו מספיק כדי להטביע את הטיטאניק.</p>
        </article>
        
        <footer>
            <p>© כל הזכויות שמורות לגדי אלכסנדרוביץ'</p>
        </footer>
    </div>

    
    <script>
        function toggleMobileMenu() {
            const navLinks = document.getElementById('navLinks');
            navLinks.classList.toggle('expanded');
        }
        
        function searchPosts() {
            const searchTerm = document.getElementById('searchInput').value;
            if (searchTerm.trim()) {
                window.location.href = '/new_blog/post_list.html?search=' + encodeURIComponent(searchTerm);
            }
        }
        
        document.getElementById('searchInput').addEventListener('keypress', function(e) {
            if (e.key === 'Enter') {
                searchPosts();
            }
        });
    </script>
    
    
    <!-- Auto-render KaTeX math -->
    <script>
        document.addEventListener("DOMContentLoaded", function() {
            renderMathInElement(document.body, {
                delimiters: [
                    {left: "\\[", right: "\\]", display: true},
                    {left: "\\(", right: "\\)", display: false}
                ],
                throwOnError: false
            });
        });
    </script>

</body>
</html>