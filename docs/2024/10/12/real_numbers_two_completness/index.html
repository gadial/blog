<!DOCTYPE html>
<html lang="he" dir="rtl">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>אז מה זה בעצם המספרים הממשיים? (חלק ג&#39;: על שתי שלמויות) - לא מדויק</title>
    <link rel="icon" type="image/x-icon" href="/favicon.ico">
    
    
    <!-- KaTeX for math rendering -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css">
    <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js"></script>
    <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js"></script>

    
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }
        
        body {
            font-family: 'Arial', 'David', 'Tahoma', sans-serif;
            line-height: 1.6;
            color: #333;
            background-color: #f5f5f5;
        }
        
        /* Top navigation bar */
        .top-nav {
            background: #2c3e50;
            padding: 15px 20px;
            box-shadow: 0 2px 5px rgba(0,0,0,0.1);
        }
        
        .top-nav .nav-container {
            max-width: 1200px;
            margin: 0 auto;
            display: flex;
            align-items: center;
            justify-content: space-between;
            gap: 20px;
        }
        
        .top-nav .site-title {
            font-size: 1.5em;
            font-weight: bold;
            color: white;
            text-decoration: none;
            white-space: nowrap;
        }
        
        .top-nav .nav-links {
            display: flex;
            gap: 20px;
            align-items: center;
            flex-wrap: wrap;
        }
        
        .top-nav .nav-links a {
            color: #ecf0f1;
            text-decoration: none;
            padding: 5px 10px;
            border-radius: 4px;
            transition: background 0.2s;
            white-space: nowrap;
        }
        
        .top-nav .nav-links a:hover {
            background: #34495e;
        }
        
        .top-nav .search-box {
            display: flex;
            gap: 5px;
        }
        
        .top-nav .search-box input {
            padding: 5px 10px;
            border: none;
            border-radius: 4px;
            font-size: 0.9em;
            min-width: 150px;
        }
        
        .top-nav .search-box button {
            padding: 5px 15px;
            background: #3498db;
            color: white;
            border: none;
            border-radius: 4px;
            cursor: pointer;
            transition: background 0.2s;
        }
        
        .top-nav .search-box button:hover {
            background: #2980b9;
        }
        
        /* Hamburger menu button */
        .menu-toggle {
            display: none;
            background: none;
            border: none;
            font-size: 1.8em;
            color: white;
            cursor: pointer;
            padding: 0;
            line-height: 1;
        }
        
        .menu-toggle:hover {
            opacity: 0.8;
        }
        
        /* Mobile responsive */
        @media (max-width: 768px) {
            .top-nav .nav-container {
                flex-direction: column;
                align-items: stretch;
            }
            
            .top-nav .site-title {
                display: flex;
                justify-content: space-between;
                align-items: center;
                margin-bottom: 0;
                padding: 10px 0;
            }
            
            .menu-toggle {
                display: block;
            }
            
            /* Hide nav links by default on mobile */
            .top-nav .nav-links {
                display: none;
                flex-direction: column;
                width: 100%;
                margin-top: 10px;
            }
            
            /* Show when expanded */
            .top-nav .nav-links.expanded {
                display: flex;
            }
            
            .top-nav .nav-links > a {
                text-align: center;
                padding: 12px;
                border-top: 1px solid rgba(255, 255, 255, 0.2);
            }
            
            .top-nav .search-box {
                width: 100%;
                flex-direction: column;
                margin-top: 10px;
                padding-top: 10px;
                border-top: 1px solid rgba(255, 255, 255, 0.2);
            }
            
            .top-nav .search-box input {
                width: 100%;
                margin-bottom: 5px;
                min-width: 0;
            }
            
            .top-nav .search-box button {
                width: 100%;
            }
        }
        
        /* Blockquote styling */
        blockquote {
            background: #f9f9f9;
            border-right: 5px solid #ccc;
            margin: 1.5em 10px;
            padding: 0.75em 16px;
            position: relative;
            font-style: italic;
        }
        
        blockquote:before {
            content: '"';
            position: absolute;
            top: -10px;
            right: 8px;
            font-size: 3.5em;
            color: #ccc;
            line-height: 1;
        }
        
        blockquote p {
            display: block;
            margin: 0 0 0.75em 0;
        }
        
        blockquote p:last-child {
            margin-bottom: 0;
        }
        
        
        body {
            line-height: 1.8;
        }
        
        .container {
            max-width: 800px;
            margin: 20px auto;
            background: white;
            padding: 40px;
            box-shadow: 0 2px 10px rgba(0,0,0,0.1);
            border-radius: 8px;
        }
        
        header {
            margin-bottom: 40px;
            border-bottom: 2px solid #e0e0e0;
            padding-bottom: 20px;
        }
        
        h1 {
            font-size: 2.5em;
            margin-bottom: 10px;
            color: #2c3e50;
        }
        
        .post-meta {
            color: #7f8c8d;
            font-size: 0.9em;
        }
        
        .post-meta .date {
            margin-left: 15px;
        }
        
        .post-meta .categories,
        .post-meta .tags {
            display: inline;
        }
        
        .post-meta .categories a,
        .post-meta .tags a {
            color: #3498db;
            text-decoration: none;
            margin: 0 5px;
        }
        
        .post-meta .categories a:hover,
        .post-meta .tags a:hover {
            text-decoration: underline;
        }
        
        article {
            font-size: 1.1em;
        }
        
        article h2 {
            margin-top: 30px;
            margin-bottom: 15px;
            color: #34495e;
            font-size: 1.8em;
        }
        
        article h3 {
            margin-top: 25px;
            margin-bottom: 12px;
            color: #34495e;
            font-size: 1.4em;
        }
        
        article p {
            margin-bottom: 15px;
            text-align: justify;
        }
        
        article ul, article ol {
            margin-right: 30px;
            margin-bottom: 15px;
        }
        
        article li {
            margin-bottom: 8px;
        }
        
        article code {
            background-color: #f4f4f4;
            padding: 2px 6px;
            border-radius: 3px;
            font-family: 'Courier New', monospace;
            font-size: 0.9em;
        }
        
        article pre {
            background-color: #2d2d2d;
            color: #f8f8f2;
            padding: 15px;
            border-radius: 5px;
            overflow-x: auto;
            margin-bottom: 20px;
            direction: ltr;
            text-align: left;
        }
        
        article pre code {
            background-color: transparent;
            padding: 0;
            color: inherit;
        }
        
        /* Image styles - responsive and contained */
        article img {
            max-width: 100%;
            height: auto;
            display: block;
            margin: 20px auto;
        }
        
        /* Math rendering styles */
        .math {
            direction: ltr;
        }
        
        span.math {
            direction: ltr;
        }
        
        /* Override RTL for KaTeX */
        .katex {
            direction: ltr;
            unicode-bidi: embed;
        }
        
        /* Force KaTeX content to wrap by overriding its internal structure */
        .katex-html {
            display: inline !important;
            white-space: normal !important;
        }
        
        .katex .base {
            display: inline !important;
            white-space: normal !important;
        }
        
        .katex .mord,
        .katex .mbin,
        .katex .mrel,
        .katex .mopen,
        .katex .mclose,
        .katex .mpunct,
        .katex .minner {
            display: inline !important;
            white-space: normal !important;
        }
        
        div.math {
            display: block;
            text-align: center;
            padding: 15px 0;
            direction: ltr;
        }
        
        /* RTL adjustments for code blocks */
        .highlight {
            direction: ltr;
            text-align: left;
        }
        
        footer {
            margin-top: 60px;
            padding-top: 20px;
            border-top: 1px solid #e0e0e0;
            text-align: center;
            color: #95a5a6;
            font-size: 0.9em;
        }
        
        /* Responsive design */
        @media (max-width: 768px) {
            .container {
                padding: 20px;
            }
            
            h1 {
                font-size: 2em;
            }
            
            article {
                font-size: 1em;
            }
            
            /* Hide post navigation on mobile */
            .post-navigation {
                display: none;
            }
        }
        
        /* Post navigation */
        .post-navigation {
            display: flex;
            justify-content: space-between;
            margin-bottom: 30px;
            padding-bottom: 20px;
            border-bottom: 2px solid #e0e0e0;
            gap: 20px;
        }
        
        .post-navigation .nav-link {
            flex: 1;
            text-decoration: none;
            color: #2c3e50;
            padding: 15px;
            background: #f8f9fa;
            border-radius: 5px;
            transition: background 0.2s;
        }
        
        .post-navigation .nav-link:hover {
            background: #e9ecef;
        }
        
        .post-navigation .nav-prev {
            text-align: right;
        }
        
        .post-navigation .nav-next {
            text-align: left;
        }
        
        .post-navigation .nav-label {
            font-size: 0.85em;
            color: #7f8c8d;
            display: block;
            margin-bottom: 5px;
        }
        
        .post-navigation .nav-title {
            font-weight: bold;
            font-size: 1.1em;
        }

    </style>
</head>
<body>
    <nav class="top-nav">
        <div class="nav-container">
            <div class="site-title">
                <a href="/" style="color: white; text-decoration: none;">לא מדויק</a>
                <button class="menu-toggle" onclick="toggleMobileMenu()" aria-label="תפריט">
                    ☰
                </button>
            </div>
            <div class="nav-links" id="navLinks">
                <a href="/">דף הבית</a>
                <a href="/random.html">פוסט אקראי</a>
                <a href="/post_list.html">כל הפוסטים</a>
                <div class="search-box">
                    <input type="text" id="searchInput" placeholder="חיפוש...">
                    <button onclick="searchPosts()">חפש</button>
                </div>
            </div>
        </div>
    </nav>
    
    
    <div class="container">
        <!-- Post Navigation -->
        
        <nav class="post-navigation">
            
            <a href="/2024/08/31/real_numbers_ordered_fields/" class="nav-link nav-prev">
                <span class="nav-label">פוסט ישן יותר →</span>
                <span class="nav-title">אז מה זה בעצם המספרים הממשיים? (חלק ב&#39;: השדה הסדור השלם)</span>
            </a>
            

            
            <a href="/2024/11/11/real_numbers_construction_cauchy_sequences/" class="nav-link nav-next">
                <span class="nav-label">← פוסט חדש יותר</span>
                <span class="nav-title">אז מה זה בעצם המספרים הממשיים? (חלק ד&#39;: בונים את המספרים הממשיים עם סדרות קושי)</span>
            </a>
            
        </nav>
        
        
        <header>
            <h1>אז מה זה בעצם המספרים הממשיים? (חלק ג&#39;: על שתי שלמויות)</h1>
            <div class="post-meta">
                <span class="date">2024-10-12</span>
                
                <span class="categories">
                    | קטגוריות:
                    
                    <a href="/categories/אנליזה מתמטית.html">אנליזה מתמטית</a>
                    
                </span>
                
                
                <span class="tags">
                    | תגיות:
                    
                    <a href="/tags/מספרים ממשיים.html">מספרים ממשיים</a>
                    
                </span>
                
            </div>
        </header>
        
        <article>
            <h2>מבוא</h2>

<p>היה זה הטוב בזמנים, היה זה הרע בזמנים. ספציפית, השנה הייתה 1872, והמתמטיקה הייתה בשיאו של תהליך של בניית עצמה מחדש אחרי שהגאומטריה ההיפרבולית שמטה את הבסיס שעליו היא ניצבה במשך אלפי שנים. אני לא אכנס לסיפור הזה כאן (והוא מסופר היטב ב"משפטי גדל ובעיית היסודות של המתמטיקה" של ארנון אברון, למשל) אבל השורה התחתונה שלו הייתה שמאמץ כביר של שלל מתמטיקאים במאה ה-19 הוביל ליצירת החשבון הדיפרנציאלי והאינטגרלי בגרסה המודרנית שלו שבה אנחנו משתמשים גם היום, מה שנתן למתמטיקה בסיס יציב (וחייבים להשחיל פנימה את המילה האהובה "ריגורוזי") ואז הגיע גאורג קנטור והעמיד את הבסיס היציב הזה על הבסיס היציב עוד יותר של תורת הקבוצות. אז אם הכל כל כך טוב, מה היה רע? שמעבר לאופק כבר הציצו הפרדוקסים שיתגלו בתורת הקבוצות הנאיבית ובפרט הפרדוקס של ראסל, ויגרמו לכך שהמתמטיקה תצטרך לבנות את עצמה מחדש פעם נוספת בתחילת המאה ה-20 והבניה הזו תסתיים בצורה שלא לגמרי עונה על השאיפות המלאות של העוסקים בה.</p>
<p>אבל זה כאמור סיפור לפעם אחרת. כרגע אנחנו בשנת 1872 (שנה לפני שקנטור יתחיל לפרסם מאמרים על תורת הקבוצות) ובשנה הזו מתפרסמים שני מאמרים, אחד של ריכארד דדקינד ("Stetigkeit und irrationale Zahlen", "רציפות ומספרים אי רציונליים") והשני של גאורג קנטור ("Ueber die Ausdehnung eines Satzes aus der Theorie der trigonometrischen Reihen ", "על הכללה של משפט מהתורה של טורים טריגונומטריים"), ובמאמרים הללו מופיעות בניות פורמליות של המספרים הממשיים שהן כל כך מוצלחות שעד היום הן הבניות המפורסמות ביותר (יש עוד, אבל זה באמת כבר יחכה לפעם אחרת). בשני המקרים, הבניות מופיעות לא כי התחשק למחברים שלהם להמציא את המתמטיקה מחדש, אלא כי הם גילו שהמתמטיקה הקיימת פשוט לא מספיק פורמלית בשביל שהם יצליחו להוכיח טענות פשוטות יחסית בצורה משביעת רצון; היה צורך בהגדרות פורמליות של הממשיים כדי שאפשר יהיה להוכיח פורמלית דברים שהיו סטנדרטיים בחשבון הדיפרנציאלי והאינטגרלי של זמנם. זה גם לא ממש מקרי ששתי ההגדרות צצו באותה בשנה - קנטור ודדקינד היו מיודדים והתכתבו, ודדקינד ספציפית קיבל מוטיבציה לפרסם את הרעיונות שלו (שהיו לו כבר שנים קודם לכן) אחרי שראה את המאמר של קנטור. אבל למרות סמיכות הזמנים והקשר בין המחברים, שתי הבניות הן שונות למדי באופיין והמוטיבציה שלהן שונה, מה שהופך את שתיהן למעניינות (ואת שתיהן לניתנות להכללה בדרכים שונות גם לדברים שאינם הממשיים), כך שלדעתי שווה לדבר על שתיהן.</p>
<p>דבר אחד שאני לא הולך לעשות בפוסט הוא להציג את הבניות בצורה <strong>פורמלית</strong>, להוכיח שהן עובדות כמו שצריך וכדומה; את זה אשאיר לפוסט הבא. מה שמעניין אותי כרגע הוא הרעיון הכללי של הבניות, אילו בעיות הן מנסות לפתור ולאילו תוצאות תיאורטיות הן מתקשרות. אז למרות שהפוסט הזה בהחלט ייכנס לפרטים טכניים, הם לא יהיו של הבניות עצמן אלא של ה"מסביב". ספציפית, אנחנו נראה שכל אחת מהבניות באה ללכוד את מושג ה"שלמות" של <span class="math">\(\mathbb{R}\)</span> והן עושות את זה בצורה די שונה - אפילו שונה <strong>מהותית</strong>, כמו שנראה בסוף.</p>
<p>לפני שאני נכנס לעובי הקורה, הנה בגדול שתי הבניות:</p>
<ul> <li><strong>דדקינד</strong> מגדיר <strong>חתך</strong> בתור פירוק של <span class="math">\(\mathbb{Q}\)</span> לשתי קבוצות <span class="math">\(A_{1},A_{2}\)</span> כך שכל איבר של <span class="math">\(A_{1}\)</span> קטן מכל איבר של <span class="math">\(A_{2}\)</span>. עכשיו דדקינד מגדיר את המספרים הממשיים בתור אוסף כל החתכים, כשהרעיון הוא שהמספר שחתך מייצג הוא המספר שנמצא "באמצע" בין <span class="math">\(A_{1}\)</span> ו-<span class="math">\(A_{2}\)</span>.</li>


<li><strong>קנטור</strong> מסתכל על <strong>סדרות קושי</strong> של מספרים רציונליים ומגדיר את המספרים הממשיים בתור אוסף כל סדרות הקושי הללו כשהוא מזהה שתי סדרות קושי ש"שואפות אחת לשניה" בתור אותו מספר. הרעיון הוא שהמספר הממשי שסדרת קושי מייצגת הוא המספר שהסדרה "שואפת" אליו.</li>

</ul>

<p>ההגדרה של דדקינד אמורה להיות ברורה יחסית אפילו ברמה הפורמלית כבר בשלב הזה למי שעקבו אחרי סדרת הפוסטים הזו, כי ראינו בפוסט הקודם את המושג של "קטן מ-". לעומת זאת ההגדרה של קנטור משתמשת במושגים שהם אמנם בסיסיים למדי בחשבון דיפרנציאלי ואינטגרלי אבל לא דיברתי עליהם בסדרת הפוסטים הזו בכלל - סדרות קושי ו"שאיפה". אלו הדברים הראשונים שארצה להבהיר בפוסט הזה ולא אניח שאנחנו כבר מכירים אותם ממקום אחר. יותר מכך - יש חשיבות בהצגה שלהם מאפס מהטעם הפשוט שבדרך כלל רואים אותם בחדו"א שעושים במסגרת <span class="math">\(\mathbb{R}\)</span> - כלומר, הלימודים מתחילים קודם כל עם זה ש-<span class="math">\(\mathbb{R}\)</span> קיים ואז הצגת מושגים כמו שאיפה וסדרות קושי באמצעותו. הפעם אני לא אעשה את זה בכלל. אז יאללה, לעבודה.</p>
<h2>הגדרת הגבול</h2>

<p>השינוי הגדול שעבר החדו"א במאה ה-19 היה ויתור על גישה לא פורמלית ואינטואיטיבית (שהובילה בסך הכל לתורה שעובדת מצויין אבל יש לה גם פינות אפלות שגויות) לטובת פורמליות שכמותה לא נראתה עד אז במתמטיקה. זה אמר להפסיק להסתמך על האינטואיציה הגאומטרית לגבי מהי "רציפות" ולנסות להגדיר אותה במפורש, וזה אמר גם להפסיק להשתמש באינפיניטסימלים ולהשתמש במושג בסיסי אחר, מדויק יותר, שנקרא <strong>גבול</strong>. זה לא מושג פשוט או קל לעיכול (ואחת הסיבות שחדו"א הוא תחום ידוע לשמצה בקושי שלו למי שמתחילים ללמוד מתמטיקה היא בדיוק ההסתמכות שלו על מושג לא קל שכזה), אבל ההגדרה שלו חזקה להפתיע. <a href="https://gadial.net/2010/10/03/limit_of_sequence/">יש לי פוסט</a> על גבולות, אז כאן אני ארשה לעצמי לפרט פחות.</p>
<p>בשביל להגדיר גבול צריך קודם כל להגדיר <strong>מרחק</strong>, וזה למרבה השמחה משהו שקל לנו להגדיר על <span class="math">\(\mathbb{Q}\)</span> בזכות פונקציית <strong>הערך המוחלט</strong> שראינו בפוסט הקודם שאפשר להגדיר ישירות מתוך <strong>הסדר</strong> שיש על <span class="math">\(\mathbb{Q}\)</span>. אפשר לחשוב על <span class="math">\(\left|q\right|\)</span> בתור "המרחק של <span class="math">\(q\)</span> מ-0" ואז להכליל את זה ולומר שהמרחק של <span class="math">\(a\)</span> מ-<span class="math">\(b\)</span> הוא <span class="math">\(d\left(a,b\right)=\left|a-b\right|\)</span>. עכשיו, בואו נראה אילו תכונות של פונקציית המרחק <span class="math">\(d\)</span> אפשר להסיק מתוך התכונות של הערך המוחלט. בפוסט הקודם ראינו ש:</p>
<ul> <li>אם <span class="math">\(x\ne0\)</span> אז <span class="math">\(\left|x\right|\ne0\)</span> ו-<span class="math">\(\left|0\right|=0\)</span>.</li>


<li><span class="math">\(\left|xy\right|=\left|x\right|\cdot\left|y\right|\)</span> ו-<span class="math">\(\left|-1\right|=1\)</span></li>


<li><span class="math">\(\left|x+y\right|\le\left|x\right|+\left|y\right|\)</span></li>

</ul>

<p>את שלוש התכונות הללו אפשר לתרגם לשלוש תכונות של פונקציית המרחק, <span class="math">\(d\)</span>:</p>
<ul> <li><span class="math">\(d\left(a,b\right)=0\)</span> אם ורק אם <span class="math">\(a=b\)</span>.</li>


<li><span class="math">\(d\left(a,b\right)=d\left(b,a\right)\)</span> לכל <span class="math">\(a,b\)</span>.</li>


<li><span class="math">\(d\left(a,c\right)\le d\left(a,b\right)+d\left(b,c\right)\)</span> לכל <span class="math">\(a,b,c\)</span>.</li>

</ul>

<p>בואו נוכיח את זה: </p>
<ul> <li><span class="math">\(d\left(a,b\right)=0\)</span> אם ורק אם <span class="math">\(\left|a-b\right|=0\)</span> כלומר אם ורק אם <span class="math">\(a-b=0\)</span> כלומר אם ורק אם <span class="math">\(a=b\)</span>.</li>


<li><span class="math">\(d\left(a,b\right)=\left|a-b\right|=\left|\left(-1\right)\left(b-a\right)\right|=\left|-1\right|\left|b-a\right|=d\left(b,a\right)\)</span></li>


<li><span class="math">\(d\left(a,c\right)=\left|a-c\right|=\left|\left(a-b\right)+\left(b-c\right)\right|\le\left|a-b\right|+\left|b-c\right|=d\left(a,b\right)+d\left(b,c\right)\)</span></li>

</ul>

<p>עכשיו שיש לנו פונקציית מרחק, אפשר לנסח את מושג הגבול באמצעותה. בדרך כלל כשמלמדים חדו"א לא טורחים לעשות את זה ופשוט עובדים ישירות עם ערך מוחלט, אבל יש יתרון גם בגישה הכללית יותר - מה שאנחנו מנסחים בלשון של פונקציית המרחק תקף בכל <strong>מרחב מטרי</strong> שהוא בסך הכל קבוצה שמוגדרת עליה פונקציית מרחק שכזו. גם פונקציית מרחק מוזרות על <span class="math">\(\mathbb{Q}\)</span> כמו זו שבה <span class="math">\(d\left(a,b\right)\)</span> הוא <span class="math">\(\frac{1}{2^{n}}\)</span> כש-<span class="math">\(2^{n}\)</span> היא החזקה הגדולה ביותר של 2 שמחלקת את <span class="math">\(a-b\)</span> (אלא אם <span class="math">\(a=b\)</span> ואז <span class="math">\(d\left(a,b\right)=0\)</span>). המטריקה המוזרה הזו נקראת "המטריקה ה-2-אדית" והיא מרתקת בפני עצמה אבל אני לא ארחיב עליה יותר מדי כאן (<a href="https://gadial.net/2010/01/12/padic_numbers_analytic_constructions/">יש לי פוסט</a> על זה).</p>
<p>אפשר להגדיר גבול על שני אובייקטים: סדרות, ופונקציות. על סדרה <span class="math">\(a_{0},a_{1},a_{2},\ldots\)</span> אפשר לחשוב בעצם בתור פונקציה <span class="math">\(g:\mathbb{N}\to\mathbb{Q}\)</span> כך ש-<span class="math">\(g\left(i\right)=a_{i}\)</span>, אז המרחק בין זה ובין גבולות של פונקציות <span class="math">\(f:\mathbb{Q}\to\mathbb{Q}\)</span> הוא באמת לא כזה גדול, אבל אני עדיין אתחיל עם ניסוח ספציפי עבור סדרות כי הוא פשוט יותר.</p>
<ul> <li>בהינתן סדרה <span class="math">\(\left\{ a_{n}\right\} _{n=0}^{\infty}\)</span> אני אומר שהיא <strong>שואפת</strong> אל <span class="math">\(L\)</span> ומסמן את זה <span class="math">\(\lim_{n\to\infty}a_{n}=L\)</span> או <span class="math">\(a_{n}\to L\)</span> אם לכל <span class="math">\(\varepsilon>0\)</span> קיים <span class="math">\(N\)</span> טבעי כך שלכל <span class="math">\(n>N\)</span> מתקיים <span class="math">\(d\left(a_{n},L\right)<\varepsilon\)</span>.</li>

</ul>

<p>במילים: לכל <strong>רמת קרבה</strong> גדולה מאפס, קיים מקום בסדרה שהחל ממנו <strong>כל</strong> אברי הסדרה נמצאים ברמת הקרבה הזו אל <span class="math">\(L\)</span>. בלי שום יוצאים מן הכלל. בלי שהסדרה פתאום "תקפוץ" למקום אחר ואז תחזור. החל משלב מסויים בסדרה, זהו, נגמר - הסדרה קרובה כולה עד כדי <span class="math">\(\varepsilon\)</span> אל <span class="math">\(L\)</span>, וזה נכון <strong>לכל</strong> <span class="math">\(\varepsilon\)</span> חיובי, לא משנה כמה קטן. הדבר היחיד שאני לא דורש בשום צורה הוא שהסדרה <strong>תגיע</strong> אל <span class="math">\(L\)</span>. אפילו לא איבר אחד שלה צריך להיות שווה אל <span class="math">\(L\)</span>.</p>
<p>ההגדרה עבור פונקציה קצת יותר מסובכת, כי בניגוד לטבעיים שהם דיסקרטיים, הרציונליים הם צפופים ולכן לכל נקודה אפשר "להתקרב" עם סדרה של רציונליים, כך שאם יש לי פונקציה שמוגדרת על כל הרציונליים ואני רוצה להגיד שהיא שואפת למשהו, עולה השאלה <strong>איפה</strong> היא שואפת אל המשהו הזה - לאילו ערך <strong>הקלטים</strong> שלה צריכים להתקרב כדי שאפשר יהיה להגיד <strong>שהפלטים</strong> שלה מתקרבים אל משהו. אז הנה הפורמליזם:</p>
<ul> <li>בהינתן פונקציה <span class="math">\(f:\mathbb{Q}\to\mathbb{Q}\)</span> אני אומר שהיא <strong>שואפת</strong> אל <span class="math">\(L\)</span> בנקודה <span class="math">\(x_{0}\)</span> ומסמן את זה <span class="math">\(\lim_{x\to x_{0}}f\left(x\right)=L\)</span> או <span class="math">\(f\left(x\right)\underset{x\to x_{0}}{\to}L\)</span> אם לכל <span class="math">\(\varepsilon>0\)</span> קיים <span class="math">\(\delta>0\)</span> כך שלכל <span class="math">\(x\)</span> עבורו <span class="math">\(0<d\left(x,x_{0}\right)<\delta\)</span> מתקיים <span class="math">\(d\left(f\left(x\right),L\right)<\varepsilon\)</span></li>

</ul>

<p>ההבדל הבולט בין ההגדרות הוא שבהגדרה עבור סדרות לא היה <span class="math">\(\delta\)</span> אלא היה <span class="math">\(N\)</span> והסתכלנו על כל ה"קלטים" <span class="math">\(n\)</span> שגדולים מ-<span class="math">\(N\)</span>, ואילו כאן אנחנו מסתכלים על כל ה-<span class="math">\(x\)</span>-ים שקרובים אל <span class="math">\(x_{0}\)</span> עד כדי <span class="math">\(\delta\)</span>. כאמור, יש דרך לאגד את שתי ההגדרות הללו ביחד אבל נעזוב את זה.</p>
<p>עוד נקודה שכדאי לשים לב אליה היא <span class="math">\(0<d\left(x,x_{0}\right)\)</span>. אי השוויון הזה אומר שאני <strong>לא</strong> מניח ש-<span class="math">\(x_{0}\)</span> עצמה הפונקציה קרובה ל-<span class="math">\(L\)</span>. הפונקציה אפילו לא חייבת להיות מוגדרת ב-<span class="math">\(L\)</span>. אם <strong>כן</strong> הייתי דורש שהקרבה ל-<span class="math">\(L\)</span> תתקיים גם ב-<span class="math">\(x_{0}\)</span>, זו הייתה דרישה חזקה יותר מ-<span class="math">\(f\)</span>, וזו דרישה חשובה כל כך שיש לה שם מיוחד: אומרים ש-<span class="math">\(f\)</span> <strong>רציפה</strong> ב-<span class="math">\(x_{0}\)</span> אם הדרישה הזו מתקיימת - מה ששקול לטענה ש-<span class="math">\(\lim_{x\to x_{0}}f\left(x\right)=f\left(x_{0}\right)\)</span>.</p>
<h2>סדרות מונוטוניות מתכנסות</h2>

<p>עכשיו, כשיש לנו את מושג הגבול אפשר להתחיל לראות את מה שהיה חסר לדדקינד וקנטור והוביל אותם להגדרה פורמלית של הממשיים, <span class="math">\(\mathbb{R}\)</span>, כשכאן "הממשיים" פירושם "הקבוצה שבה מתרחשת החדו"א" ולכן כל המשפטים שאתאר יעסקו בה. דדקינד מדבר על במפורש במאמר שלו על מה שהפריע לו. הוא מתאר איך ב-1858, כשלימד קורס חדו"א, התעורר בו תסכול מחוסר הפורמליות של ההוכחות הבסיסיות. הפריע לו שבסופו של דבר, ההוכחות הללו פונות לטיעונים גאומטריים או לכל הפחות "בהשראה" גאומטרית, ומשתמשים בצורה עמומה במושג ה"רציפות" של המספרים הממשיים. לא חייתי בזמנו של דדקינד ואני לא יודע איך נראתה הוראת המתמטיקה אז, אבל אני יכול להבין אותו; הייתה לי תחושה דומה בשעתו עם ההוכחה ש-<span class="math">\(\lim_{x\to0}\frac{\sin x}{x}=1\)</span>. על הטענה הזו נבנה כל החדו"א של פונקציות טריגונומטריות, אבל רוב ספרי החדו"א שמוכיחים אותה קופצים על שלב או שניים, ולרוב יש להם איזה "קל לראות" גאומטרי לגמרי באופיו. זה לא מפריע בדרך כלל (והמשפט כמובן נכון ויש לו הוכחות פורמליות עד הסוף <a href="https://gadial.net/2008/01/20/lim_sin_x_over_x/">וכבר דיברתי על זה</a> בבלוג), אבל מה שלא מפריע לך בתור סטודנט בהחלט יכול להתחיל להציק כשאתה בא ללמד את הנושא (או לכתוב עליו פוסט בבלוג...) ומגלה שיש איזה <strong>משהו</strong> שם שלא לגמרי עובד עד הסוף.</p>
<p>לדעתי (ושוב, לא הייתי בסביבה בזמנו של דדקינד) חוסר הפורמליות הזה לא בהכרח היה האופי הכללי של לימודי החדו"א; אני בטוח שרוב ההוכחות היו פורמליות וסבבה. הסיבה לכך היא שמרגע שמוכיחים טענה <strong>ספציפית</strong> שדורשת הסתמכות על ההגדרה הפורמלית של המספרים הממשיים, אפשר להוכיח טענות אחרות בעזרתה, בצורה פורמלית מלאה, כך שהמחסור בפורמליות מתבטא רק בהוכחה אחת ספציפית (בדיוק כמו עם ה-<span class="math">\(\lim_{x\to0}\frac{\sin x}{x}=1\)</span>) שלי. דדקינד מביא כדוגמא משפט אחד ספציפי, שהוא אכן "קרש קפיצה" כזה שממנו אפשר להוכיח את יתר הדברים:</p>
<ul> <li>כל סדרה מונוטונית עולה וחסומה מלעיל היא מתכנסת.</li>

</ul>

<p>צריך להסביר את המונחים הללו. סדרה היא <strong>מתכנסת</strong> אם היא שואפת לגבול כלשהו (גבול סופי, לא אינסוף, אבל לא הגדרתי פה שאיפה לאינסוף בכל מקרה). סדרה היא <strong>מונוטונית עולה</strong> אם <span class="math">\(a_{n}\le a_{n+1}\)</span> לכל <span class="math">\(n\)</span>, כלומר האיברים שלה יכולים רק לגדול, לא לקטון. וסדרה היא <strong>חסומה מלעיל</strong> אם קיים <span class="math">\(M\)</span> כך ש-<span class="math">\(a_{n}\le M\)</span> לכל <span class="math">\(n\)</span> (על זה דיברתי בפוסט הקודם). זו אולי נראית כמו טענה פשוטה ותמימה יחסית, אבל למעשה היא הרבה יותר ערמומית מזה - זו סדרה שמבטיחה <strong>קיום</strong> של מספר מסוים - מספר שמהווה גבול של הסדרה - והמספר הזה יכול להיות אי-רציונלי. כל אי רציונלי. כי בואו נראה דוגמא עבור <span class="math">\(\sqrt{2}=1.4142\ldots\)</span>:</p>
<p><span class="math">\(1,1.4,1.41,1.414,1.4142,\ldots\)</span></p>
<p>מה עשיתי פה? כתבתי סדרת מספרים שנבנית מהפיתוח העשרוני של <span class="math">\(\sqrt{2}\)</span>, כשבכל פעם אני מוסיף איבר נוסף אחרי הנקודה העשרונית ולכן מגדיל את המספר שבניתי ולכן זו סדרה מונוטונית עולה. היא בוודאי חסומה, למשל על ידי 2, ולכן על פי הטענה של דדקינד היא מתכנסת - ומן הסתם אנחנו מבינים שהגבול שלה יהיה חייב להיות <span class="math">\(\sqrt{2}\)</span>. כלומר הטענה הזו מבטיחה את קיום <span class="math">\(\sqrt{2}\)</span>, ואת קיום <span class="math">\(\pi\)</span> וכל מספר ממשי אחר שנרצה ואנחנו יודעים איך לתאר בעצם, וכמובן שהטענה הזו לא נכונה ב-<span class="math">\(\mathbb{Q}\)</span>. אבל איך מוכיחים אותה פורמלית עבור <span class="math">\(\mathbb{R}\)</span>?</p>
<p>טרם בניתי את <span class="math">\(\mathbb{R}\)</span> פורמלית, אבל בשביל להוכיח משפטים במסגרת <span class="math">\(\mathbb{R}\)</span> אני לא צריך לבנות אותו פורמלית, למעשה; אני אוכיח משפטים עבור <strong>השדה הסדור השלם</strong>, שזה מושג שהצגתי בפוסט הקודם, ולכן בהמשך כשאתן בניה פורמלית ל-<span class="math">\(\mathbb{R}\)</span> שאכן תניב שדה סדור שלם, ההוכחה שלי תעבוד עליה אוטומטית. אז למרות שזה לא מה שדדקינד עשה, בואו נראה איך מוכיחים את המשפט הזה עם האקסיומות של שדה סדור שלם, ומה עוד אני יכול להוכיח כשזו נקודת המוצא שלי.</p>
<p>למרבה השמחה ההוכחה קלה למדי. נסתכל על הקבוצה <span class="math">\(A=\left\{ a_{n}\ |\ n\in\mathbb{N}\right\} \)</span> של אברי הסדרה. זו בוודאי קבוצה לא ריקה (אפילו אם הסדרה קבועה, עדיין יהיה ב-<span class="math">\(A\)</span> איבר אחד לפחות) ועל פי ההנחה שהסדרה חסומה מלעיל, <span class="math">\(A\)</span> חסומה מלעיל. לכן <strong>על פי אקסיומת השלמות</strong>, יש <span class="math">\(L=\sup A\)</span>. מה שאני ארצה להוכיח הוא ש-<span class="math">\(a_{n}\to L\)</span> הזה.</p>
<p>יהא <span class="math">\(\varepsilon>0\)</span> כלשהו. מכיוון ש-<span class="math">\(L=\sup A\)</span>, קיים <span class="math">\(N\)</span> כך ש-<span class="math">\(d\left(a_{N},L\right)<\varepsilon\)</span>. זה דורש הסבר; אם לא היה אף איבר שקרוב ל-<span class="math">\(L\)</span> עד כדי <span class="math">\(\varepsilon\)</span>, היה נובע מכך ש-<span class="math">\(L^{\prime}=L-\varepsilon\)</span> הוא בעצמו חסם מלעיל של <span class="math">\(A\)</span>, בסתירה לכך ש-<span class="math">\(L\)</span> הוא החסם העליון שלה. <span class="math">\(L^{\prime}\)</span> היה חסם מלעיל כזה כי בואו ניקח <span class="math">\(a\in A\)</span> כלשהו. אני יודע ש-<span class="math">\(d\left(a,L\right)\ge\varepsilon\)</span>, כלומר <span class="math">\(\left|a-L\right|\ge\varepsilon\)</span>. אני גם יודע ש-<span class="math">\(a\le L\)</span> (כי <span class="math">\(L\)</span> הוא חסם מלעיל של <span class="math">\(A\)</span>) כלומר <span class="math">\(\left|a-L\right|=L-a\)</span>. קיבלתי ש-<span class="math">\(L-a\ge\varepsilon\)</span>, כלומר <span class="math">\(a\le L-\varepsilon=L^{\prime}\)</span> וזה <strong>לכל</strong> <span class="math">\(a\in A\)</span>.</p>
<p>אם כן, קיים <span class="math">\(N\)</span> כך ש-<span class="math">\(d\left(a_{N},L\right)<\varepsilon\)</span>. עכשיו בואו נסתכל על <span class="math">\(n>N\)</span> כלשהו: מצד אחד, <span class="math">\(a_{N}\le a_{n}\)</span> (כי הסדרה מונוטונית עולה) ומצד שני <span class="math">\(a_{n}\le L\)</span> (כי <span class="math">\(L\)</span> הוא חסם מלעיל) ולכן</p>
<p><span class="math">\(d\left(a_{n},L\right)=L-a_{n}\le L-a_{N}<\varepsilon\)</span> (כאן אני משתמש בתכונות שכבר ראינו של ערך מוחלט ואי שוויונים).</p>
<p>זה מסיים את ההוכחה ומראה לנו את השימושיות הרבה של אקסיומת השלמות ואת חוסר השימושיות הבולט של הסימון <span class="math">\(d\left(a,b\right)\)</span> שלי במקום להשתמש פשוט בערך מוחלט - ההוכחה שלי מסתמכת חזק מאוד על תכונות של ערך מוחלט, ולדבר על מטריקה כללית לא עוזר לי פה בכלל. המשפט מנוסח מלכתחילה על קבוצה סדורה ולא לגמרי ברור מה המשמעות שלו בסיטואציות כלליות יותר - אפילו במשהו כמו <span class="math">\(\mathbb{R}^{2}\)</span> עם פונקציית המרחק הסטנדרטית <span class="math">\(d\left(\left(x_{1},y_{1}\right),\left(x_{2},y_{2}\right)\right)=\sqrt{\left(x_{1}-x_{2}\right)^{2}+\left(y_{1}-y_{2}\right)^{2}}\)</span>.</p>
<p>לכאורה המשפט סובל מחוסר סימטריה מוזר - הוא מדבר על סדרה מונוטונית עולה וחסומה מלעיל. אבל מה עם סדרות מונוטוניות יורדות וחסומות מלרע? להן לא מגיע להתכנס? ובכן, אם <span class="math">\(\left\{ a_{n}\right\} _{n=0}^{\infty}\)</span> סדרה מונוטונית יורדת (<span class="math">\(a_{n}\ge a_{n+1}\)</span>) וחסומה מלרע (קיים <span class="math">\(M\)</span> כך ש-<span class="math">\(a_{n}\ge M\)</span> לכל <span class="math">\(n\)</span>) אז הסדרה <span class="math">\(\left\{ b_{n}\right\} _{n=0}^{\infty}\)</span> שמוגדרת על ידי <span class="math">\(b_{n}=-a_{n}\)</span> היא מונוטונית עולה (כי <span class="math">\(-a_{n}\le-a_{n+1}\)</span>) וחסומה מלעיל (כי <span class="math">\(-M\)</span> מקיים <span class="math">\(-a_{n}\le-M\)</span> לכל <span class="math">\(n\)</span>) ולכן היא מתכנסת לגבול <span class="math">\(L\)</span> וזה עכשיו עניין של משחק קליל עם ההגדרה כדי להראות ש-<span class="math">\(a_{n}\)</span> מתכנסת אל <span class="math">\(-L\)</span>.</p>
<h2>בולצאנו-ויירשטראס</h2>

<p>סיימנו עם המשפט על הסדרות המונוטוניות. העניין הוא שהמשפט הזה הוא מעין הקדמה למשפט מרכזי מאין כמוהו - <strong>משפט בולצאנו-ויירשטראס</strong>, שהוא כנראה המשפט שמבטא בצורה הכי ברורה את תחושת ה"רציפות" של <span class="math">\(\mathbb{R}\)</span> בכל הנוגע לסדרות:</p>
<ul> <li>(בולצאנו-ויירשטראס): לכל סדרה חסומה קיימת תת-סדרה מתכנסת.</li>

</ul>

<p>גם פה צריך לתת הסבר: "תת-סדרה" היא פשוט סדרה אינסופית שמתקבלת מסדרה קיימת על ידי בחירה של חלק מהאיברים שלה, על פי הסדר שלהם בתוך הסדרה המקורית. פורמלית (וזה כואב לכתוב את זה פורמלית) אם יש לנו סדרה <span class="math">\(\left\{ a_{n}\right\} _{n=0}^{\infty}\)</span> אז תת-סדרה שלה היא סדרה <span class="math">\(\left\{ b_{k}\right\} _{k=0}^{\infty}\)</span> כך ש-<span class="math">\(b_{k}=a_{n_{k}}\)</span> עבור <span class="math">\(n_{0}<n_{1}<n_{2}<\ldots\)</span>, כלומר עבור <strong>סדרה מונוטונית עולה ממש</strong> של אינדקסים. עוד דבר שכדאי להזכיר הוא ש"חסומה" אומר שקיימים גם חסם מלעיל וגם חסם מלרע.</p>
<p>אפשר לנסח את בולצאנו-ויירשטראס גם באופן שקול, שיהיה רלוונטי כשנדבר על קנטור: לכל קבוצה <span class="math">\(A\)</span> שהיא אינסופית וחסומה קיימת <strong>נקודת הצטברות</strong>. כש"נקודת הצטברות" היא נקודה <span class="math">\(b\in\mathbb{R}\)</span> (לאו דווקא כזו ששייכת ל-<span class="math">\(A\)</span>) כך שלכל <span class="math">\(\varepsilon>0\)</span> קיימת <span class="math">\(a\in A\)</span> כך ש-<span class="math">\(d\left(b,a\right)<\varepsilon\)</span> (לא קשה להראות שבאופן שקול זה אומר שלכל <span class="math">\(\varepsilon>0\)</span> יש <strong>אינסוף</strong> נקודות <span class="math">\(a\in A\)</span> כך ש-<span class="math">\(d\left(b,a\right)<\varepsilon\)</span>). זה תרגיל נחמד להוכיח ששני הניסוחים שקולים, אז לא אעשה את זה בעצמי פה.</p>
<p><a href="https://gadial.net/2009/06/07/lion_in_the_desert/">יש לי בבלוג</a> פוסט שמרפרף על ההוכחה של בולצאנו-ויירשטראס, אבל הפעם אכנס יותר לפרטים. למעשה, אני רוצה להראות שתי הוכחות, כל אחת עם היתרונות שלה. נתחיל מהפשוטה יותר, שתשתמש במה שראינו על התכנסות של סדרות מונוטוניות וחסומות. נתונה לי הסדרה <span class="math">\(\left\{ a_{n}\right\} _{n=0}^{\infty}\)</span>, ואני אגיד שאיבר כלשהו בסדרה הוא <strong>פסגה</strong> אם הוא גדול מכל האיברים שבאים אחריו. כלומר <span class="math">\(a_{n}\)</span> הוא פסגה אם לכל <span class="math">\(n<m\)</span> מתקיים <span class="math">\(a_{m}<a_{n}\)</span>. עכשיו, יש שתי אפשרויות: או שבסדרה יש אינסוף פסגות, או שיש מספר סופי. נטפל בכל מקרה בנפרד.</p>
<p>במקרה שבו יש אינסוף פסגות, אני אבנה את תת-הסדרה המתכנסת <span class="math">\(\left\{ b_{k}\right\} _{k=0}^{\infty}\)</span> ככה: ראשית <span class="math">\(b_{0}\)</span> תהיה הפסגה הראשונה בסדרה. שנית, בואו נניח שכבר בניתי את <span class="math">\(b_{k}\)</span> והוא פסגה בסדרה המקורית (זה נכון עבור <span class="math">\(b_{0}\)</span> ואני אבנה את <span class="math">\(b_{k+1}\)</span> כדי שזה ימשיך להיות נכון). מכיוון שבסדרה המקורית יש אינסוף פסגות, נבחר את <span class="math">\(b_{k+1}\)</span> להיות פסגה כלשהי בסדרה המקורית שמגיעה אחרי <span class="math">\(b_{k}\)</span>. עכשיו, שימו לב שבגלל ש-<span class="math">\(b_{k}\)</span> היא פסגה היא גדולה <strong>מכל</strong> איבר שבה אחריה, כלומר <span class="math">\(b_{k+1}<b_{k}\)</span>. במילים אחרות, בנינו פה תת-סדרה מונוטונית יורדת <span class="math">\(b_{0}>b_{1}>b_{2}>\ldots\)</span> והיא חסומה בגלל שהסדרה <span class="math">\(\left\{ a_{n}\right\} _{n=0}^{\infty}\)</span> חסומה (זו ההנחה של משפט בולצאנו-ויירשטראס). לכן סדרת ה-<span class="math">\(b_{k}\)</span>-ים מתכנסת.</p>
<p>עכשיו נניח שדווקא אין אינסוף פסגות. אז קיים <span class="math">\(N\)</span> כך ש-<span class="math">\(a_{N}\)</span> הוא הפסגה האחרונה בסדרה. נגדיר <span class="math">\(b_{0}=a_{N+1}\)</span>, כלומר <span class="math">\(b_{0}\)</span> <strong>אינה</strong> פסגה. נניח עכשיו באופן כללי שכבר בנינו את <span class="math">\(b_{k}\)</span> והיא אינה פסגה, אז מכיוון שהיא אינה פסגה קיים איבר שמופיע אחרי <span class="math">\(b_{k}\)</span> וגדול ממנו: נבחר את האיבר הזה להיות <span class="math">\(b_{k+1}\)</span>, ונשים לב שגם הוא לא יהיה פסגה כי אין יותר פסגות בסדרה המקורית. לכן <span class="math">\(b_{k}<b_{k+1}\)</span> ואפשר להמשיך ככה ולקבל סדרה מונוטונית עולה <span class="math">\(b_{0}<b_{1}<b_{2}<\ldots\)</span> ולכן מתכנסת. זה מסיים את ההוכחה הזו ומראה את השימושיות היפה של הטענה על סדרות מונוטוניות מתכנסות.</p>
<p>אבל אני רוצה, כאמור, להראות עוד הוכחה, כי היא תיתן לי מוטיבציה לעוד משפט שימושי שאני רוצה להציג. זו ההוכחה שהצגתי ברפרוף בפוסט הקודם ומשתמשת ברעיון שאוהבים לקרוא לו <strong>אריה במדבר</strong> בהתאם ל"בדיחה" הזו: איך תופסים אריה במדבר? קודם כל מקיפים את המדבר בגדר. עכשיו מעבירים גדר באמצע המדבר. האריה נמצא באחד משני החצאים, אז הולכים לחצי שבו האריה נמצא ומעבירים גדר באמצע שלו וכן הלאה. בסופו של דבר האריה מוגבל לשטח של מטר על מטר - תפסנו אותו!</p>
<p>מה שנחמד בדימוי הזה, כשמקזזים את ההתעללות בבעלי חיים ואת העובדה שאין אריות במדבר, הוא שאנחנו אוטומטית כבר מקבלים הצצה אל איך זה יכול לעבוד בדו-מימד, או במספר כלשהו של ממדים, וזאת להבדיל מההוכחה הקודמת שהייתה מאוד חד ממדית באופי שלה. עדיין, אני מתעסק כאן רק עם <span class="math">\(\mathbb{R}\)</span> אז אני אנסח את ההוכחה רק עבור המקרה החד ממדי, מה שיוביל לכך שהיא תהיה טיפה יותר מסורבלת מהקודמת - אבל כאמור, הרווח הוא שקל להכליל אותה (גם את ההוכחה השניה אפשר להכליל עם לא יותר מדי מאמץ, אבל לטעמי זה פחות מיידי).</p>
<p>אז יש לנו את הסדרה <span class="math">\(\left\{ a_{n}\right\} _{n=0}^{\infty}\)</span> שאני רוצה למצוא לה תת-סדרה מתכנסת ואני יודע שהיא <strong>חסומה</strong>, כלומר קיים <span class="math">\(M>0\)</span> כך ש-<span class="math">\(\left|a_{n}\right|\le M\)</span> לכל <span class="math">\(n\)</span>. זו ה"גדר" שבה מקיפים את כל המדבר. עכשיו אני הולך להגדיר סדרה של <strong>קטעים</strong>, <span class="math">\(C_{n}=\left[\alpha_{n},\beta_{n}\right]\)</span>. ההגדרה של קטע כזה, למי שלא זוכרים, היא <span class="math">\(\left[\alpha,\beta\right]\triangleq\left\{ x\in\mathbb{R}\ |\ \alpha\le x\le\beta\right\} \)</span>. זה מה שנקרא קטע <strong>סגור</strong> כי הוא כולל את נקודות הקצה שלו: זה יהיה חשוב בהמשך.</p>
<p>את סדרת הקטעים אני הולך לבנות ככה שמתקיימים הדברים הבאים:</p>
<ol> <li>בכל קטע <span class="math">\(C_{n}\)</span> יש <strong>אינסוף</strong> איברים של הסדרה <span class="math">\(\left\{ a_{n}\right\} _{n=0}^{\infty}\)</span> (זו המקבילה לכך ש"האריה נמצא בתוך הקטע").</li>


<li><span class="math">\(\left|C_{n}\right|=\beta_{n}-\alpha_{n}=\frac{M}{2^{n-1}}\)</span>, כלומר <strong>האורך</strong> של <span class="math">\(C_{n}\)</span> לא סתם ידוע לנו אלא הוא <strong>שואף לאפס</strong> כש-<span class="math">\(n\)</span> שואף לאינסוף (זה כל מה שנזדקק לו, האורך המדויק לא חשוב).</li>


<li><span class="math">\(C_{n-1}\supseteq C_{n}\)</span>, כלומר כל קטע מוכל בקטע שקודם לו.</li>

</ol>

<p>הקטע הראשון בסדרה יהיה <span class="math">\(C_{0}=\left[-M,M\right]\)</span> והוא בוודאי מקיים את תכונות 1 ו-2. תכונה 3 מתקיימת "באופן ריק" כי אין קטע שקודם לו. עכשיו, בואו נניח שבנינו כבר את <span class="math">\(C_{n}\)</span> והוא אכן מקיים את תכונות 1-3 ונבנה את <span class="math">\(C_{n+1}\)</span>. מה שנעשה הוא לקחת את <span class="math">\(C_{n}=\left[\alpha_{n},\beta_{n}\right]\)</span> ו<strong>לחצות אותו לשניים</strong> (זו המקבילה לכך ש"מעבירים גדר באמצע המדבר"), כלומר נסתכל על הקטעים <span class="math">\(\left[\alpha_{n},\frac{\alpha_{n}+\beta_{n}}{2}\right]\)</span> ו-<span class="math">\(\left[\frac{\alpha_{n}+\beta_{n}}{2},\beta_{n}\right]\)</span>. </p>
<p>האיחוד של שני הקטעים הללו הוא בדיוק <span class="math">\(C_{n}\)</span> ולכן הוא מכיל אינסוף איברים של הסדרה; לכן אחד משני החצאים חייב להכיל אינסוף איברים של הסדרה כי אם בשני החצאים היה רק מספר סופי של איברים, גם באיחוד שלהם היה רק מספר סופי של איברים. נבחר את <span class="math">\(C_{n+1}\)</span> להיות החצי שיש בו אינסוף איברים ("החצי עם האריה"). עם ההגדרה הזו של <span class="math">\(C_{n+1}\)</span> מקבלים מייד את תכונות 2-3 (תוכיחו אותן לעצמכם!)</p>
<p>עכשיו אני רוצה לבנות את תת-הסדרה שלי, <span class="math">\(\left\{ b_{k}\right\} _{k=0}^{\infty}\)</span>. נניח שכבר בניתי את כל האיברים עד <span class="math">\(b_{k}\)</span> ונראה איך בונים אותו: בקטע <span class="math">\(C_{k}\)</span> יש אינסוף איברים של הסדרה המקורית, ובתת-הסדרה שבניתי עד כה יש רק מספר סופי של איברים, אז אני אבחר את <span class="math">\(b_{k}\)</span> להיות איבר של הסדרה המקורית עם אינדקס גדול משל כל האיברים שמופיעים בתת-הסדרה שבניתי עד עכשיו. זה מסיים את הבניה, ורק נשאר להוכיח שתת-הסדרה הזו <strong>מתכנסת</strong>.</p>
<p>אינטואיטיבית, תת-הסדרה הזו נמצא באיזורים שהולכים וקטנים כל הזמן, ולכן יש הרגשה שהיא "חייבת להתכנס", אבל ההרגשה הזו (שבהמשך אתן לה שם פורמלי: <strong>סדרת קושי</strong>) לא נותנת לי איבר ספציפי שאליו הולכים להתכנס - ואכן, אם אנחנו עובדים מעל <span class="math">\(\mathbb{Q}\)</span> כל תהליך הבניה שתיארתי עד כה עובד מושלם אבל תת-הסדרה לא תהיה חייבת להתכנס. אני חייב להכניס פה לתמונה משפט שמשתמש בתכונת השלמות של הממשיים, והמשפט שאני רוצה להשתמש בו הוא מה שאני הולך עוד מעט לתאר: <strong>משפט החיתוך של קנטור</strong>.</p>
<p>הנה ניסוח פורמלי של המשפט: אם <span class="math">\(\left\{ C_{n}\right\} _{n=0}^{\infty}\)</span> היא סדרה של קטעים <strong>סגורים</strong> כך ש-<span class="math">\(C_{n}\supseteq C_{n+1}\)</span> ו-<span class="math">\(\lim_{n\to\infty}\left|C_{n}\right|=0\)</span> אז קיים <span class="math">\(c\in\mathbb{R}\)</span> <strong>יחיד</strong> כך ש-<span class="math">\(c\in\bigcap_{n=0}^{\infty}C_{n}\)</span>. במילים: קיימת נקודה <strong>יחידה</strong> שנמצאת בכל הקטעים בסדרה. זה ה<strong>קיום</strong> שאנחנו זקוקים לו.</p>
<p>אם כן, יש לנו נקודה <span class="math">\(c\)</span> והייתי רוצה להראות שתת-הסדרה שבניתי מתכנסת אליה, כלומר <span class="math">\(\lim_{k\to\infty}b_{k}=c\)</span>. זו הוכחה סטנדרטית: מתחילים עם "יהא <span class="math">\(\varepsilon>0\)</span>" ואז לוקחים <span class="math">\(N\)</span> כך שאם <span class="math">\(k>N\)</span> אז <span class="math">\(\left|C_{k}\right|<\varepsilon\)</span> (קיים כזה, כי <span class="math">\(\lim_{n\to\infty}\left|C_{n}\right|=0\)</span>). עכשיו, <span class="math">\(c\in C_{k}\)</span> (על פי משפט החיתוך של קנטור) וגם <span class="math">\(b_{k}\in C_{k}\)</span> (על פי הבניה של <span class="math">\(b_{k}\)</span>) ולכן אני יכול להסיק ש-<span class="math">\(d\left(b_{k},c\right)<\varepsilon\)</span> ונגמר הסיפור. אני אסביר עכשיו איך אני מסיק את זה במקרה של <span class="math">\(\mathbb{R}\)</span>, מה שכמובן מוסיף סרבול להוכחה; אני אגלה שבאופן כללי, משפט החיתוך של קנטור לא דורש שמה שיישאף לאפס הוא <strong>האורך</strong> של קטע, אלא <strong>הקוטר</strong> של קבוצה במרחב מטרי, כש"הקוטר" הוא המרחק המקסימלי בין זוג איברים מהקבוצה - כלומר, במקרה הכללי המסקנה ש-<span class="math">\(d\left(b_{k},c\right)<\varepsilon\)</span> מגיעה בחינם.</p>
<p>במקרה שלנו, נניח בלי הגבלת הכלליות ש-<span class="math">\(b_{k}<c\)</span>, כלומר</p>
<p><span class="math">\(d\left(b_{k},c\right)=\left|b_{k}-c\right|=c-b_{k}\)</span></p>
<p>עכשיו שימו לב ש-<span class="math">\(b_{k},c\in\left[\alpha_{k},\beta_{k}\right]\)</span> ולכן בפרט <span class="math">\(c\le\beta_{k}\)</span> וגם <span class="math">\(b_{k}\ge\alpha_{k}\)</span>, כלומר <span class="math">\(-b_{k}\le-\alpha_{k}\)</span>, ולכן</p>
<p><span class="math">\(c-b_{k}\le\beta_{k}-\alpha_{k}=\left|C_{k}\right|<\varepsilon\)</span></p>
<p>מה שמסיים את ההוכחה. השגנו את בולצאנו-ויירשטראס וקיבלנו מוטיבציה להוכיח את משפט החיתוך של קנטור, אבל לפני שאני אעשה את זה - בואו נראה מה בכלל <strong>עושים</strong> עם בולצאנו-ויירשטראס ועם משפט החיתוך של קנטור שבגללו אנחנו כל כך אוהבים אותם.</p>
<h2>משפט ערך הביניים ומשפטי ויירשטראס</h2>

<p>הדבר המרכזי שבו מתעסקים בחדו"א הוא <strong>פונקציות ממשיות</strong>, <span class="math">\(f:\mathbb{R}\to\mathbb{R}\)</span>. בואו ניזכר מה ראינו קודם לגבי מושג הגבול עבור פונקציות כאלו:</p>
<ul> <li>אומרים ש-<span class="math">\(f\left(x\right)\)</span> <strong>מתכנסת</strong> ב-<span class="math">\(x_{0}\)</span> אל <span class="math">\(L\)</span> ומסמנים זאת <span class="math">\(\lim_{x\to x_{0}}f\left(x\right)=L\)</span> אם לכל <span class="math">\(\varepsilon>0\)</span> יש <span class="math">\(\delta>0\)</span> כך שאם <span class="math">\(0<d\left(x,x_{0}\right)<\delta\)</span> אז <span class="math">\(d\left(f\left(x\right),L\right)<\varepsilon\)</span></li>


<li>אומרים ש-<span class="math">\(f\left(x\right)\)</span> <strong>רציפה</strong> ב-<span class="math">\(x_{0}\)</span> אם <span class="math">\(\lim_{x\to x_{0}}f\left(x\right)=f\left(x_{0}\right)\)</span></li>

</ul>

<p>מושג הרציפות הוא <strong>נקודתי</strong>; אנחנו מדברים על נקודה קונקרטית שבה <span class="math">\(f\)</span> רציפה. אבל המושג הזה באמת זורח כשיש לנו סיטואציה שבה <span class="math">\(f\)</span> לא רציפה רק בנקודה אחת, אלא בתוך קבוצה "נחמדה" של נקודות. למשל, קטע (קטע הוא דבר טוב כי אין בו "חורים באמצע" שבהם פתאום הפונקציה לא צריכה להיות רציפה ויכולה להשתולל). אני רוצה להראות כמה משפטים בסיסיים שמסתמכים על כך שפונקציה רציפה בקבוצה נחמדה מתנהגת נחמד, אבל לפני כן בואו נראה דרך לחבר את מושג הגבול של סדרה עם מושג הרציפות.</p>
<p>נניח ש-<span class="math">\(f\)</span> רציפה בנקודה <span class="math">\(a\)</span> ונניח שבנוסף לכך יש לנו סדרה <span class="math">\(a_{0},a_{1},a_{2},\ldots\)</span> כך ש-<span class="math">\(\lim_{n\to\infty}a_{n}=a\)</span>. עכשיו, בואו נפעיל את <span class="math">\(f\)</span> על אברי הסדרה ונקבל סדרה חדשה, <span class="math">\(f\left(a_{0}\right),f\left(a_{1}\right),\ldots\)</span>. אני טוען שהרציפות של <span class="math">\(f\)</span> גוררת ש-<span class="math">\(\lim_{n\to\infty}f\left(a_{n}\right)=f\left(a\right)\)</span>. כדי לראות את זה בואו נשתמש בהוכחה סטנדרטית: נגיד שיהא <span class="math">\(\varepsilon>0\)</span> כלשהו, ומהרציפות של <span class="math">\(f\)</span> נסיק שקיים <span class="math">\(\delta\)</span> כך שאם <span class="math">\(d\left(x,a\right)<\delta\)</span> אז <span class="math">\(d\left(f\left(x\right),f\left(a\right)\right)<\varepsilon\)</span>. עכשיו, נעבור לפתוח את הגדרת הגבול <span class="math">\(\lim_{n\to\infty}a_{n}=a\)</span>: מהגדרת הגבול נובע שעבור ה-<span class="math">\(\delta\)</span> שמצאנו קודם קיים <span class="math">\(N\)</span> כך שאם <span class="math">\(n>N\)</span> אז <span class="math">\(d\left(a_{n},a\right)<\delta\)</span>, אבל זה אומר ש-<span class="math">\(d\left(f\left(a_{n}\right),f\left(a\right)\right)<\varepsilon\)</span> כפי שרצינו, וסיימנו. עכשיו, כשיש לי את המשפט המועיל הזה, אני יכול להתחיל להראות תוצאות מגניבות של רציפות.</p>
<p>בואו נתחיל עם <strong>המשפט היסודי של האלגברה</strong>. המשפט בעל השם המפוצץ הזה אומר שבמספרים המרוכבים <span class="math">\(\mathbb{C}\)</span>, לכל פולינום יש שורש, כלומר אם <span class="math">\(p\left(x\right)=a_{n}x^{n}+a_{n-1}x^{n-1}+\ldots+a_{1}x+a_{0}\)</span> הוא פולינום, קיים <span class="math">\(z\in\mathbb{C}\)</span> כך ש-<span class="math">\(p\left(z\right)=0\)</span>. במבט ראשון לא ברור איך זה קשור אלינו, הרי זה משפט שמדבר על מספרים מרוכבים; אבל מספרים ממשיים הם מקרה פרטי חשוב של מרוכבים, ובפרט אם יש לנו פולינום שהמקדמים שלו ממשיים והדרגה שלו <strong>אי-זוגית</strong> אז קל לראות ש<strong>חייב</strong> להיות לו לפחות שורש ממשי אחד (כי השורשים הלא ממשיים בהכרח באים בזוגות של <span class="math">\(z,\overline{z}\)</span>), כלומר מקרה פרטי של המשפט היסודי הוא הטענה "לפולינום ממשי מדרגה אי זוגית יש שורש ממשי". בשעתו הראיתי בבלוג <a href="https://gadial.net/2009/10/29/fundemental_theorem_of_algebra_algebraic_proof/">הוכחה יפה</a> למשפט היסודי של האלגברה שהשתמשה בטכניקות אלגבריות מתורת גלואה - אבל הטכניקות הללו לא יכלו להוכיח בעצמן את הטענה עבור פולינום ממשי ממעלה אי זוגית, ונזקקו להוכחה שאני הולך להראות עכשיו, שהיא חדו"אית לגמרי (ועל כן יש כאלו שאוהבים ללגלג בצורה לא הוגנת ש"המשפט היסודי של האלגברה הוא משפט באנליזה").</p>
<p>הרעיון הוא זה: ראשית, פולינום הוא פונקציה <strong>רציפה</strong> (אני לא הולך להוכיח את זה, אבל זה לא קשה; <span class="math">\(f\left(x\right)=x\)</span> הוא די בבירור רציף ועכשיו רק צריך להראות שסכומים ומכפלות סופיים של פונקציות רציפות הם רציפים). שנית, אם הפולינום הוא ממעלה <strong>אי-זוגית</strong>, ואפשר להניח שהוא מתוקן כלומר שהמעלה של החזקה הגבוהה ביותר <span class="math">\(x^{n}\)</span> היא 1, אז לא קשה לראות שעל ידי הצבת ערך <span class="math">\(a\)</span> שלילי שהוא מספיק גדול בערכו המוחלט אפשר לקבל ש-<span class="math">\(p\left(a\right)<0\)</span> ובדומה אפשר למצוא <span class="math">\(b\)</span> כך ש-<span class="math">\(p\left(b\right)>0\)</span>. כלומר, קיבלנו שני ערכים ש-<span class="math">\(p\)</span> "מחליף סימן" ביניהם, בקטע <span class="math">\(\left[a,b\right]\)</span>. מכיוון ש-<span class="math">\(p\)</span> רציף, אנחנו מדמיינים אותו בתור קו כזה שמציירים על הנייר בלי להרים את העיפרון מהדף, ולכן אם ברגע אחד הוא מתחת לציר <span class="math">\(x\)</span> ורגע אחר כך הוא מעל ציר <span class="math">\(x\)</span> היה שבריר שניה שבו הוא היה <strong>בדיוק</strong> על ציר <span class="math">\(x\)</span>, כלומר יש נקודה <span class="math">\(c\in\left(a,b\right)\)</span> כך ש-<span class="math">\(f\left(c\right)=0\)</span>. משכנע?</p>
<p>לא, לא ממש משכנע. בדיוק בגלל זה צריך הוכחות. הטענה שאני רוצה להוכיח נקראת <strong>משפט ערך הביניים</strong> והנה הניסוח הפורמלי יותר שלה: אם <span class="math">\(f\)</span> היא פונקציה רציפה בקטע <span class="math">\(\left[a,b\right]\)</span> כך ש-<span class="math">\(f\left(a\right)<0<f\left(b\right)\)</span>, אז קיימת <span class="math">\(c\in\left(a,b\right)\)</span> כך ש-<span class="math">\(f\left(c\right)=0\)</span> (אפשר לנסח בצורה כללית יותר, עבור כל ערך ביניים ולא רק 0, אבל זה ניתן לרדוקציה למקרה של <span class="math">\(0\)</span> כי מחליפים את הפונקציה <span class="math">\(f\)</span> שרוצים להראות שמקבלת את הערך <span class="math">\(T\)</span> בפונקציה <span class="math">\(f\left(x\right)-T\)</span>).</p>
<p>איך מוכיחים את זה? הנה הוכחת "אריה במדבר" סטייל עם משפט החיתוך של קנטור. נבנה סדרה של קטעים <span class="math">\(\left[a_{n},b_{n}\right]\)</span> כשהקטע הראשון הוא <span class="math">\(a_{0}=a,b_{0}=0\)</span>. הכלל המנחה יהיה שבכל הקטעים הללו מתקיים <span class="math">\(f\left(a_{n}\right)<0<f\left(b_{n}\right)\)</span>, שהם מכילים אחד את השני ושהאורך של כל אחד מהם הוא <strong>חצי</strong> מהאורך של הקודם, כלומר שהאורכים שלהם שואפים לאפס. נעשה את זה בצורה פשוטה מאוד: נסתכל על נקודת האמצע של כל קטע, <span class="math">\(x_{n}=\frac{a_{n}+b_{n}}{2}\)</span>. אם <span class="math">\(f\left(x_{n}\right)=0\)</span> מצאנו את ה-<span class="math">\(c\)</span> שחיפשנו ואפשר לסיים את ההוכחה; אחרת, אם <span class="math">\(f\left(x_{n}\right)>0\)</span> אז נגדיר <span class="math">\(a_{n+1}=a\)</span> ו-<span class="math">\(b_{n+1}=x_{n}\)</span>, ואילו אם <span class="math">\(f\left(x_{n}\right)<0\)</span> אז נגדיר <span class="math">\(a_{n+1}=x_{n}\)</span> ו-<span class="math">\(b_{n+1}=b_{n}\)</span>.</p>
<p>עכשיו, משפט החיתוך של קנטור אומר לנו שקיימת נקודה יחידה <span class="math">\(c\in\bigcap_{n=1}^{\infty}\left[a_{n},b_{n}\right]\)</span>. האינטואיציה היא שזו הנקודה שחיפשתי, שבה <span class="math">\(f\left(c\right)=0\)</span>, כי עם הקטעים <span class="math">\(\left[a_{n},b_{n}\right]\)</span> אני עושה "זום אין" מדויק על רגע שבו הפונקציה עוברת משלילית לחיובית. אבל איך אני מוכיח את זה? כאן הרציפות נכנסת לתמונה. ראשית, קל להראות ש-<span class="math">\(a_{n}\to c\)</span>. שנית, בגלל ש-<span class="math">\(f\)</span> רציפה נובע ממה שהראיתי קודם ש-<span class="math">\(\lim_{n\to\infty}f\left(a_{n}\right)=f\left(c\right)\)</span>. בנוסף, <span class="math">\(f\left(a_{n}\right)<0\)</span> לכל <span class="math">\(n\)</span> כי ככה בניתי את סדרת ה-<span class="math">\(n\)</span>-ים. אז קיבלנו ש-<span class="math">\(f\left(c\right)\)</span> הוא הגבול של סדרה של מספרים שליליים, וגבול כזה חייב להיות שלילי או אפס, כי אם הוא <span class="math">\(L>0\)</span> אז <strong>כל</strong> איבר בסדרה יהיה לפחות במרחק <span class="math">\(L\)</span> ממנו ולכן עבור <span class="math">\(\varepsilon<L\)</span> הוכחת הגבול תיכשל. כלומר, <span class="math">\(f\left(c\right)\le0\)</span>. באופן דומה בעזרת סדרת ה-<span class="math">\(b\)</span>-ים מראים ש-<span class="math">\(f\left(c\right)\ge0\)</span>, והמסקנה משני אלו היא ש-<span class="math">\(f\left(c\right)=0\)</span>, כפי שרצינו.</p>
<p>מה קרה פה? הרציפות היא זו שנתנה לנו את <span class="math">\(f\left(c\right)\le0\)</span> ואת <span class="math">\(f\left(c\right)\ge0\)</span>, אבל מה שתכונת <strong>השלמות</strong> נתנה לנו הוא את זה שבכלל קיים <span class="math">\(c\)</span> כזה - קיים חלקיק שניה מדויק שבו אפשר לעצור את הסרט של <span class="math">\(f\)</span> ולהגיד "הנה! רואים?! זו השניה המדויקת שבה עברנו את ציר <span class="math">\(x\)</span>!" במספרים הרציונליים זה פשוט לא עובד: אם למשל נסתכל על הפונקציה <span class="math">\(f\left(x\right)=x-\pi\)</span>: אין מספר רציונלי שמאפס אותה, אבל היא כמובן רציפה. פשוט אין בסרט שלנו את הפריים עבור <span class="math">\(x=\pi\)</span> שבו רואים אותה מתאפסת, כי הסרט כולל רק פריימים שנלקחו בנקודות רציונליות.</p>
<p>בואו נעבור עכשיו למה שמכונה <strong>משפט ערך הקיצון של ויירשטראס</strong> (Extreme value theorem) ולפעמים מחלקים לשני משפטים - "משפט ויירשטראס הראשון" ו"משפט ויירשטראס השני" (שההוכחה שלו מסתמכת על הראשון) וגם אני כאן אדבר עליהם בתור שני משפטים. הרעיון בהם די פשוט: אם אני מצייר פונקציה רציפה בקטע סגור, העפרון שלי מתחיל בנקודה אחת ומצייר איזה קו עד שהוא מגיע לנקודה בקצה השני. הוא לא יכול בשום שלב לברוח לאינסוף, כי פונקציה רציפה היא "רגועה". אני אצייר את כולה על הנייר שעל השולחן ולא אמצא את עצמי פתאום נאלץ ללכת עד לקוטב הצפוני בשביל לצייר אותה (זה לא נכון, אני משקר כדי לתת אינטואיציה, פונקציה רציפה בהחלט עלולה לדרוש ממני ללכת עד לקוטב הצפוני, פשוט לא עד <strong>לאינסוף</strong>). באופן פורמלי: פונקציה רציפה על קטע סגור וחסום היא <strong>חסומה</strong> בו. זה משפט ויירשטראס הראשון, והשני מרחיב: לא סתם חסומה, אלא מקבלת את המקסימום והמינימום שלה, כלומר אם יש לנו את הקטע <span class="math">\(\left[a,b\right]\)</span> ופונקציה רציפה <span class="math">\(f:\left[a,b\right]\to\mathbb{R}\)</span> אז קיימות נקודות <span class="math">\(c_{1},c_{2}\in\left[a,b\right]\)</span> כך ש-<span class="math">\(f\left(c_{1}\right)=\min\left\{ f\left(x\right)\ |\ x\in\left[a,b\right]\right\} \)</span> ו-<span class="math">\(f\left(c_{2}\right)=\max\left\{ f\left(x\right)\ |\ x\in\left[a,b\right]\right\} \)</span>.</p>
<p>האם המשפט הראשון מתבסס רק על הרציפות של <span class="math">\(f\)</span> או גם על השלמות של <span class="math">\(\mathbb{R}\)</span>? לכאורה לא צריך פה את השלמות, הרי הטענה היא לא מהצורה "קיימת נקודה בקטע שמקיימת כך וכך" אלא "קיים חסם אחיד עבור כל הנקודות בקטע". אבל הנקודה היא שבלי ש-<span class="math">\(\mathbb{R}\)</span> יהיה שלם, פונקציה יכולה "להשתגע" כשהערכים שלה מתקרבים לנקודה ש"חסרה" ב-<span class="math">\(\mathbb{R}\)</span> ועדיין להיחשב רציפה, כי הדוגמא הנגדית לרציפות שלה היא נקודה שלא קיימת בכלל.</p>
<p>איך גורמים לפונקציה "להשתגע"? פשוט מאוד, מחלקים באפס. למשל, נסתכל על הקטע <span class="math">\(\left(0,1\right)\)</span> ועל הפונקציה <span class="math">\(f\left(x\right)=\frac{1}{x}\)</span>. הפונקציה הזו בבירור <strong>כן</strong> רציפה בקטע (זה דורש טיפה הוכחה) אבל כש-<span class="math">\(x\)</span> מתקרב ל-<span class="math">\(0\)</span> הפונקציה "מתפוצצת", גדלה ועוברת כל חסם אפשרי; היא בוודאי לא חסומה ב-<span class="math">\(\left(0,1\right)\)</span>, והסיבה שזו לא דוגמא נגדית למשפט ויירשטראס היא שעל הקטע <strong>הסגור </strong><span class="math">\(\left[0,1\right]\)</span> הפונקציה לא תהיה רציפה כי היא בכלל לא מוגדרת ב-0. זה ממחיש את החשיבות בכך שהקטע הוא <strong>סגור</strong>; בלי זה המשפט לא עובד.</p>
<p>עכשיו, בואו נניח לרגע ש-0 בכלל לא קיים ביקום שלנו ואנחנו מסתכלים עדיין על <span class="math">\(f\left(x\right)=\frac{1}{x}\)</span>, אבל בקטע <span class="math">\(\left[-1,1\right]\)</span>. הפונקציה עדיין לא חסומה בו כי בסביבות <span class="math">\(x=0\)</span> היא "מתפוצצת", אבל האם היא לא רציפה? בכל נקודה חוץ מ-0 היא כן רציפה, אז אם 0 לא קיים ביקום שלנו, קיבלנו פונקציה שרציפה בקטע הסגור והחסום <span class="math">\(\left[-1,1\right]\)</span> אבל לא חסומה בו. כמובן, 0 <strong>כן קיים</strong> ביקום שלנו, אבל אם אנחנו לא ב-<span class="math">\(\mathbb{R}\)</span> אלא ב-<span class="math">\(\mathbb{Q}\)</span> אז מספרים אחרים כמו <span class="math">\(\pi\)</span> לא קיימים בו ואפשר לתקן את הדוגמא כדי שתהיה סביבם, באופן הבא: נסתכל על הקטע <span class="math">\(\left[3,4\right]\)</span> ועל הפונקציה <span class="math">\(f\left(x\right)=\frac{1}{x-\pi}\)</span> ש"מתפוצצת" ב-<span class="math">\(x=\pi\)</span>.</p>
<p>ההוכחה של משפט ויירשטראס הראשון מתבססת על הדוגמא הנגדית המטופשת הזו: היא מניחה בשלילה שהפונקציה לא חסומה ולכן יש מקום שבו היא "מתפוצצת", ואז משתמשת בשלמות של הממשיים כדי למצוא נקודה שנמצאת במרכז הפיצוץ הזה והפונקציה פשוט לא יכולה להיות רציפה בה. בואו נניח בשלילה ש-<span class="math">\(f\left(x\right)\)</span> הרציפה לא חסומה בקטע <span class="math">\(\left[a,b\right]\)</span>, אז לכל <span class="math">\(n\)</span> קיימת נקודה <span class="math">\(x_{n}\in\left[a,b\right]\)</span> כך ש-<span class="math">\(f\left(x_{n}\right)\ge n\)</span>. קיבלנו סדרה <span class="math">\(\left\{ x_{n}\right\} _{n=0}^{\infty}\)</span> של נקודות שביחד מתארות את ה"התפוצצות" של <span class="math">\(f\)</span>, אלא שלרוע המזל ייתכן שהנקודות הללו נמצאות במקומות שונים לגמרי של הקטע <span class="math">\(\left[a,b\right]\)</span> ואני רוצה התפוצצות שמרוכזת בנקודה אחת; כאן בדיוק בא משפט בולצאנו-ויירשטראס לעזרתי ומוצא תת-סדרה מתכנסת <span class="math">\(\left\{ c_{n}\right\} _{n=0}^{\infty}\)</span> של <span class="math">\(\left\{ x_{n}\right\} _{n=0}^{\infty}\)</span>. תחשבו על בולצאנו-ויירשטראס כאילו הוא מתמקד בנקודת "התפוצצות" כלשהי ומעיף מהסדרה <span class="math">\(\left\{ x_{n}\right\} _{n=0}^{\infty}\)</span> את כל הנקודות שלא קשורות אליה אלא מתארות התפוצצויות אחרות או סתם מקומות שבהם הפונקציה מגיעה לגבהים בלי להתפוצץ ("הקוטב הצפוני"). נסמן <span class="math">\(c=\lim_{n\to\infty}c_{n}\)</span>, וכאן השתמשנו בשלמות של <span class="math">\(\mathbb{R}\)</span>: בלי זה הנקודה <span class="math">\(c\)</span> לא הייתה בהכרח קיימת, אפילו אם היינו מצליחים לבנות מקבץ <span class="math">\(\left\{ c_{n}\right\} _{n=0}^{\infty}\)</span> של נקודות שנראה כאילו הוא סובב סביב נקודת התפוצצות כלשהי.</p>
<p>הטיעון עכשיו הוא שבגלל הרציפות של <span class="math">\(f\)</span> צריך להתקיים <span class="math">\(f\left(c\right)=\lim_{n\to\infty}f\left(c_{n}\right)\)</span> אבל מכיוון שהסדרה <span class="math">\(f\left(c_{n}\right)\)</span> לא חסומה (קל להראות ש-<span class="math">\(f\left(c_{n}\right)\ge n\)</span> כי כשיצרנו את תת-הסדרה <span class="math">\(c_{n}\)</span> מתוך <span class="math">\(x_{n}\)</span> התכונה <span class="math">\(x_{n}\ge n\)</span> רק התחזקה) נובע שהגבול לא קיים בכלל (הוא קיים במובן הרחב, של <span class="math">\(\lim_{n\to\infty}f\left(c_{n}\right)=\infty\)</span>, אבל זו הגדרה שונה) ולכן <span class="math">\(f\left(c\right)\)</span> לא מוגדרת בכלל; זה תרגיל טוב ולא קשה לנסח את זה פורמלית עד הסוף. סיימנו את ההוכחה של משפט ויירשטראס הראשון במובן זה שהראינו שהפונקציה חסומה מלעיל, ובאותו אופן מוכיחים שהיא חסומה מלרע.</p>
<p>עכשיו אפשר לעבור למשפט ויירשטראס השני - ננצל את זה שאנחנו כבר יודעים שהפונקציה חסומה כדי להראות שהיא מקבלת את הערך המקסימלי שלה. כרגיל, כדי להבין מה זה אומר ולמה השלמות של הממשיים קריטית לזה, בואו נסתכל על דוגמת צעצוע: הפונקציה הרציפה <span class="math">\(f\left(x\right)=1-\left|x\right|\)</span>. קל לראות ש-<span class="math">\(f\left(0\right)=1\)</span> הוא הערך המקסימלי של הפונקציה הזו, אבל אם <span class="math">\(0\)</span> לא היה חלק מהיקום המתמטי שלנו, הפונקציה לא הייתה מגיעה ל-1 אף פעם, רק שואפת אליו. רק מה, 0 הוא כן חלק מהעולם שלנו אז אפשר לעשות את הטריק הרגיל של להזיז את הכל כך שהנקודה שאנחנו מדברים עליה תהיה <span class="math">\(\pi\)</span> ולא 0, כלומר להגדיר <span class="math">\(f\left(x\right)=1-\left|x-\pi\right|\)</span>. אני חוזר שוב ושוב על השטיק הזה כדי שיהיה ברור שהפואנטה של השלמות של <span class="math">\(\mathbb{R}\)</span> היא לא שקיים מספר מעניין ומיוחד כמו <span class="math">\(\pi\)</span>, כי אין למהות של <span class="math">\(\pi\)</span> תפקיד אמיתי כאן; מה שחשוב הוא המבנה של קבוצת הממשיים בכללותה, המחסור הזה בחורים, כי אם יש אפילו חור אחד אפשר "להזיז" את כל העולם כך שהחור יהיה מרכז העולם, ולא משנה אם זה חור ב-0 או ב-<span class="math">\(\pi\)</span>.</p>
<p>בדוגמא <span class="math">\(f\left(x\right)=1-\left|x-\pi\right|\)</span> יש לנו פונקציה שאם תוגדר על הרציונליים, לא תקבל את המקסימום שלה בקטע <span class="math">\(\left[3,4\right]\)</span>, אבל מה שכן יהיה נכון הוא שלפחות יהיה סופרמום לקבוצת הערכים שהיא מקבלת שם: <span class="math">\(\sup\left\{ f\left(x\right)\ |\ x\in\left[3,4\right]\right\} =1\)</span>. גם את זה אפשר לקלקל בקלות אם מגדירים <span class="math">\(f\left(x\right)=\pi-\left|x-\pi\right|\)</span>. כלומר, כדי שמשפט ויירשטראס השני יעבוד אנחנו צריכים להשתמש בשלמות <strong>פעמיים</strong>: פעם אחת בשביל התחום של <span class="math">\(f\)</span>, כדי להוכיח את קיום הנקודה שבה יתקבל המקסימום; ופעם שניה, עוד יותר מוקדמת, עבור <strong>הטווח</strong> של <span class="math">\(f\)</span> כדי להוכיח שבכלל יש ערך מקסימלי ששווה לנסות ולקבל.</p>
<p>ההוכחה הסטנדרטית הולכת כך: בואו באמת נסתכל על <span class="math">\(\sup\left\{ f\left(x\right)\ |\ x\in\left[a,b\right]\right\} \)</span>. מכיוון שידוע לנו ש-<span class="math">\(f\)</span> חסומה ב-<span class="math">\(\left[a,b\right]\)</span> (זה משפט ויירשטראס הראשון) ומכיוון ש-<span class="math">\(\left[a,b\right]\)</span> כולל לפחות נקודה אחת (אם <span class="math">\(a=b\)</span> הקטע עדיין כולל את <span class="math">\(a\)</span>) אז <span class="math">\(A=\sup\left\{ f\left(x\right)\ |\ x\in\left[a,b\right]\right\} \)</span> קיים כי לקחנו סופרמום של קבוצה חסומה לא ריקה; זה שימוש ישיר ב<strong>אקסיומת השלמות</strong> של שדה סדור שלם. עכשיו אפשר להשתמש בטריק בולצאנו-ויירשטראסי בדיוק כמו קודם, רק במקום עם סדרה שמתפוצצת, עם סדרה ששואפת אל <span class="math">\(A\)</span>: לכל <span class="math">\(n\)</span> נמצא <span class="math">\(x_{n}\in\left[a,b\right]\)</span> כך ש-<span class="math">\(A-\frac{1}{n}\le f\left(x_{n}\right)\le A\)</span> (קיים כזה כי <span class="math">\(A\)</span> סופרמום), ניקח תת-סדרה מתכנסת <span class="math">\(\left\{ c_{n}\right\} _{n=0}^{\infty}\)</span>, נסמן <span class="math">\(c=\lim_{n\to\infty}c_{n}\)</span>, נשתמש ברציפות של <span class="math">\(f\)</span> כדי להסיק <span class="math">\(f\left(c\right)=\lim_{n\to\infty}f\left(c_{n}\right)\)</span> ונוכיח די בקלות (תרגיל טוב!) ש-<span class="math">\(\lim_{n\to\infty}f\left(c_{n}\right)=A\)</span>.</p>
<p>ההוכחה הזו פשוטה ונהדרת, ולרוע המזל היא גורמת לי אי נוחות בפוסט הספציפי הזה כי קלעתי את עצמי לפינה שבה אני מנסה <strong>לא</strong> להשתמש ישירות באקסיומת השלמות, כי אני רוצה להראות שטבעי באותה מידה להתחיל מהניסוח האלטרנטיבי של קנטור לשלמות ו"להיפגש באמצע", כלומר להשתמש במשפט החיתוך של קנטור או בבולצאנו-ויירשטראס. אבל כאן אני לא רואה דרך לא מסורבלת לעשות את זה. זו כנראה נקודה פדגוגית לזכות ההצגה המוקדמת של אקסיומת השלמות.</p>
<p>לסיכום חלק הדוגמאות הזה, רציתי להביא כאן גם את <strong>משפט הערך הממוצע של לגראנז'</strong> שהוא באמת משפט שימושי בצורה יוצאת דופן, אבל אני לא אעשה את זה כי זה ייאלץ אותי לדבר גם על <strong>נגזרות</strong> ומשפטים שקשורים אליהן שאני לא רוצה להוכיח, אז הנה שורה אחת על לגראנז' למי שמכירות אותו: כדי להוכיח את לגראנז' אנחנו עושים תעלול אלגברי קטן שמבצע לו רדוקציה אל <strong>משפט רול</strong>. את משפט רול מוכיחים על ידי שילוב של שני משפטים: משפט פרמה, שאומר שנגזרת של פונקציה בנקודת קיצון מתאפסת; ומשפט ויירשטראס השני, שמראה שבתנאים של משפט רול יש לפונקציה נקודת קיצון. במילים אחרות, בכל מקרה אין כאן תוכן מתמטי רלוונטי שלא ראינו כי אנחנו מסתמכים פה על משפט ויירשטראס; ומצד שני בלי לגראנז' באמת שאין חדו"א כמו שאנחנו מכירים. וכך זה ממשיך ומפעפע עוד ועוד לכל רחבי החדו"א.</p>
<p>כל זה כנראה משכנע שאקסיומת השלמות היא דבר חשוב ושהגישה של דדקינד נכונה; אבל עכשיו הגיע הזמן לדבר גם על הגישה הנוספת.</p>
<h2>סדרות קושי</h2>

<p>בשלבים הקודמים של הפוסט ראינו את <strong>משפט החיתוך של קנטור</strong>. הנה תזכורת איך הוא הולך: אם <span class="math">\(\left\{ C_{n}\right\} _{n=0}^{\infty}\)</span> היא סדרה של קטעים <strong>סגורים</strong> כך ש-<span class="math">\(C_{n}\supseteq C_{n+1}\)</span> ו-<span class="math">\(\lim_{n\to\infty}\left|C_{n}\right|=0\)</span> אז קיים <span class="math">\(c\in\mathbb{R}\)</span> <strong>יחיד</strong> כך ש-<span class="math">\(c\in\bigcap_{n=0}^{\infty}C_{n}\)</span>. איך אפשר להוכיח את זה? ובכן, הנה גישה אחת: מכיוון שהקטעים <span class="math">\(C_{n}\)</span> הם סגורים כל אחד כולל לפחות נקודה אחת, אז פשוט ניקח <span class="math">\(c_{n}\in C_{n}\)</span> לכל קטע וקיבלנו סדרה. עכשיו נגדיר <span class="math">\(c=\lim_{n\to\infty}c_{n}\)</span> וקיבלנו את ה-<span class="math">\(c\)</span> שלנו. עכשיו צריך עדיין להוכיח שהוא בחיתוך של כל הקטעים ושהוא יחיד, אבל עברנו את השלב הקשה של להוכיח שהוא קיים... רגע רגע רגע, לא הוכחנו שום דבר. אני לא יכול להגדיר <span class="math">\(c=\lim_{n\to\infty}c_{n}\)</span> כי אני לא יודע שהסדרה <span class="math">\(\left\{ c_{n}\right\} _{n=0}^{\infty}\)</span> מתכנסת בכלל. אבל מה שאני כן יודע הוא שהסדרה הזו נראית <strong>כאילו היא אמורה להתכנס</strong>. למה? ובכן, כי בגלל שהאיברים שלה שייכים לסדרת קטעים שהולכת ומצטופפת, גם האיברים שלה צריכים, ובכן, ללכת ולהצטופף יחד. וכשיש לי סדרה שנראה שהאיברים שלה מצטופפים סביב מקום אחד, הייתי יכול לקוות שהיא תתכנס, לא?</p>
<p>זה הרעיון מאחורי המושג שנקרא <strong>סדרת קושי</strong> (במאמר שלו קנטור קרא לה "סדרה יסודית", אבל זה לא המושג המקובל כיום). פורמלית, <span class="math">\(\left\{ a_{n}\right\} _{n=0}^{\infty}\)</span> היא <strong>סדרת קושי</strong> אם לכל <span class="math">\(\varepsilon>0\)</span> קיים <span class="math">\(N\)</span> כך שלכל <span class="math">\(n,m>N\)</span> מתקיים <span class="math">\(d\left(a_{n},a_{m}\right)<\varepsilon\)</span>. כלומר, לכל אפסילון קיים מקום בסדרה שהחל ממנו <strong>כל זוג איברים</strong> בסדרה קרובים זה לזה עד כדי אפסילון. ניסוח שימושי שקול הוא שלכל <span class="math">\(\varepsilon>0\)</span> קיים <span class="math">\(N\)</span> כך שלכל <span class="math">\(n>N\)</span> מתקיים <span class="math">\(d\left(a_{n},a_{N}\right)<\varepsilon\)</span>, כלומר לכל אפסילון קיים איבר בסדרה שכל יתר אברי הסדרה קרובים אליו עד כדי אפסילון.</p>
<p>שימו לב להבדל בין זה ובין הגדרת הגבול. גבול אומר שלכל אפסילון, קיים מקום בסדרה שהחל ממנו כל יתר איברי הסדרה קרובים <strong>אל הגבול</strong> עד כדי אפסילון - הגבול עצמו בכלל לא צריך להיות איבר בסדרה. לעומת זאת בסדרת קושי לכל אפסילון אנחנו בוחרים איבר מהסדרה שאליו כל יתר האיברים יהיו קרובים - והאיבר הזה <strong>תלוי באפסילון</strong>, כלומר זה לא שיש בסדרה איבר בודד שכל יתר האיברים קרובים אליו לכל אפסילון שנרצה (להבדיל מגבול שכן מקיים את זה). כלומר, התכונה שמגדירה סדרת קושי מרגישה קצת "חלשה יותר" מקיום גבול.</p>
<p>האמנם? ובכן, יש כאן שני משפטים שאפשר להוכיח: ראשית, שאם סדרה מתכנסת לגבול אז היא סדרת קושי (מה שמראה שקיום גבול "חזק לפחות כמו" להיות סדרת קושי) ושנית, שאם סדרה היא סדרת קושי אז היא אכן מתכנסת לגבול. בואו נוכיח את שניהם.</p>
<p>ראשית, נניח ש-<span class="math">\(\left\{ a_{n}\right\} _{n=0}^{\infty}\)</span> מתכנסת, <span class="math">\(\lim_{n\to\infty}a_{n}=a\)</span>, ונוכיח ש-<span class="math">\(\left\{ a_{n}\right\} _{n=0}^{\infty}\)</span> היא סדרת קושי ממש על פי ההגדרה. ניקח <span class="math">\(\varepsilon>0\)</span>, אז קיים מקום <span class="math">\(N\)</span> בסדרה כך שלכל <span class="math">\(n>N\)</span> מתקיים <span class="math">\(d\left(a_{n},a\right)<\frac{\varepsilon}{2}\)</span> (השתמשנו בהגדרת הגבול של סדרה עם <span class="math">\(\frac{\varepsilon}{2}\)</span>). עכשיו, ניקח <span class="math">\(n,m>N\)</span>, נשתמש באי שיוויון המשולש ונקבל</p>
<p><span class="math">\(d\left(a_{n},a_{m}\right)\le d\left(a_{n},a\right)+d\left(a,a_{m}\right)<\frac{\varepsilon}{2}+\frac{\varepsilon}{2}=\varepsilon\)</span></p>
<p>וסיימנו. זה היה כיוון קל.</p>
<p>מה עם הכיוון השני? ובכן, אם <span class="math">\(\left\{ a_{n}\right\} _{n=0}^{\infty}\)</span> היא סדרת קושי אנחנו עדיין לא יודעים אם היא מתכנסת או לא, אבל בזכות <strong>בולצאנו-ויירשטראס</strong> אנחנו יודעים שקיימת לה <strong>תת-סדרה</strong> מתכנסת. נסמן את הגבול של תת-הסדרה הזו ב-<span class="math">\(a\)</span>. עכשיו נראה ש-<span class="math">\(\lim_{n\to\infty}a_{n}=a\)</span> בשיטה הסטנדרטית: ניקח <span class="math">\(\varepsilon>0\)</span> כלשהו ונמצא <span class="math">\(N\)</span> כך שאם <span class="math">\(n>N\)</span> אז <span class="math">\(d\left(a_{n},a\right)<\varepsilon\)</span>. בשביל זה נשלב גם את התכונה של סדרת קושי וגם את הקטע של תת-סדרה מתכנסת.</p>
<p>ראשית, בגלל ש-<span class="math">\(\left\{ a_{n}\right\} _{n=0}^{\infty}\)</span> היא סדרת קושי, קיים <span class="math">\(N\)</span> כך שלכל <span class="math">\(n,m>N\)</span> מתקיים <span class="math">\(d\left(a_{n},a_{m}\right)<\frac{\varepsilon}{2}\)</span>. עכשיו, בתת-הסדרה המתכנסת של <span class="math">\(\left\{ a_{n}\right\} _{n=0}^{\infty}\)</span> קיים מקום <span class="math">\(N^{\prime}\)</span> כך שלכל <span class="math">\(n>N^{\prime}\)</span>, אם <span class="math">\(a_{n}\)</span> שייך לתת-הסדרה אז <span class="math">\(d\left(a_{n},a\right)<\frac{\varepsilon}{2}\)</span>. בואו ניקח <span class="math">\(m\)</span> כך ש-<span class="math">\(m>\max\left\{ N,N^{\prime}\right\} \)</span> אז בפרט מתקיים <span class="math">\(d\left(a_{m},a\right)<\frac{\varepsilon}{2}\)</span> ובנוסף, לכל <span class="math">\(n>N\)</span>, מכיוון ש-<span class="math">\(n,m>N\)</span> אז <span class="math">\(d\left(a_{n},a_{m}\right)<\frac{\varepsilon}{2}\)</span> ואפשר להשתמש באי שוויון המשולש:</p>
<p><span class="math">\(d\left(a_{n},a\right)\le d\left(a_{n},a_{m}\right)+d\left(a_{m},a\right)<\frac{\varepsilon}{2}+\frac{\varepsilon}{2}=\varepsilon\)</span></p>
<p>וסיימנו גם את הכיוון הזה. אבל שימו לב מה היה המחיר ששילמנו: בניגוד להוכחה של הכיוון הקודם שהייתה אלמנטרית, כאן השתמשנו במשפט המאוד לא טריוויאלי של <strong>בולצאנו-ויירשטראס</strong>. זה רומז לנו שיש כאן משהו מהותי, ובעצם זה לא צריך להיות מפתיע - אנחנו שוב פעם בוראים איבר יש מאין, במקרה הזה את גבול הסדרה. כבר ראינו בפוסט הזה את הסדרה <span class="math">\(1,1.4,1.41,1.414,1.4142,\ldots\)</span> ש"אמורה להתכנס" אל <span class="math">\(\sqrt{2}\)</span>; הבאתי אותה במקור בתור סדרה מונוטונית חסומה, אבל זו גם בבירור סדרת קושי של מספרים ב-<span class="math">\(\mathbb{Q}\)</span> ולכן בלי ש-<span class="math">\(\sqrt{2}\)</span> יהיה חלק מהעולם שלנו פשוט לא יהיה לה לאן להתכנס.</p>
<p>זה זמן טוב לעצור לרגע ולראות את שרשרת ההוכחות שיש לנו:</p>
<ul> <li><strong>אקסיומת השלמות</strong> <span class="math">\(\leftarrow\)</span> כל סדרה מונוטונית וחסומה מתכנסת <span class="math">\(\leftarrow\)</span> בולצאנו ויירשטראס (הוכחת ה"פסגות") <span class="math">\(\leftarrow\)</span> כל סדרת קושי מתכנסת</li>

</ul>

<p>בתוך כל זה גם הכנסתי את משפט החיתוך של קנטור, בתור דרך <strong>אחרת</strong> להוכיח את בולצאנו ויירשטראס, וקיבלתי מוטיבציה להוכחה של משפט החיתוך של קנטור דווקא מסדרות קושי. זה רומז לנו במעורפל שאולי אפשר גם לקחת את שרשרת ההוכחות הזו בכיוון ההפוך - להתחיל מכך שכל סדרת קושי מתכנסת ולהסיק מכך את בולצאנו ויירשטראס, את ההתכנסות של כל סדרה מונוטונית וחסומה, ואת אקסיומת השלמות.</p>
<p>כלומר, אני מציע שבמקום להתחיל מאקסיומת השלמות, נתחיל ממה שאני אקרא לו "שלמות-קנטור", בזמן שלשלמות ה"רגילה" אני אקרא "שלמות-דדקינד":</p>
<ul> <li><strong>שלמות-קנטור</strong>: כל סדרת קושי מתכנסת.</li>


<li><strong>שלמות-דדקינד</strong>: לכל קבוצה לא ריקה וחסומה קיים חסם עליון.</li>

</ul>

<p>נתחיל אם כן מהאקסיומה שבמספרים הממשיים מתקיימת שלמות-קנטור ונראה לאן נגיע עם זה. כרגיל, אני מזהיר שהמילה <strong>אקסיומה</strong> פה לא אומרת "משהו שברור מאליו ולא צריך להוכיח" אלא "תכונה שהיא בסיסית מספיק כדי שנציין אותה במפורש ואנחנו מצפים מהבניה של המרחב שלנו לוודא שהיא מתקיימת". בבניה של קנטור למספרים הממשיים, שלמות-קנטור היא מה שכל הבניה סובבת סביבו כדי להבטיח שיתקיים, בעוד שבבניה של דדקינד, באופן לא מפתיע, הבניה סובבת סביב להראות ששלמות-דדקינד מתקיימת. את שתי הבניות, כאמור, אני לא אציג בפוסט הזה כי הוא גם ככה ארוך מדי.</p>
<p>בואו נוכיח דברים עם שלמות-קנטור. בראש ובראשונה, את משפט החיתוך של קנטור. כבר התחלתי את זה: הייתה לי סדרה <span class="math">\(\left\{ C_{n}\right\} _{n=0}^{\infty}\)</span> של קטעים <strong>סגורים</strong> כך ש-<span class="math">\(C_{n}\supseteq C_{n+1}\)</span> ו-<span class="math">\(\lim_{n\to\infty}\left|C_{n}\right|=0\)</span>. אמרתי שאני בונה סדרה <span class="math">\(c_{n}\in C_{n}\)</span>. בגלל התכונה <span class="math">\(C_{n}\supseteq C_{n+1}\)</span> נובע שאם <span class="math">\(n>N\)</span> אז <span class="math">\(a_{n}\in C_{N}\)</span>, ולכן קל להראות שזו סדרת קושי: עבור <span class="math">\(\varepsilon>0\)</span> כלשהו, נשתמש בכך ש-<span class="math">\(\lim_{n\to\infty}\left|C_{n}\right|=0\)</span> כדי למצוא <span class="math">\(N\)</span> כך ש-<span class="math">\(\left|C_{N}\right|<\varepsilon\)</span>. כלומר, פורמלית, <span class="math">\(C_{N}=\left[a_{N},b_{N}\right]\)</span> כך ש-<span class="math">\(\left|a_{N}-b_{N}\right|<\varepsilon\)</span>, אבל אפשר לחשוב על זה קצת יותר כללי: לחשוב על<span class="math">\(\left|C_{n}\right|\)</span> בתור סימון של <strong>הקוטר</strong> של הקבוצה <span class="math">\(C_{N}\)</span>, המרחק המקסימלי בין כל שני איברים שלה. כשמכלילים את משפט קנטור למרחבים מטריים כלליים, זה המושג שנעזרים בו.</p>
<p>גם במקרה הפרטי שלנו זה מתקיים: אם <span class="math">\(x,y\in\left[a,b\right]\)</span> אני טוען ש-<span class="math">\(\left|x-y\right|\le\left|a-b\right|\)</span>. כדי לראות את זה צריך קצת חשבונות קטנים וקטנוניים: אני מניח בלי הגבלת הכלליות ש-<span class="math">\(a\le x\le y\le b\)</span> ולכן בפרט <span class="math">\(-a\ge-x\)</span> ולכן <span class="math">\(b-a\ge y-a\ge y-x\)</span> ולכן <span class="math">\(\left|x-y\right|\le\left|a-b\right|\)</span>.</p>
<p>זה נותן לנו את סדרת הקושי שלנו: ניקח <span class="math">\(n,m>N\)</span> אז בגלל ש-<span class="math">\(c_{n},c_{m}\in C_{N}\)</span> נקבל ש-<span class="math">\(d\left(c_{n},c_{m}\right)\le\left|C_{N}\right|<\varepsilon\)</span>, כפי שרצינו. ועכשיו נשתמש בשלמות-קנטור כדי לקבל <span class="math">\(c\)</span> כך ש-<span class="math">\(c=\lim_{n\to\infty}c_{n}\)</span>. זה היה החלק הקריטי - לעבור ממצב שבו אין לנו איבר ביד למצב שבו יש לנו אותו ביד. עכשיו צריך להראות עדיין ש-<span class="math">\(c\in\bigcap_{n=0}^{\infty}C_{n}\)</span> ושהוא האיבר היחיד שמקיים את זה, אבל זה החלק הקל.</p>
<p>ראשית, כדי להראות ש-<span class="math">\(c\in C_{n}\)</span> לכל <span class="math">\(n\ge0\)</span>, נשים לב לכך ש-<span class="math">\(c\)</span> הוא הגבול של הסדרה <span class="math">\(a_{n},a_{n+1},a_{n+2},\ldots\)</span> (כלומר, הסדרה <span class="math">\(\left\{ c_{n}\right\} _{n=0}^{\infty}\)</span> שבניתי כשאני זורק לפח את האיברים הראשונים עד <span class="math">\(a_{n}\)</span>). בגלל התכונה <span class="math">\(C_{n}\supseteq C_{n+1}\)</span> אנחנו יודעים שכל אברי הסדרה הזו שייכים ל-<span class="math">\(C_{n}\)</span>, כך ש-<span class="math">\(a\)</span> הוא גבול של סדרה ששייכת ל-<span class="math">\(C_{n}\)</span>, ו-<span class="math">\(C_{n}\)</span> הוא קטע <strong>סגור</strong> ולכן הוא בפרט <strong>קבוצה סגורה</strong> וההגדרה של קבוצה סגורה היא "קבוצה של הגבולות של איבריה שייכים אליה" ולכן <span class="math">\(c\in C_{n}\)</span>. שכנעתי אתכם? בוודאי שלא, מאיפה שלפתי את ההגדרה הזו של קבוצה סגורה? תכף נחזור לזה.</p>
<p>שנית, בואו נראה את היחידות של <span class="math">\(c\)</span>. ניקח <span class="math">\(c_{1},c_{2}\in\bigcap_{n=0}^{\infty}C_{n}\)</span> כלשהם. כעת, לכל <span class="math">\(n\)</span> מתקיים <span class="math">\(d\left(c_{1},c_{2}\right)\le\left|C_{n}\right|\)</span> כי <span class="math">\(c_{1},c_{2}\in C_{n}\)</span>, ולכן <span class="math">\(d\left(c_{1},c_{2}\right)\le\lim_{n\to\infty}\left|C_{n}\right|=0\)</span> והמסקנה היא ש-<span class="math">\(d\left(c_{1},c_{2}\right)=0\)</span> כלומר <span class="math">\(c_{1}=c_{2}\)</span> (ושוב - זה תרגיל טוב לפרמל את זה עד הסוף אם אתם מרגישים שמשהו חסר). אז הכל פה באמת קל, ורק נשארה לי הטענה "קטע סגור הוא קבוצה סגורה" שלא באמת קשורה להוכחה הזו אלא היא משהו כללי יותר.</p>
<p>כדי לעשות לעצמנו סדר בהגדרות, הנה הן שוב, במפורט:</p>
<ul> <li><strong>קבוצה סגורה</strong> היא קבוצה <span class="math">\(D\)</span> כך שלכל סדרה מתכנסת <span class="math">\(\left\{ a_{n}\right\} _{n=0}^{\infty}\)</span>, אם <span class="math">\(a_{n}\in D\)</span> לכל <span class="math">\(n\)</span>, גם <span class="math">\(\lim_{n\to\infty}a_{n}\in D\)</span>.</li>


<li><strong>קטע סגור</strong> הוא קבוצה מהצורה <span class="math">\(D=\left[a,b\right]=\left\{ x\in\mathbb{R}\ |\ a\le x\le b\right\} \)</span></li>

</ul>

<p>במבט ראשון לא נראה שיש ביניהן קשר וזה סתם שימוש מבלבל כפול ב"סגור", אבל בפועל קל להראות שקטע סגור הוא אכן קבוצה סגורה. ניקח <span class="math">\(D=\left[a,b\right]\)</span> שכזה. אם יש לנו סדרה מתכנסת <span class="math">\(\left\{ c_{n}\right\} _{n=0}^{\infty}\)</span> שכל אבריה שייכים ל-<span class="math">\(D\)</span>, נסמן את הגבול שלה ב-<span class="math">\(c=\lim_{n\to\infty}c_{n}\)</span>. אם <span class="math">\(a\le c\le b\)</span> הכל בסדר, אז בואו נראה למשל איך מגיעים לסתירה אם <span class="math">\(c<a\)</span>. זה די פשוט: נסמן <span class="math">\(\varepsilon=a-c\)</span>, ולכן על פי הגדרת הגבול קיים <span class="math">\(c_{n}\)</span> כך ש-<span class="math">\(d\left(c_{n},c\right)<\varepsilon\)</span>. אבל <span class="math">\(c_{n}\in D\)</span>, כלומר <span class="math">\(a\le c_{n}\)</span>, כלומר</p>
<p><span class="math">\(d\left(c_{n},c\right)=\left|c_{n}-c\right|=c_{n}-c=\left(c_{n}-a\right)+\left(a-c\right)\ge\varepsilon\)</span></p>
<p>וזו סתירה ל-<span class="math">\(d\left(c_{n},c\right)<\varepsilon\)</span>, מה שמסיים את ההוכחה הזו.</p>
<p>סיכום ביניים: הראינו איך שלמות-קנטור גוררת את משפט החיתוך של קנטור, וראינו עוד קודם שמשפט החיתוך של קנטור גורר את בולצאנו-ויירשטראס. מה שנחמד הוא שאפשר לדבר על כל התוצאות הללו בהקשרים כלליים יותר של מרחבים מטריים וההוכחות די דומות, אבל לא אכנס לזה כאן - אנחנו מאוד ממוקדים באובייקט של "שדה סדור שלם".</p>
<p>מה נשאר לנו להראות? ראינו את המשפט על כך שסדרה מונוטונית חסומה היא מתכנסת. האם בולצאנו-ויירשטראס מוכיח אותו? אם <span class="math">\(\left\{ a_{n}\right\} _{n=0}^{\infty}\)</span> היא הסדרה המונוטונית החסומה אז החסימות שלה נותנת לנו את בולצאנו-ויירשטראס ואנחנו מקבלים תת-סדרה <span class="math">\(\left\{ c_{n}\right\} _{n=0}^{\infty}\)</span> שמתכנסת אל <span class="math">\(c\)</span>. שימו לב שבהכרח <span class="math">\(c_{n}\le c\)</span> לכל איבר בתת-הסדרה, בגלל המונוטוניות שלה: אם היה מתקיים <span class="math">\(c<c_{N}\)</span> עבור <span class="math">\(N\)</span> כלשהו, אז עבור <span class="math">\(\varepsilon=c_{N}-c\)</span> היינו מקבלים שלכל <span class="math">\(n>N\)</span>, <span class="math">\(d\left(c_{n},c\right)=\left(c_{n}-c_{N}\right)+\left(c_{N}-c\right)\ge\varepsilon\)</span>.</p>
<p>בואו נוכיח ש-<span class="math">\(\lim_{n\to\infty}a_{n}=c\)</span>: ניקח <span class="math">\(\varepsilon>0\)</span> כלשהו, אז קיים <span class="math">\(N\)</span> כך ש-<span class="math">\(a_{N}\)</span> שייך לתת-הסדרה וגדול מספיק כדי שיתקיים <span class="math">\(d\left(a_{N},c\right)<\varepsilon\)</span>, כלומר <span class="math">\(c-a_{N}<\varepsilon\)</span>. עכשיו, לכל <span class="math">\(n>N\)</span> מתקיים <span class="math">\(a_{N}<a_{n}\le c\)</span> ולכן <span class="math">\(c-a_{n}<c-a_{N}<\varepsilon\)</span>, כמו שרצינו (הסיבה שבגללה <span class="math">\(a_{n}\le c\)</span> היא שאם היה מתקיים <span class="math">\(a_{n}>c\)</span> זה היה מכריח גם איברים של תת-הסדרה שמופיעים בסדרה אחרי <span class="math">\(a_{n}\)</span> להיות גדולים מ-<span class="math">\(c\)</span> וראינו שזה לא יכול לקרות).</p>
<p>אם כן, לסיכום - הראינו איך משלמות-קנטור נובעות אותן התוצאות בחדו"א שעניינו אותנו - מלבד אחת, זו של שלמות-דדקינד עצמה. בשביל זה כדאי לעבור לחלק נוסף ואחרון.</p>
<h2>שלמות דדקינד נגד שלמות קנטור - הקרב האחרון</h2>

<p>מה ראינו עד כה?</p>
<ul> <li>שלמות-דדקינד גוררת את שלמות-קנטור.</li>


<li>שלמות-קנטור גוררת את כל התוצאות שראינו בפוסט בערך חוץ מאשר את שלמות-דדקינד (ולכן בעצם גם המשפט השני של ויירשטראס שמשתמש בה).</li>

</ul>

<p>אם נחזור לטרמינולוגיה של הפוסט הקודם, ראינו ששדה סדור שלם הוא גם שלם-קנטור. למעשה, סביר להניח שחלק נכבד מהקוראים נתקלו בשלמות-קנטור בתור המשמעות של "שלם"; כשמדברים בטופולוגיה על "מרחב מטרי שלם" ועל "השלמה של מרחב מטרי" זה במובן של שלמות-קנטור. האם ההפרדה הזו בין שלמות-דדקינד ושלמות-קנטור היא לא קצת מלאכותית? אי אפשר לקרוא לשני אלו "שלמות" וזהו?</p>
<p>ובכן, למרבה הצער, לא בדיוק.</p>
<p>הטענה "אם <span class="math">\(\mathbb{F}\)</span> הוא שדה סדור שבו כל סדרת קושי מתכנסת, אז הוא שלם" היא פשוט לא נכונה.</p>
<p>מה שנכון, ואני הולך להוכיח, הוא הטענה "אם <span class="math">\(\mathbb{F}\)</span> הוא שדה סדור <strong>ארכימדי</strong> שבו כל סדרת קושי מתכנסת, אז הוא שלם". אבל צריך את הארכימדיות. מה זו ארכימדיות? כזכור, זו התכונה לפיה לכל <span class="math">\(a\in\mathbb{F}\)</span> קיים <span class="math">\(n\in\mathbb{Z}\)</span> כך ש-<span class="math">\(a<n\)</span>. כשיש לנו שדה סדור <strong>שלם</strong> הוא אוטומטית ארכימדי. זה כבר אומר שיהיה לנו קצת קשה להראות דוגמא לשדה סדור שהוא שלם-קנטור אבל לא שלם-דדקינד, כי הוא יצטרך להיות <strong>מוזר</strong> בגלל חוסר הארכימדיות שלו. יש דוגמא סטנדרטית עם שדה של <strong>טורי לורן</strong> אבל אני לא אכנס לזה כאן כי היא טכנית וארוכה. במקום זה אני אעשה משהו טכני וארוך אחר: אוכיח ששדה סדור ארכימדי שבו כל סדרת קושי מתכנסת הוא שלם.</p>
<p>יש כל מני הוכחות שראיתי ואני אלך דווקא על אחת טכנית יחסית כי אני מרגיש שזו דרך טובה להרגיש בידיים "מה הולך פה". אני לוקח קבוצה לא ריקה וחסומה <span class="math">\(A\subseteq\mathbb{F}\)</span> ורוצה להוכיח ש-<span class="math">\(\sup A\)</span> קיים. בשביל זה אני צריך כלי כלשהו שיודע להראות לי שמשהו קיים, והכלי הזה עבורי יהיה משפט החיתוך של קנטור, שכבר ראינו שנובע משלמות-קנטור. הרעיון המרכזי הוא פשוט: נבנה סדרה של קטעים, <span class="math">\(\left[a_{n},b_{n}\right]\)</span>, שמקיימים את התנאים הרגילים של משפט החיתוך כלומר <span class="math">\(\left[a_{n},b_{n}\right]\supseteq\left[a_{n+1},b_{n+1}\right]\)</span> ו-<span class="math">\(\lim_{n\to\infty}\left(b_{n}-a_{n}\right)=0\)</span>, ובנוסף הם מקיימים את התכונה הבאה: לכל <span class="math">\(n\)</span>, <span class="math">\(b_{n}\)</span> הוא <strong>חסם מלעיל</strong> של <span class="math">\(A\)</span> אבל <span class="math">\(a_{n}\)</span> <strong>אינו</strong> חסם מלעיל של <span class="math">\(A\)</span>. עכשיו נשתמש במשפט החיתוך ונקבל <span class="math">\(c\)</span> שמקיים ש-<span class="math">\(a_{n}\le c\le b_{n}\)</span> לכל <span class="math">\(n\)</span>.</p>
<p>מצד אחד, <span class="math">\(c\)</span> חייב להיות חסם מלעיל של <span class="math">\(A\)</span>, כי אם הוא לא היה כזה, אז היה קיים <span class="math">\(a\in A\)</span> כך ש-<span class="math">\(c<a\)</span>, ומכאן בפרט ש-<span class="math">\(a_{n}<a\)</span> לכל <span class="math">\(n\)</span> (כלומר, נקודות הקצה השמאליות של הקטעים שלנו "לא מתקרבות מספיק לקצה של <span class="math">\(A\)</span>"). אבל תזכרו שסדרת נקודות הקצה הימניות, ה-<span class="math">\(b_{n}\)</span>-ים, מתקרבות כרצוננו אל ה-<span class="math">\(a_{n}\)</span>-ים, אז ברור שנוכל להנדס פה סתירה עם טכניקות שכבר ראינו לא אחת בפוסט הבא: נגדיר <span class="math">\(\varepsilon=a-c\)</span> (מכיוון ש-<span class="math">\(c<a\)</span> אז <span class="math">\(\varepsilon>0\)</span>) וניעזר בכך ש-<span class="math">\(\lim_{n\to\infty}\left(b_{n}-a_{n}\right)=0\)</span> כדי למצוא <span class="math">\(N\)</span> עבורו <span class="math">\(b_{N}-a_{N}<\varepsilon\)</span>. אבל עכשיו תראו מה קרה: <span class="math">\(a_{N}<c<a\le b_{N}\)</span>, כשאי השוויון האחרון נובע מכך ש-<span class="math">\(b_{N}\)</span> הוא חסם מלעיל של <span class="math">\(A\)</span> וש-<span class="math">\(a\in A\)</span>. המסקנה מהשרשרת היא ש</p>
<p><span class="math">\(\varepsilon=a-c\le b_{N}-c<b_{N}-a_{N}<\varepsilon\)</span></p>
<p>וזו סתירה. אז קיבלנו ש-<span class="math">\(c\)</span> הוא חסם מלעיל של <span class="math">\(A\)</span>. </p>
<p>בנוסף, אני טוען ש-<span class="math">\(c\)</span> הוא החסם מלעיל המינימלי של <span class="math">\(A\)</span>, כי אם הוא לא היה כזה אז היה קיים <span class="math">\(b\)</span> שהוא חסם מלעיל של <span class="math">\(A\)</span> כך ש-<span class="math">\(b<c\)</span>, ומכאן בפרט ש-<span class="math">\(b<b_{n}\)</span> לכל <span class="math">\(n\)</span> (כלומר, נקודות הקצה הימניות של הקטעים שלנו "הן לא חסמים מלעיל מספיק קטנים של <span class="math">\(A\)</span>"). רואים את הדז'ה-וו? בואו נסיים את זה באותו האופן: נגדיר <span class="math">\(\varepsilon=c-b\)</span> ונמצא <span class="math">\(N\)</span> עבורו <span class="math">\(b_{N}-a_{N}<\varepsilon\)</span> ועכשיו תראו מה קרה: <span class="math">\(a_{N}\le b<c<b_{N}\)</span> כשאי השוויון הראשון נובע מכך ש-<span class="math">\(b\)</span> הוא חסם מלעיל של <span class="math">\(A\)</span> (גדול או שווה לכל אברי <span class="math">\(A\)</span>) ואילו <span class="math">\(a_{N}\)</span> אינו חסם מלעיל כזה (קיים איבר ב-<span class="math">\(A\)</span> שגדול ממנו, ו-<span class="math">\(b\)</span> גדול או שווה מאותו איבר). המסקנה מהשרשרת היא ש</p>
<p><span class="math">\(\varepsilon=c-b<b_{N}-b\le b_{N}-a_{N}<\varepsilon\)</span></p>
<p>וזו סתירה. אז קיבלנו ש-<span class="math">\(c\)</span> קטן מכל חסם מלעיל אחר של <span class="math">\(A\)</span>, ולכן הוא החסם מלעיל המינימלי, ולכן <span class="math">\(c=\sup A\)</span>. זה מסיים את החלק התיאורטי יותר בהוכחה ונשאר לעבור לחלק הקונקרטי - איך בונים בפועל סדרת קטעים <span class="math">\(\left[a_{n},b_{n}\right]\)</span> כזו שעוטפת בצורה כל כך אפקטיבית את הקצה הימני של הקבוצה <span class="math">\(A\)</span>? וכאן הארכימדיות הולכת לצוץ בכל הכוח כי בלעדיה יכול להיות חור <strong>עצום</strong> בין קבוצת האיברים ב-<span class="math">\(A\)</span> וקבוצת החסמים מלעיל שלהם.</p>
<p>הרעיון הבסיסי הוא זה: בואו נחלק את כל ציר המספרים למקטעים באורכים קצרים - נאמר, <span class="math">\(\frac{1}{2}\)</span>. עכשיו נעבור על נקודות הקצה של המקטעים הללו: <span class="math">\(-\frac{1}{2},0,\frac{1}{2},1,\frac{3}{2},\ldots\)</span>. מתישהו יגיע הרגע הראשון שבו אנחנו עוברים את <span class="math">\(A\)</span>, כלומר מוצאים מספר <span class="math">\(\frac{k}{2}\)</span> שהוא חסם מלעיל של <span class="math">\(A\)</span> אבל <span class="math">\(\frac{k-1}{2}\)</span> הוא לא חסם מלעיל של <span class="math">\(A\)</span>. כשזה קורה, נסמן <span class="math">\(a_{1}=\frac{k-1}{2}\)</span> ו-<span class="math">\(b_{1}=\frac{k}{2}\)</span>.</p>
<p>איך נגדיר עכשיו את <span class="math">\(a_{2},b_{2}\)</span>? כדאי לחלק את העולם לחלקים <strong>עוד יותר קטנים</strong>, כי ככל שאנחנו מקטינים את העולם ככה הדיוק שלנו משתפר. אבל צריך להיות זהירים <strong>מאוד</strong> כאן: אם למשל אני אחלק את העולם לשלישים, <span class="math">\(-\frac{1}{3},0,\frac{1}{3},\frac{2}{3},\ldots\)</span>, נקודות הקצה ממש לא בהכרח יהיו שיפור ביחס לקודם. למשל, אם הסופרמום של <span class="math">\(A\)</span> הוא <span class="math">\(\frac{1}{2}\)</span> אז נקבל <span class="math">\(a_{1}=0,b_{1}=\frac{1}{2}\)</span> אבל <span class="math">\(a_{2}=\frac{1}{3},b_{2}=\frac{2}{3}\)</span>. במקרה הזה אמנם <span class="math">\(a_{1}<a_{2}\)</span> כפי שהיינו רוצים שיקרה (כי אנחנו רוצים שיתקיים <span class="math">\(\left[a_{1},b_{1}\right]\supseteq\left[a_{2},b_{2}\right]\)</span>) אבל ממש לא מתקיים <span class="math">\(b_{2}<b_{1}\)</span>. אז לא מספיק להגדיל את המכנה - צריך להגדיל אותו בצורה שבעצם לוקחת את החלוקה הקודמת ומחלקת אותה עוד קצת. אם קודם חילקנו לקטעים באורך <span class="math">\(\frac{1}{2}\)</span>, עכשיו משתלם לחלק לקטעים באורך <span class="math">\(\frac{1}{4}\)</span>, וכן הלאה: באופן כללי נחלק לקטעים באורך <span class="math">\(\frac{1}{2^{n}}\)</span>.</p>
<p>אם כן, הבניה שלי תהיה כזו: לכל <span class="math">\(n\ge1\)</span> אני אמצא מספר שלם <span class="math">\(k_{n}\)</span> שהוא המספר השלם המינימלי עבורו <span class="math">\(\frac{k_{n}}{2^{n}}\)</span> הוא חסם מלעיל של <span class="math">\(A\)</span> - כלומר, כך ש-<span class="math">\(\frac{k_{n}}{2^{n}}\)</span> הוא חסם מלעיל של <span class="math">\(A\)</span> אבל <span class="math">\(\frac{k_{n}-1}{2^{n}}\)</span> אינו חסם מלעיל של <span class="math">\(A\)</span> (אני כמובן אצטרך להוכיח שקיים <span class="math">\(k_{n}\)</span> כזה) ואז אגדיר <span class="math">\(a_{n}=\frac{k_{n}-1}{2^{n}}\)</span> ו-<span class="math">\(b_{n}=\frac{k_{n}}{2^{n}}\)</span>.</p>
<p>תחת ההגדרה הזו, <span class="math">\(b_{n}-a_{n}=\frac{k_{n}-\left(k_{n}-1\right)}{2^{n}}=\frac{1}{2^{n}}\)</span> ולכן <span class="math">\(\lim_{n\to\infty}\left(b_{n}-a_{n}\right)=0\)</span> וזה אחד משני הדברים שרצינו עבור תנאי משפט החיתוך של קנטור. הדבר השני שאנחנו צריכים להוכיח הוא <span class="math">\(\left[a_{n},b_{n}\right]\supseteq\left[a_{n+1},b_{n+1}\right]\)</span>.</p>
<p>ראשית, להוכיח ש-<span class="math">\(b_{n+1}\le b_{n}\)</span> יהיה קל יחסית. נסתכל על <span class="math">\(b_{n}=\frac{k_{n}}{2^{n}}\)</span> ונכפול ונחלק את זה ב-2, כלומר</p>
<p><span class="math">\(b_{n}=\frac{k_{n}}{2^{n}}=\frac{2k_{n}}{2^{k+1}}\)</span></p>
<p>המכנה עכשיו הוא מה שאנחנו מחפשים. המונה? ובכן, תזכרו שאנחנו לוקחים את <span class="math">\(k_{n+1}\)</span> להיות המספר <strong>הקטן ביותר</strong> עבורו <span class="math">\(\frac{k_{n+1}}{2^{n+1}}\)</span> הוא חסם מלעיל של <span class="math">\(A\)</span> אבל <span class="math">\(\frac{k_{n+1}-1}{2^{n+1}}\)</span> לא. ואנחנו כבר יודעים ש-<span class="math">\(b_{n}\)</span> הוא חסם מלעיל של <span class="math">\(A\)</span>, ולכן <span class="math">\(k_{n+1}\le2k_{n}\)</span>, כלומר קיבלנו</p>
<p><span class="math">\(b_{n+1}=\frac{k_{n+1}}{2^{n+1}}\le\frac{2k_{n}}{2^{n+1}}=b_{n}\)</span></p>
<p>יהיה קצת יותר טריקי להראות ש-<span class="math">\(a_{n}\le a_{n+1}\)</span>, כלומר להראות ש-<span class="math">\(\frac{k_{n}-1}{2^{n}}\le\frac{k_{n+1}-1}{2^{n+1}}\)</span>. נכפול את שני האגפים ב-<span class="math">\(2^{n+1}\)</span> ונקבל שמספיק להראות <span class="math">\(2\left(k_{n}-1\right)\le k_{n+1}-1\)</span>, ואחרי העברת אגפים נקבל שמספיק להראות <span class="math">\(2k_{n}-1\le k_{n+1}\)</span>.</p>
<p>כדי לראות את זה, בואו נסתכל על <span class="math">\(2k_{n}-2\)</span>. כזכור, בחרנו את <span class="math">\(k_{n}\)</span> כך ש-<span class="math">\(\frac{k_{n}}{2^{n}}\)</span> הוא חסם מלעיל של <span class="math">\(A\)</span> אבל <span class="math">\(\frac{k_{n}-1}{2^{n}}\)</span> אינו חסם מלעיל שכזה. אם נכפול מונה ומכנה ב-2 נקבל ש-<span class="math">\(\frac{2k_{n}-2}{2^{n+1}}\)</span> אינו חסם מלעיל של <span class="math">\(A\)</span>. אנחנו יודעים ש-<span class="math">\(\frac{k_{n+1}}{2^{n+1}}\)</span> הוא <strong>כן</strong> חסם מלעיל של <span class="math">\(A\)</span> ולכן <span class="math">\(2k_{n}-2<k_{n+1}\)</span>, ומכיוון שבשני האגפים יש מספרים שלמים, הוספת 1 לאגף שמאל יכולה לכל היותר להפוך את אי השוויון לשוויון, אגף שמאל לא יכול להפוך לגדול יותר מאגף ימין. לכן <span class="math">\(2k_{n}-1\le k_{n+1}\)</span>, כפי שרצינו.</p>
<p>כל מה שנשאר לנו לעשות הוא להסביר איך עושים את זה: לכל <span class="math">\(n\)</span>, למצוא מספר שלם <span class="math">\(k_{n}\)</span> כך ש-<span class="math">\(\frac{k_{n}}{2^{n}}\)</span> הוא חסם מלעיל של <span class="math">\(A\)</span> אבל <span class="math">\(\frac{k_{n}-1}{2^{n}}\)</span> אינו חסם מלעיל של <span class="math">\(A\)</span>. </p>
<p>הנתון שלנו הוא ש-<span class="math">\(A\)</span> היא קבוצה לא ריקה וחסומה. מכך שהיא לא ריקה נסיק שיש <span class="math">\(x\in A\)</span> כלשהו. מכך שהיא חסומה נסיק קיים מספר <span class="math">\(M\in\mathbb{F}\)</span> שהוא חסם מלעיל של <span class="math">\(A\)</span>.</p>
<p>עכשיו הגיע הזמן להשתמש בארכימדיות. אני אצטט את אחד מהניסוחים של ארכימדיות שנתתי בפוסט הקודם:</p>
<p>"עוד דרך לחשוב על זה, שאני אוהב במיוחד, היא זו: בואו ניקח <span class="math">\(\varepsilon>0\)</span> כלשהו, כשהאינטואיציה היא לחשוב על <span class="math">\(\varepsilon\)</span> בתור משהו ממש ממש קטן (זה השימוש הסטנדרטי של האות הזו בחדו"א). בואו ניקח גם <span class="math">\(M>0\)</span> כלשהו, כשהאינטואיציה היא לחשוב עליו בתור מספר ממש ממש ענק. אז ארכימדיות פירושה שקיים <span class="math">\(n\)</span> כך ש-<span class="math">\(n>\frac{M}{\varepsilon}\)</span>, או במילים אחרות <span class="math">\(n\varepsilon>M\)</span>. זה אומר שלא משנה עד כמה משהו קטן - אם אנחנו בשדה ארכימדי, לחבר אותו מספר פעמים לעצמו יגרום לו לעבור בגודלו כל מספר כולל ענקיים."</p>
<p>אוקיי, "מספר ענק" <span class="math">\(M\)</span> כבר יש לנו - זה החסם מלעיל של <span class="math">\(A\)</span>. המספר הקטן שלנו יהיה <span class="math">\(\varepsilon=\frac{1}{2^{n}}\)</span>, והארכימדיות תיתן לנו מספר שלם <span class="math">\(T\)</span> כך ש-<span class="math">\(\frac{T}{2^{n}}>M\)</span> - כלומר, קיבלנו שקיים חסם מלעיל של <span class="math">\(A\)</span> שהוא מהצורה <span class="math">\(\frac{T}{2^{n}}\)</span> כאשר <span class="math">\(T\)</span> שלם. הרעיון הוא שעכשיו אפשר להתחיל "ללכת אחורה" מה-<span class="math">\(T\)</span> הזה עד שמוצאים את הערך המינימלי שעדיין נשאר חסם מלעיל, אבל בשביל זה צריך כמובן להשתכנע שאם נלך <strong>מספיק</strong> אחורה באמת נגיע למצב שבו האיברים שלנו הם כבר לא חסמים מלעיל. כאן נזדקק ל-<span class="math">\(x\in A\)</span> שמצאנו, ולתכונה הארכימדית פעם נוספת.</p>
<p>מה שהייתי רוצה למצוא הוא <span class="math">\(S\)</span> שלם כך ש-<span class="math">\(\frac{S}{2^{n}}<x\)</span>, כי אז <span class="math">\(\frac{S}{2^{n}}\)</span> הוא בודאות לא חסם מלעיל של <span class="math">\(A\)</span>. אבל איך מוצאים את זה עם ארכימדיות, שנותנת לנו משהו <strong>גדול יותר</strong>? בפוסט הקודם אמרנו שזו לא בעיה כי עושים טריק של כפל ב-<span class="math">\(-1\)</span>, אז בואו נעשה טריק של כפל ב-<span class="math">\(-1\)</span>: נשתמש בארכימדיות כדי למצוא <span class="math">\(R\)</span> שלם כך ש-<span class="math">\(-x<\frac{R}{2^{n}}\)</span>, ואז נכפול את שני האגפים ב-<span class="math">\(-1\)</span>, נסמן <span class="math">\(S=-R\)</span> ונקבל שמצאנו <span class="math">\(S\)</span> שלם כך ש-<span class="math">\(\frac{S}{2^{n}}<x\)</span>.</p>
<p>עכשיו סיימנו: קיבלנו את הסדרה הסופית <span class="math">\(S,S+1,S+2,\ldots,T\)</span> שהאיבר הראשון בה <strong>לא נותן</strong> חסם מלעיל של <span class="math">\(A\)</span> והאיבר האחרון בה <strong>כן נותן</strong> חסם מלעיל כזה, אז פשוט ניקח את <span class="math">\(k_{n}\)</span> להיות האיבר <strong>המינימלי</strong> בסדרה שנותן חסם מלעיל. הוא בודאות קיים (כי זו סדרה סופית, ויש לפחות איבר אחד בסדרה שמקיים את הקריטריון הזה) והוא בודאות גדול מ-<span class="math">\(S\)</span> ולכן <span class="math">\(k_{n}-1\)</span> הוא גם כן איבר בסדרה, והוא איבר שעבורו <strong>לא מתקבל</strong> חסם מלעיל של <span class="math">\(A\)</span> - בדיוק מה שרצינו.</p>
<p>אם כן - סיימנו את ההוכחה, הבנו את הקשר בין שלמות-דדקינד ושלמות-קנטור, ועכשיו נשאר לנו רק דבר אחד: להראות את הבניות של קנטור ודדקינד ואיך הן שתיהן נותנות לנו את <span class="math">\(\mathbb{R}\)</span>.</p>
        </article>
        
        <footer>
            <p>© כל הזכויות שמורות לגדי אלכסנדרוביץ'</p>
        </footer>
    </div>

    
    <script>
        function toggleMobileMenu() {
            const navLinks = document.getElementById('navLinks');
            navLinks.classList.toggle('expanded');
        }
        
        function searchPosts() {
            const searchTerm = document.getElementById('searchInput').value;
            if (searchTerm.trim()) {
                window.location.href = '/post_list.html?search=' + encodeURIComponent(searchTerm);
            }
        }
        
        document.getElementById('searchInput').addEventListener('keypress', function(e) {
            if (e.key === 'Enter') {
                searchPosts();
            }
        });
    </script>
    
    
    <!-- Auto-render KaTeX math -->
    <script>
        document.addEventListener("DOMContentLoaded", function() {
            renderMathInElement(document.body, {
                delimiters: [
                    {left: "\\[", right: "\\]", display: true},
                    {left: "\\(", right: "\\)", display: false}
                ],
                throwOnError: false
            });
        });
    </script>

</body>
</html>