<!DOCTYPE html>
<html lang="he" dir="rtl">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>על עקומות ואינטגרלים - לא מדויק</title>
    <link rel="icon" type="image/x-icon" href="/favicon.ico">
    
    <meta name="description" content="לא מדויק - בלוג על מתמטיקה ומדעי המחשב" />
    <!-- Open Graph / Facebook -->
    <meta property="og:type" content="article">
    <meta property="og:url" content="https://gadial.net/2024/06/15/curves_and_line_integrals/">
    <meta property="og:title" content="על עקומות ואינטגרלים">
    <meta property="og:description" content="לא מדויק - בלוג על מתמטיקה ומדעי המחשב">
    <meta property="og:site_name" content="לא מדויק">
    

<meta property="og:image" content="http://gadial.net/img/main/default-card.png" />


        
    <!-- Twitter -->
    

<meta name="twitter:card" content="summary">


    <meta name="twitter:url" content="https://gadial.net/2024/06/15/curves_and_line_integrals/">
    <meta name="twitter:description" content="לא מדויק - בלוג על מתמטיקה ומדעי המחשב">
    <meta name="twitter:site" content="@" />
    <meta property="twitter:title" content="על עקומות ואינטגרלים">
    

<meta property="twitter:image" content="http://gadial.net/img/main/default-card.png" />


    
    <!-- RSS Feed -->
    <link rel="alternate" type="application/rss+xml" title="לא מדויק - RSS Feed" href="/feed.xml">
       
    
    <!-- KaTeX for math rendering -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css">
    <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js"></script>
    <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js"></script>
    <link rel="stylesheet" href="/css/main.css">

    
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }
        
        body {
            font-family: 'Arial', 'David', 'Tahoma', sans-serif;
            line-height: 1.6;
            color: #333;
            background-color: #f5f5f5;
        }
        
        /* Top navigation bar */
        .top-nav {
            background: #2c3e50;
            padding: 15px 20px;
            box-shadow: 0 2px 5px rgba(0,0,0,0.1);
        }
        
        .top-nav .nav-container {
            max-width: 1200px;
            margin: 0 auto;
            display: flex;
            align-items: center;
            justify-content: space-between;
            gap: 20px;
        }
        
        .top-nav .site-title {
            font-size: 1.5em;
            font-weight: bold;
            color: white;
            text-decoration: none;
            white-space: nowrap;
        }
        
        .top-nav .nav-links {
            display: flex;
            gap: 20px;
            align-items: center;
            flex-wrap: wrap;
        }
        
        .top-nav .nav-links a {
            color: #ecf0f1;
            text-decoration: none;
            padding: 5px 10px;
            border-radius: 4px;
            transition: background 0.2s;
            white-space: nowrap;
        }
        
        .top-nav .nav-links a:hover {
            background: #34495e;
        }
        
        .top-nav .search-box {
            display: flex;
            gap: 5px;
        }
        
        .top-nav .search-box input {
            padding: 5px 10px;
            border: none;
            border-radius: 4px;
            font-size: 0.9em;
            min-width: 150px;
        }
        
        .top-nav .search-box button {
            padding: 5px 15px;
            background: #3498db;
            color: white;
            border: none;
            border-radius: 4px;
            cursor: pointer;
            transition: background 0.2s;
        }
        
        .top-nav .search-box button:hover {
            background: #2980b9;
        }
        
        /* Hamburger menu button */
        .menu-toggle {
            display: none;
            background: none;
            border: none;
            font-size: 1.8em;
            color: white;
            cursor: pointer;
            padding: 0;
            line-height: 1;
        }
        
        .menu-toggle:hover {
            opacity: 0.8;
        }
        
        /* Mobile responsive */
        @media (max-width: 768px) {
            .top-nav .nav-container {
                flex-direction: column;
                align-items: stretch;
            }
            
            .top-nav .site-title {
                display: flex;
                justify-content: space-between;
                align-items: center;
                margin-bottom: 0;
                padding: 10px 0;
            }
            
            .menu-toggle {
                display: block;
            }
            
            /* Hide nav links by default on mobile */
            .top-nav .nav-links {
                display: none;
                flex-direction: column;
                width: 100%;
                margin-top: 10px;
            }
            
            /* Show when expanded */
            .top-nav .nav-links.expanded {
                display: flex;
            }
            
            .top-nav .nav-links > a {
                text-align: center;
                padding: 12px;
                border-top: 1px solid rgba(255, 255, 255, 0.2);
            }
            
            .top-nav .search-box {
                width: 100%;
                flex-direction: column;
                margin-top: 10px;
                padding-top: 10px;
                border-top: 1px solid rgba(255, 255, 255, 0.2);
            }
            
            .top-nav .search-box input {
                width: 100%;
                margin-bottom: 5px;
                min-width: 0;
            }
            
            .top-nav .search-box button {
                width: 100%;
            }
        }
        
        /* Blockquote styling */
        blockquote {
            background: #f9f9f9;
            border-right: 5px solid #ccc;
            margin: 1.5em 10px;
            padding: 0.75em 16px;
            position: relative;
            font-style: italic;
        }
        
        blockquote:before {
            content: '"';
            position: absolute;
            top: -10px;
            right: 8px;
            font-size: 3.5em;
            color: #ccc;
            line-height: 1;
        }
        
        blockquote p {
            display: block;
            margin: 0 0 0.75em 0;
        }
        
        blockquote p:last-child {
            margin-bottom: 0;
        }
        
        
    </style>
</head>
<body>
    <nav class="top-nav">
        <div class="nav-container">
            <div class="site-title">
                <a href="/" style="color: white; text-decoration: none;">לא מדויק</a>
                <button class="menu-toggle" onclick="toggleMobileMenu()" aria-label="תפריט">
                    ☰
                </button>
            </div>
            <div class="nav-links" id="navLinks">
                <a href="/">דף הבית</a>
                <a href="/random.html">פוסט אקראי</a>
                <a href="/post_list.html">כל הפוסטים</a>
                <a href="/categories/">קטגוריות</a>
                <a href="/lecture_notes.html">סיכומי הרצאות</a>
                <div class="search-box">
                    <input type="text" id="searchInput" placeholder="חיפוש...">
                    <button onclick="searchPosts()">חפש</button>
                </div>
            </div>
        </div>
    </nav>
    
    
    <div class="container">
        <!-- Post Navigation -->
        
        <nav class="post-navigation">
            
            <a href="/2024/05/18/taylor_series_proofs/" class="nav-link nav-prev">
                <span class="nav-label">פוסט ישן יותר →</span>
                <span class="nav-title">טורי טיילור - ההוכחות הפורמליות</span>
            </a>
            

            
            <a href="/2024/08/09/dividing_by_zero_allowed/" class="nav-link nav-next">
                <span class="nav-label">← פוסט חדש יותר</span>
                <span class="nav-title">למה מותר לחלק באפס?</span>
            </a>
            
        </nav>
        
        
        <header>
            <h1>על עקומות ואינטגרלים</h1>
            <div class="post-meta">
                <span class="date">2024-06-15</span>
                
                <span class="categories">
                    | קטגוריות:
                    
                    <a href="/categories/אנליזה מתמטית.html">אנליזה מתמטית</a>
                    
                </span>
                
                
                <span class="tags">
                    | תגיות:
                    
                    <a href="/tags/אינטגרל קווי.html">אינטגרל קווי</a>
                    
                </span>
                
            </div>
        </header>
        
        <article>
            <h2>מבוא</h2>

<p>הפוסט הזה נולד מהרצון שלי לכתוב פוסט על <strong>אינטגרל מרוכב</strong>, שהוא נושא יפהפה ומרתק שנפתח כמובן עם הגדרה. ההגדרה בסיסית ומוכרת ואף אחד בעולם לא חולק עליה ולכן כמובן שהייתי צריך <strong>לשכנע את עצמי</strong> שהיא מוצדקת, מה שהוביל אותי למחילת ארנב: האינטגרל המרוכב הוא סוג של <strong>אינטגרל קווי</strong>, ולכן חזרתי אל הפוסט שלי על <a href="https://gadial.net/2016/04/19/line_integral/">אינטגרל קווי</a> כדי לראות מה כתבתי אז, כשהעמקתי לעובי הקורה. מה חשכו עיני כשגיליתי שבחלקים מסוימים חיפפתי ובחלקים אחרים <strong>פשוט טעיתי</strong>. אז הפוסט הזה כאן כדי לתקן (אל תחפשו לי טעויות בפוסט ההוא; פשוט הורדתי אותן וקישרתי לפוסט הזה במקום זאת למי שרוצים להעמיק).</p>
<p>מה אני הולך לעשות בפוסט הזה? מטרת העל שלי היא להסביר אינטגרלים קוויים (יש שני סוגים, אינטגרל קווי מסוג ראשון ואינטגרל קווי מסוג שני ולמרות שהם דומים עדיין יש מספיק מה לדבר על כל אחד בנפרד). בשביל זה אני ארצה קודם כל להזכיר מה זה בכלל אינטגרל, ולא פחות חשוב - נצטרך להסביר מה זה בכלל "קו" - או ליתר דיוק, מה זו <strong>עקומה</strong>. הלב הטכני של הפוסט הזה מתחבא לדעתי בכלל בנוסחה שנותנת לנו אורך של עקומה באמצעות אינטגרל, כלומר נגיע אל הלב הטכני עוד לפני שנציג אינטגרלים קוויים. בנוסף, אני מתכנן להיות פדנט אפילו יותר מהרגיל - למרות שהבלוג נקרא "לא מדויק" זה מהפוסטים הללו שבהם אני מרגיש שאני פשוט <strong>חייב</strong> להיות מדויק עד הסוף אחרת אני ארגיש שאני בכלל לא מבין את הנושא (על מי אני עובד? אני באמת לא מבין את הנושא כרגע! אני אולי אבין אותו רק אחרי שאסיים לכתוב את הפוסט הזה, ולא משנה כמה ספרים כבר קראתי על הנושא).</p>
<p>אז בואו נתחיל מההתחלה.</p>
<h2>אינטגרל רימן</h2>

<p>ראשית, מה זה בכלל אינטגרל? בהינתן פונקציה <span class="math">\(f\)</span> ותחום מסוים שהיא מוגדרת בו, אפשר לחשוב על אינטגרל בתור סכום משוקלל של הערכים של הפונקציה בכל התחום. אם הפונקציה קבועה, האינטגרל שלה על התחום צריך להיות שווה לאורך/שטח/נפח שלו (<strong>המידה</strong> שלו, אם קופצים למושג מתמטי שלא אשתמש בו כאן). האופן שבו עושים את זה הוא על ידי קירובים שהולכים ומשתפרים, כפי שתמיד עושים באינפי.</p>
<p>האינטגרל הבסיסי ביותר הוא <strong>אינטגרל רימן</strong> ויש שתי שיטות סטנדרטיות להגדיר אותו שנותנות בסופו של דבר את אותו הדבר. שיטה מקובלת אחת משתמשת במשהו שנקרא <strong>סכומי דארבו</strong> וזו דרך די יפה ואלגנטית ואני לא אשתמש בה כאן. השניה, <strong>סכומי רימן</strong>, תתאים הרבה יותר למה שאני רוצה לעשות. באינטגרל רימן יש לנו פונקציה <span class="math">\(f:\left[a,b\right]\to\mathbb{R}\)</span> ואנחנו רוצים להגדיר את הביטוי <span class="math">\(\int_{a}^{b}f\left(t\right)dt\)</span>. הרעיון הוא להגדיר אותו בעזרת <strong>קירובים</strong>: במקום לחשב סכום אינסופי, אנחנו מחלקים את הקטע <span class="math">\(\left[a,b\right]\)</span> למספר סופי של קטעים, בוחרים נקודה שרירותית בכל אחד מהקטעים, וסוכמים את הערך של <span class="math">\(f\)</span> על נקודה כזו באורך הקטע שבו הנקודה נמצאת. התקווה היא שככל שהקטעים הופכים לקטנים יותר ויותר, כך הסכום שנקבל יתקרב יותר ויותר אל משהו ספציפי; <span class="math">\(\int_{a}^{b}f\left(t\right)dt\)</span> יוגדר להיות המשהו הספציפי הזה.</p>
<p>אם כן, בואו נגדיר <strong>חלוקה</strong> של <span class="math">\(\left[a,b\right]\)</span>. נסמן חלוקה כזו באות <span class="math">\(P\)</span> (מלשון Partition) והיא כוללת סדרה של נקודות <span class="math">\(a=t_{0}<t_{1}<t_{2}<\ldots<t_{n}=b\)</span> שאנחנו חושבים עליהן כמגדירות סדרה של <span class="math">\(n\)</span> קטעים: <span class="math">\(\left[t_{0},t_{1}\right],\left[t_{1},t_{2}\right],\ldots,\left[t_{n-1},t_{n}\right]\)</span>. האיחוד של כל הקטעים הללו נותן את הקטע <span class="math">\(\left[a,b\right]\)</span> המקורי. בשביל לפרמל את "הקטעים הופכים לקטנים יותר ויותר" אני מסמן <span class="math">\(\Delta t_{i}=t_{i}-t_{i-1}\)</span> ומגדיר לכל חלוקה <span class="math">\(P\)</span> את <strong>פרמטר החלוקה</strong> <span class="math">\(\lambda\left(P\right)=\max\left\{ \Delta t_{i}\right\} _{i=1}^{n}\)</span>, האורך של הקטע הארוך ביותר בחלוקה.</p>
<p>עכשיו כשיש לנו חלוקה אפשר לבחור באופן שרירותי נקודות מכל קטע שלה, וליצור את מה שקראתי לו סכום רימן: אז בוחרים סדרה <span class="math">\(t_{1}^{*},\ldots,t_{n}^{*}\)</span> של נקודות כך ש-<span class="math">\(t_{i}^{*}\in\left[t_{i-1},t_{i}\right]\)</span> ואז בונים את הסכום <span class="math">\(S_{P}=\sum_{i=1}^{n}f\left(t_{i}^{*}\right)\Delta t_{i}\)</span> של הערכים של <span class="math">\(f\)</span> בנקודות שבחרתי בתוך כל קטע, כפול אורך הקטע הזה. שימו לב שב-<span class="math">\(S_{P}\)</span> מופיעה החלוקה <span class="math">\(P\)</span> אבל לא טרחתי לציין במפורש את סדרת ה-<span class="math">\(t_{i}^{*}\)</span>-ים שבחרתי; אינטואיטיבית זה בגלל שעבור <strong>כל</strong> בחירות נקודות בתוך החלוקה <span class="math">\(P\)</span> אמור להתקיים אותו דבר נחמד.</p>
<p>מה הדבר הנחמד? הנה ההגדרה הפורמלית לאינטגרל שנעזרת בסכומי רימן: אם קיים מספר ממשי <span class="math">\(I\in\mathbb{R}\)</span> כך שלכל <span class="math">\(\varepsilon>0\)</span> קיים <span class="math">\(\delta>0\)</span> כך שעבור כל חלוקה <span class="math">\(P\)</span> שמקיימת <span class="math">\(\lambda\left(P\right)<\delta\)</span> וכל סכום רימן <span class="math">\(S_{P}\)</span> שמתאים לחלוקה הזו, מתקיים <span class="math">\(\left|S_{P}-I\right|<\varepsilon\)</span>, אז אומרים ש-<span class="math">\(\int_{a}^{b}f\left(t\right)dt\)</span> מוגדר ו-<span class="math">\(\int_{a}^{b}f\left(t\right)dt=I\)</span>.</p>
<p>זו הייתה הגדרה טיפה ארוכה ומפותלת, אבל אין כאן שום דבר מורכב במיוחד למי שכבר התרגלו להגדרות <span class="math">\(\varepsilon-\delta\)</span> בחדו"א, אז אני לא אתעכב עליה יותר מזה.</p>
<h2>עקומות והאורך שלהן</h2>

<p>הרעיון באינטגרלים קוויים הוא לבצע אינטגרציה שבה התחום הוא <strong>עקומה</strong> שחיה ב-<span class="math">\(\mathbb{R}^{n}\)</span>. מה זו עקומה? אינטואיטיבית זו קבוצת נקודות ב-<span class="math">\(\mathbb{R}^{n}\)</span> שנראית כמו קו חד ממדי, אבל כזה שיכול להסתובב ולהתפתל - תחשבו על חוט מתוח שאנחנו נותנים לחתול להתפרע איתו. כמובן, אנחנו לא רוצים להתפרע <strong>יותר מדי</strong> - אסור לקו הזה להיקרע, או לבצע סיבובים חדים מדי; הדרך שלנו לפרמל את זה היא להגדיר עקומה בתור פונקציה <span class="math">\(\gamma:\left[a,b\right]\to\mathbb{R}^{n}\)</span> שהיא גזירה ברציפות, מה שנקרא <strong>חלקה</strong>. אפשר לדמיין את מה ש-<span class="math">\(\gamma\)</span> עושה בתור לקחת את הקטע <span class="math">\(\left[a,b\right]\)</span>, לשתול אותו במרחב <span class="math">\(\mathbb{R}^{n}\)</span> ולעקם ולפתל אותו כמו חתול, בלי לקרוע - האובייקט שמתקבל הוא עדיין חד ממדי. אפשר לדמיין את מה ש-<span class="math">\(\gamma\)</span> עושה גם בתור "טיול על העקומה": יש לנו משתנה <span class="math">\(a\le t\le b\)</span> שמתאר את הזמן הנוכחי של הטיול, שמתחיל בזמן <span class="math">\(a\)</span> ומסתיים בזמן <span class="math">\(b\)</span>, ו-<span class="math">\(\gamma\left(t\right)\)</span> אומר איפה בתוך <span class="math">\(\mathbb{R}^{n}\)</span> אנחנו נמצאים בדיוק בזמן <span class="math">\(t\)</span> של הטיול. </p>
<p>שימו לב ש-<span class="math">\(\gamma\)</span> לא בדיוק מתארת קבוצת נקודות במישור - היא מתארת <strong>טיול</strong> על הקבוצה הזו. אפשר לסמן את הקבוצה הזו בסימון קונקרטי - <span class="math">\(C=\gamma\left(\left[a,b\right]\right)\)</span> ואני לרוב קורא ל-<span class="math">\(C\)</span> <strong>עקום</strong>. כלומר - העקום הוא אוסף הנקודות עצמו, העקומה היא דרך אפשרית אחת לתאר אותו (לפעמים גם משתמשים בביטוי <strong>פרמטריזציה של העקום</strong> כדי לתאר את <span class="math">\(\gamma\)</span>). אפשר להוכיח שלא משנה איזו <span class="math">\(\gamma\)</span> נבחר עבור <span class="math">\(C\)</span> - כל עוד בחרנו <span class="math">\(\gamma\)</span> "נחמדה מספיק", תמיד נקבל את אותו ערך של אינטגרל - אבל אני לא אכנס לזה כאן. </p>
<p>לפני שאני מתחיל להשתמש בעקומות כדי לתאר אינטגרלים, יש שתי שאלות שאני רוצה לענות עליהן:</p>
<ol> <li>איך <strong>מגדירים</strong> את האורך של עקומה?</li>


<li>איך <strong>מחשבים</strong> את האורך של עקומה?</li>

</ol>

<p>עבור 1 אפשר לתת הגדרה פשוטה למדי שלא מניחה כמעט כלום על <span class="math">\(\gamma\)</span> מלבד זה שהיא רציפה. בשביל חישוב האורך נצטרך ש-<span class="math">\(\gamma\)</span> תהיה גם חלקה, אבל בואו קודם נתחיל מהגדרת האורך של העקומה. שימו לב שההגדרה הזו <strong>לא</strong> תחול על כל העקומות, פשוט כי על פיה יוצא שיש עקומות בעלות אורך אינסופי למרות שהן נוצרות מהקטע <span class="math">\(\left[a,b\right]\)</span> בעל האורך הסופי; אלו עקומות "פתולוגיות" חריגות, ואני לא אתעסק איתן; אני כן אגיד שאומרים שעקומה היא Rectifiable (לא יודע איך זה נקרא בעברית) אם ההגדרה שאתן עכשיו עובדת ונותנת אורך סופי.</p>
<p>הרעיון הבסיסי מאחורי ההגדרה הוא ההנחה/אקסיומה/וואטאבר שהמרחק הקצר ביותר בין שתי נקודות הוא הקו הישר שמחבר אותן - זה מה שקורה בגאומטריה האוקלידית, אבל לאו דווקא נכון בגאומטריות אחרות (תלוי מה זה "קו ישר"). אם מקבלים את ההנחה הזו, אז אפשר לחשוב על שיטת <strong>קירוב</strong> לאורך של עקומה שמתבססת על לקחת סדרת נקודות על העקומה, לחבר אותן בקווים ישרים ולקבל <strong>קירוב פוליגוני</strong> של העקומה על ידי משהו שקל לנו יחסית לחשב את האורך שלו כי לחשב אורך של קו זה קל. פורמלית, אם העקומה שלנו היא <span class="math">\(\gamma:\left[a,b\right]\to\mathbb{R}^{n}\)</span>, אז לוקחים חלוקה <span class="math">\(a=t_{0}<t_{1}<t_{2}<\ldots<t_{m}=b\)</span> שאני מסמן ב-<span class="math">\(P\)</span> כמו קודם, ועכשיו אפשר לסמן את הקירוב הפוליגוני ש-<span class="math">\(P\)</span> מגדירה עם <span class="math">\(\pi\left(P\right)\)</span> ולהגדיר את האורך שלו בתור</p>
<p><span class="math">\(\left|\pi\left(P\right)\right|=\sum_{i=1}^{m}\|\gamma\left(t_{i}\right)-\gamma\left(t_{i-1}\right)\|\)</span></p>
<p>צריך טיפה להסביר מה קורה כאן. ראשית, אם <span class="math">\(v=\left(v_{1},\ldots,v_{n}\right)\in\mathbb{R}^{n}\)</span> אז במטריקה האוקלידית מגדירים את <strong>הנורמה</strong> שלו להיות</p>
<p><span class="math">\(\|v\|=\sqrt{\sum_{k=1}^{n}\left|v_{k}\right|^{2}}\)</span></p>
<p>זה קצת מפחיד אבל אם מסתכלים על המקרה של <span class="math">\(n=2\)</span> רואים שהמרחק בין שתי נקודות <span class="math">\(\left(x_{1},y_{1}\right),\left(x_{2},y_{2}\right)\)</span> יוצא </p>
<p><span class="math">\(\|\left(x_{1},y_{1}\right)-\left(x_{1},y_{1}\right)\|=\sqrt{\left|x_{1}-x_{2}\right|^{2}+\left|y_{1}-y_{2}\right|^{2}}\)</span></p>
<p>וזה פשוט שימוש רגיל במשפט פיתגורס, אז הנורמה ה-<span class="math">\(n\)</span>-ממדית היא פשוט הכללה של זה. מה שאולי טיפה פחות ברור הוא ש-<span class="math">\(\gamma\left(t_{i}\right)-\gamma\left(t_{i-1}\right)\)</span> הוא הנקודה שהקו שמחבר אותה עם ראשית הצירים הוא מאותו אורך כמו הקו שמחבר את <span class="math">\(\gamma\left(t_{i-1}\right)\)</span> עם <span class="math">\(\gamma\left(t_{i}\right)\)</span> - זה שימוש <strong>בכלל המקבילית</strong> שקל להבין עם איור.</p>
<p><img src="/img/2024/vectors.png" alt=""/></p>
<p>באיור הזה אני מצייר שתי נקודות <span class="math">\(a,b\)</span>, כשהוקטור אל <span class="math">\(a\)</span> הוא כחול והוקטור אל <span class="math">\(b\)</span> הוא אדום. הרעיון בכלל המקבילית הוא שכאשר אני <strong>מחבר</strong> שני וקטורים, אני מדביק עותק של כל אחד מהם לקצה של השני, כך שאני יוצאר מקבילית, והנקודה שבה שני העותקים הללו נפגשים היא הסכום. אצלנו אני מתעניין ב-<span class="math">\(a-b\)</span> ולכן אני מצייר מקבילית שהוקטורים שבונים אותה הם <span class="math">\(b\)</span> ו-<span class="math">\(a-b\)</span> (שהוקטור שמתאים לו הוא סגול), ואפשר לראות איך אורך הוקטור של <span class="math">\(a-b\)</span> (הקו הסגול התחתון יותר, שמחבר את <span class="math">\(a-b\)</span> עם ראשית הצירים) זהה באורכו לקו הסגול העליון, שהוא מה שמחבר את <span class="math">\(b\)</span> עם <span class="math">\(a\)</span>.</p>
<p>עכשיות אמרתי שהרעיון בקירוב פוליגוני הוא שהקו הישר בין שתי נקודות הוא תמיד <strong>קצר יותר</strong> מאשר העקומה שעוברת דרכן (ליתר דיוק - לא ארוך יותר, כי אולי גם העקומה היא קו ישר בין שתי הנקודות הללו) לכן אנחנו מצפים מאורך העקומה להיות <strong>חסם עליון</strong> עבור כל אורך של קירוב פוליגונלי אליה. מצד שני, ככל שאנחנו מוסיפים יותר ויותר נקודות כך אפשר לקוות שהקירובים שלנו מתקרבים יותר ויותר אל העקומה - כלומר, אנחנו מצפים לכך שהאורך של הקירובים ילך ויתקרב אל אורך העקומה עצמו, בלי "להיתקע" מתחת לאורך קטן יותר בדרך. לכן אנחנו מצפים שאורך העקומה יהיה <strong>החסם העליון הקטן ביותר</strong> של קבוצת אורכי הקירובים הפוליגונליים - או כמו שזה נקרא במתמטיקה, <strong>סופרמום</strong>. לכן אנחנו <strong>מגדירים</strong> את האורך של העקומה <span class="math">\(\gamma\)</span> בין הנקודות <span class="math">\(a,b\)</span> להיות <span class="math">\(\Lambda_{\gamma}\left(a,b\right)=\sup_{P}\left\{ \left|\pi\left(P\right)\right|\right\} \)</span> כאשר <span class="math">\(P\)</span> רץ על כל החלוקות הסופיות של <span class="math">\(\left[a,b\right]\)</span>. בשביל שההגדרה הזו באמת תעבוד, הכרחי שבכלל יהיה חסם סופי לקבוצה הזו, כלומר שיהיה קיים <span class="math">\(M\)</span> כלשהו כך ש-<span class="math">\(\left|\pi\left(P\right)\right|\le M\)</span> לכל חלוקה <span class="math">\(P\)</span>; אם אין כזה, העקום הוא Nonrectifiable.</p>
<p>זה מטפל בהגדרה, אבל מה עם <strong>חישוב</strong> של האורך? בשביל זה אני מכניס לתמונה את ההנחה ש-<span class="math">\(\gamma\)</span> גזירה ברציפות, ואני רוצה להראות שבמקרה הזה יתקיים <span class="math">\(\Lambda_{\gamma}\left(a,b\right)=\int_{a}^{b}\|\gamma^{\prime}\left(t\right)\|dt\)</span>, אבל זה לא יהיה טריוויאלי להראות את זה - למעשה, זה הלב הטכני של הפוסט הזה.</p>
<p>ראשית, אינטואיציות: אם <span class="math">\(\gamma\left(t\right)\)</span> היא פונקציה שמתארת <strong>טיול</strong> על העקומה, במובן של "בזמן <span class="math">\(t\)</span> הייתי כאן וכאן", אז הנגזרת שלה, <span class="math">\(\gamma^{\prime}\left(t\right)\)</span>, מתארת את <strong>מהירות</strong> הטיול הזה - מהירות במובן שנקרא בפיזיקה Velocity, כלומר כזה שמדבר גם על כיוון התנועה ולא רק על הגודל שלה. אם נסתכל על <span class="math">\(\|\gamma^{\prime}\left(t\right)\|\)</span> נקבל את ה<strong>מהירות</strong> במובן של Speed, גודל בלבד שלא תלוי בכיוון. לכן האינטגרל <span class="math">\(\int_{a}^{b}\|\gamma^{\prime}\left(t\right)\|dt\)</span> מודד "כמה מרחק עברתי". זו נראית הגדרה כל כך מתבקשת שרוב הספרים מתחילים איתה וזהו; רק אני (ולמשל הספר של Tom Apostol שהחלק הזה של הפוסט מסתמך מאוד על דרך ההצגה שלו) מתעקש לדבר על הסופרמום (טוב, אם להודות על האמת, לא מעט ספרים מדברים על הסופרמום ואז אומרים בנפנוף ידיים שזה שווה לאינטגרל וגם זה בסדר).</p>
<p>שנית, למה זה בעצם טריקי? אני אראה עכשיו הוכחה שגויה, שהיא פחות או יותר משהו שהופיע בפוסט המקורי שלי. אנחנו לוקחים קירוב פוליגונלי עם <span class="math">\(P\)</span> כלשהי:</p>
<p><span class="math">\(\left|\pi\left(P\right)\right|=\sum_{i=1}^{m}\|\gamma\left(t_{i}\right)-\gamma\left(t_{i-1}\right)\|\)</span></p>
<p>ואז אנחנו אומרים - היי, אנחנו מכירים דרך טובה להתמודד עם ביטויים שהם הפרש של הפונקציה בשתי נקודות שונות; זה מזכיר לנו משפט אולטרה-שימושי מחדו"א, <strong>משפט הערך הממוצע של לגראנז'</strong>. המשפט הזה אומר שאם <span class="math">\(f:\left[a,b\right]\to\mathbb{R}\)</span> היא פונקציה רציפה ובנוסף היא גזירה ב-<span class="math">\(\left(a,b\right)\)</span> אז קיימת נקודה <span class="math">\(c\in\left(a,b\right)\)</span> כך ש-<span class="math">\(f^{\prime}\left(c\right)=\frac{f\left(b\right)-f\left(a\right)}{b-a}\)</span> - הנגזרת של <span class="math">\(f\)</span> מקבלת ב-<span class="math">\(c\)</span> את <strong>הערך הממוצע</strong> של הפונקציה <span class="math">\(f\)</span> בקטע. זה מאפשר לנו לומר ש-<span class="math">\(f\left(b\right)-f\left(a\right)=\left(b-a\right)f^{\prime}\left(c\right)\)</span>, כלומר להמיר את ההפרש בין ערכי הפונקציה בקטע, אל אורך הקטע כפול הנגזרת בתוכו. אז אם אני מפעיל את זה על הביטוי שלמעלה אני מקבל</p>
<p><span class="math">\(\sum_{i=1}^{m}\|\gamma\left(t_{i}\right)-\gamma\left(t_{i-1}\right)\|=\sum_{i=1}^{m}\|\gamma^{\prime}\left(t_{i}^{*}\right)\|\Delta t_{i}\)</span></p>
<p>והדבר הזה נראה כמו <strong>סכום רימן</strong> של הפונקציה <span class="math">\(f\left(t\right)=\|\gamma^{\prime}\left(t\right)\|\)</span>, כלומר ככל שהחלוקה <span class="math">\(P\)</span> קטנה יותר כך הקירוב הפוליגונלי שואף גם ל-<span class="math">\(\Lambda_{\gamma}\left(a,b\right)\)</span> וגם אל <span class="math">\(\int_{a}^{b}\|\gamma^{\prime}\left(t\right)\|dt\)</span>. זה נראה מצוין, אבל הבעיה היא <strong>שאי אפשר </strong>להשתמש כאן במשפט הערך הממוצע של לגראנז'. כי המשפט הזה עובד עבור פונקציות שהטווח שלהן הוא <span class="math">\(\mathbb{R}\)</span>, ואילו במקרה שלנו <span class="math">\(\gamma\)</span> היא <strong>פונקציה וקטורית</strong>, פונקציה שהטווח שלה הוא <span class="math">\(\mathbb{R}^{n}\)</span>, ובאופן כללי משפט הערך הממוצע לא עובד עבורן. לכן או שצריך עוד עבודה טכנית כדי להציל את ההוכחה הזו, או שצריך ללכת על הוכחה שונה, וזה מה שאני הולך לעשות כאן.</p>
<p>לפני שנעבור להוכחה, בואו נדבר שניה על מה זה בעצם אומר ש-<span class="math">\(\gamma\)</span> היא פונקציה וקטורית, כי עד עכשיו החבאתי את המורכבות של זה בכוונה. בפועל זה אומר שקיימות פונקציות ממשיות <span class="math">\(\gamma_{1},\gamma_{2},\ldots,\gamma_{n}:\left[a,b\right]\to\mathbb{R}\)</span> כך ש-<span class="math">\(\gamma\left(t\right)=\left(\gamma_{1}\left(t\right),\ldots,\gamma_{n}\left(t\right)\right)\)</span>. אפשר להוכיח שהרציפות של <span class="math">\(\gamma\)</span> עוברת לפונקציות הרכיבים הללו, וש-<span class="math">\(\gamma^{\prime}\left(t\right)=\left(\gamma_{1}^{\prime}\left(t\right),\ldots,\gamma_{n}^{\prime}\left(t\right)\right)\)</span> ובהמשך אני גם אשתמש בסימון <span class="math">\(\int_{a}^{b}\gamma\left(t\right)dt\)</span> כשהכוונה היא לוקטור <span class="math">\(\left(\int_{a}^{b}\gamma_{1}\left(t\right)dt,\ldots,\int_{a}^{b}\gamma_{n}\left(t\right)dt\right)\)</span>.</p>
<p>עכשיו בואו נעבור להוכחה. הטריק מאחוריה די מזכיר את האופן שבו מגדירים אינטגרל לא מסוים ומחברים אותו אל האינטגרל המסוים עם המשפט היסודי של החדו"א. אנחנו נגדיר פונקציה ממשית <span class="math">\(s:\left[a,b\right]\to\mathbb{R}\)</span> שמודדת את המרחק שעברנו לאורך העקום מתחילתו ועד הנקודה שהגענו אליה, כלומר <span class="math">\(s\left(t\right)=\Lambda_{\gamma}\left(a,t\right)\)</span> (בפרט, <span class="math">\(s\left(a\right)=0\)</span>). אם נצליח להראות ש-<span class="math">\(s^{\prime}\left(t\right)=\|\gamma^{\prime}\left(t\right)\|\)</span> בכל נקודה <span class="math">\(t\in\left[a,b\right]\)</span>, אז נוכל להשתמש במשפט היסודי של החדו"א כדי להראות ש-</p>
<p><span class="math">\(\Lambda_{\gamma}\left(a,b\right)=s\left(b\right)-s\left(a\right)=\int_{a}^{b}s^{\prime}\left(t\right)dt=\int_{a}^{b}\|\gamma^{\prime}\left(t\right)\|dt\)</span></p>
<p>אז המטרה שלנו היא להוכיח שמתקיים <span class="math">\(s^{\prime}\left(t\right)=\|\gamma^{\prime}\left(t\right)\|\)</span>. זה יהיה קצת טריקי, ואני אצטרך שתי תוצאות לפני כן:</p>
<ol> <li><span class="math">\(\Lambda_{\gamma}\left(a,b\right)\le\int_{a}^{b}\|\gamma^{\prime}\left(t\right)\|dt\)</span>, כלומר האינטגרל הוא קירוב מלמעלה של האורך.</li>


<li>פונקציית אורך העקומה היא <strong>חיבורית</strong> ("אדיטיבית") במובן הבא: אם <span class="math">\(c\in\left[a,b\right]\)</span> אז <span class="math">\(\Lambda_{\gamma}\left(a,b\right)=\Lambda_{\gamma}\left(a,c\right)+\Lambda_{\gamma}\left(c,b\right)\)</span></li>

</ol>

<p>נתחיל מ-1. בגלל ש-<span class="math">\(\Lambda_{\gamma}\left(a,b\right)\)</span> הוגדר בתור סופרמום על קבוצה, אם נוכיח שכל איבר בקבוצה קטן או שווה למשהו, גם הסופרמום יהיה קטן או שווה ממנו. לכן אנחנו לוקחים חלוקה <span class="math">\(P\)</span> כללית ורוצים להוכיח ש-<span class="math">\(\left|\pi\left(P\right)\right|\le\int_{a}^{b}\|\gamma^{\prime}\left(t\right)\|dt\)</span>. כאן נלך על פי ההגדרות ועל פי תכונות בסיסיות של אינטגרלים:</p>
<p><span class="math">\(\left|\pi\left(P\right)\right|=\sum_{i=1}^{m}\|\gamma\left(t_{i}\right)-\gamma\left(t_{i-1}\right)\|=\sum_{i=1}^{m}\|\int_{t_{i-1}}^{t_{i}}\gamma^{\prime}\left(t\right)dt\|\le\)</span></p>
<p><span class="math">\(\sum_{i=1}^{m}\int_{t_{i-1}}^{t_{i}}\|\gamma^{\prime}\left(t\right)\|dt=\int_{a}^{b}\|\gamma^{\prime}\left(t\right)\|dt\)</span></p>
<p>בואו נבין את המעברים. הראשון הוא פשוט הגדרת האורך שכבר ראינו. השני הוא שימוש במשפט היסודי של החדו"א. המעבר האחרון משתמש באדיטיביות של אינטגרלים (<span class="math">\(\int_{a}^{c}f\left(t\right)dt+\int_{c}^{b}f\left(t\right)dt=\int_{a}^{b}f\left(t\right)dt\)</span> - דומה למה שאנחנו הולכים להוכיח עבור <span class="math">\(\Lambda\)</span>). המעבר שבו מתחבא הלב הטכני הוא זה שמסתמך על <span class="math">\(\|\int_{t_{i-1}}^{t_{i}}\gamma^{\prime}\left(t\right)dt\|\le\int_{t_{i-1}}^{t_{i}}\|\gamma^{\prime}\left(t\right)\|dt\)</span>. כאן אני מרשה לעצמי סוף סוף לעצור ולא להוכיח את הטענה הזו, פשוט כי היא הכללה טבעית של טענה מוכרת עבור פונקציות ממשיות עם משתנה יחיד (להבדיל ממשפט הערך הממוצע של לגראנז' שפשוט לא היה אפשר להכליל). אם רוצים את ההוכחה, היא נמצאת למשל בספר של Apostol ואולי יום אחד יהיה לי התקף של רצון עז להוכיח גם אותה - אבל הפעם אני נמנע מזה כי זה יאריך את הפוסט הארוך ממילא הזה אפילו עוד יותר.</p>
<p>עכשיו בואו נוכיח את האדיטיביות של <span class="math">\(\Lambda_{\gamma}\left(a,b\right)\)</span>. זה יהיה טיעון קליל וחמוד ומאוד חדו"אי באופי שלו. אנחנו לוקחים נקודה כלשהי <span class="math">\(c\in\left[a,b\right]\)</span> ורוצים להוכיח ש--<span class="math">\(\Lambda_{\gamma}\left(a,b\right)=\Lambda_{\gamma}\left(a,c\right)+\Lambda_{\gamma}\left(c,b\right)\)</span>, אז יהיה מעורב פה אי שוויון דו כיווני. מכיוון ש-<span class="math">\(\Lambda_{\gamma}\)</span> מוגדר בתור סופרמום על קבוצת איברים, הדרך להתמודד איתו היא על ידי לקיחת איבר כלשהו מהקבוצה ומעבר לרמה הזו של הדיון. </p>
<p>שימו לב שלפני שנוכיח <span class="math">\(\Lambda_{\gamma}\left(a,b\right)=\Lambda_{\gamma}\left(a,c\right)+\Lambda_{\gamma}\left(c,b\right)\)</span> בכלל צריך להוכיח ש-<span class="math">\(\Lambda_{\gamma}\left(a,c\right),\Lambda_{\gamma}\left(c,b\right)\)</span> מוגדרים בכלל - שתת-העקומות הללו הן Rectifiable, מה שלא נתון לי כי הנתון מדבר רק על <span class="math">\(\Lambda_{\gamma}\left(a,b\right)\)</span>. ובכן, בואו ניקח שתי חלוקות, חלוקה <span class="math">\(P_{1}\)</span> של <span class="math">\(\left[a,b\right]\)</span> וחלוקה <span class="math">\(P_{2}\)</span> של <span class="math">\(\left[c,b\right]\)</span>. האיחוד של שתי החלוקות הללו נותן לי חלוקה <span class="math">\(P\)</span> של <span class="math">\(\left[a,b\right]\)</span> ואם אני מסתכל על הקירוב הפוליגונלי <span class="math">\(\pi\left(P\right)\)</span> הוא כולל בדיוק את הקווים שב-<span class="math">\(\pi\left(P_{1}\right)\)</span> ו-<span class="math">\(\pi\left(P_{2}\right)\)</span> ולכן</p>
<p><span class="math">\(\left|\pi\left(P_{1}\right)\right|+\left|\pi\left(P_{2}\right)\right|=\left|\pi\left(P\right)\right|\le\Lambda_{\gamma}\left(a,b\right)\)</span></p>
<p>בפרט, קיבלתי שקיים חסם מלעיל עבור <span class="math">\(\left|\pi\left(P_{1}\right)\right|\)</span> וגם עבור <span class="math">\(\left|\pi\left(P_{2}\right)\right|\)</span> ולכן <span class="math">\(\Lambda_{\gamma}\left(a,c\right),\Lambda_{\gamma}\left(c,b\right)\)</span> קיימים. אבל כדי להראות את הכיוון הראשון של אי שוויון שאנחנו רוצים, <span class="math">\(\Lambda_{\gamma}\left(a,c\right)+\Lambda_{\gamma}\left(c,b\right)\le\Lambda_{\gamma}\left(a,b\right)\)</span>, נצטרך לעבוד עוד טיפה. ניקח את אי השוויון שקיבלנו</p>
<p><span class="math">\(\left|\pi\left(P_{1}\right)\right|+\left|\pi\left(P_{2}\right)\right|\le\Lambda_{\gamma}\left(a,b\right)\)</span></p>
<p>נעביר אגף ונקבל</p>
<p><span class="math">\(\left|\pi\left(P_{1}\right)\right|\le\Lambda_{\gamma}\left(a,b\right)-\left|\pi\left(P_{2}\right)\right|\)</span></p>
<p>אם אני משאיר את <span class="math">\(P_{2}\)</span> קבוע ומרשה ל-<span class="math">\(P_{1}\)</span> לרוץ על כל קבוצת החלוקות של <span class="math">\(\left[a,b\right]\)</span> אנחנו רואים ש-<span class="math">\(\Lambda_{\gamma}\left(a,b\right)-\left|\pi\left(P_{2}\right)\right|\)</span> הוא חסם מלעיל של אורכי כל החלוקות בקבוצה הזו, ולכן הסופרמום של הקבוצה גם כן קטן ממנו. הסופרמום הוא בדיוק <span class="math">\(\Lambda_{\gamma}\left(a,c\right)\)</span> אז קיבלנו</p>
<p><span class="math">\(\Lambda_{\gamma}\left(a,c\right)\le\Lambda_{\gamma}\left(a,b\right)-\left|\pi\left(P_{2}\right)\right|\)</span></p>
<p>אי השוויון הזה נכון <strong>לכל</strong> חלוקה <span class="math">\(P_{2}\)</span> שניקח, ולכן אפשר להסיק ממנו ש-<span class="math">\(\Lambda_{\gamma}\left(a,c\right)\le\Lambda_{\gamma}\left(a,b\right)-\Lambda_{\gamma}\left(b,c\right)\)</span>. אם זה נראה לכם ברור, נהדר! אבל למקרה שלא, בואו נראה את זה פורמלית בכל זאת. אני אשתמש בטכניקה הסטנדרטית: אני אראה שלכל <span class="math">\(\varepsilon>0\)</span> מתקיים <span class="math">\(\Lambda_{\gamma}\left(a,c\right)\le\Lambda_{\gamma}\left(a,b\right)-\Lambda_{\gamma}\left(b,c\right)+\varepsilon\)</span> ומכיוון שזה קורה <strong>לכל</strong> <span class="math">\(\varepsilon>0\)</span> אז אי השוויון חייב להתקיים גם כשאני מציב <span class="math">\(\varepsilon=0\)</span>, כי באופן כללי - אם <span class="math">\(X\le Y+\varepsilon\)</span> לכל <span class="math">\(\varepsilon>0\)</span> אבל <span class="math">\(X>Y\)</span> אז ניקח <span class="math">\(\varepsilon=\frac{X-Y}{2}\)</span> ונקבל </p>
<p><span class="math">\(X\le Y+\varepsilon=Y+\frac{X-Y}{2}=\frac{X+Y}{2}<\frac{X+X}{2}=X\)</span></p>
<p>וקיבלנו <span class="math">\(X<X\)</span>, וזו בוודאי סתירה. אז חזרה למקרה שלנו, לקחנו <span class="math">\(\varepsilon>0\)</span> כלשהו, ועכשיו אנחנו מסתכלים על <span class="math">\(\Lambda_{\gamma}\left(b,c\right)\)</span>. מכיוון שזה סופרמום של קבוצה, אז קיים בקבוצה איבר <span class="math">\(\left|\pi\left(P_{2}\right)\right|\)</span> כך ש-<span class="math">\(\left|\pi\left(P_{2}\right)\right|\ge\Lambda_{\gamma}\left(b,c\right)-\varepsilon\)</span>, כלומר <span class="math">\(-\left|\pi\left(P_{2}\right)\right|\le-\Lambda_{\gamma}\left(b,c\right)+\varepsilon\)</span> ולכן</p>
<p><span class="math">\(\Lambda_{\gamma}\left(a,c\right)\le\Lambda_{\gamma}\left(a,b\right)-\left|\pi\left(P_{2}\right)\right|\le\Lambda_{\gamma}\left(a,b\right)-\Lambda_{\gamma}\left(b,c\right)+\varepsilon\)</span></p>
<p>כמו שרצינו. זה מראה ש-<span class="math">\(\Lambda_{\gamma}\left(a,c\right)\le\Lambda_{\gamma}\left(a,b\right)-\Lambda_{\gamma}\left(b,c\right)\)</span>, ואחרי העברת אגפים <span class="math">\(\Lambda_{\gamma}\left(a,c\right)+\Lambda_{\gamma}\left(b,c\right)\le\Lambda_{\gamma}\left(a,b\right)\)</span> וזה הכיוון הראשון של אי השוויון שרצינו.</p>
<p>עבור הכיוון השני אז בואו ניקח חלוקה <span class="math">\(P\)</span> של <span class="math">\(\left[a,b\right]\)</span>. ונראה שלא משנה מה, <span class="math">\(\left|\pi\left(P\right)\right|\le\Lambda_{\gamma}\left(a,c\right)+\Lambda_{\gamma}\left(c,b\right)\)</span> ומזה ינבע ש-<span class="math">\(\Lambda_{\gamma}\left(a,b\right)\le\Lambda_{\gamma}\left(a,c\right)+\Lambda_{\gamma}\left(c,b\right)\)</span>.</p>
<p>אם אני לוקח את <span class="math">\(P\)</span> ומוסיף לה את הנקודה <span class="math">\(c\)</span> (אלא אם <span class="math">\(c\)</span> כבר נמצאת בה), מה משתנה? אני יכול עכשיו להסתכל על <span class="math">\(P\)</span> בתור איחוד של שתי חלוקות, חלוקה <span class="math">\(P_{1}\)</span> של <span class="math">\(\left[a,c\right]\)</span> וחלוקה <span class="math">\(P_{2}\)</span> של <span class="math">\(\left[c,b\right]\)</span>. החלוקות הללו כוללת בדיוק את אותם קטעים כמו ב-<span class="math">\(P\)</span> למעט אולי קטע <span class="math">\(\left[t_{i-1},t_{i}\right]\)</span> שעבורו <span class="math">\(c\in\left(t_{i-1},t_{i}\right)\)</span>, ובמקרה זה הקטע הזה הוחלף בשני הקטעים <span class="math">\(\left[t_{i-1},c\right]\)</span> ו-<span class="math">\(\left[c,t_{i}\right]\)</span>. כעת נכניס לתמונה את אי שוויון המשולש ב-<span class="math">\(\mathbb{R}^{n}\)</span>:</p>
<p><span class="math">\(\|\gamma\left(t_{i}\right)-\gamma\left(t_{i-1}\right)\|=\|\gamma\left(t_{i}\right)-\gamma\left(c\right)+\gamma\left(c\right)-\gamma\left(t_{i-1}\right)\|\le\)</span></p>
<p><span class="math">\(\le\|\gamma\left(t_{i}\right)-\gamma\left(c\right)\|+\|\gamma\left(c\right)-\gamma\left(t_{i-1}\right)\|\)</span></p>
<p>כלומר, אורך הקטע שהסרנו קטן או שווה לאורך שני הקטעים שהוספנו, ולכן נקבל</p>
<p><span class="math">\(\left|\pi\left(P\right)\right|\le\left|\pi\left(P_{1}\right)\right|+\left|\pi\left(P_{2}\right)\right|\le\Lambda_{\gamma}\left(a,c\right)+\Lambda_{\gamma}\left(c,b\right)\)</span></p>
<p>מה שמסיים את הכיוון הזה, ואת הוכחת האדיטיביות. עכשיו אפשר לחזור אל העיקר: ההוכחה ש-<span class="math">\(\Lambda_{\gamma}\left(a,b\right)=\int_{a}^{b}\|\gamma^{\prime}\left(t\right)\|dt\)</span> שכבר צמצמנו אל הצורך להוכיח רק <span class="math">\(s^{\prime}\left(t\right)=\|\gamma^{\prime}\left(t\right)\|\)</span> כאשר, כזכור, <span class="math">\(s\left(t\right)=\Lambda_{\gamma}\left(a,t\right)\)</span>. בשביל לראות איך עושים את זה, בואו נחזור ליסודות - איך מגדירים נגזרת? <span class="math">\(s^{\prime}\left(t\right)=\lim_{h\to0}\frac{s\left(t+h\right)-s\left(t\right)}{h}\)</span>. אני אנסה לחסום את הביטוי הזה משני הכיוונים על ידי גבולות ששואפים לאותו דבר כש-<span class="math">\(h\to0\)</span> ואז להשתמש <strong>בכלל הסנדוויץ'</strong>.</p>
<p>בתור התחלה, בואו נסתכל על <span class="math">\(\|\gamma^{\prime}\left(t\right)\|\)</span>. אם אני מנסה להבין אותו בתור גבול, אני מקבל</p>
<p><span class="math">\(\lim_{h\to0}\|\frac{\gamma\left(t+h\right)-\gamma\left(t\right)}{h}\|=\lim_{h\to0}\frac{1}{h}\|\gamma\left(t+h\right)-\gamma\left(t\right)\|\)</span></p>
<p>כאן <span class="math">\(\|\gamma\left(t+h\right)-\gamma\left(t\right)\|\)</span> הוא בעצם האורך של קו ישר שמחבר את שתי הנקודות <span class="math">\(\gamma\left(t+h\right)\)</span> ו-<span class="math">\(\gamma\left(t\right)\)</span>. כלומר, זה ביטוי שחסום מלמעלה על ידי אורך העקומה <span class="math">\(\Lambda_{\gamma}\left(t,t+h\right)\)</span> (אם <span class="math">\(h<0\)</span> אז <span class="math">\(t+h\)</span> בעצם באה קודם ולכן צריך לכתוב <span class="math">\(\Lambda_{\gamma}\left(t+h,t\right)\)</span> אבל העיקרון זהה). אבל </p>
<p><span class="math">\(\Lambda_{\gamma}\left(t,t+h\right)=\Lambda_{\gamma}\left(a,t+h\right)-\Lambda_{\gamma}\left(a,t\right)=s\left(t+h\right)-s\left(t\right)\)</span> </p>
<p>בזכות האדיטיביות שהוכחנו קודם, כך שאנחנו מקבלים</p>
<p><span class="math">\(\|\gamma\left(t+h\right)-\gamma\left(t\right)\|\le s\left(t+h\right)-s\left(h\right)\)</span></p>
<p>ולכן</p>
<p><span class="math">\(\frac{1}{h}\|\gamma\left(t+h\right)-\gamma\left(t\right)\|\le\frac{s\left(t+h\right)-s\left(t\right)}{h}\)</span></p>
<p>אגף שמאל פה שואף ל-<span class="math">\(\|\gamma^{\prime}\left(t\right)\|\)</span> כאשר <span class="math">\(h\to0\)</span>, אז נשאר רק לחסום מלמעלה את <span class="math">\(\frac{s\left(t+h\right)-s\left(t\right)}{h}\)</span>. בשביל זה אני אסתמך על כך שכבר הוכחתי <span class="math">\(\Lambda_{\gamma}\left(a,b\right)\le\int_{a}^{b}\|\gamma^{\prime}\left(t\right)\|dt\)</span>, כלומר</p>
<p><span class="math">\(s\left(t+h\right)-s\left(t\right)=\Lambda_{\gamma}\left(t,t+h\right)\le\int_{t}^{t+h}\|\gamma^{\prime}\left(t\right)\|dt\)</span></p>
<p>עכשיו, שימו לב שאם אני מגדיר פונקציה <span class="math">\(f:\left[a,b\right]\to\mathbb{R}\)</span> על ידי <span class="math">\(f\left(x\right)=\int_{a}^{x}\|\gamma^{\prime}\left(t\right)\|dt\)</span> אז בזכות העובדה ש-<span class="math">\(\|\gamma^{\prime}\left(t\right)\|\)</span> היא פונקציה רציפה (מה שנובע מכך ש-<span class="math">\(\gamma\)</span> חלקה) המשפט היסודי של החדו"א נותן לי ש-<span class="math">\(f^{\prime}=\|\gamma^{\prime}\left(t\right)\|\)</span> בכל <span class="math">\(\left[a,b\right]\)</span> וש-<span class="math">\(\int_{t}^{t+h}\|\gamma^{\prime}\left(t\right)\|dt=f\left(t+h\right)-f\left(t\right)\)</span>. כלומר, קיבלתי את החסם</p>
<p><span class="math">\(s\left(t+h\right)-s\left(t\right)\le f\left(t+h\right)-f\left(t\right)\)</span></p>
<p>וכשנחלק את שניהם ב-<span class="math">\(h\)</span> נקבל</p>
<p><span class="math">\(\frac{s\left(t+h\right)-s\left(t\right)}{h}\le\frac{f\left(t+h\right)-f\left(t\right)}{h}\)</span></p>
<p>וכאשר <span class="math">\(h\to0\)</span> אז אגף ימין שואף, על פי הגדרה, אל <span class="math">\(f^{\prime}\left(t\right)=\|\gamma^{\prime}\left(t\right)\|\)</span>, וזה בדיוק מה שרצינו. זה מסיים את ההוכחה: הראינו שאורך העקומה <span class="math">\(\gamma\)</span> הוא בדיוק <span class="math">\(\int_{a}^{b}\|\gamma^{\prime}\left(t\right)\|dt\)</span>, במקרה שבו <span class="math">\(\gamma\)</span> חלקה, מה שמצדיק את ההגדרה של אורך העקומה באמצעות האינטגרל הזה כדי לחסוך את כל ההתעסקות הטכנית שראינו כאן.</p>
<h2>אינטגרל קווי (מסוג ראשון)</h2>

<p>אפשר לחשוב על אינטגרל רימן בתור סכימה של הערכים של <span class="math">\(f\)</span> לאורך הקו הישר שמחבר את <span class="math">\(a\)</span> אל <span class="math">\(b\)</span> ביקום החד-ממדי <span class="math">\(\mathbb{R}\)</span>. הרעיון ב<strong>אינטגרל קווי</strong> הוא להכליל את אותו קונספט של סכימה בדיוק אל ופונקציות שחיים בתוך מרחב גדול יותר - למשל, ב-<span class="math">\(\mathbb{R}^{n}\)</span>, אבל כדי לשמור על החד-ממדיות של אינטגרל רימן, אנחנו לא סוכמים את הערכים של <span class="math">\(f\)</span> בכל המרחב, אלא על תת-מרחב ש"נראה כמו" משהו חד ממדי, או במילים אחרות - על <strong>עקומה</strong>. הסיבה שיש לנו שני סוגים של אינטגרלים קוויים היא שיש שני סוגים של פונקציות שאנחנו רוצים לבצע עליהן אינטגרציה: פונקציה <strong>סקלרית</strong> <span class="math">\(f:\mathbb{R}^{n}\to\mathbb{R}\)</span> שמחזירה מספר ממשי בודד, ופונקציה <strong>וקטורית</strong> <span class="math">\(F:\mathbb{R}^{n}\to\mathbb{R}^{n}\)</span> שמחזירה וקטור מהמרחב שעליו הפונקציה פועלת (אני לא מכיר דרך נפוצה שבה מטפלים בפונקציות שבהן הטווח הוא <span class="math">\(\mathbb{R}^{m}\)</span> כך ש-<span class="math">\(m\ne n,1\)</span>). </p>
<p>שתי ההנחות הקבועות שלי בהמשך יהיו שהפונקציה <span class="math">\(f\)</span> או <span class="math">\(F\)</span> שאני מבצע לה אינטגרציה היא <strong>רציפה</strong>, ושהעקומה שאני מבצע עליה את האינטגרציה מיוצגת על ידי <span class="math">\(\gamma\)</span> שהיא פונקציה <strong>חלקה</strong> (גזירה ובעלת נגזרת רציפה). בלי אלו ההוכחות שלי לא הולכות לעבוד (ואני לא בטוח אם הן יכולות לעבוד בכלל או שאפשר לתת דוגמאות נגדיות פתולוגיות).</p>
<p>בואו נתחיל מלדבר על המקרה הראשון. אני אסמן ב-<span class="math">\(\int_{C}fd\gamma\)</span> אינטגרל של <span class="math">\(f\)</span> על העקום <span class="math">\(C\)</span>. בפוסט הקודם שלי על אינטגרלים קוויים דיברתי קצת על מה שנדרש מ-<span class="math">\(\gamma\)</span> כדי שהאינטגרל על <span class="math">\(C\)</span> לא יהיה תלוי בפרמטריזציה <span class="math">\(\gamma\)</span> המדויקת, אבל הפעם אני לא אכנס לזה כי זה לא קשור למה שאני רוצה להוכיח. מה אני כן רוצה להוכיח? את השוויון <span class="math">\(\int_{C}fd\gamma=\int_{a}^{b}f\left(\gamma\left(t\right)\right)\|\gamma^{\prime}\left(t\right)\|dt\)</span> שבו בדרך כלל משתמשים כדי <strong>להגדיר</strong> את משמעות הביטוי <span class="math">\(\int_{C}fd\gamma\)</span>. זה אומר שאני צריך להתחיל מלהגדיר את <span class="math">\(\int_{C}fd\gamma\)</span> בדרך אחרת, בתור הכללה טבעית של סכומי רימן.</p>
<p>בואו נתחיל שוב מאינטואיציה. מה בעצם קורה בביטוי <span class="math">\(\int_{a}^{b}f\left(\gamma\left(t\right)\right)\|\gamma^{\prime}\left(t\right)\|dt\)</span>? אם אנחנו לוקחים את הפונקציה הקבועה <span class="math">\(f\left(x\right)=1\)</span>, אנחנו מקבלים בדיוק את האינטגרל שחישב את האורך של <span class="math">\(\gamma\)</span>. אפשר לדמיין את <span class="math">\(\gamma\)</span> כאילו היא מתארת חוט של חומר שמפוזר במרחב, ואת <span class="math">\(f\)</span> כאילו היא מתארת את <strong>צפיפות</strong> החומר בכל נקודה במרחב, ואנחנו רוצים לחשב את כמות החומר הכוללת; אם הצפיפות היא 1 בכל נקודה, הכמות הזו תהיה בדיוק אורך החוט, אבל אנחנו רוצים לטפל בסיטואציה היותר מורכבת של צפיפות משתנה. אפשר גם לחשוב על זה בצורה הרגילה שבה חושבים על אינטגרלים: באינטגרל רגיל, <span class="math">\(\int_{a}^{b}f\left(t\right)dt\)</span>, אנחנו לכאורה לוקחים את הערך <span class="math">\(f\left(t\right)\)</span> של הפונקציה בנקודה קונקרטית <span class="math">\(t\)</span>, כופלים באורך של "המרחק מ-<span class="math">\(t\)</span> אל הנקודה הבאה אחריה", אורך שאנחנו מסמנים ב-<span class="math">\(dt\)</span> וחושבים עליו בתור מספר קטן יותר מכל מספר ממשי, וסוכמים את הכל. אז גם ב-<span class="math">\(\int_{a}^{b}f\left(\gamma\left(t\right)\right)\|\gamma^{\prime}\left(t\right)\|dt\)</span> אפשר לחשוב שאנחנו לוקחים את הערך של <span class="math">\(f\)</span> בנקודה קונקרטית - הפעם בנקודה הקונקרטית על העקומה <span class="math">\(\gamma\left(t\right)\)</span> שהיא בעצמה הנקודה שמגיעים אליה בטיול על העקומה שמגיע לנקודה הקונקרטית <span class="math">\(t\)</span>, ואז כופלים את ערך הפונקציה הזו ב"מרחק מ-<span class="math">\(\gamma\left(t\right)\)</span> אל הנקודה הבאה על <span class="math">\(\gamma\)</span> אחריה". ראינו כבר שמרחק כזה הוא <span class="math">\(\|\gamma^{\prime}\left(t\right)\|dt\)</span>, אבל כל זה היה נפנופי ידיים אינטואיטיביים בלבד; אין כאן משהו פורמלי. לפורמליזם נגיע עכשיו.</p>
<p>את התשתית כבר יש לנו - אנחנו מבינים את הרעיון של לקחת חלוקה <span class="math">\(P\)</span> של <span class="math">\(\left[a,b\right]\)</span> שמורכבת מהנקודות <span class="math">\(a=t_{0}<t_{1}<t_{2}<\ldots<t_{m}=b\)</span> (אני משתמש ב-<span class="math">\(m\)</span> לאינדקס האחרון כי <span class="math">\(n\)</span> תפוס על ידי המימד של המרחב) ולהסתכל על החלוקה שהיא משרה על העקומה <span class="math">\(\gamma\)</span>. עכשיו נמשיך בדיוק כמו עם סכומי רימן הרגילים: בוחרים סדרה <span class="math">\(t_{1}^{*},\ldots,t_{m}^{*}\)</span> של נקודות כך ש-<span class="math">\(t_{i}^{*}\in\left[t_{i-1},t_{i}\right]\)</span> ואז בונים את הסכום <span class="math">\(S_{P}^{\gamma}=\sum_{i=1}^{m}f\left(\gamma\left(t_{i}^{*}\right)\right)\Delta\gamma_{i}\)</span> כאשר <span class="math">\(f\left(\gamma\left(t_{i}^{*}\right)\right)\)</span> הוא באופן מובן מאליו הערך של <span class="math">\(f\)</span> על הנקודה בעקומה שמגיעים אליה בזמן <span class="math">\(t_{i}^{*}\)</span>, ו-<span class="math">\(\Delta\gamma_{i}\)</span> הוא המרחק בין <span class="math">\(\gamma\left(t_{i}\right)\)</span> ו-<span class="math">\(\gamma\left(t_{i-1}\right)\)</span>.</p>
<p>הגענו להגדרה של האינטגרל עצמו: אם קיים מספר <span class="math">\(I\)</span> כך שלכל <span class="math">\(\varepsilon>0\)</span> קיים <span class="math">\(\delta>0\)</span> כך שלכל חלוקה <span class="math">\(P\)</span> עם <span class="math">\(\lambda\left(P\right)<\delta\)</span> מתקיים <span class="math">\(\left|S_{P}^{\gamma}-I\right|<\varepsilon\)</span>, אז אומרים ש-<span class="math">\(\int_{C}fd\gamma\)</span> קיים ו-<span class="math">\(\int_{C}fd\gamma=I\)</span>. זה ממש 1:1 ההגדרה של אינטגרל רימן הרגיל. נשאר רק לקבל עבורה נוסחה.</p>
<p>בואו נסתכל על המרחק <span class="math">\(\Delta\gamma_{i}\)</span> שמופיע בסכום שבנינו. עבדנו <strong>ממש קשה</strong> כדי לקבל נוסחה שימושית למרחק הזה אז בואו נשתמש בה עכשיו: <span class="math">\(\Delta\gamma_{i}=\int_{t_{i-1}}^{t_{i}}\|\gamma^{\prime}\left(t\right)\|dt\)</span>. במבט ראשון הייצוג הזה ל-<span class="math">\(\Delta\gamma_{i}\)</span> נראה לי מעורר חלחלה. בגרסאות המקוריות והכושלות של הפוסט הזה כתבתי <span class="math">\(\Delta\gamma_{i}=\left|\gamma\left(t_{i}\right)-\gamma\left(t_{i-1}\right)\right|\)</span> ואז השתמשתי בלגראז' כדי לקבל <span class="math">\(\Delta\gamma_{i}=\Delta t_{i}\cdot\left|\gamma^{\prime}\left(c_{i}\right)\right|\)</span> וקיבלתי מייד משהו שנראה כמו סכום רימן של <span class="math">\(\int_{a}^{b}f\left(\gamma\left(t\right)\right)\|\gamma^{\prime}\left(t\right)\|dt\)</span>. אלא שכאמור, השימוש הזה בלגראנז' הוא פשוט שגוי. אני לא יכול לעשות אותו, כי <span class="math">\(\gamma\)</span> היא לא פונקציה ממשית אלא פונקציה וקטורית.</p>
<p>העניין הוא ש<strong>קיימת</strong> הכללה של משפט לגראנז' שבה אני כן יכול להשתמש - הכללה עבור <strong>אינטגרלים</strong>. הנה הניסוח המדויק: אם <span class="math">\(g:\left[a,b\right]\to\mathbb{R}\)</span> היא פונקציה רציפה, אז קיימת <span class="math">\(c\in\left(a,b\right)\)</span> כך ש-<span class="math">\(\int_{a}^{b}g\left(t\right)dt=g\left(c\right)\left(b-a\right)\)</span>. במקרה שלנו, <span class="math">\(g\left(t\right)=\|\gamma^{\prime}\left(t\right)\|\)</span>. זו פונקציה ממשית, כי הנורמה של וקטור היא מספר ממשי בודד. זו פונקציה רציפה כי היא הרכבה של פונקציה רציפה (הנורמה) על פונקציה שהנחתי שהיא רציפה (הנחתי ש-<span class="math">\(\gamma\)</span> חלקה, לכן <span class="math">\(\gamma^{\prime}\)</span> רציפה). לכן אפשר להשתמש במשפט הזה עבור <span class="math">\(\Delta\gamma_{i}=\int_{t_{i-1}}^{t_{i}}\|\gamma^{\prime}\left(t\right)\|dt\)</span> ולקבל שקיים <span class="math">\(t_{i}^{*}\in\left(t_{i-1},t_{i}\right)\)</span> כך ש-<span class="math">\(\Delta\gamma_{i}=\|\gamma^{\prime}\left(t_{i}^{*}\right)\|\Delta t_{i}\)</span>, כמו שרציתי.</p>
<p>אינטואיטיבית, סיימנו: אנחנו אומרים "היי, תראו, מצאנו ייצוג ל-<span class="math">\(S_{P}^{\gamma}\)</span> שנראה בדיוק כמו סכום רימן רגיל!" כשהייצוג הזה הוא <span class="math">\(S_{P}^{\gamma}=\sum_{i=1}^{m}f\left(\gamma\left(t_{i}^{*}\right)\right)\|\gamma^{\prime}\left(t_{i}^{*}\right)\|\Delta t_{i}\)</span>, אבל אם רוצים להיות ממש פורמליים צריך להיזהר. למשל, בביטוי של הסכום מופיע <span class="math">\(t_{i}^{*}\)</span> פעמיים - פעם אחת בתוך <span class="math">\(\gamma^{\prime}\left(t_{i}^{*}\right)\)</span>, ולשם הוא הגיע בעזרת משפט לגראנז' האינטגרלי שהמציא אותו יש מאין, אבל הוא גם מופיע בתוך <span class="math">\(f\left(\gamma\left(t_{i}^{*}\right)\right)\)</span> ולשם הוא הגיע סתם כי בחרנו סדרת נקודות שרירותית לחלוטין, הרבה לפני שבכלל דיברנו על משפט לגראנז' האינטגרלי. בניסוח זהיר צריך להפוך את היוצרות - קודם לקבל את סדרת הנקודות שלגראנז' נותן, ואז לומר "מכיוון שבסכום רימן אנחנו בוחרים נקודות באופן שרירותי אז ניקח את הנקודות שמצאנו קודם". בואו נעשה את זה מסודר טיפ טופ עד הסוף, כי זה הפוסט שבו אני מרכז את כל הקטנוניות שלי.</p>
<p>אני רוצה להוכיח <span class="math">\(\int_{C}fd\gamma=\int_{a}^{b}f\left(\gamma\left(t\right)\right)\|\gamma^{\prime}\left(t\right)\|dt\)</span>. הדרך החדו"אית הפורמלית להוכיח ששני דברים הם שווים היא להוכיח שלכל <span class="math">\(\varepsilon>0\)</span> מתקיים</p>
<p><span class="math">\(\left|\int_{C}fd\gamma-\int_{a}^{b}f\left(\gamma\left(t\right)\right)\|\gamma^{\prime}\left(t\right)\|dt\right|<\varepsilon\)</span></p>
<p>טריק חדו"אי ידוע בשביל להוכיח דבר כזה הוא למצוא מספר <span class="math">\(S\)</span> שקרוב לשני הביטויים הללו עד כדי <span class="math">\(\frac{\varepsilon}{2}\)</span>:</p>
<p><span class="math">\(\left|\int_{C}fd\gamma-S\right|<\frac{\varepsilon}{2}\)</span></p>
<p><span class="math">\(\left|S-\int_{a}^{b}f\left(\gamma\left(t\right)\right)\|\gamma^{\prime}\left(t\right)\|dt\right|<\frac{\varepsilon}{2}\)</span></p>
<p>אם נמצא מספר כזה, נוכל ללכת לביטוי המקורי, לחבר ולחסר בו את <span class="math">\(S\)</span> ולהשתמש באי שוויון המשולש:</p>
<p><span class="math">\(\left|\int_{C}fd\gamma-\int_{a}^{b}f\left(\gamma\left(t\right)\right)\|\gamma^{\prime}\left(t\right)\|dt\right|=\left|\left(\int_{C}fd\gamma-S\right)+\left(S-\int_{a}^{b}f\left(\gamma\left(t\right)\right)\|\gamma^{\prime}\left(t\right)\|dt\right)\right|\le\)</span></p>
<p><span class="math">\(\left|\int_{C}fd\gamma-S\right|+\left|S-\int_{a}^{b}f\left(\gamma\left(t\right)\right)\|\gamma^{\prime}\left(t\right)\|dt\right|\le\frac{\varepsilon}{2}+\frac{\varepsilon}{2}=\varepsilon\)</span></p>
<p>מי ה-<span class="math">\(S\)</span> הזה יהיה? כמובן, הוא יהיה <strong>סכום רימן</strong> שקרוב מספיק לשני הביטויים הללו. בואו נבנה אותו בזהירות כדי שסדרת ה-<span class="math">\(t_{i}^{*}\)</span>-ים תתקבל בצורה נכונה.</p>
<p>ראשית, אנחנו יודעים שעבור <span class="math">\(\frac{\varepsilon}{2}\)</span> קיים <span class="math">\(\delta_{1}>0\)</span> כך שלכל חלוקה <span class="math">\(P\)</span> עם <span class="math">\(\lambda\left(P\right)<\delta_{1}\)</span>, <strong>לכל</strong> סכום רימן <span class="math">\(S_{P}^{\gamma}\)</span> שנבנה על החלוקה <span class="math">\(P\)</span> עם בחירה של סדרת נקודות <strong>כלשהי</strong>, מתקיים <span class="math">\(\left|\int_{C}fd\gamma-S_{P}^{\gamma}\right|<\frac{\varepsilon}{2}\)</span>. אני עדיין לא מגדיר את <span class="math">\(S\)</span> המדובר; בינתיים רק קיבלתי את <span class="math">\(\delta_{1}\)</span>.</p>
<p>בנוסף, שעבור <span class="math">\(\frac{\varepsilon}{2}\)</span> קיים <span class="math">\(\delta_{2}>0\)</span> כך שלכל חלוקה <span class="math">\(P\)</span> עם <span class="math">\(\lambda\left(P\right)<\delta_{2}\)</span>, <strong>לכל</strong> סכום רימן <span class="math">\(S_{P}\)</span> שנבנה על החלוקה <span class="math">\(P\)</span> עם בחירה של סדרת נקודות <strong>כלשהי</strong>, מתקיים <span class="math">\(\left|S_{P}-\int_{a}^{b}f\left(\gamma\left(t\right)\right)\|\gamma^{\prime}\left(t\right)\|dt\right|<\frac{\varepsilon}{2}\)</span>. גם פה: עוד לא בניתי את <span class="math">\(S\)</span>, רק מצאתי את <span class="math">\(\delta_{2}\)</span>.</p>
<p>עכשיו אני אגדיר <span class="math">\(\delta=\min\left\{ \delta_{1},\delta_{2}\right\} \)</span>. ואקח חלוקה <strong>כלשהי</strong> <span class="math">\(P\)</span> של <span class="math">\(\left[a,b\right]\)</span> כך ש-<span class="math">\(\lambda\left(P\right)<\delta\)</span> (זו יכולה להיות חלוקה אחידה, למשל; זה לא ממש משנה לי). שימו לב שגם בשלב הזה עדיין לא בניתי את <span class="math">\(S\)</span>; אבל אני כבר יודע שכל סכום רימן שייבנה על פי <span class="math">\(P\)</span> הולך להיות קרוב לאינטגרלים שלעיל. העניין הוא שאני צריך למצוא <span class="math">\(S\)</span> ספציפי כך ש-<span class="math">\(S=S_{P}=S_{P}^{\gamma}\)</span> למרות ש-<span class="math">\(S_{P}\)</span> ו-<span class="math">\(S_{P}^{\gamma}\)</span> מוגדרים בצורה שונה - זה בדיוק האופן שבו לגראנז' נכנס לעניין.</p>
<p>אם כן, אני מפעיל את לגראנז' על החלוקה <span class="math">\(P\)</span> ומוצא סדרת נקודות <span class="math">\(t_{1}^{*},t_{2}^{*},\ldots,t_{m}^{*}\)</span> כך ש-<span class="math">\(\Delta\gamma_{i}=\|\gamma^{\prime}\left(t_{i}^{*}\right)\|\Delta t_{i}\)</span>, ועכשיו אני מגדיר:</p>
<p><span class="math">\(S=\sum_{i=1}^{m}f\left(\gamma\left(t_{i}^{*}\right)\right)\|\gamma^{\prime}\left(t_{i}^{*}\right)\|\Delta t_{i}\)</span></p>
<p>עכשיו שיחקתי אותה, כי מצד אחד אם אני אסתכל על סכום הרימן שנוצר על ידי הפונקציה <span class="math">\(f\left(\gamma\left(t\right)\right)\|\gamma^{\prime}\left(t\right)\|\)</span>, החלוקה <span class="math">\(P\)</span> וסדרת הנקודות <span class="math">\(t_{1}^{*},t_{2}^{*},\ldots,t_{m}^{*}\)</span>, הסכום הזה הוא בדיוק</p>
<p><span class="math">\(S_{P}=\sum_{i=1}^{m}f\left(\gamma\left(t_{i}^{*}\right)\right)\|\gamma^{\prime}\left(t_{i}^{*}\right)\|\Delta t_{i}=S\)</span></p>
<p>ומצד שני אם אני אסתכל על סכום הרימן <span class="math">\(S_{P}^{\gamma}\)</span> שנוצר על ידי העקומה <span class="math">\(\gamma\)</span>, החלוקה <span class="math">\(P\)</span>, סדרת הנקודות <span class="math">\(t_{1}^{*},t_{2}^{*},\ldots,t_{m}^{*}\)</span> והפונקציה <span class="math">\(f\)</span>, הסכום הזה הוא בדיוק</p>
<p><span class="math">\(S_{P}^{\gamma}=\sum_{i=1}^{m}f\left(\gamma\left(t_{i}^{*}\right)\right)\Delta\gamma_{i}=\sum_{i=1}^{m}f\left(\gamma\left(t_{i}^{*}\right)\right)\|\gamma^{\prime}\left(t_{i}^{*}\right)\|\Delta t_{i}=S\)</span></p>
<p>וקיבלתי את <span class="math">\(S\)</span> המבוקש שלי, מה שמסיים את ההוכחה: ראינו ש-<span class="math">\(\int_{C}fd\gamma=\int_{a}^{b}f\left(\gamma\left(t\right)\right)\|\gamma^{\prime}\left(t\right)\|dt\)</span>. מבחינתי הסיפור של הוכחת הנוסחה הזו סגור ואני עכשיו בסדר עם ספרים שמשתמשים בה פשוט בתור ההגדרה.</p>
<h2>אינטגרל קווי (מסוג שני)</h2>

<p>אינטגרל קווי מסוג שני מטפל בסיטואציה שבה מבצעים אינטגרל על פונקציה וקטורית, <span class="math">\(F:\mathbb{R}^{n}\to\mathbb{R}^{n}\)</span>. היה אפשר לחשוב על כל מני דרכים לעשות את זה: אפשר למשל להתייחס אל <span class="math">\(F\)</span> בתור <span class="math">\(F\left(x\right)=\left(f_{1}\left(x\right),\ldots,f_{n}\left(x\right)\right)\)</span> כשכל <span class="math">\(f_{i}\)</span> היא פונקציה סקלרית ובמקרה הזה כבר טיפלנו עם אינטגרל קווי מסוג ראשון. בצורה הזו היינו מקבלים אינטגרל שהתוצאה שלו היא וקטור. אני לא רואה משהו שמונע מאיתנו להגדיר דבר כזה, כמו שאני לא רואה סיבה לא להגדיר כפל מטריצות "איבר-איבר". זו פשוט לא הגדרה שימושית במיוחד.</p>
<p>מה כן הגדרה שימושית? או, אם אמרנו <strong>שימושים</strong> אז כאן אין מנוס מלהיכנס <strong>לפיזיקה</strong> כי אינטגרל קווי מסוג שני משמש שם לתיאור אחד מהדברים הבסיסיים ביותר במכניקה - תיאור של <strong>עבודה</strong>. </p>
<p>בואו נחשוב על הסיטואציה הבאה - אנחנו לוקחים כדורגל ומעיפים אותו גבוה לאוויר, בקו אנכי לגמרי. מה שיקרה הוא שהכדורגל יתחיל לעוף במהירות מסוימת, וככל שכח הכובד יפעל עליו כך המהירות תקטן עוד ועוד עד אשר הכדורגל ייעצר לרגע באוויר, ואז יתחיל לצבור מהירות לכיוון ההפוך. עד שיפול בחזרה למטה. בכל הזמן הזה פעל על הכדור כוח אחד ויחיד - כוח הכובד. בהתחלה הוא הקטין את מהירות הכדור, ואחר כך הוא הגדיל אותה. מה השתנה? דרך אחת לחשוב על כך היא זו: בהתחלה הכדור זז <strong>למעלה</strong> בזמן שכוח הכובד פעל <strong>למטה</strong>, ואחר כך הכדור זז <strong>למטה</strong> תוך כדי שכוח הכובד פועל <strong>למטה</strong>. יש כאן קשר בין וקטור הכוח (כלומר לא רק הגודל שלו, גם הכיוון שלו) ומסלול התנועה של הכדור.</p>
<p>הנה עוד סיטואציה לדוגמא: נדמיין לווין שמסתובב סביב כדור הארץ במסלול מעגלי לגמרי. מסלול מעגלי שכזה לא מתרחש "מעצמו"; החוק הראשון של ניוטון אומר שאם לא מופעלים על גוף כוחות, הוא יתמיד במסלול שהוא קו ישר. מסלול מעגלי נוצר רק כשבכל רגע משנים את כיוון התנועה של האובייקט. כאן ספציפית אפשר לדמיין שהלווין נע <strong>שמאלה</strong> בזמן שכדור הארץ מפעיל עליו כוח <strong>למטה</strong>, בניצב לכיוון התנועה של הלווין. זה גורם לכיוון התנועה של הלווין להשתנות ולהיות "שמאלה וקצת למטה" ; בשלב הזה הוא כבר זז קצת אבל כדור הארץ ממשיך להפעיל עליו כוח שניצב לכיוון התנועה שלו, וכן הלאה. בסיטואציה כזו של תנועה מעגלית מושלמת (ולא, נאמר, שהלווין נע במעין אליפסה) הגודל של המהירות של הלווין (מה שנקרא speed, להבדיל מ-velocity) הולך להישאר קבוע - זה שונה מהכדורגל שבו המהירות השתנתה כל הזמן. מה ההבדל? בסיפור של הלווין הכוח פועל <strong>בניצב</strong> לכיוון התנועה של הלווין, ובסיפור הכדורגל וקטור הכוח היה חופף לכיוון התנועה (או שהוא היה זהה לו, או שהוא היה הפוך בכיוונו).</p>
<p>בואו נעבור לפורמליזם הפיזיקלי. בפיזיקה משתמשים ב-<span class="math">\(v\left(t\right)\)</span> כדי לתאר את וקטור המהירות של גוף בזמן <span class="math">\(t\)</span>. אם אנחנו במרחב תלת ממדי, למשל, אז <span class="math">\(v\left(t\right)=\left(v_{x}\left(t\right),v_{y}\left(t\right),v_{z}\left(t\right)\right)\)</span>. המהירות במובן של speed של הוקטור הזה היא <span class="math">\(\|v\|=\sqrt{v_{x}^{2}+v_{y}^{2}+v_{z}^{2}}\)</span>, אבל אפשר לפשט את הסימונים אם מכניסים לתמונה <strong>מכפלה סקלרית</strong>. באופן כללי, מכפלה סקלרית של שני וקטורים <span class="math">\(a,b\in\mathbb{R}^{n}\)</span> היא <span class="math">\(a\cdot b=\sum_{i=1}^{n}a_{i}b_{i}\)</span>, ולא קשה לראות ש-<span class="math">\(\|v\|^{2}=v\cdot v\)</span> (למי שזוכרים אלגברה לינארית, מכפלה סקלרית היא מקרה פרטי של מכפלה פנימית).</p>
<p>עכשיו, בפיזיקה יש לנו את <strong>החוק השני של ניוטון</strong> שמתאר את האופן שבו כוח שפועל על גוף משפיע על המהירות שלו: <span class="math">\(F=ma\)</span>, כאשר <span class="math">\(F\)</span> הואה כוח שפועל על הגוף ו-<span class="math">\(a\)</span> היא <strong>התאוצה</strong> של הגוף, כלומר <span class="math">\(a=v^{\prime}\)</span> (הפיזיקאים מעדיפים סימון כמו <span class="math">\(a=\frac{dv}{dt}\)</span> ועושים איתו להטוטים אבל אני בכוונה אמנע מכך כאן). עכשיו, מערכת שכוללת גוף וכוח שפועל עליו יכולה להיות מסובכת למדי: הכוח משפיע על התאוצה, שהיא הנגזרת הראשונה של המהירות, ולכן הנגזרת השנייה של המיקום, אבל המיקום עצמו עשוי להשפיע על הכוח כי באופן כללי הכוח תלוי במיקום האובייקט במרחב. אם נפתח את זה עד הסוף נקבל <strong>משוואה דיפרנצאלית</strong> וזה יכול להיות אתגר להתמודד עם דבר כזה, אז הפיזיקאים מוצאים דרכים להתמודד עם הקשיים בלי ללכת איתם ראש בראש, ואחת מהדרכים הללו היא לדבר על <strong>אנרגיה</strong>.</p>
<p>אנרגיה היא גודל מספרי כלשהו שניתן לחשב עבור מערכת, והרעיון בו הוא שהחישוב הוא כזה שהערך של האנרגיה <strong>נשאר קבוע</strong> גם כשהמערכת עוברת שינויים (הרעיון הזה של <strong>אינוריאנטה</strong> ככלי להבנה של מערכות מסובכות הוא להיט גם במתמטיקה; <a href="https://gadial.net/2007/04/23/invariants_15_game_domino/">הפוסט הראשון בבלוג</a> דיבר על זה). אחד מהגדלים שצריך לחשב כדי לקבל את האנרגיה של מערכת הוא <strong>האנרגיה הקינטית</strong> של העצמים שנמצאים בה, שמתארת גודל שנובע מהמהירות שלהם. עבור גוף בעל מסה <span class="math">\(m\)</span> ומהירות <span class="math">\(v\)</span>, האנרגיה הקינטית היא <span class="math">\(\frac{m\|v\|^{2}}{2}=\frac{m\left(v\cdot v\right)}{2}\)</span>. עכשיו, לפני שאתקדם, הנה להטוט חמוד: אם <span class="math">\(a\left(t\right),b\left(t\right)\)</span> הן שתי פונקציות וקטוריות, <span class="math">\(a,b:\mathbb{R}\to\mathbb{R}^{n}\)</span>, אז לא קשה להראות בעזרת חוקי הנגזרות הרגילים שמתקיים</p>
<p><span class="math">\(\left(a\cdot b\right)^{\prime}=\left(\sum_{i=1}^{n}a_{i}b_{i}\right)^{\prime}=\sum_{i=1}^{n}a_{i}^{\prime}b_{i}+\sum_{i=1}^{n}a_{i}b_{i}^{\prime}=a^{\prime}\cdot b+a\cdot b^{\prime}\)</span></p>
<p>לכן, אם אני אסמן <span class="math">\(T=\frac{m\|v\|^{2}}{2}\)</span> כדי לתאר את האנרגיה הקינטית של גוף, ואז אחשב את קצב השינוי שלה, אני אקבל</p>
<p><span class="math">\(T^{\prime}=\frac{m}{2}\left(v\cdot v\right)^{\prime}=mv^{\prime}\cdot v=F\cdot v\)</span></p>
<p>כלומר, השינוי באנרגיה הקינטית של הגוף הוא הכוח <span class="math">\(F\)</span> שפועל עליו, כפול וקטור המהירות של הגוף - זה תואם את הדיון שלמעלה, ומן הסתם לא במקרה - ההגדרה של אנרגיה קינטית מיועדת כדי שזה יעבוד. עכשיו, נפנוף הידיים הפיזיקאי אומר בשלב הזה ש-<span class="math">\(F\cdot v\)</span> מתאר את השינוי <strong>הרגעי</strong> באנרגיה בהתאם לשינוי הרגעי בזמן, ולכן <span class="math">\(\int_{a}^{b}F\cdot vdt\)</span> הולך לתאר את השינוי באנרגיה לאורך פרק הזמן <span class="math">\(a\le t\le b\)</span>, מה שנקרא <strong>העבודה</strong> של הכוח על הגוף. עכשיו, אם נתאר ב-<span class="math">\(\gamma\)</span> את המסלול שהעצם עבר בפרק הזמן הזה, אז <span class="math">\(v=\gamma^{\prime}\)</span> (כי מהירות היא תמיד הנגזרת של המקום), ולכן השינוי באנרגיה של הגוף יהיה <span class="math">\(\int_{a}^{b}F\cdot\gamma^{\prime}dt\)</span>. עכשיו אפשר להחזיר את מה שהסתרנו - הרי <span class="math">\(F\)</span> היא פונקציה שתלויה לא בזמן אלא <strong>במקום</strong> של העצם בכל רגע נתון, כלומר ב-<span class="math">\(\gamma\left(t\right)\)</span>, אז את האינטגרל אפשר לכתוב בתור</p>
<p><span class="math">\(\int_{a}^{b}F\left(\gamma\left(t\right)\right)\cdot\gamma^{\prime}dt\)</span></p>
<p>הדבר <strong>הזה</strong> הוא איך שמוגדר אינטגרל קווי מסוג שני. לפעמים הוא מסומן גם בתור <span class="math">\(\int_{C}F\cdot\gamma d\gamma\)</span>, בדומה למה שקורה לאינטגרל קווי מסוג ראשון, אבל צריך לזכור שכאן הכפל בין <span class="math">\(F\)</span> ל-<span class="math">\(\gamma\)</span> הוא <strong>מכפלה סקלרית</strong> וחישוב האינטגרל בפועל מסתמך עליה: <span class="math">\(\int_{C}F\cdot\gamma d\gamma=\int_{a}^{b}F\left(\gamma\left(t\right)\right)\cdot\gamma^{\prime}dt\)</span>.</p>
<p>ושוב עולה אצלי השאלה - האם אני <strong>חייב</strong> פשוט להגדיר את האינטגרל להיות <span class="math">\(\int_{a}^{b}F\left(\gamma\left(t\right)\right)\cdot\gamma^{\prime}dt\)</span>? או שאני יכול להשתמש בגישת סכומי רימן גם כאן? בואו נחשוב איך סכום רימן כזה הולך להיראות כאן. כרגיל, אני אקח את הקטע <span class="math">\(\left[a,b\right]\)</span> ואחלק אותו לחלוקה <span class="math">\(P\)</span> כלשהי עם נקודות הביניים <span class="math">\(a=t_{0}\le t_{1}\le\ldots\le t_{m}=b\)</span>. אני אקח נקודה <span class="math">\(t_{i}^{*}\in\left[t_{i-1},t_{i}\right]\)</span> מתוך כל קטע כזה, אחשב את הפונקציה באותה נקודה של העקום שמתאימה לזמן <span class="math">\(t_{i}^{*}\)</span> כלומר אסתכל על <span class="math">\(F\left(\gamma\left(t_{i}^{*}\right)\right)\)</span>, ואת זה אני אכפול באורך... לא, רגע, עוד לא. כאמור, <span class="math">\(F\left(\gamma\left(t_{i}^{*}\right)\right)\)</span> הוא וקטור שאנחנו לא רוצים לקחת את כולו; אנחנו רוצים לקחת רק את <strong>הגודל של ההיטל</strong> שלו על הכיוון שאליו העקום <span class="math">\(\gamma\)</span> הולך בזמן <span class="math">\(t_{i}^{*}\)</span>. בשביל דברים כאלו יש לנו מכפלה סקלרית.</p>
<p>הנה עוד תזכורת על מכפלה סקלרית. מצד אחד, <span class="math">\(u\cdot v=\sum_{i=1}^{n}u_{i}v_{i}\)</span> וזו דרך לחשוב על מכפלה סקלרית בתור איך בדיוק מחשבים אותה. מצד שני, אפשר להראות ש-<span class="math">\(u\cdot v=\|u\|\cdot\|v\|\cdot\cos\theta\)</span> כש-<span class="math">\(\theta\)</span> היא הזווית שבין שני הוקטורים. עכשיו, אפשר לחשוב על <span class="math">\(\|u\|\cdot\cos\theta\)</span> בתור <strong>גודל ההיטל</strong> של <span class="math">\(u\)</span> על הציר ש-<span class="math">\(v\)</span> מגדיר - הנה דרך לדמיין את זה (החלק של <span class="math">\(v\)</span> עד הקו המקווקו, שצבעתי בסגול, הוא מאורך <span class="math">\(\|u\|\cdot\cos\theta\)</span>):</p>
<p><img src="/img/2024/projection.png" alt=""/></p>
<p>ולכן אפשר לחשוב על <span class="math">\(u\cdot v\)</span> בתור גודל ההיטל של <span class="math">\(u\)</span> על <span class="math">\(v\)</span>, כל זה כפול הגודל של <span class="math">\(v\)</span>. אם אנחנו רוצים להשתמש ב-<span class="math">\(v\)</span> רק בתור וקטור שמצביע על כיוון, בלי לכפול בגודל שלו, אפשר פשוט לנרמל אותו - להסתכל על המכפלה <span class="math">\(u\cdot\frac{v}{\|v\|}\)</span>. אפשר לעשות את זה גם כאן: אם אנחנו רוצים רק את וקטור הכיוון שאליו <span class="math">\(\gamma\)</span> הולכת בזמן <span class="math">\(t_{i}^{*}\)</span> אפשר להסתכל על הוקטור <span class="math">\(\frac{\gamma^{\prime}\left(t_{i}^{*}\right)}{\|\gamma^{\prime}\left(t_{i}^{*}\right)\|}\)</span>. כמובן, זה מניח ש-<span class="math">\(\gamma^{\prime}\left(t_{i}^{*}\right)\ne0\)</span>, כי אם <span class="math">\(\gamma^{\prime}\left(t_{i}^{*}\right)=0\)</span> אין מה לחלק בנורמה שלו אבל יותר גרוע מזה, הוא בכלל לא מגדיר כיוון מוגדר ולכן כל הדיון חסר תוחלת; אבל אנחנו מניחים שהפרמטריזציה היא "נחמדה" ולכן אין לה סיבה לבצע עצירות פתאומיות, אז נתעלם מזה באלגנטיות.</p>
<p>אם כן, הפונקציה שאנחנו רוצים שתופיע לנו בסכום הרימן, ותוכפל כרגיל ב-<span class="math">\(\Delta\gamma_{i}\)</span> כמו שקרה באינטגרל קווי מסוג ראשון, היא הפונקציה <span class="math">\(\frac{F\left(\gamma\left(t_{i}^{*}\right)\right)\cdot\gamma^{\prime}\left(t_{i}^{*}\right)}{\|\gamma^{\prime}\left(t_{i}^{*}\right)\|}\)</span>, ולכן סכום הרימן שלי הולך להיות</p>
<p><span class="math">\(S_{P}^{\gamma}=\sum_{i=1}^{m}\frac{F\left(\gamma\left(t_{i}^{*}\right)\right)\cdot\gamma^{\prime}\left(t_{i}^{*}\right)}{\|\gamma^{\prime}\left(t_{i}^{*}\right)\|}\cdot\Delta\gamma_{i}\)</span></p>
<p>ובכן, זו נראית כמו חתיכת מהומה ענקית! אבל בואו ניזכר שעשינו לא מעט עבודה כשדיברנו על אינטגרל קווי מסוג ראשון כדי להראות שאפשר לכתוב <span class="math">\(\Delta\gamma_{i}=\|\gamma^{\prime}\left(t_{i}^{*}\right)\|\Delta t_{i}\)</span>. זה <strong>לא</strong> נכון לכל סדרה שרירותית של נקודות <span class="math">\(t_{i}^{*}\)</span>! אבל בהינתן חלוקה <span class="math">\(P\)</span> תמיד אפשר למצוא סדרה ספציפית כזו של נקודות שעבורן השוויון יתקיים - זה היה שימוש במשפט לגראנז' האינטגרלי. לכן, עבור בחירה מתאימה של נקודות כאלו, סכום הרימן שלנו הופך להיות</p>
<p><span class="math">\(S_{P}^{\gamma}=\sum_{i=1}^{m}F\left(\gamma\left(t_{i}^{*}\right)\right)\cdot\gamma^{\prime}\left(t_{i}^{*}\right)\cdot\Delta t_{i}\)</span></p>
<p>ואפשר להשתמש בדיוק באותה הוכחה שראינו במקרה של אינטגרל קווי מסוג ראשון כדי להראות שבגלל שהסכום הזה הוא בעצם אותו דבר כמו סכום רימן של האינטגרל הרגיל <span class="math">\(\int_{a}^{b}F\left(\gamma\left(t\right)\right)\cdot\gamma^{\prime}dt\)</span>, אנחנו מקבלים <span class="math">\(\int_{C}F\cdot\gamma d\gamma=\int_{a}^{b}F\left(\gamma\left(t\right)\right)\cdot\gamma^{\prime}dt\)</span>. למעשה, אפשר ממש לחשוב על מה שעשינו פה בתור <strong>רדוקציה</strong> למקרה של אינטגרל קווי מסוג ראשון - כאילו אמרנו "היי, בואו נסתכל על הפונקציה <span class="math">\(\frac{F\left(\gamma\left(t\right)\right)\cdot\gamma^{\prime}\left(t\right)}{\|\gamma^{\prime}\left(t\right)\|}\)</span>, זו פונקציה סקלרית אז בואו נחשב לה אינטגרל קווי מסוג <strong>ראשון</strong>". זה מסיים עבורי את הסיפור של אינטגרל קווי מסוג שני - גם פה, אני עכשיו בסדר גמור עם פשוט להגדיר אותו בתור <span class="math">\(\int_{a}^{b}F\left(\gamma\left(t\right)\right)\cdot\gamma^{\prime}dt\)</span>.</p>
<h2>ומה עם אינטגרל מרוכב?</h2>

<p>כל המהומה הזו נולדה מהנסיון לשכנע את עצמי שההגדרה של אינטגרל מרוכב היא "מה שהיא צריכה להיות" למרות שאין שום צורך בשכנוע כזה מלכתחילה כי מרגע שמתחילים עם ההגדרה הזו קורים קסמים. אז אני לא יכול לסיים את הפוסט הזה בלי לדבר גם על ההגדרה הזו.</p>
<p>ההגדרה עצמה דומה מאוד להגדרה של אינטגרל קווי מסוג שני: יש לנו עקומה <span class="math">\(C\)</span>, רק שהפעם היא לא עקומה ב-<span class="math">\(\mathbb{R}^{n}\)</span> אלא <strong>במישור המרוכב</strong>, כלומר אני מתאר אותה עם פונקציה שאסמן <span class="math">\(z:\left[a,b\right]\to\mathbb{C}\)</span>. יש לנו פונקציה מרוכבת <span class="math">\(f:\mathbb{C}\to\mathbb{C}\)</span>, ואנחנו מגדירים </p>
<p><span class="math">\(\int_{C}f\left(z\right)dz=\int_{a}^{b}f\left(z\left(t\right)\right)z^{\prime}\left(t\right)dt\)</span></p>
<p>זה מאוד, מאוד מזכיר אינטגרל קווי מסוג שני, אבל יש הבדל ברור אחד - הכפל שמופיע בתור האינטגרל הימני הוא <strong>לא</strong> מכפלה סקלרית, הוא פשוט פעולת הכפל הרגילה של מספרים מרוכבים, שהיא די שונה ממכפלה סקלרית. אם אני כותב את המספר המרוכב <span class="math">\(a+bi\)</span> בתור <span class="math">\(\left(a,b\right)\)</span>, אז נקבל את המכפלה <span class="math">\(\left(a_{1},b_{1}\right)\cdot\left(a_{2},b_{2}\right)=\left(a_{1}a_{2}-b_{1}b_{2},a_{1}b_{2}+a_{2}b_{1}\right)\)</span> שהיא כמובן גם לא סקלר ממשי אלא עדיין משהו עם שני רכיבים ממשיים שונים, וגם היא ערבוביה מוחלטת של המקדמים, בזכות פעולת הכפל המוזרה של מספרים מרוכבים. אז אי אפשר להגיד שזה פשוט לקחת את ההגדרה של אינטגרל קווי מסוג שני ולהשתמש בה על מרוכבים; ועוד דבר שהפריע לי מאוד הוא למה להשתמש דווקא באינטגרל קווי מסוג שני ולא באינטגרל קווי מסוג <strong>ראשון</strong>, שלכאורה מתאים יותר לסיטואציה של פונקציה שמחזירה סקלר שאפשר לכפול בו כפל רגיל. למה לא להגדיר <span class="math">\(\int_{C}f\left(z\right)dz=\int_{a}^{b}f\left(z\left(t\right)\right)\|z^{\prime}\left(t\right)\|dt\)</span>?</p>
<p>ובכן, אפשר היה להגדיר ככה, זה פשוט לא היה שימושי כמו מה שכן הוגדר. הטעות הבסיסית שלי כשניגשתי לנושא הייתה לחשוב שאינטגרל מרוכב מוגדר בצורה דומה לאינטגרל קווי, כשבפועל הוא לא: הוא מוגדר בצורה דומה למה שנקרא <strong>אינטגרל רימן-סטילטיס</strong>.</p>
<p>מה הרעיון של אינטגרל רימן-סטילטיס? זה כמובן ראוי לפוסט משלו, אז אשאר כאן יחסית ממוקד. באינטגרל רימן, סכום רימן נראה כמו <span class="math">\(S_{P}=\sum_{i=1}^{n}f\left(t_{i}^{*}\right)\Delta t_{i}\)</span> כאשר <span class="math">\(\Delta t_{i}=t_{i}-t_{i-1}\)</span> והרעיון הוא ש-<span class="math">\(\Delta t_{i}\)</span> מייצג <strong>אורך קטע</strong>. בעצם, אפשר לחשוב על הסכום הזה בתור סכום <strong>ממושקל</strong>, כשהערך של פונקציה בקטע מסוים מקבלת משקל שמתאים לאורך שלו. זה תואם את האינטואיציה שלנו כשאנו חושבים על אינטגרל בתור "השטח שמתחת לגרף הפונקציה <span class="math">\(f\)</span>". אבל למה להגביל את עצמנו? אפשר להשתמש בפונקציות משקל שונות ומשונות שנקראות <strong>אינטגרטורים</strong>. אם כן, לוקחים פונקציה <span class="math">\(g:\left[a,b\right]\to\mathbb{R}\)</span> ומגדירים סכום רימן-סטילטיס בתור <span class="math">\(S_{P}=\sum_{i=1}^{n}f\left(t_{i}^{*}\right)\left(g\left(t_{i}\right)-g\left(t_{i-1}\right)\right)\)</span>. אם כל הדבר הזה מתכנס למשהו באותו מובן שבו סכום רימן התכנס, מסמנים את התוצאה ב-<span class="math">\(\int_{a}^{b}fdg\)</span>, כאשר כאן ה-<span class="math">\(dg\)</span> במקום <span class="math">\(dt\)</span> רומז לנו ש-<span class="math">\(g\)</span> הוא אינטגרטור. אינטגרל רימן ה"רגיל" מתקבל אם בוחרים <span class="math">\(g\left(t\right)=t\)</span>.</p>
<p>במקרים שבהם <span class="math">\(g\)</span> חלקה, אפשר להמיר את החישוב של אינטגרל רימן-סטילטיס בחישוב של אינטגרל רימן, באופן דומה למה שכבר ראינו אבל למרבה השמחה אפילו עוד יותר קל כי כאן <strong>אפשר</strong> להשתמש במשפט הערך הממוצע המקורי של לגראנז', על <span class="math">\(g\)</span> עצמה, ולקבל <span class="math">\(g\left(t_{i}\right)-g\left(t_{i-1}\right)=g^{\prime}\left(t_{i}^{*}\right)\Delta t_{i}\)</span> לכל תת-קטע. מרגע שיש לנו את זה, זו פשוט חזרה על ההוכחה שכבר ראינו קודם ש-<span class="math">\(\int_{a}^{b}fdg=\int_{a}^{b}f\left(t\right)g^{\prime}\left(t\right)dt\)</span> (שימו לב שכאן הפרמטר של <span class="math">\(f\)</span> הוא פשוט <span class="math">\(t\)</span>; הוא לא <span class="math">\(g\left(t\right)\)</span> כמו שקורה באינטגרל קווי).</p>
<p>אינטגרל מרוכב מוגדר בצורה דומה מאוד. יש לנו את העקומה <span class="math">\(\gamma:\left[a,b\right]\to\mathbb{C}\)</span> שממלאת את התפקיד של <span class="math">\(g\)</span>, אבל במקום לסכום "סתם" ערכים של <span class="math">\(f\)</span>, אנחנו סוכמים ערכים של <span class="math">\(f\left(\gamma\left(t\right)\right)\)</span>, כלומר אנחנו מסתכלים על משהו דמוי רימן-סטילטיס עבור אינטגרטור <span class="math">\(\gamma\)</span> והפונקציה <span class="math">\(f\circ\gamma\)</span>. מכיוון שאנחנו כבר ממש ממש ממש בסוף, בואו עוד פעם אחת אחרונה ודי נעשה את הכל פורמלי, כדי שלא יהיו לי יותר דאגות.</p>
<p>אם כן: נתונה לנו פונקציה <span class="math">\(f:\mathbb{C}\to\mathbb{C}\)</span> ועקומה <span class="math">\(z:\left[a,b\right]\to\mathbb{C}\)</span>. אנחנו לוקחים חלוקה <span class="math">\(P\)</span> של <span class="math">\(\left[a,b\right]\)</span>, ולכל בחירת נקודות <span class="math">\(t_{i}^{*}\)</span> אנחנו בונים את הסכום <span class="math">\(S_{P}^{z}=\sum_{i=1}^{n}f\left(z\left(t_{i}^{*}\right)\right)\left(z\left(t_{i}\right)-z\left(t_{i-1}\right)\right)\)</span>. הפעם זה סכום של <strong>מספרים מרוכבים</strong>; גם <span class="math">\(f\left(z\left(t_{i}^{*}\right)\right)\)</span> וגם <span class="math">\(\left(z\left(t_{i}\right)-z\left(t_{i-1}\right)\right)\)</span> הם מספרים מרוכבים. הגדרת ההתכנסות נשארת זהה: אם קיים <span class="math">\(I\in\mathbb{C}\)</span> כך שלכל <span class="math">\(\varepsilon>0\)</span> קיים <span class="math">\(\delta\)</span> כך שלכל חלוקה <span class="math">\(P\)</span> עם <span class="math">\(\lambda\left(P\right)<\delta\)</span> וכל בחירת נקודות עבור חלוקה כזו, מתקיים <span class="math">\(\left|S_{P}^{z}-I\right|<\varepsilon\)</span>, אז אומרים ש-<span class="math">\(\int_{C}f\left(z\right)dz=I\)</span>. הפעם הערך המוחלט ב-<span class="math">\(\left|S_{P}^{z}-I\right|\)</span> הוא פונקציית הערך המוחלט של מספרים מרוכבים: <span class="math">\(\left|a+bi\right|=\sqrt{a^{2}+b^{2}}\)</span>.</p>
<p>אני רוצה להוכיח שתחת ההגדרה הזו מתקיים השוויון <span class="math">\(\int_{C}f\left(z\right)dz=\int_{a}^{b}f\left(z\left(t\right)\right)z^{\prime}\left(t\right)dt\)</span>, אבל מה בעצם הולך באגף ימין? זה לא אינטגרל רימן רגיל. אמנם, <strong>המשתנה</strong> של הפונקציה שבאינטגרל הוא מספר ממשי, <span class="math">\(t\in\left[a,b\right]\)</span>, אבל הפונקציות עצמן הן עדיין מרוכבות ולא דיברתי על אינטגרלים של פונקציות מרוכבות עם משתנה ממשי. למרבה המזל, זה ממש פשוט: כל פונקציה מרוכבת <span class="math">\(g:\left[a,b\right]\to\mathbb{C}\)</span> אפשר להציג בתור <span class="math">\(g\left(t\right)=x\left(t\right)+iy\left(t\right)\)</span> כאשר <span class="math">\(x,y:\mathbb{R}\to\mathbb{R}\)</span> הן פונקציות ממשיות, ואז אפשר להגדיר </p>
<p><span class="math">\(\int_{a}^{b}g\left(t\right)dt=\int_{a}^{b}x\left(t\right)dt+i\int_{a}^{b}y\left(t\right)dt\)</span></p>
<p>כאשר כאן באגף ימין יש שני אינטגרלים רגילים של פונקציות ממשיות. זה גם מה שעשינו כשלקחנו אינטגרל של פונקציה וקטורית, כשהתעסקנו באינטגרלים קוויים. דבר דומה קורה גם עבור נגזרות:</p>
<p><span class="math">\(g^{\prime}\left(t\right)=\lim_{h\to0}\frac{g\left(t+h\right)-g\left(t\right)}{h}=\lim_{h\to0}\left(\frac{x\left(t+h\right)-x\left(t\right)}{h}+i\frac{y\left(t+h\right)-y\left(t\right)}{h}\right)=x^{\prime}\left(t\right)+iy^{\prime}\left(t\right)\)</span></p>
<p>אז זה מה שנצטרך לעשות כדי להוכיח את השוויון <span class="math">\(\int_{C}f\left(z\right)dz=\int_{a}^{b}f\left(z\left(t\right)\right)z^{\prime}\left(t\right)dt\)</span> - לפרק לשני חלקים שאחד ממשי והשני מדומה, ולהוציא את ה-<span class="math">\(i\)</span> החוצה. אז בואו ונכתוב</p>
<p><span class="math">\(f\left(z\left(t\right)\right)=u\left(t\right)+iv\left(t\right)\)</span></p>
<p><span class="math">\(z\left(t\right)=x\left(t\right)+iy\left(t\right)\)</span></p>
<p><span class="math">\(z^{\prime}\left(t\right)=x^{\prime}\left(t\right)+iy^{\prime}\left(t\right)\)</span></p>
<p>ועכשיו:</p>
<p><span class="math">\(\int_{a}^{b}f\left(z\left(t\right)\right)z^{\prime}\left(t\right)dt=\int_{a}^{b}\left[u\left(t\right)+iv\left(t\right)\right]\left[x^{\prime}\left(t\right)+iy^{\prime}\left(t\right)\right]dt\)</span></p>
<p><span class="math">\(=\int_{a}^{b}\left[u\left(t\right)x^{\prime}\left(t\right)-v\left(t\right)y^{\prime}\left(t\right)\right]dt+i\int_{a}^{b}\left[u\left(t\right)y^{\prime}\left(t\right)+v\left(t\right)x^{\prime}\left(t\right)\right]dt\)</span></p>
<p>זה נראה כמו סמטוחה אחת גדולה, אבל אין עם זה בעיה - כל עוד גם <span class="math">\(\int_{C}f\left(z\right)dz\)</span> מתכנן להיראות כמו סמטוחה אחת גדולה דומה כשנסיים איתו. בואו נכתוב סכום רימן כללי עבורו:</p>
<p><span class="math">\(\sum_{i=1}^{n}f\left(z\left(t_{i}^{*}\right)\right)\left(z\left(t_{i}\right)-z\left(t_{i-1}\right)\right)\)</span></p>
<p>בינתיים אני <strong>לא יכול</strong> לפשט את <span class="math">\(z\left(t_{i}\right)-z\left(t_{i-1}\right)\)</span> כי אין לי אנלוג ישיר למשפט לגראנז' עבור פונקציות עם טווח מרוכב. אז מה אני אעשה? אני אלך עם הראש בקיר ואציב דברים:</p>
<p><span class="math">\(\sum_{i=1}^{n}f\left(z\left(t_{i}^{*}\right)\right)\left(z\left(t_{i}\right)-z\left(t_{i-1}\right)\right)=\)</span></p>
<p><span class="math">\(=\sum_{i=1}^{n}\left[\left(u\left(t_{i}^{*}\right)+iv\left(t_{i}^{*}\right)\right)\left(x\left(t_{i}\right)+iy\left(t_{i}\right)-x\left(t_{i-1}\right)-iy\left(t_{i-1}\right)\right)\right]=\)</span></p>
<p><span class="math">\(=\sum_{i=1}^{n}\left[u\left(t_{i}^{*}\right)\left(x\left(t_{i}\right)-x\left(t_{i-1}\right)\right)-v\left(t_{i}^{*}\right)\left(y\left(t_{i}\right)-y\left(t_{i-1}\right)\right)\right]+\)</span></p>
<p><span class="math">\(+i\sum_{i=1}^{n}\left[u\left(t_{i}^{*}\right)\left(y\left(t_{i}\right)-y\left(t_{i-1}\right)\right)+v\left(t_{i}^{*}\right)\left(x\left(t_{i}\right)-x\left(t_{i-1}\right)\right)\right]\)</span></p>
<p>בינתיים זה נראה טוב, אבל שוד ושבר - יש לנו גם את הביטוי <span class="math">\(x\left(t_{i}\right)-x\left(t_{i-1}\right)\)</span> וגם את הביטוי <span class="math">\(y\left(t_{i}\right)-y\left(t_{i-1}\right)\)</span> ולא נוכל להשתמש בלגראנז' סימולטנית על שניהם. לכן אני אנקוט בטקטיקה אחרת - אני אפצל את הכל <strong>עוד פעם</strong> ואקבל מהאינטגרל המקורי סכום של ארבעה אינטגרלים, ומסכום הרימן המקורי ארבעה סכומים. בואו נכתוב אותם זה לצד זה:</p>
<ul> <li><span class="math">\(\int_{a}^{b}u\left(t\right)x^{\prime}\left(t\right)dt\)</span> אל מול <span class="math">\(\sum_{i=1}^{n}u\left(t_{i}^{*}\right)\left(x\left(t_{i}\right)-x\left(t_{i-1}\right)\right)\)</span></li>


<li><span class="math">\(-\int_{a}^{b}v\left(t\right)y^{\prime}\left(t\right)dt\)</span> אל מול <span class="math">\(-\sum_{i=1}^{n}v\left(t_{i}^{*}\right)\left(y\left(t_{i}\right)-y\left(t_{i-1}\right)\right)\)</span></li>


<li><span class="math">\(i\int_{a}^{b}u\left(t\right)y^{\prime}\left(t\right)dt\)</span> אל מול <span class="math">\(i\sum_{i=1}^{n}u\left(t_{i}^{*}\right)\left(y\left(t_{i}\right)-y\left(t_{i-1}\right)\right)\)</span></li>


<li><span class="math">\(i\int_{a}^{b}v\left(t\right)x^{\prime}\left(t\right)dt\)</span> אל מול <span class="math">\(i\sum_{i=1}^{n}v\left(t_{i}^{*}\right)\left(x\left(t_{i}\right)-x\left(t_{i-1}\right)\right)\)</span></li>

</ul>

<p>עכשיו אני אוכיח שמתקיים<span class="math">\(\int_{C}f\left(z\right)dz=\int_{a}^{b}f\left(z\left(t\right)\right)z^{\prime}\left(t\right)dt\)</span> על פי ההגדרה של <span class="math">\(\int_{C}f\left(z\right)dz\)</span>. כלומר, ניקח <span class="math">\(\varepsilon>0\)</span> ונוכיח שקיימת <span class="math">\(\delta>0\)</span> כך שאם <span class="math">\(P\)</span> היא חלוקה כלשהי עם <span class="math">\(\lambda\left(P\right)<\delta\)</span>, אז <span class="math">\(\left|S_{P}^{z}-\int_{a}^{b}f\left(z\left(t\right)\right)z^{\prime}\left(t\right)dt\right|<\varepsilon\)</span>.</p>
<p>עכשיו, ראינו איך אפשר לפצל גם את <span class="math">\(S_{P}^{z}\)</span> וגם את <span class="math">\(\int_{a}^{b}f\left(z\left(t\right)\right)z^{\prime}\left(t\right)dt\)</span> לארבעה חלקים שמתאימים זה לזה בזוגות. לכן כדי לחסום את ההפרש, אני משתמש באי שוויון המשולש על פיצול לארבעה חלקים של כל אחד מהביטויים. בואו נראה איך דבר כזה נראה, סכמטית:</p>
<p><span class="math">\(\left|\left(A_{1}+B_{1}+C_{1}+D_{1}\right)-\left(A_{2}+B_{2}+C_{2}+D_{2}\right)\right|\le\)</span></p>
<p><span class="math">\(\le\left|A_{1}-A_{2}\right|+\left|B_{1}-B_{2}\right|+\left|C_{1}-C_{2}\right|+\left|D_{1}-D_{2}\right|\)</span></p>
<p>במקרה שלנו המקבילה ל-<span class="math">\(\left|A_{1}-A_{2}\right|\)</span> תהיה</p>
<p><span class="math">\(\left|\int_{a}^{b}u\left(t\right)x^{\prime}\left(t\right)dt-\sum_{i=1}^{n}u\left(t_{i}^{*}\right)\left(x\left(t_{i}\right)-x\left(t_{i-1}\right)\right)\right|\)</span></p>
<p>ודי ברור מה יהיו שאר המקבילות (ושהכפל ב-<span class="math">\(-1\)</span> או ב-<span class="math">\(i\)</span> לא משפיע; הערך המוחלט מעלים אותו).</p>
<p>עכשיו צריך לשים לב לנקודה עדינה: <span class="math">\(\int_{a}^{b}u\left(t\right)x^{\prime}\left(t\right)dt\)</span> נראה כמו החישוב של אינטגרל רימן-סטילטיס, וכבר ראינו ש-<span class="math">\(\int_{a}^{b}u\left(t\right)x^{\prime}\left(t\right)dt=\int_{a}^{b}u\left(t\right)dx\)</span>. המשמעות של השוויון הזה היא שסכומי רימן-סטילטיס של <span class="math">\(\int_{a}^{b}u\left(t\right)dx\)</span> מתקרבים אל <span class="math">\(\int_{a}^{b}u\left(t\right)x^{\prime}\left(t\right)dt\)</span>. כלומר, עבור <span class="math">\(\frac{\varepsilon}{4}\)</span> קיים <span class="math">\(\delta_{1}\)</span> כך שאם <span class="math">\(P\)</span> חלוקה עם <span class="math">\(\lambda\left(P\right)<\delta_{1}\)</span>, אז <strong>כל</strong> סכום רימן-סטילטיס ובפרט הסכום <span class="math">\(\sum_{i=1}^{n}u\left(t_{i}^{*}\right)\left(x\left(t_{i}\right)-x\left(t_{i-1}\right)\right)\)</span> יהיה קרוב אל <span class="math">\(\int_{a}^{b}u\left(t\right)x^{\prime}\left(t\right)dt\)</span> עד כדי <span class="math">\(\frac{\varepsilon}{4}\)</span>.</p>
<p>באותו האופן אנחנו מוצאים <span class="math">\(\delta_{2},\delta_{3},\delta_{4}\)</span> עבור שלושת הביטויים האחרים, ואז מגדירים <span class="math">\(\delta=\min\left\{ \delta_{1},\delta_{2},\delta_{3},\delta_{4}\right\} \)</span>. עכשיו מובטח לנו שעבור כל חלוקה <span class="math">\(P\)</span> שמקיימת <span class="math">\(\lambda\left(P\right)<\delta\)</span> וכל סכום רימן <span class="math">\(S_{P}^{z}\)</span> שמתאים לה, <span class="math">\(\left|S_{P}^{z}-\int_{a}^{b}f\left(z\left(t\right)\right)z^{\prime}\left(t\right)dt\right|<\varepsilon\)</span>. זה מסיים את ההוכחה, ומרגיע אותי סופית. עכשיו מבחינתי זה בסדר גמור להגדיר אינטגרל מרוכב על ידי <span class="math">\(\int_{C}f\left(z\right)dz=\int_{a}^{b}f\left(z\left(t\right)\right)z^{\prime}\left(t\right)dt\)</span> ותו לא. סוף טוב הכל טוב!</p>
        </article>
        
        <footer>
            <p>© כל הזכויות שמורות לגדי אלכסנדרוביץ'</p>
        </footer>
    </div>

    
    <script>
        function toggleMobileMenu() {
            const navLinks = document.getElementById('navLinks');
            navLinks.classList.toggle('expanded');
        }
        
        function searchPosts() {
            const searchTerm = document.getElementById('searchInput').value;
            if (searchTerm.trim()) {
                window.location.href = '/post_list.html?search=' + encodeURIComponent(searchTerm);
            }
        }
        
        document.getElementById('searchInput').addEventListener('keypress', function(e) {
            if (e.key === 'Enter') {
                searchPosts();
            }
        });
    </script>
    
    
    <!-- Auto-render KaTeX math -->
    <script>
        document.addEventListener("DOMContentLoaded", function() {
            renderMathInElement(document.body, {
                delimiters: [
                    {left: "\\[", right: "\\]", display: true},
                    {left: "\\(", right: "\\)", display: false}
                ],
                throwOnError: false
            });
        });
    </script>

</body>
</html>