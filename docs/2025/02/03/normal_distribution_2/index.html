<!DOCTYPE html>
<html lang="he" dir="rtl">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>מה הקטע עם התפלגות נורמלית? (חלק ב&#39;: על שתי הסתברויות) - לא מדויק</title>
    <link rel="icon" type="image/x-icon" href="/favicon.ico">
    
    <meta name="description" content="לא מדויק - בלוג על מתמטיקה ומדעי המחשב" />
    <!-- Open Graph / Facebook -->
    <meta property="og:type" content="article">
    <meta property="og:url" content="https://gadial.net/2025/02/03/normal_distribution_2/">
    <meta property="og:title" content="מה הקטע עם התפלגות נורמלית? (חלק ב&#39;: על שתי הסתברויות)">
    <meta property="og:description" content="לא מדויק - בלוג על מתמטיקה ומדעי המחשב">
    <meta property="og:site_name" content="לא מדויק">
    <meta property="og:image" content="http://gadial.net/img/main/default-card.png" />
        
    <!-- Twitter -->
    <meta name="twitter:card" content="summary">
    <meta name="twitter:url" content="https://gadial.net/2025/02/03/normal_distribution_2/">
    <meta name="twitter:description" content="לא מדויק - בלוג על מתמטיקה ומדעי המחשב">
    <meta name="twitter:site" content="@" />
    <meta property="twitter:title" content="מה הקטע עם התפלגות נורמלית? (חלק ב&#39;: על שתי הסתברויות)">
    <meta property="twitter:image" content="http://gadial.net/img/main/default-card.png" />
    
    <!-- RSS Feed -->
    <link rel="alternate" type="application/rss+xml" title="לא מדויק - RSS Feed" href="/feed.xml">
       
    
    <!-- KaTeX for math rendering -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css">
    <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js"></script>
    <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js"></script>

    
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }
        
        body {
            font-family: 'Arial', 'David', 'Tahoma', sans-serif;
            line-height: 1.6;
            color: #333;
            background-color: #f5f5f5;
        }
        
        /* Top navigation bar */
        .top-nav {
            background: #2c3e50;
            padding: 15px 20px;
            box-shadow: 0 2px 5px rgba(0,0,0,0.1);
        }
        
        .top-nav .nav-container {
            max-width: 1200px;
            margin: 0 auto;
            display: flex;
            align-items: center;
            justify-content: space-between;
            gap: 20px;
        }
        
        .top-nav .site-title {
            font-size: 1.5em;
            font-weight: bold;
            color: white;
            text-decoration: none;
            white-space: nowrap;
        }
        
        .top-nav .nav-links {
            display: flex;
            gap: 20px;
            align-items: center;
            flex-wrap: wrap;
        }
        
        .top-nav .nav-links a {
            color: #ecf0f1;
            text-decoration: none;
            padding: 5px 10px;
            border-radius: 4px;
            transition: background 0.2s;
            white-space: nowrap;
        }
        
        .top-nav .nav-links a:hover {
            background: #34495e;
        }
        
        .top-nav .search-box {
            display: flex;
            gap: 5px;
        }
        
        .top-nav .search-box input {
            padding: 5px 10px;
            border: none;
            border-radius: 4px;
            font-size: 0.9em;
            min-width: 150px;
        }
        
        .top-nav .search-box button {
            padding: 5px 15px;
            background: #3498db;
            color: white;
            border: none;
            border-radius: 4px;
            cursor: pointer;
            transition: background 0.2s;
        }
        
        .top-nav .search-box button:hover {
            background: #2980b9;
        }
        
        /* Hamburger menu button */
        .menu-toggle {
            display: none;
            background: none;
            border: none;
            font-size: 1.8em;
            color: white;
            cursor: pointer;
            padding: 0;
            line-height: 1;
        }
        
        .menu-toggle:hover {
            opacity: 0.8;
        }
        
        /* Mobile responsive */
        @media (max-width: 768px) {
            .top-nav .nav-container {
                flex-direction: column;
                align-items: stretch;
            }
            
            .top-nav .site-title {
                display: flex;
                justify-content: space-between;
                align-items: center;
                margin-bottom: 0;
                padding: 10px 0;
            }
            
            .menu-toggle {
                display: block;
            }
            
            /* Hide nav links by default on mobile */
            .top-nav .nav-links {
                display: none;
                flex-direction: column;
                width: 100%;
                margin-top: 10px;
            }
            
            /* Show when expanded */
            .top-nav .nav-links.expanded {
                display: flex;
            }
            
            .top-nav .nav-links > a {
                text-align: center;
                padding: 12px;
                border-top: 1px solid rgba(255, 255, 255, 0.2);
            }
            
            .top-nav .search-box {
                width: 100%;
                flex-direction: column;
                margin-top: 10px;
                padding-top: 10px;
                border-top: 1px solid rgba(255, 255, 255, 0.2);
            }
            
            .top-nav .search-box input {
                width: 100%;
                margin-bottom: 5px;
                min-width: 0;
            }
            
            .top-nav .search-box button {
                width: 100%;
            }
        }
        
        /* Blockquote styling */
        blockquote {
            background: #f9f9f9;
            border-right: 5px solid #ccc;
            margin: 1.5em 10px;
            padding: 0.75em 16px;
            position: relative;
            font-style: italic;
        }
        
        blockquote:before {
            content: '"';
            position: absolute;
            top: -10px;
            right: 8px;
            font-size: 3.5em;
            color: #ccc;
            line-height: 1;
        }
        
        blockquote p {
            display: block;
            margin: 0 0 0.75em 0;
        }
        
        blockquote p:last-child {
            margin-bottom: 0;
        }
        
        
        body {
            line-height: 1.8;
        }
        
        .container {
            max-width: 800px;
            margin: 20px auto;
            background: white;
            padding: 40px;
            box-shadow: 0 2px 10px rgba(0,0,0,0.1);
            border-radius: 8px;
        }
        
        header {
            margin-bottom: 40px;
            border-bottom: 2px solid #e0e0e0;
            padding-bottom: 20px;
        }
        
        h1 {
            font-size: 2.5em;
            margin-bottom: 10px;
            color: #2c3e50;
        }
        
        .post-meta {
            color: #7f8c8d;
            font-size: 0.9em;
        }
        
        .post-meta .date {
            margin-left: 15px;
        }
        
        .post-meta .categories,
        .post-meta .tags {
            display: inline;
        }
        
        .post-meta .categories a,
        .post-meta .tags a {
            color: #3498db;
            text-decoration: none;
            margin: 0 5px;
        }
        
        .post-meta .categories a:hover,
        .post-meta .tags a:hover {
            text-decoration: underline;
        }
        
        article {
            font-size: 1.1em;
        }
        
        article h2 {
            margin-top: 30px;
            margin-bottom: 15px;
            color: #34495e;
            font-size: 1.8em;
        }
        
        article h3 {
            margin-top: 25px;
            margin-bottom: 12px;
            color: #34495e;
            font-size: 1.4em;
        }
        
        article p {
            margin-bottom: 15px;
            text-align: justify;
        }
        
        article ul, article ol {
            margin-right: 30px;
            margin-bottom: 15px;
        }
        
        article li {
            margin-bottom: 8px;
        }
        
        article code {
            background-color: #f4f4f4;
            padding: 2px 6px;
            border-radius: 3px;
            font-family: 'Courier New', monospace;
            font-size: 0.9em;
        }
        
        article pre {
            background-color: #2d2d2d;
            color: #f8f8f2;
            padding: 15px;
            border-radius: 5px;
            overflow-x: auto;
            margin-bottom: 20px;
            direction: ltr;
            text-align: left;
        }
        
        article pre code {
            background-color: transparent;
            padding: 0;
            color: inherit;
        }
        
        /* Image styles - responsive and contained */
        article img {
            max-width: 100%;
            height: auto;
            display: block;
            margin: 20px auto;
        }
        
        /* Math rendering styles */
        .math {
            direction: ltr;
        }
        
        span.math {
            direction: ltr;
        }
        
        /* Override RTL for KaTeX */
        .katex {
            direction: ltr;
            unicode-bidi: embed;
        }
        
        /* Force KaTeX content to wrap by overriding its internal structure */
        .katex-html {
            display: inline !important;
            white-space: normal !important;
        }
        
        .katex .base {
            display: inline !important;
            white-space: normal !important;
        }
        
        .katex .mord,
        .katex .mbin,
        .katex .mrel,
        .katex .mopen,
        .katex .mclose,
        .katex .mpunct,
        .katex .minner {
            display: inline !important;
            white-space: normal !important;
        }
        
        div.math {
            display: block;
            text-align: center;
            padding: 15px 0;
            direction: ltr;
        }
        
        /* RTL adjustments for code blocks */
        .highlight {
            direction: ltr;
            text-align: left;
        }
        
        footer {
            margin-top: 60px;
            padding-top: 20px;
            border-top: 1px solid #e0e0e0;
            text-align: center;
            color: #95a5a6;
            font-size: 0.9em;
        }
        
        /* Responsive design */
        @media (max-width: 768px) {
            .container {
                padding: 20px;
            }
            
            h1 {
                font-size: 2em;
            }
            
            article {
                font-size: 1em;
            }
            
            /* Hide post navigation on mobile */
            .post-navigation {
                display: none;
            }
        }
        
        /* Post navigation */
        .post-navigation {
            display: flex;
            justify-content: space-between;
            margin-bottom: 30px;
            padding-bottom: 20px;
            border-bottom: 2px solid #e0e0e0;
            gap: 20px;
        }
        
        .post-navigation .nav-link {
            flex: 1;
            text-decoration: none;
            color: #2c3e50;
            padding: 15px;
            background: #f8f9fa;
            border-radius: 5px;
            transition: background 0.2s;
        }
        
        .post-navigation .nav-link:hover {
            background: #e9ecef;
        }
        
        .post-navigation .nav-prev {
            text-align: right;
        }
        
        .post-navigation .nav-next {
            text-align: left;
        }
        
        .post-navigation .nav-label {
            font-size: 0.85em;
            color: #7f8c8d;
            display: block;
            margin-bottom: 5px;
        }
        
        .post-navigation .nav-title {
            font-weight: bold;
            font-size: 1.1em;
        }

    </style>
</head>
<body>
    <nav class="top-nav">
        <div class="nav-container">
            <div class="site-title">
                <a href="/" style="color: white; text-decoration: none;">לא מדויק</a>
                <button class="menu-toggle" onclick="toggleMobileMenu()" aria-label="תפריט">
                    ☰
                </button>
            </div>
            <div class="nav-links" id="navLinks">
                <a href="/">דף הבית</a>
                <a href="/random.html">פוסט אקראי</a>
                <a href="/post_list.html">כל הפוסטים</a>
                <div class="search-box">
                    <input type="text" id="searchInput" placeholder="חיפוש...">
                    <button onclick="searchPosts()">חפש</button>
                </div>
            </div>
        </div>
    </nav>
    
    
    <div class="container">
        <!-- Post Navigation -->
        
        <nav class="post-navigation">
            
            <a href="/2025/01/31/normal_distribution_1/" class="nav-link nav-prev">
                <span class="nav-label">פוסט ישן יותר →</span>
                <span class="nav-title">מה הקטע עם התפלגות נורמלית? (חלק א&#39;: שלוש היסטוגרמות למלכי ההתפלגות במרומם, ועקומה אחת למשול בם ולקשרם)</span>
            </a>
            

            
            <a href="/2025/02/05/normal_distribution_3/" class="nav-link nav-next">
                <span class="nav-label">← פוסט חדש יותר</span>
                <span class="nav-title">מה הקטע עם התפלגות נורמלית? (חלק ג&#39;: על תוחלת וסטיית תקן)</span>
            </a>
            
        </nav>
        
        
        <header>
            <h1>מה הקטע עם התפלגות נורמלית? (חלק ב&#39;: על שתי הסתברויות)</h1>
            <div class="post-meta">
                <span class="date">2025-02-03</span>
                
                <span class="categories">
                    | קטגוריות:
                    
                    <a href="/categories/הסתברות.html">הסתברות</a>
                    
                </span>
                
                
                <span class="tags">
                    | תגיות:
                    
                    <a href="/tags/התפלגות נורמלית.html">התפלגות נורמלית</a>
                    
                </span>
                
            </div>
        </header>
        
        <article>
            <h2>מבוא</h2>

<p><a href="https://gadial.net/2025/01/31/normal_distribution_1/">בפוסט הקודם</a> התחלתי לדבר על מה שנקרא <strong>התפלגות נורמלית</strong> ופורמלית מוגדר בתור <span class="math">\(f\left(x\right)=\frac{1}{\sqrt{2\pi}\sigma}e^{-\left(x-\mu\right)^{2}/2\sigma^{2}}\)</span> אבל בגלל שאלו הרבה סימנים מפחידים שלא אומרים הרבה כרגע, העדפתי להסתכל על הדבר הזה:</p>
<p><img src="/img/2025/histogram_8.png" alt=""/></p>
<p>התמונה הזו מציגה את הקשר בין שתי התפלגויות שונות. אחת נקראת <strong>התפלגות בינומית</strong> ומתוארת על ידי הפסים, והשניה שמתוארת על ידי קו רציף היא ההתפלגות הנורמלית, ומה שאנחנו רואים הוא שבמובן מסוים ההתפלגות הנורמלית היא <strong>קירוב טוב</strong> של ההתפלגות הבינומית. בפוסט הזה אני רוצה שנבהיר בצורה מתמטית איך בעצם מגדירים את הנפשות הפועלות - איך מגדירים התפלגויות ומה הולך בהגדרה של התפלגות נורמלית. העניין הוא שההגדרות בתורת ההסתברות הן <strong>לא דבר פשוט</strong> ולכן הפוסט הזה כבר ייכנס למתמטיקה לא לגמרי טריוויאלית. למעשה, תמונת הפסים-מול-עקומה ממחישה את זה יפה - יש שתי דרכים <strong>שונות</strong> להגדיר התפלגויות, דרך אחת שנקראת <strong>התפלגות בדידה</strong> וכאן מתאימה לפסים, והדרך השניה שנקראת <strong>התפלגות רציפה</strong> ומתאימה לעקומה. יש המון דמיון בין שתי הגישות אבל גם הבדלים מהותיים; ויש דרך "מאחדת" להציג את שניהם בתור מקרים פרטיים של אותו דבר, אבל היא לא בהכרח הופכת את הסיטואציה לקלה יותר להבנה אז אני לא אכנס אליה כאן. בואו נתחיל מהמקרה שקצת יותר מתאים לתפיסה היומיומית שלנו של הסתברות - התפלגות בדידה.</p>
<h2>התפלגויות בדידות</h2>

<p>בואו נסתכל על סיטואציה הסתברותית פשוטה: הטלת קוביה הוגנת. במקרה הזה, יש שש תוצאות אפשריות להטלת הקוביה: <span class="math">\(X=\left\{ 1,2,3,4,5,6\right\} \)</span>. לכל תוצאה כזו אנחנו מתאימים <strong>הסתברות</strong> שהיא תקרה: <span class="math">\(p\left(1\right)=p\left(2\right)=\ldots=p\left(6\right)=\frac{1}{6}\)</span>. הרעיון פה הוא שהסכום של כל ההסתברויות יוצא 1, או כמו שמסמנים בקיצור, <span class="math">\(\sum_{i=1}^{6}p\left(i\right)=1\)</span>. אפשר כמובן גם לדבר על קוביה לא הוגנת, למשל כזו שיש לה סיכוי של לא פחות מאשר <span class="math">\(\frac{1}{2}\)</span> ליפול על 4, וכל יתר הצדדים מתחלקים שווה בשווה. במקרה הזה, מכיוון שההסתברויות צריכות להסתכם ל-1, יש לנו הסתברות של <span class="math">\(\frac{1}{2}\)</span> לחלק בין חמישה צדדים של הקוביה, אז נקבל <span class="math">\(p\left(1\right)=\frac{1}{10}\)</span> וכן הלאה לכל <span class="math">\(i\)</span> חוץ מאשר <span class="math">\(p\left(4\right)=\frac{1}{2}\)</span>.</p>
<p>אפשר להכליל את הרעיון הזה בקלות: <span class="math">\(A=\left\{ a_{1},a_{2},\ldots,a_{n}\right\} \)</span> תהיה קבוצה של <span class="math">\(n\)</span> תוצאות אפשריות של הסיטואציה ההסתברותית שלנו. לכזו קבוצה קוראים <strong>מרחב המדגם</strong> (כי הסיטואציה ההסתברותית <strong>דוגמת</strong> תוצאה אחת מתוכו) ואנחנו מגדירים פונקציה <span class="math">\(p:A\to\left[0,1\right]\)</span> שמתאימה לכל איבר במרחב המדגם מספר בין 0 ל-1 כך ש-<span class="math">\(\sum_{i=1}^{n}p\left(a_{i}\right)=1\)</span>. ההגדרה הפשוטה הזו מספיקה להרבה מאוד סיטואציות הסתברותיות שאנחנו נתקלים בהן במציאות.</p>
<p>אבל ממש לא לכולן.</p>
<p>בפוסט הקודם דיברתי על הסיטואציה שבה אני זורק כדורסל ובגלל שאני לא באמת יודע איך לזרוק כדורסל לסל, יש לי הסתברות של <span class="math">\(\frac{1}{10}\)</span> לקלוע (הייתי נדיב) והשאלה שאני שואל היא - כמה זריקות לסל יידרשו לי עד שאקלע? ובכן, ברור שיש לי הסתברות של <span class="math">\(\frac{1}{10}\)</span> לקלוע בנסיון הראשון. אם פספסתי, זה קרה בהסתברות <span class="math">\(\frac{9}{10}\)</span> והסיכוי שאני אצליח בנסיון השני הוא <span class="math">\(\frac{1}{10}\)</span>, אז אינטואיטיבית יש לי הסתברות של <span class="math">\(\frac{9}{10}\cdot\frac{1}{10}=\frac{9}{100}\)</span> להצליח בזריקה השניה, וכן הלאה. טוב ויפה, אבל איך ממדלים את זה כמו שעשיתי לפני רגע, עם קבוצה <span class="math">\(X\)</span> של כל התוצאות האפשריות? אני יכול לומר משהו כמו <span class="math">\(p\left(1\right)=\frac{1}{10}\)</span> ו-<span class="math">\(p\left(2\right)=\frac{9}{100}\)</span> וכן הלאה, אבל מספר ההטלות שיידרשו לי עד שאקלע לסל הוא <strong>לא חסום</strong>. אני לא יכול להבטיח שיידרשו לי רק 42 הטלות. אם אני אגיע אל ההטלה ה-42 זה אומר שהייתי מאוד חסר מזל עד כה, אבל ליקום לא אכפת מחוסר המזל שלי עד כה - גם בהטלה ה-42, הסיכוי שלי לקלוע יהיה רק <span class="math">\(\frac{1}{10}\)</span> ולכן בהחלט ייתכן שאגיע להטלה ה-43. במילים אחרות, אם אני רוצה שיהיה לי סיכוי כלשהו למשל אפילו את הסיטואציה המאוד פשוטה הזו אני צריך ש-<span class="math">\(X\)</span> תהיה קבוצה <strong>אינסופית</strong>, במקרה הזה <span class="math">\(A=\left\{ 1,2,3,\ldots\right\} \)</span>.</p>
<p>אם <span class="math">\(X=\left\{ a_{1},a_{2},a_{3},\ldots\right\} \)</span> היא קבוצה אינסופית, זה יוצר לנו קושי טכני חדש. דרשתי קודם שיתקיים <span class="math">\(\sum_{i=1}^{n}p\left(a_{i}\right)=1\)</span>, אבל עכשיו <span class="math">\(X\)</span> היא <strong>אינסופית</strong> ולכן גם הסכום צריך להיות אינסופי: <span class="math">\(\sum_{i=1}^{\infty}p\left(a_{i}\right)=1\)</span>. זה מכניס לנו לתמונה מושג חדש <strong>וממש לא טריוויאלי</strong> - <a href="https://gadial.net/2008/06/17/infinite_series/">סכום אינסופי</a>, משהו שלומדים בדרך כלל בחדו"א. כל הסיפור הפך לפתע למסובך יותר: בשביל למדל סיטואציה פשוטה יחסית, אנחנו צריכים כלים מתמטיים לא לגמרי טריוויאליים.</p>
<p>יש עוד מושג מרכזי אחד שצריך להכיר. בואו נחזור אל ההיסטוגרמה שהבאתי בתחילת הפוסט; בפוסט הקודם סיפרתי עליה סיפור של משחק שבו אני מטיל מטבע הוגן 10 פעמים וסופר כמה פעמים נפלתי על "עץ". אפשר למדל כאן את מרחב המדגם בתור <span class="math">\(A=\left\{ 0,1,\ldots,10\right\} \)</span> אבל זה יהיה טיפה מסובך כי לא לגמרי ברור איזו הסתברות לתת לכל איבר במרחב המדגם. תחת זאת אפשר לתת מרחב מדגם שבמובן מסוים הוא פשוט יותר: <span class="math">\(X\)</span> פשוט יכיל את כל התוצאות האפשריות של הטלת מטבע הוגן 10 פעמים. אם אני אסמן "עץ" בתור 1 ו"פלי" בתור 0 אני יכול לחשוב על כל תוצאה אפשרית בתור עשירייה <span class="math">\(b=\left(b_{1},b_{2},\ldots,b_{10}\right)\)</span> כך ש-<span class="math">\(b_{i}\in\left\{ 0,1\right\} \)</span>, כלומר מרחב המדגם שלי הוא מה שמסומן ב-<span class="math">\(A=\left\{ 0,1\right\} ^{10}\)</span>. בגלל שלעץ ולפלי יש בדיוק אותה הסתברות <span class="math">\(\frac{1}{2}\)</span> בכל הטלה, ההסתברות של כל עשירייה היא <span class="math">\(\frac{1}{2}\cdot\frac{1}{2}\cdots\frac{1}{2}=\frac{1}{2^{10}}\)</span> (זו עדיין אמירה אינטואיטיבית ולא טענה פורמלית - אגיע לטענה הפורמלית עוד מעט).</p>
<p>עכשיו, אני יכול להגדיר <strong>פונקציה</strong> <span class="math">\(X:A\to\mathbb{R}\)</span> שלכל עשירייה, סופרת כמה "עץ" יש בה, כלומר הכי פורמלית שרק אפשר, <span class="math">\(X\left(b\right)=\sum_{i=1}^{10}b_{i}\)</span>. זו פונקציה במובן הרגיל של תורת הקבוצות, אבל מכיוון שהיא מוגדרת על מרחב מדגם שיש עליו <strong>מבנה</strong> של אקראיות, המבנה הזה עובר גם אליה - אפשר לשאול עכשיו שאלות כמו "אם אני בוחר איבר מ-<span class="math">\(A\)</span> באקראי, מה ההסתברות ש-<span class="math">\(X\)</span> יחזיר עליו 3?" או בכתיב הסטנדרטי, מהו <span class="math">\(P\left(X=3\right)\)</span>. התשובה לזה פשוטה: כדי ש-<span class="math">\(X\)</span> יקבל 3, צריך שמי שיעלה בגורל הוא אחד מאיברי מרחב המדגם שיש לו בדיוק 3 פעמים 1 ויתר הפעמים 0, אז אני סוכם את ההסתברויות של <strong>כל</strong> האיברים הללו. לכל איבר, ההסתברות שלו היא <span class="math">\(\frac{1}{2^{10}}\)</span>, ומספר האיברים הללו הוא בדיוק <span class="math">\({10 \choose 3}\)</span> - מספר הדרכים לבחור 3 מקומות מתוך 10 כדי לשים בהם 1 (<a href="https://gadial.net/2010/06/20/combinatorics_intro/">יש לי פוסט</a> שמסביר את זה; כאן אני מניח שאנחנו מכירים קומבינטוריקה בסיסית), אז בסך הכל נקבל <span class="math">\(P\left(X=3\right)={10 \choose 3}\frac{1}{2^{10}}\)</span>.</p>
<p>הפונקציה <span class="math">\(X\)</span> שהגדרתי כאן מכונה <strong>משתנה מקרי</strong>. זה סוג האובייקטים המרכזי שאנחנו מתעסקים בו בהסתברות. היופי בשימוש במשתנים מקריים הוא שאנחנו יכולים לשמור את מרחב המדגם שלנו פשוט יחסית, ולהגדיר מעל אותו מרחב מדגם שלל משתנים מקריים שונים ומשונים, ולשאול גם שאלות יותר מורכבות מאשר סתם "איך מחשבים את זה?" אלא גם "מה הקשרים בין המשתנים המקריים השונים" וכן הלאה.</p>
<p>בואו נעבור למשהו כללי יותר. נניח שאני מטיל מטבע <strong>לא הוגן</strong> בדיוק <span class="math">\(n\)</span> פעמים וסופר כמה פעמים קיבלתי עץ, וניקח <span class="math">\(0\le k\le n\)</span> - מה ההסתברות שקיבלתי <span class="math">\(k\)</span> פעמים עץ? אפשר להגדיר משתנה מקרי <span class="math">\(X\)</span> כמו קודם, ועכשיו השאלה היא מהו <span class="math">\(P\left(X=k\right)\)</span>. אני אסמן ב-<span class="math">\(p\)</span> את ההסתברות שבהטלת המטבע מקבלים עץ וב-<span class="math">\(q\)</span> את ההסתברות שמקבלים פלי (<span class="math">\(p+q=1\)</span> כי בכל הטלה יש הסתברות 1 שתתקבל אחת משתי התוצאות). אז כדי לקבל <strong>בדיוק</strong> <span class="math">\(k\)</span> פעמים עץ, צריך לבחור <span class="math">\(k\)</span> מתוך <span class="math">\(n\)</span> ההטלות שבהן יתקבל עץ (לזה יש <span class="math">\({n \choose k}\)</span> אפשרויות) ואז באותן <span class="math">\(k\)</span> הטלות ההסתברות לקבל עץ הוא <span class="math">\(p\)</span> לכל הטלה, כלומר <span class="math">\(p^{k}\)</span> בסך הכל, ועבור יתר ההטלות ההסתברות לקבל פלי היא <span class="math">\(q\)</span> בכל הטלה, כלומר <span class="math">\(q^{n-k}\)</span> בסך הכל, ולכן נקבל <span class="math">\(P\left(X=k\right)={n \choose k}p^{k}q^{n-k}\)</span>. משתנה מקרי שמקיים את הנוסחה הזו נקרא <strong>משתנה מקרי בינומי</strong> או פשוט <strong>התפלגות בינומית</strong> כשהמילה "בינומי" כאן מגיעה מכך שהמספרים בנוסחה מגיעים מהבינום של ניוטון (הנוסחה <span class="math">\(\left(p+q\right)^{n}=\sum_{k=0}^{n}{n \choose k}p^{k}q^{n-k}\)</span>).</p>
<p>לא הייתי חייב לספר את כל סיפור המטבעות הזה. הייתי יכול פשוט <strong>להגדיר</strong> משתנה מקרי בינומי עם הנוסחה <span class="math">\(P\left(X=k\right)={n \choose k}p^{k}q^{n-k}\)</span>. להגיד "בואו ניקח <span class="math">\(X\)</span> שמקיים את הנוסחה הזו ועכשיו בואו נעשה איתו דברים". אני טרחתי וסיפרתי סיפור ובניתי מרחב מדגם <span class="math">\(A\)</span> ספציפי, אבל אפשר גם לספר סיפורים אחרים ולבנות מרחבי מדגם אחרים שעדיין יניבו לנו משתנה מקרי <span class="math">\(X\)</span> עם אותה התפלגות (אפילו אם בתור פונקציה, <span class="math">\(X\)</span> יוגדר בצורה שונה). זו רמת אבסטרקציה שקצת צריך להתרגל אליה.</p>
<p>עדיין, סיפור המטבעות <strong>כן</strong> עוזר לנו להבין את <span class="math">\(X\)</span> יותר טוב. הנה דוגמא: על אותו מרחב מדגם של <span class="math">\(A=\left\{ 0,1\right\} ^{n}\)</span> אני יכול להגדיר עוד משתנים מקריים <span class="math">\(Y_{1},Y_{2},\ldots,Y_{n}\)</span>. כל משתנה מקרי מסתכל על הטלת מטבע אחת ויחידה ואומר האם <strong>בה</strong> התקבל עץ או פלי. למשל <span class="math">\(Y_{7}\)</span> מקבל 1 אם בהטלה 7 יצא עץ ואחרת הוא מקבל 0. פורמלית, <span class="math">\(Y_{k}\left(b\right)=b_{k}\)</span>, אבל אני הולך לוותר יותר ויותר על ה"פורמלית" הזה ככל שנתקדם. משתנה מקרי כזה, שמקבל או 0 או 1, נקרא <strong>אינדיקטור</strong>, ובמקרה שלנו <span class="math">\(P\left(Y_{k}=1\right)=p\)</span> ואפשר לראות שמתקיים <span class="math">\(X=Y_{1}+Y_{2}+\ldots+Y_{n}\)</span>, כלומר אני יכול לתאר את <span class="math">\(X\)</span> בתור סכום של אינדיקטורים. כשאני אגיע לדיבורים על <strong>תוחלת</strong> זה יהיה נוח למדי לראות את <span class="math">\(X\)</span> ככה.</p>
<p>יש עוד נקודה אחת לגבי משתנים מקריים ששווה לדבר עליה עכשיו. בואו נניח שאני שולף איבר <span class="math">\(b\in A\)</span> אקראי ממרחב המדגם שלי, ועכשיו אני מסתכל על <span class="math">\(Y_{3}\left(b\right)\)</span>. האם זה נותן לי <strong>אינפורמציה</strong> כלשהי על הערכים של משתנים מקריים אחרים? למשל, אם <span class="math">\(Y_{3}\left(b\right)=1\)</span>, בהחלט קיבלתי אינפורמציה כלשהי על <span class="math">\(X\)</span>: אני יודע ש-<span class="math">\(X\left(b\right)>0\)</span>. זה אומר שחשיפה למידע ש-<span class="math">\(Y_{3}\left(b\right)=1\)</span> <strong>שינתה</strong> את הערכות ההסתברות שלי לגבי <span class="math">\(X\)</span>; אם קודם הערכתי ש-<span class="math">\(P\left(X=0\right)=q^{n}\)</span>, עכשיו אני מעריך ש-<span class="math">\(P\left(X=0|Y_{3}=1\right)=0\)</span> (הקו המפריד אומר "בתנאי ש-", כלומר ההסתברות של <span class="math">\(X=0\)</span> בתנאי שמתקיים <span class="math">\(Y_{3}=1\)</span>). לעומת זאת, המידע שלי על <span class="math">\(Y_{5}\)</span> לא מושפע מידע כלשהו על <span class="math">\(Y_{3}\)</span> (כי הם בודקים הטלות שונות). כלומר, אפשר לכתוב באופן כללי <span class="math">\(P\left(Y_{5}=k|Y_{3}=t\right)=P\left(Y_{5}=k\right)\)</span>. על סיטואציה כזו, שבה יש לנו משתנים <span class="math">\(X,Y\)</span> ואנחנו יודעים ש-<span class="math">\(P\left(X=k|Y=t\right)=P\left(X=k\right)\)</span> אנחנו אומרים ש-<span class="math">\(X,Y\)</span> הם משתנים <strong>בלתי תלויים</strong>.</p>
<p>עכשיו, מה ההסתברות ש-<span class="math">\(X=k\)</span> וגם <span class="math">\(Y=t\)</span> <strong>ביחד</strong>? אני אסמן את זה ב-<span class="math">\(P\left(X=k\wedge Y=t\right)\)</span>. אינטואיטיבית (ואפשר גם להוכיח את זה פורמלית) זה יהיה שווה להסתברות <span class="math">\(P\left(Y=t\right)\)</span>, כפול ההסתברות ש-<span class="math">\(X=k\)</span> <strong>בהינתן</strong> שאנחנו כבר יודעים ש-<span class="math">\(Y=t\)</span>, כלומר </p>
<p><span class="math">\(P\left(X=k\wedge Y=t\right)=P\left(Y=t\right)\cdot P\left(X=k|Y=t\right)\)</span></p>
<p>ואם ידוע ש-<span class="math">\(X,Y\)</span> בלתי תלויים אפשר להציב <span class="math">\(P\left(X=k|Y=t\right)=P\left(X=k\right)\)</span> ולקבל</p>
<p><span class="math">\(P\left(X=k\wedge Y=t\right)=P\left(X=k\right)P\left(Y=t\right)\)</span></p>
<p>כלומר - עבור משתנים בלתי תלויים, ההסתברות לאירוע משותף לשניהם היא <strong>מכפלת</strong> ההסתברויות עבור כל אחד מהם בנפרד. זו ההצדקה (בנפנוף ידיים) לכך שההסתברות לקבל בדיוק <span class="math">\(k\)</span> פעמים "עץ" בהטלת מטבע ספציפית היא <span class="math">\(p^{k}q^{n-k}\)</span> - אחרי שבחרנו <span class="math">\(k\)</span> משתנים שיקבלו "עץ" ההסתברות שכולם אכן יקבלו עץ היא <span class="math">\(p^{k}\)</span>, מכפלת ההסתברויות של כל אחד מהם, כי הם בלתי תלויים (ואז גם מוסיפים את <span class="math">\(n-k\)</span> המשתנים האחרים שמקבלים פלי בהסתברות <span class="math">\(q\)</span> לתמונה).</p>
<h2>התפלגויות רציפות</h2>

<p>עד עכשיו מה שראינו היה יחסית פשוט. עכשיו בואו נסבך את זה ממש. נתחיל משאלה תמימה: איך, בעצם, עם הכלים שיש לי כרגע, אני יכול להגדיר סיטואציה הסתברותית שבה אני בוחר מספר בין <span class="math">\(0\)</span> ל-<span class="math">\(1\)</span> באקראי, בהסתברות שווה לכל מספר?</p>
<p>זו כמובן לא סיטואציה מופרכת. בכל שפת תכנות שמכבדת את עצמה יש פונקציית ספרייה שמחזירה מספר בין 0 ל-1 באקראי ובהסתברות אחידה לכל תוצאה. אבל לדבר על זה במונחים של שפת תכנות זו רמאות, כי בשפת תכנות יש רק מספר <strong>סופי</strong> של מספרים בין 0 ל-1 שאנחנו בכלל טורחים לייצג, אז אנחנו פשוט במקרה פשוט של הסתברות בדידה. אבל בין 0 ל-1 <strong>אין</strong> מספר סופי של מספרים. יש למשל את <span class="math">\(1\)</span>, ואת <span class="math">\(\frac{1}{2}\)</span>, ואת <span class="math">\(\frac{1}{3}\)</span>, ואת <span class="math">\(\frac{1}{4}\)</span> וכן הלאה וכן הלאה. עכשיו, מה ההסתברות שכל אחד מהמספרים הללו יתקבל? נניח ש-<span class="math">\(p\left(1\right)=\frac{1}{n}\)</span> עבור <span class="math">\(0\le\frac{1}{n}\le1\)</span> כלשהו. מכיוון שההתפלגות הזו היא אחידה, גם <span class="math">\(p\left(\frac{1}{2}\right)=\frac{1}{n}\)</span> וכן הלאה, ואז אני מקבל <span class="math">\(p\left(1\right)+p\left(\frac{1}{2}\right)+\ldots+p\left(\frac{1}{n+1}\right)=\frac{n+1}{n}>1\)</span> ואופס! חרגתי מהגבול. סכום ההסתברויות על <strong>כל</strong> התוצאות האפשריות במרחב חייב להיות לכל היותר 1 וכבר עברתי את זה. המסקנה היא פשוטה: אם אני רוצה להגדיר התפלגות כלשהי על אינסוף איברים, ההתפלגות <strong>לא יכולה</strong> להיות אחידה; היא חייבת לקטון כל הזמן, אחרת סכום ההסתברות של כל התוצאות האפשריות יעבור את 1.</p>
<p>אז יש לנו בעיה מהותית פה, וקל להצביע על האשם בבעיה המהותית הזו: <strong>אינסוף</strong>. מושג האינסוף מסבך לנו את החיים בצורה שבה מחשבים לא מסתבכים. העניין הוא שמתמטיקאים דווקא אוהבים את האינסוף הזה - אחרי שמתרגלים אליו ומאלפים אותו, הרבה יותר קל לבצע חישובים איתו. יש תחום שלם שעוסק בזה שנקרא <strong>חדו"א</strong>. הנקודה היא שאת מה שהולך לקרות עכשיו המתמטיקאים מקבלים בשמחה ובששון כי הוא <strong>משפר</strong> להם את תורת ההסתברות, לא מסבך אותה. אבל במבט ראשון זה יהיה קצת מוזר.</p>
<p>הרעיון הבסיסי הוא לשנות את הגישה שלנו להסתברות. עד עכשיו הגישה הייתה "יש לנו קבוצה <span class="math">\(A\)</span> ולכל איבר <span class="math">\(a\in A\)</span> אנחנו מגדירים הסתברות <span class="math">\(p\left(a\right)\)</span>". עכשיו הגישה תהיה שונה - אנחנו <strong>לא</strong> נגדיר הסתברות עבור איבר בודד אלא עבור <strong>קבוצות</strong> של איברים, וההסתברות שנקבל באה לומר מה הסיכוי שנעלה בגורל איבר <strong>כלשהו</strong> מתוך הקבוצה.</p>
<p>בואו נבין קודם איך זה עובד עבור התפלגות אחידה בין 0 ל-1 כי אפילו במקרה הפשוט הזה אפשר לראות את הסיבוכים. ראשית, <span class="math">\(p\left(\left[0,1\right]\right)=1\)</span> על פי מה שזה עתה תיארתי - ההסתברות שאני אקבל איבר <strong>כלשהו</strong> בין 0 ל-1 היא כמובן 1, ההסתברות הכוללת האפשרית.</p>
<p>מה עם <span class="math">\(p\left(\left[0,\frac{1}{2}\right]\right)\)</span>? אם חילקתי את הקטע שלי לשני חלקים שווים בגודלם, וההתפלגות אחידה, אני מניח שההסתברות שמספר אקראי יפול בחצי הראשון היא <span class="math">\(\frac{1}{2}\)</span>. אז קיבלנו <span class="math">\(p\left(\left[0,\frac{1}{2}\right]\right)=\frac{1}{2}\)</span> ומאותו נימוק <span class="math">\(p\left(\left[\frac{1}{2},1\right]\right)=\frac{1}{2}\)</span>. ואם אני אחלק את העולם שלי לשלושה חלקים? אז מתבקש ש-<span class="math">\(p\left(\left[0,\frac{1}{3}\right]\right)=\frac{1}{3}\)</span> וכן הלאה, ומכאן קצרה הדרך לטענה הכללית: <span class="math">\(p\left(\left[a,b\right]\right)=b-a\)</span>, לכל <span class="math">\(0\le a<b\le1\)</span>. כלומר, ההסתברות שמספר ייפול בקטע כלשהו שווה ממש לאורך שלו.</p>
<p>זה כמובן מעלה את השאלה מה קורה אם <span class="math">\(a=b\)</span>. אם ה"קטע" שלי כולל בדיוק נקודה אחת. על פי מה שאמרתי כרגע, <span class="math">\(p\left(\left[a,a\right]\right)=0\)</span>, ואם חושבים על זה לרגע פשוט <strong>אין לי ברירה</strong>, זה חייב להיות ככה בדיוק מהנימוק שכבר ראינו. אבל אם ההסתברות של איבר בודד היא 0, מה הולך כאן? איך זה ייתכן שעבור איבר בודד ההסתברות היא 0 אבל עבור קבוצה של איברים היא לא, הרי ההסתברות של כל איבר בקבוצה היא 0!</p>
<p>אז ראשית, אנחנו לומדים מכאן ש"הסתברות 0" בהקשר הרציף שבו אנחנו נמצאים עכשיו היא בעלת משמעות <strong>שונה</strong> מאשר "הסתברות 0" בהקשר הבדיד. בהקשר הבדיד הסתברות 0 פירושה "זה אף פעם לא יקרה לעולם בחיים תשכחו מזה אין מצב" ואילו בהקשר הרציף הסתברות 0 פירושה "זה לא משהו סביר בפני עצמו אבל זה יכול לקרות". זה לא "פרדוקס" או משהו דומה פשוט כי הסתברות רציפה היא משהו שאני ממציא <strong>כרגע</strong>. זה מבנה מתמטי שבא להקל עלינו לתאר כל מני דברים; אין איזה חוק טבע קוסמי שקובע מה המשמעות של "הסתברות 0" במבנה הזה <strong>אמורה להיות</strong>.</p>
<p>שנית, הקטע הזה של משהו שאינו 0 שמורכב מהרבה דברים שהם כן 0 לא אמור להיות חדש לנו, זו לא המצאה של תורת ההסתברות, אלא זו תוצאה של <strong>הגאומטריה</strong> שבחרנו לבסס את תורת ההסתברות עליה. אנחנו מגדירים את ההסתברות של קטע בתור <strong>האורך</strong> שלו, וקטע שכולל נקודה אחת הוא מאורך 0. אנחנו חיים עם זה טוב למרות שזה אומר שקטעים מאורך שגדול מ-0 מורכבים מאינסוף נקודות שהאורך של כל אחת מהן הוא כן 0, כי אנחנו לא <strong>מצפים</strong> שהאורך של קטע יהיה בסך הכל סכום האורכים של הנקודות שמרכיבות אותו אלא משהו כללי יותר. באופן דומה כשאנחנו עוברים לדו מימד אז לקו אין <strong>שטח</strong> למרות שאם ניקח ריבוע, אפשר לפרק אותו לאוסף של קווים, וכן הלאה.</p>
<p>בסדר, אז השלמנו נפשית עם זה שלנקודה יש הסתברות 0, והיה לנו קל לקנות את זה שבהתפלגות האחידה, ההסתברות של הקטע <span class="math">\(\left[a,b\right]\)</span> היא <span class="math">\(b-a\)</span>. אבל מה ההסתברות של קבוצות מורכבות יותר של נקודות? אז למשל, אם ניקח את איחוד הקטעים <span class="math">\(\left[0,\frac{1}{3}\right]\cup\left[\frac{2}{3},1\right]\)</span> שאורך כל אחד מהם הוא <span class="math">\(\frac{1}{3}\)</span> והם זרים, נצפה שהאורך של שניהם ביחד יהיה סכום האורכים שלהם, <span class="math">\(\frac{1}{3}+\frac{1}{3}\)</span>. זה יוצר ציפיה כללית יותר: שאם <span class="math">\(A,B\)</span> הן קבוצות זרות (או אפילו בעלות חיתוך שהוא נקודה משותפת בודדת כי פשוט אפשר להשמיט את הנקודה הזו מאחת הקבוצות) אז <span class="math">\(p\left(A\cup B\right)=p\left(A\right)+p\left(B\right)\)</span>. התכונה הזו נקראת <strong>אדיטיביות</strong> ואם היא מתקיימת אז אפשר להוכיח באינדוקציה שמתקיים <span class="math">\(p\left(\bigcup_{i=1}^{n}A_{i}\right)=\sum_{i=1}^{n}p\left(A_{i}\right)\)</span> עבור קבוצות זרות. אבל למעשה, אנחנו רוצים אפילו יותר מכך - בגלל שאפשר לעשות לקטע <span class="math">\(\left[0,1\right]\)</span> את מה שנקרא "פרדוקס הדיכוטומיה" (הפרדוקס שבו אכילס רוצה לרוץ מקצה אחד של מסלול לקצה השני אבל קודם הוא צריך לעבור את חצי הדרך ואז את חצי מה שנשאר וכן הלאה) ולקבל <span class="math">\(\left[0,1\right]=\left[0,\frac{1}{2}\right]\cup\left[\frac{1}{2},\frac{3}{4}\right]\cup\left[\frac{3}{4},\frac{7}{8}\right]\cup\ldots\)</span> כך שהיינו מצפים שיתקיים <span class="math">\(p\left(\left[0,\frac{1}{2}\right]\cup\left[\frac{1}{2},\frac{3}{4}\right]\cup\left[\frac{3}{4},\frac{7}{8}\right]\cup\ldots\right)=1\)</span> וזה אכן מתקיים אם מניחים ש-</p>
<p><span class="math">\(p\left(\left[0,\frac{1}{2}\right]\cup\left[\frac{1}{2},\frac{3}{4}\right]\cup\left[\frac{3}{4},\frac{7}{8}\right]\cup\ldots\right)=p\left(\left[0,\frac{1}{2}\right]\right)+p\left(\left[\frac{1}{2},\frac{3}{4}\right]\right)+\ldots=\frac{1}{2}+\frac{1}{4}+\frac{1}{8}+\ldots=1\)</span></p>
<p>כשהשוויון האחרון נובע ממה שאנחנו יודעים על סכומים אינסופיים (ואנחנו יודעים אותו כי זה חלק מחדו"א). אז התכונה שאנחנו מצפים שתתקיים היא <span class="math">\(p\left(\bigcup_{i=1}^{\infty}A_{i}\right)=\sum_{i=1}^{\infty}p\left(A_{i}\right)\)</span> ולדבר כזה קוראים "<span class="math">\(\sigma\)</span>-אדיטיביות".</p>
<p>במילים אחרות, אנחנו רוצים ש-<span class="math">\(p\)</span> תהיה פונקציה על תתי-קבוצות של <span class="math">\(\left[0,1\right]\)</span> שמקיימת <span class="math">\(\sigma\)</span>-אדיטיביות ושלכל <span class="math">\(A\)</span> יתקיים <span class="math">\(p\left(A\right)\ge0\)</span> ולא אמרתי את זה במפורש אבל מן הסתם <span class="math">\(p\left(\emptyset\right)=0\)</span> כי אפילו על קבוצה עם נקודה אחת מקבלים 0. לפונקציה <span class="math">\(p\)</span> כזו יש שם: <strong>מידה</strong>. יש תחום שלם שעוסק במידות ובשימושים הנרחבים שלהן, אבל אני לא אכנס לזה בכלל כאן, רק אעיר שלוש הערות. ראשית, מ-<span class="math">\(p\)</span> אנחנו דורשים עוד משהו שלא נדרש ממידות באופן כללי - ש-<span class="math">\(p\)</span> על "הכל" יהיה שווה 1. למידה שמקיימת את זה קוראים <strong>מידת הסתברות</strong>. שנית, גם אם ההתפלגויות הבדידות שראינו קודם אפשר לנסח בפורמליזם של מידות. אני אוותר על זה כאן, אבל זו הדרך "לאחד" את ההתפלגויות הבדידות עם הרציפות. לבסוף, וזה החלק הקריטי, <strong>למידה יש מגבלות</strong>. בפרט, פשוט אי אפשר להגדיר מידה על <strong>כל</strong> תת-הקבוצות של <span class="math">\(\left[0,1\right]\)</span> ואני נותן הוכחה לזה <a href="https://gadial.net/2010/03/03/no_measure_on_the_real_line/">כאן</a>. זה אומר שלא לכל תת-קבוצה של <span class="math">\(\left[0,1\right]\)</span> תהיה הסתברות מוגדרת, אפילו תחת ההתפלגות האחידה, פשוט כי תתי-הקבוצות הללו "מסובכות מדי" (לא לבלבל את זה עם תת-הקבוצה <span class="math">\(\left\{ a\right\} \)</span> שההסתברות שלה בהחלט מוגדרת, פשוט שווה לאפס).</p>
<p>כל זה דיבר רק על התפלגות <strong>אחידה</strong>, אבל מה קורה באופן כללי? במקרה הכללי עדיין ההסתברות של כל נקודה תהיה אפס, אבל לא כל הנקודות יהיו שוות זו לזו - יהיו נקודות שהאפס שלהן "יותר גדול". למעשה, זה <strong>כבר קרה</strong> אם חושבים על ההתפלגות האחידה על <span class="math">\(\left[0,1\right]\)</span> בתור משהו שה"עולם" שלו הוא כל הממשיים, <span class="math">\(\mathbb{R}\)</span>. מה שקרה הוא שלממשיים ב-<span class="math">\(\left[0,1\right]\)</span> היה משקל חיובי שבא לידי ביטוי כשמאגדים מספיק מהם ביחד, בזמן שלממשיים מחוץ לקטע היה משקל אפס ולכן לא משנה כמה מהם מאגדים ביחד, לא יוצא מזה כלום. עולה השאלה - מה הכלי הטכני שיש לנו שמסוגל לשלב ככה בין <strong>האורך</strong> של קטע ובין <strong>המשקל</strong> שאנחנו נותנים לו? ויש כלי כזה, שהוא אחד מהכוכבים הנוצצים של המתמטיקה: <strong>אינטגרל</strong>.</p>
<p>הנה הרעיון הפורמלי: כשאנחנו באים להגדיר משתנה מקרי רציף <span class="math">\(X\)</span>, הוא תאופיין על ידי פונקציה <span class="math">\(f:\mathbb{R}\to[0,\infty(\)</span> שנקראת <strong>פונקציית צפיפות ההסתברות</strong> כך ש-<span class="math">\(P\left(X\in B\right)=\int_{B}f\left(x\right)dx\)</span> בהנחה שהאינטגרל מוגדר (ואחרת <span class="math">\(P\left(X\in B\right)\)</span> פשוט לא יהיה מוגדר). ה"צפיפות" בשם הפונקציה לא תפתיע כנראה אף אחת שמכירה פיזיקה: אם יש לנו צורה <span class="math">\(B\)</span> ואנחנו רוצים לחשב את המסה שלה, אנחנו מבצעים אינטגרל על <span class="math">\(B\)</span> על הפונקציה שמתארת את <strong>הצפיפות</strong> של <span class="math">\(B\)</span> (כמה מסה מרוכזת בכל איזור של <span class="math">\(B\)</span>). זה בדיוק אותו רעיון.</p>
<p>הדרישה היחידה שלנו מ-<span class="math">\(f\)</span> פרט לחיוביות שלה היא שההסתברות הכוללת תצא 1, כלומר שיתקיים <span class="math">\(\int_{-\infty}^{\infty}f\left(x\right)dx=1\)</span>. אני מניח כאן שאנחנו בסדר עם אינטגרלים מוכללים - אבל גם אם אנחנו לא בסדר לא נורא, נראה שהחישובים הרלוונטיים הם לא סוף העולם.</p>
<p>עבור ההתפלגות האחידה, פונקציית הצפיפות די פשוטה:</p>
<p><span class="math">\(f\left(x\right)=\begin{cases} 1 & x\in\left[0,1\right]\\ 0 & x\notin\left[0,1\right] \end{cases}\)</span>.</p>
<p>אם היינו רוצים להגדיר התפלגות אחידה על קטע גדול יותר, למשל <span class="math">\(\left[0,2\right]\)</span>, היינו צריכים לשנות את הפונקציה בהתאם כדי שהאינטגרל על הכל ייצא 1:</p>
<p><span class="math">\(f\left(x\right)=\begin{cases} \frac{1}{2} & x\in\left[0,2\right]\\ 0 & x\notin\left[0,2\right] \end{cases}\)</span></p>
<p>הבנו את הרעיון? יפה, אז אפשר סוף כל סוף להגיע אל ההתפלגות שהיא הסיבה שלשמה נתכנסנו: ההתפלגות הנורמלית.</p>
<h2>מפגש ראשון עם התפלגות נורמלית</h2>

<p>אמרתי בתחילת הפוסט שהתפלגות נורמלית מוגדרת עם <span class="math">\(f\left(x\right)=\frac{1}{\sqrt{2\pi}\sigma}e^{-\left(x-\mu\right)^{2}/2\sigma^{2}}\)</span> ועכשיו אנחנו סוף סוף יכולים להבין מה הולך כאן, אבל זה <strong>עדיין</strong> מסובך מדי; לעת עתה אני אסתכל על מקרה פרטי מרכזי, שממנו בעצם קל יחסית להבין את המקרה הכללי - הפונקציה <span class="math">\(f\left(x\right)=\frac{1}{\sqrt{2\pi}}e^{-\frac{x^{2}}{2}}\)</span> שמתקבלת מהצבת <span class="math">\(\mu=0,\sigma=1\)</span> בנוסחה הקודמת. ככה הפונקציה הזו נראית כשמציירים גרף שלה:</p>
<p><img src="/img/2025/histogram_11.png" alt=""/></p>
<p>הגרף הזה מתאר רק את החלק <span class="math">\(\left[-3,3\right]\)</span> כי זה החלק המעניין; מחוץ לו הפונקציה פשוט נראית ממש שטוחה. לפונקציה הזו יש שלל שמות - בפרט "עקומת הפעמון" בגלל הצורה שלה, או "גאוסיאן" על שם המתמטיקאי גאוס שעשה בה שימוש נרחב (אבל לא היה הראשון שתיאר אותה; זה היה דה-מואבר).</p>
<p>השאלה המנחה שלנו בכל סדרת הפוסטים הזו היא "מאיפה הפונקציה הזו הגיעה בכלל?" והתשובה שאני נותן כאן היא "ממשפט הגבול המרכזי" שאותו אני עוד צריך להראות פורמלית אבל כבר אמרתי מהו - העקומה הספציפית הזו פשוט מתארת <strong>ממש טוב</strong> את מה שקורה כשיש לנו משתנה מקרי ואנחנו מחברים הרבה עותקים בלתי תלויים של עצמו. אבל כבר בשלב הזה אני יכול להסביר מאיפה<strong> חלק</strong> מהפונקציה הגיע - למה <span class="math">\(\pi\)</span> נמצא שם. התשובה הקצרה היא שהוא שם כי <span class="math">\(2\pi\)</span> הוא היקף מעגל היחידה. התשובה הקצת פחות קצרה היא שהוא שם בגלל הדרישה <span class="math">\(\int_{-\infty}^{\infty}f\left(x\right)dx=1\)</span> על פונקציות צפיפות. בואו נעבור לתשובה המלאה.</p>
<p>אז כאמור, אנחנו צריכים להראות שמתקיים <span class="math">\(\int_{-\infty}^{\infty}f\left(x\right)dx=1\)</span>, כלומר <span class="math">\(\int_{-\infty}^{\infty}\frac{1}{\sqrt{2\pi}}e^{-\frac{x^{2}}{2}}dx=\frac{1}{\sqrt{2\pi}}\int_{-\infty}^{\infty}e^{-\frac{x^{2}}{2}}dx=1\)</span>, כלומר מספיק להראות ש-<span class="math">\(\int_{-\infty}^{\infty}e^{-\frac{x^{2}}{2}}dx=\sqrt{2\pi}\)</span>. עכשיו, איך בדרך כלל מחשבים אינטגרל מהצורה <span class="math">\(\int_{-\infty}^{\infty}f\left(x\right)dx\)</span>? קודם כל מוצאים <strong>פונקציה קדומה</strong>, <span class="math">\(F\left(x\right)\)</span> כך ש-<span class="math">\(F^{\prime}\left(x\right)=f\left(x\right)\)</span>. אחר כך מחשבים את האינטגרל על הגבולות הסופיים <span class="math">\(\int_{a}^{b}f\left(x\right)dx=F\left(b\right)-F\left(a\right)\)</span>, ולבסוף משאיפים בזהירות את <span class="math">\(b\)</span> ל-<span class="math">\(\infty\)</span> ואת <span class="math">\(a\)</span> ל-<span class="math">\(-\infty\)</span> ובודקים לאן הביטוי הולך.</p>
<p>זה לא מה שיקרה כאן.</p>
<p>לב הבעיה הוא שלפונקציה <span class="math">\(e^{-x^{2}}\)</span> <strong>אין</strong> פונקציה קדומה שאפשר להציג בצורה פשוטה ("אלמנטרית"). להוכיח את זה זה סיפור בפני עצמו ואני לא אכנס לזה הפעם, אבל תשכחו מהשיטה המסורתית. לא נחשב את האינטגרל הזה בדרך המסורתית. למרבה השמחה, לא חסרות דרכים אחרות.</p>
<p>בואו נסמן <span class="math">\(I=\int_{-\infty}^{\infty}e^{-\frac{x^{2}}{2}}dx\)</span>. במקום להוכיח <span class="math">\(I=\sqrt{2\pi}\)</span>, נוכיח ש-<span class="math">\(I^{2}=2\pi\)</span> (ובגלל שהאינטגרל של <span class="math">\(I\)</span> הוא על פונקציה <strong>חיובית</strong>, <span class="math">\(I\)</span> הוא השורש החיובי של <span class="math">\(2\pi\)</span>). הרעיון הוא להפוך את <span class="math">\(I^{2}\)</span>, שהוא מכפלה של שני אינטגרלים במשתנה יחיד, לאינטגרל <strong>כפול</strong> באמצעות מה שנקרא <strong>משפט פוביני</strong>. בואו נתחיל מלראות איך זה בערך עובד ואז נדבר על הפרטים הטכניים שצריך לגהץ. הטריק הבסיסי הוא זה:</p>
<p><span class="math">\(I^{2}=\left(\int_{-\infty}^{\infty}e^{-\frac{x^{2}}{2}}dx\right)\left(\int_{-\infty}^{\infty}e^{-\frac{y^{2}}{2}}dy\right)=\int_{-\infty}^{\infty}\int_{-\infty}^{\infty}e^{-\frac{\left(x^{2}+y^{2}\right)}{2}}dxdy\)</span></p>
<p>עכשיו מבצעים <strong>החלפת משתנים</strong> של האינטגרל הכפול. מגדירים</p>
<p><span class="math">\(x=r\cos\theta\)</span></p>
<p><span class="math">\(y=r\sin\theta\)</span></p>
<p>עבור <span class="math">\(r\in[0,\infty(\)</span> ו-<span class="math">\(\theta\in\left[0,2\pi\right]\)</span></p>
<p>מה שנותן לנו:</p>
<p><span class="math">\(x^{2}+y^{2}=r^{2}\left(\cos^{2}\theta+\sin^{2}\theta\right)=r^{2}\)</span></p>
<p><span class="math">\(dxdy=rd\theta dr\)</span></p>
<p>כלומר</p>
<p><span class="math">\(\int_{-\infty}^{\infty}\int_{-\infty}^{\infty}e^{-\frac{\left(x^{2}+y^{2}\right)}{2}}dxdy=\int_{0}^{\infty}\left(\int_{0}^{2\pi}re^{-\frac{r^{2}}{2}}d\theta\right)dr=\)</span></p>
<p><span class="math">\(=2\pi\int_{0}^{\infty}re^{-\frac{r^{2}}{2}}dr=-2\pi\left.e^{\frac{-r^{2}}{2}}\right|_{0}^{\infty}=2\pi\)</span></p>
<p>אוקיי, מה קרה פה כרגע? לי זה נראה כמו קסם בכל פעם שאני רואה את זה, אבל האמת היא שלא קרה פה שום דבר חריג - זה תרגיל מאוד סטנדרטי בחדו"א, וכפי שקורה בדרך כלל בחדו"א - <strong>להצדיק</strong> כל מעבר דורש עבודה אבל מרגע שיושב לנו למה אפשר להצדיק את כולם, העבודה היא די פשוטה. אני אתחיל דווקא מהסוף ואלך אחורה צעד-צעד כדי שנראה שהכל תקין, כי ככל שמתקרבים להתחלה כך הנניח-נזניח שלנו נהיה גדול יותר.</p>
<p>ראשית, האינטגרל <span class="math">\(\int_{0}^{\infty}re^{-\frac{r^{2}}{2}}dr\)</span>. הוא מאוד מזכיר את מה שהתחלנו ממנו, <span class="math">\(\int_{-\infty}^{\infty}e^{-\frac{x^{2}}{2}}dx\)</span>, אבל יש הבדל מהותי אחד: <span class="math">\(e^{-\frac{r^{2}}{2}}\)</span> מוכפל ב-<span class="math">\(r\)</span>, וההבדל הקטן הזה פירושו <strong>שיש</strong> פונקציה קדומה אלמנטרית לאינטגרנד. אם אנחנו גוזרים את <span class="math">\(e^{x}\)</span> אנחנו מקבלים <span class="math">\(e^{x}\)</span>; זו התכונה הבסיסית של הפונקציה הזו (אפשר אפילו <strong>להגדיר</strong> אותה באמצעותה, <a href="https://gadial.net/2010/03/27/exponent/">הנה פוסט</a> שעושה את זה). עכשיו, על פי כלל השרשרת, <span class="math">\(\left(e^{g\left(x\right)}\right)^{\prime}=g^{\prime}\left(x\right)e^{g\left(x\right)}\)</span>, ומכיוון שבמקרה שלנו <span class="math">\(g\left(r\right)=-\frac{r^{2}}{2}\)</span> נקבל <span class="math">\(g^{\prime}\left(r\right)=-r\)</span> כלומר <span class="math">\(\left(e^{-\frac{r^{2}}{2}}\right)=-re^{-\frac{r^{2}}{2}}\)</span> ולכן הפונקציה הקדומה של <span class="math">\(re^{-\frac{r^{2}}{2}}\)</span> היא <span class="math">\(-e^{-\frac{r^{2}}{2}}\)</span>.</p>
<p>מה שנשאר לנו, אם אנחנו יודעים את הפונקציה הקדומה, הוא לחשב את <span class="math">\(-2\pi\left.e^{\frac{-r^{2}}{2}}\right|_{0}^{\infty}\)</span>. החישוב הוא סטנדרטי לאינטגרלים מוכללים: כדי לחשב את <span class="math">\(\left.F\left(r\right)\right|_{0}^{\infty}\)</span> לוקחים <span class="math">\(a\in[0,\infty(\)</span> כלשהו ומחשבים את <span class="math">\(\lim_{a\to\infty}\left[F\left(a\right)-F\left(0\right)\right]\)</span>. במקרה שלנו, <span class="math">\(\lim_{a\to\infty}e^{-\frac{a^{2}}{2}}=0\)</span> כי <span class="math">\(e^{x}\)</span> הוא פונקציה רציפה וכש-<span class="math">\(a\to\infty\)</span> אז <span class="math">\(-\frac{a^{2}}{2}\to-\infty\)</span> ואנחנו יודעים ש-<span class="math">\(\lim_{x\to-\infty}e^{x}=0\)</span>. מצד שני, כשמציבים <span class="math">\(ra=0\)</span> ב-<span class="math">\(e^{\frac{-r^{2}}{2}}\)</span> מקבלים 1, ולכן בסך הכל נשארים עם <span class="math">\(-2\pi\cdot0-\left(-2\pi\cdot1\right)=2\pi\)</span>. עד כאן הכל טוב.</p>
<p>עכשיו בואו נדבר על <strong>החלפת המשתנים</strong> שמאפשרת לנו לכתוב <span class="math">\(\int_{-\infty}^{\infty}\int_{-\infty}^{\infty}e^{-\frac{\left(x^{2}+y^{2}\right)}{2}}dxdy=\int_{0}^{\infty}\left(\int_{0}^{2\pi}re^{-\frac{r^{2}}{2}}d\theta\right)dr\)</span>. כאן יש את הפער הגדול ביותר בין כמה שהפעולה הטכנית הזו היא סטנדרטית אחרי שהתרגלנו אליה, וכמה המשפט שעליה היא מבוססת הוא עמוק ומורכב. <a href="https://gadial.net/2016/04/12/general_change_of_variables/">יש לי פוסט</a> על הוכחת המשפט באופן כללי וזה... לא כל כך פשוט. אבל למרבה השמחה מה שפשוט הוא <strong>הרעיון</strong>. את הרעיון, גם במקרה הכי כללי, אפשר לתאר על ידי הנוסחה הפשוטה</p>
<p><span class="math">\(\int_{B}f=\int_{A}\left(f\circ g\right)\left|\det Dg\right|\)</span></p>
<p>(הנוסחה הזו משמיטה את ה-<span class="math">\(dx\)</span>-ים למיניהם שאנחנו משתמשים בהם כדי לעקוב אחרי משתני האינטגרציה). הרעיון פה הוא ש-<span class="math">\(f\)</span> היא הפונקציה שעליה מבצעים אינטגרציה, וכדי שהמשפט יעבוד היא צריכה להיות רציפה (במקרה שלנו <span class="math">\(e^{-\frac{\left(x^{2}+y^{2}\right)}{2}}\)</span> רציפה) ואילו <span class="math">\(g\)</span> היא הפונקציה שמתארת את החלפת המשתנים - במקרה שלנו זו החלפה היא <strong>מאוד סטנדרטית</strong>, אולי ההחלפה הכי בסיסית שרואים בחדו"א. היא מתבססת על פונקציה <span class="math">\(g:\mathbb{R}^{2}\to\mathbb{R}^{2}\)</span> שמוגדרת על ידי <span class="math">\(g\left(r,\theta\right)=\left(r\cos\theta,r\sin\theta\right)\)</span>. את הפונקציה הזו צריך לצמצם לתת-קבוצה <span class="math">\(A\)</span>, כך שעל תת-הקבוצה הזו <span class="math">\(g\)</span> היא חח"ע ועל, והתמונה שלה היא בדיוק <span class="math">\(B\)</span>, הקבוצה שעליה אנחנו מנסים לבצע את האינטגרציה של <span class="math">\(f\)</span>. במקרה שלנו, <span class="math">\(A=\left(0,\infty\right)\times[0,2\pi(\)</span> בזמן ש-<span class="math">\(B=\mathbb{R}^{2}\backslash\left\{ 0\right\} \)</span> (אני משמיט את 0 כי איתו <span class="math">\(g\)</span> כבר לא תהיה חח"ע, אבל נקודה אחת לא משפיעה על האינטגרל). על <span class="math">\(g\)</span> יש דרישה חזקה יותר של רציפות - גם היא וגם ההופכית שלה צריכות להיות גזירות ברציפות, אבל לא קשה לבדוק שזה מתקיים.</p>
<p>הביטוי <span class="math">\(f\circ g\)</span> פירושו "קודם להפעיל את <span class="math">\(g\)</span> ואז את <span class="math">\(f\)</span>" (כן, אני יודע שיש טקסטים שעושים בדיוק ההפך) אז במקרה שלנו אנחנו מקבלים</p>
<p><span class="math">\(\left(f\circ g\right)\left(r,\theta\right)=e^{-\frac{\left(r\cos\theta\right)^{2}+\left(r\sin\theta\right)^{2}}{2}}=e^{-\frac{r^{2}}{2}}\)</span></p>
<p>זו "החלפת המשתנים" בפעולה (ואני מקווה שזה מבהיר למה <span class="math">\(g\)</span> היא דווקא מהמשתנים ה"חדשים" ל"ישנים"; אותי זה תמיד מבלבל). מה שנשאר לעשות הוא לכפול בביטוי <span class="math">\(\left|\det Dg\right|\)</span> שנקרא <strong>היעקוביאן</strong> של <span class="math">\(g\)</span>, שהוא הגורם שמודד כמה <span class="math">\(g\)</span> "מעוותת את המרחב" ולכן משנה את תפיסת השטח שלנו. כאן <span class="math">\(Dg\)</span> היא מטריצה של כל הנגזרות החלקיות של <span class="math">\(g\)</span>: מכיוון ש-<span class="math">\(g:\mathbb{R}^{2}\to\mathbb{R}^{2}\)</span> היא פונקציה בשני משתנים יש ל-<span class="math">\(Dg\)</span> שתי עמודות - בעמודה הראשונה גוזרים לפי <span class="math">\(r\)</span> ובשניה לפי <span class="math">\(\theta\)</span>. בנוסף, מכיוון ש-<span class="math">\(g\)</span> היא פונקציה עם שני רכיבים, יש ל-<span class="math">\(Dg\)</span> שני שורות: בראשונה גוזרים את הרכיב <span class="math">\(r\cos\theta\)</span> ובשניה את הרכיב <span class="math">\(r\sin\theta\)</span>. מקבלים:</p>
<p><span class="math">\(Dg=\left[\begin{array}{cc} \cos\theta & -r\sin\theta\\ \sin\theta & r\cos\theta \end{array}\right]\)</span></p>
<p>ולכן</p>
<p><span class="math">\(\det Dg=r\cos^{2}\theta+r\sin^{2}\theta=r\left(\cos^{2}\theta+\sin^{2}\theta\right)=r\)</span></p>
<p>ואנחנו כופלים <strong>בערך המוחלט</strong> של הביטוי הזה, כלומר עדיין כופלים ב-<span class="math">\(r\)</span>. כל הדבר הזה מתבטא בפועל בכלל המצחיק <span class="math">\(dxdy=rd\theta dr\)</span> שהוא לא משהו פורמלי (למרות <a href="https://gadial.net/2016/08/21/stokes_theorem_overview/">שאם באמת רוצים</a> <strong>אפשר</strong> לפרמל את המשמעות של ה-<span class="math">\(dx\)</span>-ים הללו אבל בואו לא נעשה את זה הפעם) שאומר לנו "אחרי שהחלפתם את המשתנים באינטגרנד, תחליפו גם את הסימן שמתאר לכם את משתני הסכימה אבל אל תשכחו בנוסף גם לכפול ביעקוביאן <span class="math">\(r\)</span>". מכאן והלאה האינטגרל נפתר בקלות.</p>
<p>מה שנשאר לי להסביר הוא את המעבר</p>
<p><span class="math">\(\left(\int_{-\infty}^{\infty}e^{-\frac{x^{2}}{2}}dx\right)\left(\int_{-\infty}^{\infty}e^{-\frac{y^{2}}{2}}dy\right)=\int_{-\infty}^{\infty}\int_{-\infty}^{\infty}e^{-\frac{\left(x^{2}+y^{2}\right)}{2}}dxdy\)</span></p>
<p>שבו הופכים מכפלה של שני אינטגרלים חד-ממדיים לאינטגרל דו-ממדי. הכלי הבסיסי פה הוא <strong>משפט פוביני</strong>:</p>
<p><span class="math">\(\int\int_{X\times Y}f\left(x,y\right)dxdy=\int_{X}\left(\int_{Y}f\left(x,y\right)dy\right)dx\)</span></p>
<p>כאן באגף שמאל יש לנו אינטגרל כפול, ובאגף ימין יש לנו שני אינטגרלים חד-ממדיים, אבל לא מוכפלים אלא מופעלים אחד על השני. כלומר, האינטגרל החיצוני <span class="math">\(\int_{X}\left(\ldots\right)dx\)</span> מופעל על פונקציה של <span class="math">\(x\)</span> שמתקבלת מכך שבוחרים ערך ל-<span class="math">\(x\)</span>, "מקפיאים" אותו ומחשבים את האינטגרל החד-ממדי <span class="math">\(\int_{Y}f_{x}\left(y\right)dy\)</span> שמופעל על הפונקציה <span class="math">\(f_{x}\left(y\right)\)</span> שמוגדרת על ידי <span class="math">\(f_{x}\left(y\right)=f\left(x,y\right)\)</span>. כדי שהטריק הזה יעבוד צריך שה-<span class="math">\(f\)</span> שלנו תהיה רציפה (כבר ראינו שזה קורה) או שהאינטגרל לא יהיה אינטגרל רגיל אלא הגרסה המוכללת והחזקה שלו, <strong>אינטגרל לבג</strong>, אבל על זה אני לא אדבר הפעם.</p>
<p>במקרה הספציפי שלנו, <span class="math">\(f\left(x,y\right)=e^{-\frac{\left(x^{2}+y^{2}\right)}{2}}=e^{-\frac{x^{2}}{2}}\cdot e^{-\frac{y^{2}}{2}}\)</span> כלומר אם אני מסתכל על <span class="math">\(f_{x}\left(y\right)\)</span> זו פונקציה מהצורה של קבוע (שתלוי ב-<span class="math">\(x\)</span>) שמוכפל ב-<span class="math">\(e^{-\frac{y^{2}}{2}}\)</span>. מכפלה בקבוע אפשר להוציא מחוץ לאינטגרל:</p>
<p><span class="math">\(\int_{X}\left(\int_{Y}f\left(x,y\right)dy\right)dx=\int_{X}e^{-\frac{x^{2}}{2}}\left(\int_{Y}e^{-\frac{y^{2}}{2}}dy\right)dx\)</span></p>
<p>אבל עכשיו מה שיש באינטגרל הפנימי <strong>לא תלוי</strong> ב-<span class="math">\(x\)</span> בשום צורה, כלומר הוא תמיד יוצא אותו מספר לא משנה מה הערך של <span class="math">\(x\)</span>, ולכן מנקודת המבט של האינטגרל החיצוני, <span class="math">\(\int_{Y}e^{-\frac{y^{2}}{2}}dy\)</span> הוא <strong>קבוע</strong> שאפשר להוציא החוצה, ומקבלים</p>
<p><span class="math">\(\int_{X}\left(\int_{Y}f\left(x,y\right)dy\right)dx=\int_{X}e^{-\frac{x^{2}}{2}}dx\int_{Y}e^{-\frac{y^{2}}{2}}dy\)</span></p>
<p>וזה מה שהשתמשתי בו בהוכחה.</p>
<p>יש רק בעיה קטנה אחת פה: בשביל להשתמש במשפט פוביני, אני צריך ש-<span class="math">\(X,Y\)</span> יהיו קטעים סופיים. זה גורר עוד סיבוך טכני. במקום לחשב את <span class="math">\(I=\int_{-\infty}^{\infty}e^{-\frac{x^{2}}{2}}dx\)</span> אני בוחר <span class="math">\(a\in[0,\infty(\)</span> ומחשב את <span class="math">\(I\left(a\right)=\int_{-a}^{a}e^{-\frac{x^{2}}{2}}dx\)</span> ואז בודק מה יוצא <span class="math">\(\lim_{a\to\infty}I\left(a\right)\)</span>. אבל אפילו כאן מתחבא <strong>עוד</strong> סיבוך טכני! כי באינטגרל מוכלל מהצורה <span class="math">\(\int_{-\infty}^{\infty}f\left(x\right)dx\)</span> זה <strong>לא תקין</strong> לבחור נקודה אחת <span class="math">\(a\)</span> ולהסתכל על הגבול <span class="math">\(\lim_{a\to\infty}\int_{-a}^{a}f\left(x\right)dx\)</span> כי הסימטריה שזה יוצר עלולה "למסך" תקלות. האופן שבו <strong>באמת</strong> מגדירים את הערך של אינטגרל אינסופי לשני הכיוונים שכזה הוא עם אחת משתי השיטות הבאות: או שבוחרים <span class="math">\(a,b\)</span> ומסתכלים על הגבול <strong>הכפול</strong> <span class="math">\(\lim_{a\to\infty}\lim_{b\to\infty}\int_{a}^{b}f\left(x\right)dx\)</span> או שמפצלים את האינטגרל לסכום של שני אינטגרלים, <span class="math">\(\int_{-\infty}^{\infty}f\left(x\right)dx=\int_{-\infty}^{c}f\left(x\right)dx+\int_{c}^{\infty}f\left(x\right)d\left(x\right)\)</span>.</p>
<p>כדי לראות למה זה קריטי, בואו ניקח <span class="math">\(f\left(x\right)=x\)</span>. אז למשל <span class="math">\(\int_{0}^{\infty}xdx=\left.\frac{x^{2}}{2}\right|_{0}^{\infty}=\infty\)</span> ובדומה <span class="math">\(\int_{-\infty}^{0}xdx=-\infty\)</span> והביטוי <span class="math">\(\infty-\infty\)</span> בכלל לא מוגדר; ואם אני מסתכל על <span class="math">\(\int_{a}^{b}xdx=\frac{b^{2}-a^{2}}{2}\)</span> אז הגבול הכפול <span class="math">\(\lim_{a\to\infty}\lim_{b\to\infty}\frac{b^{2}-a^{2}}{2}\)</span> שוב לא יהיה מוגדר, מאותן סיבות.</p>
<p>באינטגרל שלנו, <span class="math">\(\int_{-\infty}^{\infty}e^{-\frac{x^{2}}{2}}dx\)</span>, זו לא בעיה אמיתית כי אפשר לפרק את האינטגרל באמצע ולקבל שני חלקים שכל אחד מהם מתכנס יפה למשהו סופי (אל <span class="math">\(\frac{\sqrt{2\pi}}{2}\)</span> בגלל הסימטריה) אבל אם אני חותך את האינטגרל באמצע, כל הטריקים היפים שעשיתי קודם כבר לא עובדים! הצילו! חדו"א יכול להיות מאוד אכזרי לפעמים.</p>
<p>למרבה המזל, יש לנו דרך קיצור כאן. יש שיטה שנקראת "הערך העיקרי של קושי" (Principal Value) שמאפשרת לתת ערך ל-<span class="math">\(\lim_{a\to\infty}\int_{-a}^{a}f\left(x\right)dx\)</span>, והערך הזה יוצא שווה אל <span class="math">\(\int_{-\infty}^{\infty}f\left(x\right)dx\)</span> במקרים שבהם <span class="math">\(f\left(x\right)\)</span> מתכנסת בערך מוחלט, כלומר אם <span class="math">\(\int_{-\infty}^{\infty}\left|f\left(x\right)\right|dx<\infty\)</span>. זה בהחלט המצב גם עבור <span class="math">\(\int_{-\infty}^{\infty}e^{-\frac{x^{2}}{2}}dx\)</span>. ראשית, הערך המוחלט בכלל לא משפיע כאן כי <span class="math">\(e\)</span> בחזקת משהו ממשי הוא תמיד חיובי; ושנית, אפשר לחסום את האינטגרל הזה בצורה די נחמדה:</p>
<p><span class="math">\(\int_{-\infty}^{\infty}e^{-\frac{x^{2}}{2}}dx<\int_{-\infty}^{-1}-xe^{-\frac{x^{2}}{2}}dx+\int_{-1}^{1}e^{-\frac{x^{2}}{2}}dx+\int_{1}^{\infty}xe^{-\frac{x^{2}}{2}}dx\)</span></p>
<p>כי כאשר <span class="math">\(x\)</span> גדול מ-1 מכפלה בו רק מגדילה את האינטגרל, וכשהוא קטן ממינוס 1 מכפלה ב-<span class="math">\(-x\)</span> רק מגדילה את האינטגרל. עכשיו קיבלנו סכום של שלושה אינטגרלים שהאמצעי מביניהם הוא בוודאי סופי (כי הוא של פונקציה רציפה על קטע סגור) ואת האחרים אפשר לחשב במפורש כפי שכבר ראינו קודם, למשל <span class="math">\(\int_{1}^{\infty}xe^{-\frac{x^{2}}{2}}=\left.-e^{-\frac{x^{2}}{2}}\right|_{1}^{\infty}=e^{-\frac{1}{2}}\)</span>. זה מוכיח שהאינטגרל חסום ואפשר כמו שאמרתי קודם לכתוב <span class="math">\(I\left(a\right)=\int_{-a}^{a}e^{-\frac{x^{2}}{2}}dx\)</span> ולבדוק מה יוצא <span class="math">\(\lim_{a\to\infty}I\left(a\right)\)</span>.</p>
<p>את <span class="math">\(I\left(a\right)=\int_{-a}^{a}e^{-\frac{x^{2}}{2}}dx\)</span> אפשר לחשב כמו שראינו עם משפט פוביני, ומקבלים </p>
<p><span class="math">\(\int_{-a}^{a}e^{-\frac{x^{2}}{2}}dx=\int_{-a}^{a}\int_{-a}^{a}e^{-\frac{\left(x^{2}+y^{2}\right)}{2}}dxdy\)</span></p>
<p>אבל עכשיו נוצר לנו סיבוך בשלב החלפת המשתנים. אנחנו עדיין משתמשים באותה החלפה בדיוק:</p>
<p><span class="math">\(x=r\cos\theta\)</span></p>
<p><span class="math">\(y=r\sin\theta\)</span></p>
<p>אבל הרעיון בהחלפת משתנים הוא כזכור לקחת אינטגרל שמוגדר על קבוצה אחת <span class="math">\(A\)</span> ולהגדיר אותו על קבוצה אחרת <span class="math">\(B\)</span> כך שהחלפת המשתנים מעבירה את <span class="math">\(B\)</span> <strong>בדיוק</strong> אל <span class="math">\(A\)</span>. ואצלנו עכשיו <span class="math">\(A\)</span> הוא <strong>ריבוע</strong>, <span class="math">\(A=\left[-a,a\right]\times\left[-a,a\right]\)</span> בזמן שהחלפת המשתנים מוגדרת על קבוצה <span class="math">\(B=\left[0,t\right]\times\left[0,2\pi\right]\)</span> (שוב, עד כדי התעלמות מהבעייתיות בנקודה 0) ומעבירה את הקבוצה הזו אל <strong>העיגול </strong><span class="math">\(\left\{ \left(r\cos\theta,r\sin\theta\right)\ |\ 0\le\theta\le2\pi,0\le r\le t\right\} \)</span> שהרדיוס שלו הוא <span class="math">\(t\)</span>.</p>
<p>אז מה עושים? שוב חוסמים! העיגול ש<strong>חסום</strong> בתוך <span class="math">\(A\)</span> הוא בעל רדיוס <span class="math">\(a\)</span>, והמעגל <strong>שחוסם</strong> את <span class="math">\(A\)</span> הוא בעל רדיוס <span class="math">\(\sqrt{2}a\)</span> (זה תרגיל נחמד לצייר את הריבע ולהבין למה אלו רדיוסי המעגלים), ומכיוון שהפונקציה חיובית, האינטגרל שלה על <span class="math">\(A\)</span> יהיה בין האינטגרלים שלה על שני המעגלים הללו:</p>
<p><span class="math">\(\int_{0}^{a}\left(\int_{0}^{2\pi}re^{-\frac{r^{2}}{2}}d\theta\right)dr\le I\left(a\right)\le\int_{0}^{\sqrt{2}a}\left(\int_{0}^{2\pi}re^{-\frac{r^{2}}{2}}d\theta\right)dr\)</span></p>
<p>ואת האינטגרלים הללו כבר ראינו איך לחשב. מכיוון שאין <span class="math">\(\infty\)</span> מעורב שמאפס את האקספוננט, הם יוצאים פחות "נקיים", אבל אנחנו כבר שקועים בלכלוך מכאן ועד להודעה חדשה אז למי אכפת? בסופו של חישוב האינטגרל מקבלים <span class="math">\(-2\pi\left.e^{\frac{-r^{2}}{2}}\right|_{0}^{t}=-2\pi\left(e^{-\frac{t^{2}}{2}}-1\right)=2\pi\left(1-e^{-\frac{t^{2}}{2}}\right)\)</span> ורק נשאר להציב <span class="math">\(t=a,\sqrt{2}a\)</span> ולקבל:</p>
<p><span class="math">\(2\pi\left(1-e^{-\frac{a^{2}}{2}}\right)\le I\left(a\right)\le2\pi\left(1-e^{-a^{2}}\right)\)</span></p>
<p>עכשיו אפשר להשתמש בכלל הסנדוויץ': <span class="math">\(\lim_{a\to\infty}2\pi\left(1-e^{-\frac{a^{2}}{2}}\right)=2\pi\left(1-e^{-a^{2}}\right)=2\pi\)</span> ולכן מקבלים <span class="math">\(\lim_{a\to\infty}I\left(a\right)=2\pi\)</span> בצורה הכי פורמלית בעולם.</p>
<p>בספרי לימוד של תורת ההסתברות בדרך כלל לא יראו לכם את כל המהומה הזו; יסתפקו בהוכחה שהראיתי בהתחלה, שמדלגת מעל שלבים בצורה קלילה. עכשיו אנחנו כנראה גם מבינים למה - כי אחרי שרואים את זה צריך לנוח, ולכן אני מסיים את הפוסט כאן ולא מדלג בקלילות אל הנושא הבא - כלומר, אל השאלה מה בנוסחה הכללית <span class="math">\(f\left(x\right)=\frac{1}{\sqrt{2\pi}\sigma}e^{-\left(x-\mu\right)^{2}/2\sigma^{2}}\)</span> התפקיד של אותם <span class="math">\(\sigma\)</span> ו-<span class="math">\(\mu\)</span> מזעזעים שמתחבאים בה ואיך אנחנו מקשרים את המקרה הכללי איתם אל מה שראינו כרגע.</p>
        </article>
        
        <footer>
            <p>© כל הזכויות שמורות לגדי אלכסנדרוביץ'</p>
        </footer>
    </div>

    
    <script>
        function toggleMobileMenu() {
            const navLinks = document.getElementById('navLinks');
            navLinks.classList.toggle('expanded');
        }
        
        function searchPosts() {
            const searchTerm = document.getElementById('searchInput').value;
            if (searchTerm.trim()) {
                window.location.href = '/post_list.html?search=' + encodeURIComponent(searchTerm);
            }
        }
        
        document.getElementById('searchInput').addEventListener('keypress', function(e) {
            if (e.key === 'Enter') {
                searchPosts();
            }
        });
    </script>
    
    
    <!-- Auto-render KaTeX math -->
    <script>
        document.addEventListener("DOMContentLoaded", function() {
            renderMathInElement(document.body, {
                delimiters: [
                    {left: "\\[", right: "\\]", display: true},
                    {left: "\\(", right: "\\)", display: false}
                ],
                throwOnError: false
            });
        });
    </script>

</body>
</html>