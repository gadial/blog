<!DOCTYPE html>
<html lang="he" dir="rtl">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>מה הקטע עם התפלגות נורמלית? (חלק ד&#39; ואחרון: משפט הגבול המרכזי) - לא מדויק</title>
    <link rel="icon" type="image/x-icon" href="/new_blog/favicon.ico">
    
    
    <!-- KaTeX for math rendering -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css">
    <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js"></script>
    <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js"></script>

    
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }
        
        body {
            font-family: 'Arial', 'David', 'Tahoma', sans-serif;
            line-height: 1.6;
            color: #333;
            background-color: #f5f5f5;
        }
        
        /* Top navigation bar */
        .top-nav {
            background: #2c3e50;
            padding: 15px 20px;
            box-shadow: 0 2px 5px rgba(0,0,0,0.1);
        }
        
        .top-nav .nav-container {
            max-width: 1200px;
            margin: 0 auto;
            display: flex;
            align-items: center;
            justify-content: space-between;
            gap: 20px;
        }
        
        .top-nav .site-title {
            font-size: 1.5em;
            font-weight: bold;
            color: white;
            text-decoration: none;
            white-space: nowrap;
        }
        
        .top-nav .nav-links {
            display: flex;
            gap: 20px;
            align-items: center;
            flex-wrap: wrap;
        }
        
        .top-nav .nav-links a {
            color: #ecf0f1;
            text-decoration: none;
            padding: 5px 10px;
            border-radius: 4px;
            transition: background 0.2s;
            white-space: nowrap;
        }
        
        .top-nav .nav-links a:hover {
            background: #34495e;
        }
        
        .top-nav .search-box {
            display: flex;
            gap: 5px;
        }
        
        .top-nav .search-box input {
            padding: 5px 10px;
            border: none;
            border-radius: 4px;
            font-size: 0.9em;
            min-width: 150px;
        }
        
        .top-nav .search-box button {
            padding: 5px 15px;
            background: #3498db;
            color: white;
            border: none;
            border-radius: 4px;
            cursor: pointer;
            transition: background 0.2s;
        }
        
        .top-nav .search-box button:hover {
            background: #2980b9;
        }
        
        /* Mobile responsive */
        @media (max-width: 768px) {
            .top-nav .nav-container {
                flex-direction: column;
                align-items: stretch;
            }
            
            .top-nav .site-title {
                text-align: center;
                margin-bottom: 10px;
            }
            
            .top-nav .nav-links {
                flex-direction: column;
                width: 100%;
            }
            
            .top-nav .nav-links a {
                text-align: center;
                padding: 8px;
            }
            
            .top-nav .search-box {
                width: 100%;
                flex-direction: column;
            }
            
            .top-nav .search-box input {
                width: 100%;
                margin-bottom: 5px;
                min-width: 0;
            }
            
            .top-nav .search-box button {
                width: 100%;
            }
        }
        
        /* Blockquote styling */
        blockquote {
            background: #f9f9f9;
            border-right: 5px solid #ccc;
            margin: 1.5em 10px;
            padding: 0.75em 16px;
            position: relative;
            font-style: italic;
        }
        
        blockquote:before {
            content: '"';
            position: absolute;
            top: -10px;
            right: 8px;
            font-size: 3.5em;
            color: #ccc;
            line-height: 1;
        }
        
        blockquote p {
            display: block;
            margin: 0 0 0.75em 0;
        }
        
        blockquote p:last-child {
            margin-bottom: 0;
        }
        
        
        body {
            line-height: 1.8;
        }
        
        .container {
            max-width: 800px;
            margin: 20px auto;
            background: white;
            padding: 40px;
            box-shadow: 0 2px 10px rgba(0,0,0,0.1);
            border-radius: 8px;
        }
        
        header {
            margin-bottom: 40px;
            border-bottom: 2px solid #e0e0e0;
            padding-bottom: 20px;
        }
        
        h1 {
            font-size: 2.5em;
            margin-bottom: 10px;
            color: #2c3e50;
        }
        
        .post-meta {
            color: #7f8c8d;
            font-size: 0.9em;
        }
        
        .post-meta .date {
            margin-left: 15px;
        }
        
        .post-meta .categories,
        .post-meta .tags {
            display: inline;
        }
        
        .post-meta .categories a,
        .post-meta .tags a {
            color: #3498db;
            text-decoration: none;
            margin: 0 5px;
        }
        
        .post-meta .categories a:hover,
        .post-meta .tags a:hover {
            text-decoration: underline;
        }
        
        article {
            font-size: 1.1em;
        }
        
        article h2 {
            margin-top: 30px;
            margin-bottom: 15px;
            color: #34495e;
            font-size: 1.8em;
        }
        
        article h3 {
            margin-top: 25px;
            margin-bottom: 12px;
            color: #34495e;
            font-size: 1.4em;
        }
        
        article p {
            margin-bottom: 15px;
            text-align: justify;
        }
        
        article ul, article ol {
            margin-right: 30px;
            margin-bottom: 15px;
        }
        
        article li {
            margin-bottom: 8px;
        }
        
        article code {
            background-color: #f4f4f4;
            padding: 2px 6px;
            border-radius: 3px;
            font-family: 'Courier New', monospace;
            font-size: 0.9em;
        }
        
        article pre {
            background-color: #2d2d2d;
            color: #f8f8f2;
            padding: 15px;
            border-radius: 5px;
            overflow-x: auto;
            margin-bottom: 20px;
            direction: ltr;
            text-align: left;
        }
        
        article pre code {
            background-color: transparent;
            padding: 0;
            color: inherit;
        }
        
        /* Image styles - responsive and contained */
        article img {
            max-width: 100%;
            height: auto;
            display: block;
            margin: 20px auto;
        }
        
        /* Math rendering styles */
        .math {
            direction: ltr;
        }
        
        span.math {
            direction: ltr;
        }
        
        /* Override RTL for KaTeX */
        .katex {
            direction: ltr;
            unicode-bidi: embed;
        }
        
        div.math {
            display: block;
            text-align: center;
            padding: 15px 0;
            direction: ltr;
        }
        
        /* RTL adjustments for code blocks */
        .highlight {
            direction: ltr;
            text-align: left;
        }
        
        footer {
            margin-top: 60px;
            padding-top: 20px;
            border-top: 1px solid #e0e0e0;
            text-align: center;
            color: #95a5a6;
            font-size: 0.9em;
        }
        
        /* Responsive design */
        @media (max-width: 768px) {
            .container {
                padding: 20px;
            }
            
            h1 {
                font-size: 2em;
            }
            
            article {
                font-size: 1em;
            }
        }
        
        /* Post navigation */
        .post-navigation {
            display: flex;
            justify-content: space-between;
            margin-bottom: 30px;
            padding-bottom: 20px;
            border-bottom: 2px solid #e0e0e0;
            gap: 20px;
        }
        
        .post-navigation .nav-link {
            flex: 1;
            text-decoration: none;
            color: #2c3e50;
            padding: 15px;
            background: #f8f9fa;
            border-radius: 5px;
            transition: background 0.2s;
        }
        
        .post-navigation .nav-link:hover {
            background: #e9ecef;
        }
        
        .post-navigation .nav-prev {
            text-align: right;
        }
        
        .post-navigation .nav-next {
            text-align: left;
        }
        
        .post-navigation .nav-label {
            font-size: 0.85em;
            color: #7f8c8d;
            display: block;
            margin-bottom: 5px;
        }
        
        .post-navigation .nav-title {
            font-weight: bold;
            font-size: 1.1em;
        }

    </style>
</head>
<body>
    <nav class="top-nav">
        <div class="nav-container">
            <a href="/new_blog/" class="site-title">לא מדויק</a>
            <div class="nav-links">
                <a href="/new_blog/">דף הבית</a>
                <a href="/new_blog/random.html">פוסט אקראי</a>
                <a href="/new_blog/post_list.html">כל הפוסטים</a>
                <div class="search-box">
                    <input type="text" id="searchInput" placeholder="חיפוש...">
                    <button onclick="searchPosts()">חפש</button>
                </div>
            </div>
        </div>
    </nav>
    
    
    <div class="container">
        <!-- Post Navigation -->
        
        <nav class="post-navigation">
            
            <a href="/new_blog/2025/02/05/normal_distribution_3/" class="nav-link nav-prev">
                <span class="nav-label">פוסט ישן יותר →</span>
                <span class="nav-title">מה הקטע עם התפלגות נורמלית? (חלק ג&#39;: על תוחלת וסטיית תקן)</span>
            </a>
            

            
            <a href="/new_blog/2025/03/15/why_0999_equals_1/" class="nav-link nav-next">
                <span class="nav-label">← פוסט חדש יותר</span>
                <span class="nav-title">אז למה 1=...0.999?</span>
            </a>
            
        </nav>
        
        
        <header>
            <h1>מה הקטע עם התפלגות נורמלית? (חלק ד&#39; ואחרון: משפט הגבול המרכזי)</h1>
            <div class="post-meta">
                <span class="date">2025-02-07</span>
                
                <span class="categories">
                    | קטגוריות:
                    
                    <a href="/categories/הסתברות.html">הסתברות</a>
                    
                </span>
                
                
                <span class="tags">
                    | תגיות:
                    
                    <a href="/tags/התפלגות נורמלית.html">התפלגות נורמלית</a>
                    
                </span>
                
            </div>
        </header>
        
        <article>
            <h2>אז מה משפט הגבול המרכזי אומר?</h2>

<p>סדרת הפוסטים הזו מנסה להבין למה התפלגות נורמלית נראית כמו שהיא נראית. מן הסתם השאלה הראשונה שצריך לענות עליה בשביל זה היא "מה זו בכלל התפלגות נורמלית?" ולזה יש שתי תשובות: אחת יבשה, של לתת את ההגדרה הפורמלית, וזה מה שעשינו בפוסטים הקודמים; והשניה, המהותית יותר, היא להסביר למה בכלל מתעניינים בהתפלגות הזו - והתשובה היא <strong>משפט הגבול המרכזי</strong>. תיארתי אותו בנפנופי ידיים קודם, אז עכשיו הגיע הזמן לתת את הניסוח הפורמלי.</p>
<p>משפט הגבול המרכזי מסתכל על סדרה אינסופית <span class="math">\(X_{1},X_{2},X_{3},\ldots\)</span> של משתנים מקריים שהם בלתי תלויים ובעלי אותה התפלגות (בדומה לתנאים של <strong>חוק המספרים הגדולים</strong> שהזכרתי בפוסט הקודם). אנחנו מסמנים ב-<span class="math">\(\mu\)</span> את התוחלת וב-<span class="math">\(\sigma^{2}\)</span> את השונות שלהם (בפרט, אנחנו מניחים שהמספרים הללו מוגדרים, סופיים וש-<span class="math">\(\sigma\ne0\)</span>). עכשיו, לכל <span class="math">\(n\)</span> אנחנו מגדירים משתנה מקרי <span class="math">\(Z_{n}\)</span> שהוא בערך הסכום של ה-<span class="math">\(X_{i}\)</span>-ים עד האיבר ה-<span class="math">\(n\)</span>-י, אבל עם שקלול נוסף שאמור לנרמל את הסכום:</p>
<p><span class="math">\(Z_{n}=\frac{X_{1}+\ldots+X_{n}-n\mu}{\sigma\sqrt{n}}\)</span></p>
<p>אז הסדרה <span class="math">\(Z_{n}\)</span> שואפת להתפלגות הנורמלית <span class="math">\(N\left(0,1\right)\)</span> כאשר <span class="math">\(n\)</span> שואף לאינסוף. פורמלית, לכל <span class="math">\(-\infty&lt;a&lt;\infty\)</span>:</p>
<p><span class="math">\(\lim_{n\to\infty}P\left(Z_{n}\le a\right)=\frac{1}{\sqrt{2\pi}}\int_{-\infty}^{a}e^{-x^{2}/2}dx\)</span></p>
<p>זה הניסוח הפורמלי, אבל הוא די שונה ממה שהצגתי עד כה בפוסטים שלי. מה שאני תמיד אמרתי הוא "בואו ניקח משתנה מקרי <span class="math">\(X\)</span> כלשהו. עכשיו בואו נחזור על ההגרלה שלו המון פעמים ונחבר את התוצאות" - כלומר, הסתכלתי על הסכום <span class="math">\(X_{1}+\ldots+X_{n}\)</span>. מכאן אמרתי "היי תראו עכשיו אם מציירים היסטוגרמה של הסכום אז פתאום יש עקומה של התפלגות נורמלית שמתארת אותה די במדויק". כדי לקבל את העקומה, חישבתי את <span class="math">\(\text{E}\left[X\right]=\mu\)</span> ואת <span class="math">\(\text{Var}\left(X\right)=\sigma^{2}\)</span> ואז בניתי את העקומה <span class="math">\(N\left(n\mu,\sqrt{n}\sigma\right)\)</span>. בואו נראה שזה באמת אמור לעבוד, על פי משפט הגבול המרכזי.</p>
<p>ראשית, תזכורת: טענתי בפוסט הקודם שאם <span class="math">\(N\left(\mu,\sigma\right)\)</span> היא התפלגות נורמלית עם תוחלת <span class="math">\(\mu\)</span> וסטיית תקן <span class="math">\(\sigma\)</span> אז <span class="math">\(N\left(0,1\right)=\frac{N\left(\mu,\sigma\right)-\mu}{\sigma}\)</span>, או בניסוח אחר - <span class="math">\(N\left(\mu,\sigma\right)=\sigma N\left(0,1\right)+\mu\)</span>.</p>
<p>עכשיו, אם אני אסמן <span class="math">\(Y_{n}=X_{1}+\ldots+X_{n}\)</span> אז משפט הגבול המרכזי אומר ש-<span class="math">\(N\left(0,1\right)\)</span> היא קירוב טוב של <span class="math">\(Z_{n}=\frac{Y_{n}-n\mu}{\sigma\sqrt{n}}\)</span>. השוויון הזה מלמד אותי ש-<span class="math">\(Y_{n}=\sigma\sqrt{n}Z_{n}+n\mu\)</span>, כך שאני מצפה שקירוב טוב אל <span class="math">\(Y_{n}\)</span> (שהוא המשתנה המקרי שהופיע בהיסטוגרמות שלי) יהיה <span class="math">\(\sigma\sqrt{n}N\left(0,1\right)+n\mu=N\left(n\mu,\sigma\sqrt{n}\right)\)</span>, וזו העקומה שציירתי בפועל. זה מסביר מאיפה האיורים שלי הגיעו אבל עדיין לא ברור למה משפט הגבול המרכזי נראה כמו שהוא נראה; לי למשל מפריע שהחלוקה היא ב-<span class="math">\(\sqrt{n}\)</span> ולא ב-<span class="math">\(n\)</span> כמו שעושים בחוק המספרים הגדולים. בהוכחה של משפט הגבול המרכזי אנחנו נראה למה הדברים הללו הם כמות שהם.</p>
<h2>פונקציות יוצרות מומנטים</h2>

<p>הכלי הטכני המרכזי שבו משתמשים בהוכחה הוא מושג שטרם הזכרתי בסדרת הפוסטים הזו: <strong>פונקציה יוצרת מומנטים</strong>. מה זה מומנטים כן הזכרתי, בחטף: עבור משתנה מקרי <span class="math">\(X\)</span>, <strong>המומנטים</strong> שלו הם הערכים המספריים <span class="math">\(\text{E}\left[X^{n}\right]\)</span> עבור <span class="math">\(n=1,2,\ldots\)</span>. עבור <span class="math">\(n=1\)</span> המומנט הוא פשוט התוחלת, וראינו שעבור <span class="math">\(n=2\)</span> המומנט הוא פשוט השונות ועוד התוחלת בריבוע (כי <span class="math">\(\text{Var}\left(X\right)=\text{E}\left[X^{2}\right]-\text{E}\left[X\right]^{2}\)</span>), אבל לא דיברתי על המומנטים עבור חזקות גבוהות יותר. הרעיון הוא שסדרת המומנטים של משתנה מקרי היא כמו ה-DNA שלו: מכילה כמות גדולה כל כך של מידע עליו שאפשר להסיק ממנה דברים מאוד לא טריוויאליים, גם אם היא לבדה לא כל הסיפור.</p>
<p>עוד מושג מאוד מועיל במתמטיקה, <a href="https://gadial.net/2011/08/07/generating_functions_hardcore_1/">שכבר הזכרתי</a> בבלוג כמה פעמים, הוא <strong>פונקציה יוצרת</strong>. הרעיון בפונקציה יוצרת הוא זה: אם יש לנו סדרה מעניינת של מספרים, <span class="math">\(a_{0},a_{1},a_{2},\ldots\)</span>, אחד מהקסמים שאנחנו יכולים לעשות הוא "לשתול" את המספרים הללו בתור מקדמים של טור חזקות, <span class="math">\(\sum_{n=0}^{\infty}a_{n}x^{n}\)</span> ואז פתאום אנחנו מסוגלים לעשות עם הטור הזה מניפולציות מעניינות שמתורגמות לפעולות לא טריוויאליות על כל סדרת המספרים בבת אחת. זה כלי חזק ומרהיב.</p>
<p>על הרעיון הבסיסי הזה יש כמה וריאציות מועילות, ואחת מהן היא מה שנקרא <strong>הפונקציה היוצרת האקספוננציאלית</strong> של סדרת המספרים. כאן הרעיון הוא לשתול את המספרים בתוך הטור <span class="math">\(\sum_{n=0}^{\infty}a_{n}\frac{x^{n}}{n!}\)</span> שמזכיר קצת את הטור של פונקציית האקספוננט (עבור הסדרה <span class="math">\(a_{n}=1\)</span> מקבלים בדיוק את הטור של <span class="math">\(e^{x}\)</span>). איכשהו יצא לגמרי במקרה שדיברתי על הפונקציה הזו <a href="https://gadial.net/2024/12/18/bernoulli_numbers/">באחד מהפוסטים האחרונים</a> בבלוג; זה לא יצא ככה בכוונה, פשוט היא כל כך מועילה שהיא מתעקשת לצוץ בשני הקשרים שונים כמעט בו זמנית (אחרי שמעולם לא כתבתי עליה קודם בבלוג לדעתי אבל נעזוב את זה).</p>
<p>מה שנקרא בתורת ההסתברות <strong>פונקציה יוצרת מומנטים</strong> הוא בדיוק זה - הפונקציה היוצרת האקספוננציאלית של סדרת המומנטים, אם כי נוח להגדיר אותה בצורה קצת שונה. ראשית, אני אשתמש במשתנה <span class="math">\(t\)</span> כדי לא לבלבל עם המשתנה המקרי <span class="math">\(X\)</span> שהוא מרכז הדיון שלנו. עכשיו, עם משתנה מקרי אפשר כזכור להשתגע בשלל צורות, כי בסופו של דבר מדובר במשהו שמחזיר מספרים ממשיים אז אפשר לעשות איתו דברים שאנחנו עושים עם מספרים ממשיים - למשל להסתכל על <span class="math">\(e^{X}\)</span>, שזה פשוט משתנה מקרי שאומר "תגריל תוצאה כלשהי, תבדוק מה הערך ש-<span class="math">\(X\)</span> נותן על התוצאה הזו, תעלה את <span class="math">\(e\)</span> בחזקת הערך הזה". כדי לעשות את זה מעניין אני יכול גם לדחוף פנימה ערך מספרי <span class="math">\(t\)</span> כלשהו שאני מתייחס אליו כפרמטר ומכפיל אותו ב-<span class="math">\(X\)</span>, כלומר אני מסתכל על המשתנה המקרי <span class="math">\(e^{tX}\)</span>. אם זה משתנה מקרי, אפשר לחשב את התוחלת שלו, והיא תהיה תלויה בפרמטר <span class="math">\(t\)</span>, כלומר קיבלנו <strong>פונקציה</strong></p>
<p><span class="math">\(M\left(t\right)=\text{E}\left[e^{tX}\right]\)</span></p>
<p>זו הפונקציה יוצרת המומנטים, ואנחנו ליטרלי יכולים להשתמש בה כדי <strong>ליצור</strong> את המומנטים על ידי "חילוץ" המקדמים מתוך הטור של <span class="math">\(e^{tX}\)</span> על ידי גזירה, כמו שקורה בחדו"א עם מה שנקרא <strong>טור טיילור</strong>. הנה איך שזה עובד:</p>
<p><span class="math">\(M^{\prime}\left(t\right)=\left(\text{E}\left[e^{tX}\right]\right)^{\prime}=\text{E}\left[\left(e^{tX}\right)^{\prime}\right]=\text{E}\left[Xe^{tX}\right]\)</span></p>
<p>אוקיי, קצת מיהרתי פה. אני מבצע <strong>החלפה</strong> בין אופרטור התוחלת ואופרטור הגזירה במעבר האמצעי - למה זה מעבר לגיטימי? אם פותחים את ההגדרה של התוחלת במקרה הסופי מקבלים</p>
<p><span class="math">\(\text{E}\left[e^{tX}\right]=\sum_{i=1}^{k}P\left(X=a_{i}\right)e^{ta_{i}}\)</span></p>
<p>ואפשר להשתמש בכך שנגזרת היא לינארית, כלומר <span class="math">\(\left(f+g\right)^{\prime}=f^{\prime}+g^{\prime}\)</span>, מה שניתן להכללה באינדוקציה לכל סכום סופי, ולכן </p>
<p><span class="math">\(\left[\sum_{i=1}^{k}P\left(X=a_{i}\right)e^{ta_{i}}\right]^{\prime}=\sum_{i=1}^{k}P\left(X=a_{i}\right)\left(e^{ta_{i}}\right)^{\prime}=\sum_{i=1}^{k}P\left(X=a_{i}\right)a_{i}e^{ta_{i}}\)</span></p>
<p>וקיבלנו בדיוק את הביטוי של <span class="math">\(\text{E}\left[Xe^{tX}\right]\)</span>.</p>
<p>העניין הוא שמה שעובד עבור סכום <strong>סופי</strong> לא בהכרח עובד במקרה של סכום אינסופי, או במקרה הרציף שבו התוחלת היא אינטגרל. כלומר, את הקסם הזה אי אפשר לעשות <strong>לכל</strong> משתנה מקרי אלא רק לכאלו שהם "נחמדים מספיק", אבל בואו לא ניכנס לתנאים המדויקים הפעם. במקום זה, בואו נראה איך אפשר להשתמש בזה: אם <span class="math">\(M^{\prime}\left(t\right)=\text{E}\left[Xe^{tX}\right]\)</span> אז <span class="math">\(M^{\prime}\left(0\right)=\text{E}\left[X\right]\)</span> וקיבלנו את המומנט הראשון.</p>
<p>עכשיו, אפשר להמשיך לגזור את <span class="math">\(Xe^{tX}\)</span>. מכיוון שהנגזרת היא על פי <span class="math">\(t\)</span>, ה-<span class="math">\(X\)</span> שבו מוכפל <span class="math">\(e^{tX}\)</span> הוא בסך הכל קבוע, ולכן מקבלים</p>
<p><span class="math">\(M^{\prime\prime}\left(t\right)=\text{E}\left[X^{2}e^{tX}\right]\)</span></p>
<p>כלומר</p>
<p><span class="math">\(M^{\prime\prime}\left(0\right)=\text{E}\left[X^{2}\right]\)</span></p>
<p>ובאופן כללי נקבל <span class="math">\(M^{\left(i\right)}=\text{E}\left[X^{i}\right]\)</span>. זה בדיוק מה שקורה גם כשגוזרים את הטור <span class="math">\(\sum_{n=0}^{\infty}a_{n}\frac{x^{n}}{n!}\)</span> בדיוק <span class="math">\(i\)</span> פעמים ומציבים <span class="math">\(x=0\)</span>; מקבלים את <span class="math">\(a_{i}\)</span>.</p>
<p>איך כל זה מתקשר למשפט הגבול המרכזי? עם הטענה הבאה: אם יש לנו סדרה <span class="math">\(Z_{1},Z_{2},\ldots\)</span> של משתנים מקריים עם פונקציות צפיפות <span class="math">\(F_{Z_{n}}\)</span> ופונקציות יוצרות הסתברות <span class="math">\(M_{Z_{n}}\)</span>, ואם <span class="math">\(Z\)</span> הוא משתנה מקרי עם פונקציית צפיפות <span class="math">\(F_{Z}\)</span> ופונקציה יוצרת הסתברות <span class="math">\(M_{Z}\)</span>, אז אם מתקיים <span class="math">\(\lim_{n\to\infty}M_{Z_{n}}\left(t\right)=M_{Z}\left(t\right)\)</span> עבור כל <span class="math">\(t\)</span>, אז <span class="math">\(F_{Z_{n}}\left(t\right)\to F_{Z}\left(t\right)\)</span> עבור כל <span class="math">\(t\)</span> שעבורו <span class="math">\(F_{Z}\left(t\right)\)</span> רציפה. במילים אחרות - מספיק לנו להראות שאיפה של סדרת הפונקציות יוצרות המומנטים כדי להראות שאיפה של פונקציות הצפיפות, שהן לכאורה האובייקט המורכב יותר.</p>
<p>הטענה הזו היא טענה <strong>כבדה</strong>. כדי להוכיח אותה אני אצטרך כנראה פוסט שלם (או אפילו יותר) ולהיכנס למתמטיקה טכנית יותר מאשר אני רוצה כרגע. המטרה שלי בפוסטים הללו היא לראות איך זה שהתפלגות נורמלית היא מה שהיא גורר את משפט הגבול המרכזי; אז בואו נראה איך טענת העזר הזו מוכיחה לנו את משפט הגבול המרכזי.</p>
<h2>הוכחת משפט הגבול המרכזי</h2>

<p>בואו נזכיר שוב מה אנחנו רוצים להוכיח. אנחנו לוקחים סדרה <span class="math">\(X_{1},X_{2},\ldots\)</span> של משתנים מקריים בלתי תלויים שמתפלגים באותו אופן, עם תוחלת <span class="math">\(\mu\)</span> וסטיית תקן <span class="math">\(\sigma\)</span>, מגדירים</p>
<p><span class="math">\(Z_{n}=\frac{X_{1}+\ldots+X_{n}-n\mu}{\sigma\sqrt{n}}\)</span></p>
<p>ומקבלים שהסדרה <span class="math">\(Z_{n}\)</span> שואפת להתפלגות הנורמלית <span class="math">\(N\left(0,1\right)\)</span> כאשר <span class="math">\(n\)</span> שואף לאינסוף. מה שנוכיח הוא את המשפט למקרה שבו <span class="math">\(\mu=0,\sigma=1\)</span>, כי אפשר לבצע רדוקציה מהמקרה הכללי למקרה הזה: אם נגדיר <span class="math">\(Y_{i}=\frac{X_{i}-\mu}{\sigma}\)</span> אז נקבל שהתוחלת של <span class="math">\(Y_{i}\)</span> היא 0 וסטיית התקן היא 1, ולכן <span class="math">\(\frac{Y_{i}+\ldots+Y_{n}}{\sqrt{n}}\)</span> שואפת אל <span class="math">\(N\left(0,1\right)\)</span>. עכשיו נציב את <span class="math">\(Y_{i}=\frac{X_{i}-\mu}{\sigma}\)</span> בביטוי <span class="math">\(\frac{Y_{i}+\ldots+Y_{n}}{\sqrt{n}}\)</span> ששואף ל-<span class="math">\(N\left(0,1\right)\)</span> ונקבל את הביטוי <span class="math">\(\frac{X_{1}+\ldots+X_{n}-n\mu}{\sigma\sqrt{n}}\)</span> שגם שואף ל-<span class="math">\(N\left(0,1\right)\)</span> כי זה אותו ביטוי.</p>
<p>אם כן, מעתה והלאה נניח <span class="math">\(\mu=0\)</span> ו-<span class="math">\(\sigma=1\)</span> ולכן <span class="math">\(Z_{n}=\frac{X_{1}+\ldots+X_{n}}{\sqrt{n}}=\frac{X_{1}}{\sqrt{n}}+\ldots+\frac{X_{n}}{\sqrt{n}}\)</span>. המטרה שלי היא למצוא את <span class="math">\(M_{Z_{n}}\left(t\right)\)</span> - הפונקציה יוצרת המומנטים של <span class="math">\(Z_{n}\)</span>, ולראות לאן היא שואפת (כשאני אראה לאן היא שואפת זה מה ש<strong>יכתיב</strong> לי את האופן שבו התפלגות נורמלית אמורה להיראות). מכיוון שהצגתי את <span class="math">\(Z_{n}\)</span> בתור סכום סופי, בואו קודם נראה איך הפונקציה יוצרת המומנטים של כל איבר בסכום נראית. </p>
<p>ראשית, עבור <span class="math">\(X_{i}\)</span>, הפונקציה יוצרת המומנטים שלו היא <span class="math">\(M\left(t\right)=\text{E}\left[e^{tX_{i}}\right]\)</span>. שנית, עבור האיבר המנורמל <span class="math">\(\frac{X_{i}}{\sqrt{n}}\)</span> הפונקציה יוצרת המומנטים היא <span class="math">\(\text{E}\left[e^{t\frac{X_{i}}{\sqrt{n}}}\right]=\text{E}\left[e^{\frac{t}{\sqrt{n}}X_{i}}\right]=M\left(\frac{t}{\sqrt{n}}\right)\)</span>. ולכן עכשיו נקבל</p>
<p><span class="math">\(M_{Z_{n}}\left(t\right)=\text{E}\left[e^{tZ_{n}}\right]=\text{E}\left[e^{t\sum_{i=1}^{n}\frac{X_{i}}{\sqrt{n}}}\right]=\text{E}\left[\prod_{i=1}^{n}e^{t\frac{X_{i}}{\sqrt{n}}}\right]\)</span></p>
<p>כי זה הקסם של אקספוננט - סכום במעריך הופך למכפלת אקספוננטים (על פי כללי החזקות: <span class="math">\(e^{a+b}=e^{a}\cdot e^{b}\)</span>).</p>
<p>עכשיו, זה <strong>בהחלט לא נכון</strong> באופן כללי שתוחלת של מכפלה היא מכפלת התוחלות, כלומר <span class="math">\(\text{E}\left[XY\right]\ne\text{E}\left[X\right]\text{E}\left[Y\right]\)</span> באופן כללי, וזה די ברור - אם זה היה נכון, היינו מקבלים ש-<span class="math">\(\text{E}\left[X^{2}\right]=\text{E}\left[X\right]^{2}\)</span> וכל מושג סטיית התקן היה נעלם. אבל השוויון <span class="math">\(\text{E}\left[XY\right]=\text{E}\left[X\right]\text{E}\left[Y\right]\)</span> דווקא <strong>כן נכון</strong> אם <span class="math">\(X,Y\)</span> הם משתנים מקריים בלתי תלויים, וזה בדיוק מה שאני מניח כאן - שכל אברי הסדרה <span class="math">\(X_{1},X_{2},\ldots,X_{n}\)</span> הם בלתי תלויים, ולכן גם המשתנים <span class="math">\(e^{t\frac{X_{i}}{\sqrt{n}}}\)</span> שנבנים מתוכם. כך שאני מקבל:</p>
<p><span class="math">\(\text{E}\left[\prod_{i=1}^{n}e^{t\frac{X_{i}}{\sqrt{n}}}\right]=\prod_{i=1}^{n}\text{E}\left[e^{t\frac{X_{i}}{\sqrt{n}}}\right]=\prod_{i=1}^{n}M\left(\frac{t}{\sqrt{n}}\right)=\left[M\left(\frac{t}{\sqrt{n}}\right)\right]^{n}\)</span></p>
<p>אז מה שאנחנו רוצים להבין הוא את הגבול <span class="math">\(\lim_{n\to\infty}\left[M\left(\frac{t}{\sqrt{n}}\right)\right]^{n}\)</span>. זה בעצם המקום הראשון שבו קופץ לעיניים למה "צריך" ש-<span class="math">\(e\)</span> יופיע בהתפלגות נורמלית. כזכור, אחת מהדרכים השקולות לתאר את <span class="math">\(e^{x}\)</span> היא באמצעות גבול: <span class="math">\(e^{x}=\lim_{n\to\infty}\left(1+\frac{x}{n}\right)^{n}\)</span>, אז העובדה שיש לנו בביטוי <span class="math">\(\lim_{n\to\infty}\left[M\left(\frac{t}{\sqrt{n}}\right)\right]^{n}\)</span> גבול שתלוי ב-<span class="math">\(n\)</span>, חזקה שהיא <span class="math">\(n\)</span> ואיבר פנימי שהוא <span class="math">\(\frac{t}{\sqrt{n}}\)</span> זה... מעורר חשד. </p>
<p>עכשיו, איך מטפלים בביטוי <span class="math">\(\left[M\left(\frac{t}{\sqrt{n}}\right)\right]^{n}\)</span>? ה-<span class="math">\(n\)</span> במעריך הוא מעצבן, והדרך הסטנדרטית להיפטר ממנו היא לקחת לוגריתם להכל, כי <span class="math">\(\left(a^{n}\right)=n\log a\)</span><span class="math">\(\log\)</span>. אז בואו נשאל את עצמנו מהו הגבול</p>
<p><span class="math">\(\lim_{n\to\infty}n\log M\left(\frac{t}{\sqrt{n}}\right)\)</span></p>
<p>אם הגבול הזה יהיה <span class="math">\(A\)</span> והלוגריתם שלי הוא על בסיס <span class="math">\(a\)</span>, אז הגבול של <span class="math">\(\lim_{n\to\infty}\left[M\left(\frac{t}{\sqrt{n}}\right)\right]^{n}\)</span> יהיה <span class="math">\(a^{A}\)</span>. איזה בסיס של לוגריתם <strong>כדאי לי</strong> לבחור? אני לא רוצה שיהיו לי החלטות שרירותיות, אז בואו נתקדם עם ההוכחה ונראה איזה בסיס יצוץ מאליו (ספוילר: <span class="math">\(e\)</span>. זה תמיד <span class="math">\(e\)</span>).</p>
<p>אם כן, הביטוי שאנחנו צריכים להבין עכשיו הוא הפונקציה <span class="math">\(\log M\left(\frac{t}{\sqrt{n}}\right)\)</span>. הכל נהיה פשוט יותר אחרי שיש לנו סימונים, אז נסמן: <span class="math">\(L\left(t\right)=\log M\left(t\right)\)</span>, ועכשיו אנחנו רוצים להבין את הגבול <span class="math">\(\lim_{n\to\infty}nL\left(\frac{t}{\sqrt{n}}\right)\)</span>. איך עושים את זה? אין לי מושג, אבל לגשש בצורה עיוורת אפשר, ואחד מהכלים המועילים שיש לנו בחישוב גבולות הוא <strong>כלל לופיטל</strong>. הרעיון בו פשוט: אם <span class="math">\(f\left(x\right),g\left(x\right)\)</span> הן שתי פונקציות כך ש-<span class="math">\(\lim_{x\to\infty}f\left(x\right)=\lim_{x\to\infty}g\left(x\right)=0\)</span> אז <span class="math">\(\lim_{x\to\infty}\frac{f\left(x\right)}{g\left(x\right)}=\lim_{x\to\infty}\frac{f^{\prime}\left(x\right)}{g^{\prime}\left(x\right)}\)</span>. כלומר, בדומה לאינטגרציה בחלקים שבה השתמשתי בפוסט הקודם, גם כאן אפשר לחשב דברים על ידי גזירה של הפונקציות הרלוונטיות עד שיהיו פשוטות מספיק.</p>
<p>אצלנו הגבול הוא לא של פונקציות אלא של סדרה, אבל כל עוד הפונקציות המעורבות הן רציפות מקבלים אותו דבר. אבל בשביל להשתמש בלופיטל אנחנו צריכים <strong>מנה </strong>של שתי פונקציות ששואפות לאפס: אצלנו יש <strong>מכפלה</strong> של שתי פונקציות, <span class="math">\(nL\left(\frac{t}{\sqrt{n}}\right)\)</span>, שאחת מהן (<span class="math">\(n\)</span>) בכלל שואפת לאינסוף... אה, הטריק פה הוא פשוט מאוד: <span class="math">\(nL\left(\frac{t}{\sqrt{n}}\right)=\frac{L\left(\frac{t}{\sqrt{n}}\right)}{n^{-1}}\)</span>, ועכשיו הפונקציה במכנה היא <span class="math">\(\frac{1}{n}\)</span> ששואפת לאפס כש-<span class="math">\(n\to\infty\)</span>. ומה קורה במונה? הרציפות של <span class="math">\(L\)</span> אומרת ש-<span class="math">\(L\left(\frac{t}{\sqrt{n}}\right)\to L\left(0\right)\)</span>, אבל מהו <span class="math">\(L\left(0\right)\)</span>? ומה נקבל אחרי שנגזור?</p>
<p>ובכן, כזכור <span class="math">\(L\left(t\right)=\log M\left(t\right)\)</span>. מכיוון ש-<span class="math">\(M\left(t\right)=\text{E}\left[e^{tX_{i}}\right]\)</span> הרי ש-<span class="math">\(M\left(0\right)=\text{E}\left[e^{0\cdot X_{i}}\right]=\text{E}\left[1\right]=1\)</span> כך ש-<span class="math">\(L\left(0\right)=\log1=0\)</span>. זה טוב, זה בדיוק מה שאנחנו רוצים. עכשיו, מה עם הנגזרת? יש לנו כאן עסק עם הרכבה של פונקציות: <span class="math">\(\log\)</span> שמורכבת על <span class="math">\(M\)</span>. זה מצריך מאיתנו שני דברים: את הכלל של נגזרת של לוגריתם, ואת כלל השרשרת. והכלל לנגזרת של לוגריתם הוא</p>
<p><span class="math">\(\left(\log_{a}t\right)^{\prime}=\frac{1}{t\ln a}\)</span>, כאשר <span class="math">\(\ln\)</span> הוא לוגריתם על בסיס <span class="math">\(e\)</span>. הביטוי הזה הופך לפשוט יותר אם מלכתחילה הלוגריתם שלנו הוא על בסיס <span class="math">\(e\)</span>; אז מקבלים <span class="math">\(\left(\log t\right)^{\prime}=\frac{1}{t}\)</span>. אז יש לנו סיבה טובה לבחור שהלוגריתם שלנו יהיה על בסיס <span class="math">\(e\)</span>, מה שאומר שאחרי שנצליח לחשב את <span class="math">\(\lim_{n\to\infty}n\log M\left(\frac{t}{\sqrt{n}}\right)=A\)</span>, נקבל ש-<span class="math">\(\lim_{n\to\infty}\left[M\left(\frac{t}{\sqrt{n}}\right)\right]^{n}=e^{A}\)</span>.</p>
<p>עכשיו, על פי כלל השרשרת <span class="math">\(\left[f\left(g\left(x\right)\right)\right]^{\prime}=f^{\prime}\left(g\left(x\right)\right)g^{\prime}\left(x\right)\)</span> אנחנו מקבלים</p>
<p><span class="math">\(L^{\prime}=\left(\log M\right)^{\prime}=\frac{M^{\prime}}{M}\)</span> (יש לדבר כזה שם - "הנגזרת הלוגריתמית" של <span class="math">\(M\)</span>)</p>
<p>ראינו כבר ש-<span class="math">\(M\left(0\right)=1\)</span>. כמו כן, <span class="math">\(M^{\prime}\left(0\right)=\text{E}\left[X\right]=\mu=0\)</span> (זוכרים? ראינו שככה פונקציה יוצרת מומנטים עובדת). אז קיבלנו ש-<span class="math">\(L^{\prime}\left(0\right)=0\)</span>, מה שאומר שכלל לופיטל צפוי להיתקל בקשיים כי גם אחרי הגזירה המונה ישאף ל-0. אבל אפשר לגזור שוב! הפעם נשתמש בכלל לגזירה של מנה, <span class="math">\(\left(\frac{f}{g}\right)^{\prime}=\frac{f^{\prime}g-fg^{\prime}}{g^{2}}\)</span> ונקבל</p>
<p><span class="math">\(L^{\prime\prime}=\left(\frac{M^{\prime}}{M}\right)^{\prime}=\frac{M^{\prime\prime}M-\left(M^{\prime}\right)^{2}}{M^{2}}\)</span></p>
<p>ולכן כשנציב <span class="math">\(0\)</span> ונשתמש בכך ש-<span class="math">\(M\left(0\right)=1,M^{\prime}\left(0\right)=0,M^{\prime\prime}\left(0\right)=\text{E}\left[X^{2}\right]=\sigma^{2}+\mu^{2}=1\)</span>, נקבל</p>
<p><span class="math">\(L^{\prime\prime}\left(0\right)=\frac{1-0^{2}}{1}=1\)</span></p>
<p>וזה כבר משהו לעבוד איתו! כל מה שנשאר לנו הוא לקחת את הביטוי <span class="math">\(\frac{L\left(\frac{t}{\sqrt{n}}\right)}{n^{-1}}\)</span> ולגזור בו (בנפרד!) את המונה והמכנה פעמיים. זה לא יהיה כזה נורא, נכון? נקודה אחת שצריך לשים לב אליה היא שהגזירה שלנו היא ביחס למשתנה <span class="math">\(n\)</span>, ואילו דווקא אל <span class="math">\(t\)</span> אנחנו מתייחסים בתור קבוע, כי הגבול שלנו הוא כש-<span class="math">\(n\)</span> רץ לאינסוף. זה הופך את הכל לטיפה יותר מסובך.</p>
<p>כלל הגזירה הבסיסי ביותר הוא <span class="math">\(\left(x^{a}\right)^{\prime}=ax^{a-1}\)</span>. מכאן נקבל ש-<span class="math">\(\left(n^{-1}\right)^{\prime}=-n^{-2}\)</span> וש-<span class="math">\(\left(\frac{1}{\sqrt{n}}\right)^{\prime}=\left(n^{-\frac{1}{2}}\right)^{\prime}=-\frac{1}{2}n^{-\frac{3}{2}}\)</span>.</p>
<p>הנגזרת של <span class="math">\(L\left(\frac{t}{\sqrt{n}}\right)\)</span> על פי כלל השרשרת היא <span class="math">\(\left(\frac{t}{\sqrt{n}}\right)^{\prime}L^{\prime}\left(\frac{t}{\sqrt{n}}\right)=-\frac{t}{2}n^{-\frac{3}{2}}L^{\prime}\left(\frac{t}{\sqrt{n}}\right)\)</span> , ולכן מכלל לופיטל אנחנו מקבלים</p>
<p><span class="math">\(\lim_{n\to\infty}\frac{L\left(\frac{t}{\sqrt{n}}\right)}{n^{-1}}=\lim_{n\to\infty}\frac{-\frac{t}{2}n^{-\frac{3}{2}}L^{\prime}\left(\frac{t}{\sqrt{n}}\right)}{-n^{-2}}=\lim_{n\to\infty}\frac{tL^{\prime}\left(\frac{t}{\sqrt{n}}\right)}{2n^{-1/2}}\)</span></p>
<p>המונה עדיין שואף לאפס כש-<span class="math">\(n\to\infty\)</span> (כי ראינו <span class="math">\(L^{\prime}\left(0\right)=0\)</span>) והמכנה, שהוא עכשיו <span class="math">\(-\frac{2}{\sqrt{n}}\)</span>, גם כן שואף לאפס, אז אפשר להשתמש שוב בכלל לופיטל. הנגזרת של המכנה תהיה <span class="math">\(\left(2n^{-\frac{1}{2}}\right)^{\prime}=-n^{-\frac{3}{2}}\)</span>. המונה יהיה כמו קודם (אל ה-<span class="math">\(t\)</span> שמופיע שם אנחנו כאמור מתייחסים בתור קבוע והוא לא משפיע על הגזירה). לכן נקבל מכלל לופיטל</p>
<p><span class="math">\(\lim_{n\to\infty}\frac{tL^{\prime}\left(\frac{t}{\sqrt{n}}\right)}{2n^{-1/2}}=\lim_{n\to\infty}\frac{-\frac{t^{2}}{2}n^{-\frac{3}{2}}L^{\prime\prime}\left(\frac{t}{\sqrt{n}}\right)}{-n^{-3/2}}=\lim_{n\to\infty}\frac{t^{2}}{2}L^{\prime\prime}\left(\frac{t}{\sqrt{n}}\right)\)</span></p>
<p>הופה! העלמנו לגמרי את מה שהופיע במכנה! ועכשיו, בגלל ש-<span class="math">\(L^{\prime\prime}\left(0\right)=1\)</span>, אנחנו מקבלים גבול פשוט במיוחד: <span class="math">\(\lim_{n\to\infty}\frac{t^{2}}{2}L^{\prime\prime}\left(\frac{t}{\sqrt{n}}\right)=\frac{t^{2}}{2}\)</span>. זה אומר שמצאנו את מה שהפונקציה יוצרת המומנטים של <span class="math">\(Z_{n}\)</span> שואפת אליו: <span class="math">\(\lim_{n\to\infty}M_{Z_{n}}\left(t\right)=e^{\frac{t^{2}}{2}}\)</span>. זה, סוף כל סוף, מסביר מאיפה מגיע <span class="math">\(e^{\frac{t^{2}}{2}}\)</span> להתפלגות הנורמלית - לפחות מבחינה טכנית - אם כי יש עוד שלב לא טריוויאלי אחד שצריך להתגבר עליו.</p>
<h2>הפונקציה יוצרת המומנטים של התפלגות נורמלית</h2>

<p>ההוכחה עדיין לא בדיוק הסתיימה. מה שהראיתי הוא שאם <span class="math">\(Z\)</span> הוא משתנה מקרי עם פונקציה יוצרת מומנטים <span class="math">\(M_{Z}\left(t\right)=e^{\frac{t^{2}}{2}}\)</span> אז הפונקציה יוצרת המומנטים של אברי הסדרה <span class="math">\(Z_{n}\)</span> תתכנס לפונקציה יוצרת המומנטים של <span class="math">\(Z\)</span>. המסקנה, מטענת העזר שציטטתי בלי הוכחה, היא ש-<span class="math">\(F_{Z_{n}}\left(t\right)\)</span> מתכנסת אל <span class="math">\(F_{Z}\left(t\right)\)</span>. אבל מהי פונקציית הצפיפות <span class="math">\(F_{Z}\left(t\right)\)</span>? זה השלב שבו צריך לקחת את ההתפלגות הנורמלית, לחשב את הפונקציה יוצרת המומנטים שלה ולקבל <span class="math">\(e^{\frac{t^{2}}{2}}\)</span>. זה חישוב די פשוט בהינתן כל החישובים שכבר עברנו, אבל יש כאן גם שאלה מעניינת - האם אפשר ללכת "בכיוון השני"? להתחיל מהשוויון שצריך להתקיים ולהסיק איך ההתפלגות הנורמלית אמורה להיראות?</p>
<p>באופן כללי אני יכול לסמן <span class="math">\(F_{Z}\left(z\right)=f\left(z\right)\)</span> ואז להשתמש בשוויון <span class="math">\(e^{t^{2}/2}=\text{E}\left[e^{tZ}\right]\)</span> כש-<span class="math">\(\text{E}\left[e^{tZ}\right]\)</span> הוא מה ש<strong>מגדיר</strong> את הפונקציה יוצרת המומנטים, ולקבל שאני צריך שיתקיים השוויון </p>
<p><span class="math">\(e^{t^{2}/2}=\int_{-\infty}^{\infty}e^{tz}f\left(z\right)dz\)</span></p>
<p>הדבר הזה נקרא <strong>משוואה אינטגרלית</strong>: בדומה למשוואה דיפרנציאלית, זו משוואה שבה הנעלם הוא לא סתם ערך מספרי אלא <strong>פונקציה</strong>, והמידע שיש לנו על הפונקציה הזו מערב אינטגרל שלה. כמו עם משוואות דיפרנציאליות, פתרון משוואות אינטגרליות זה עניין מסובך והרבה פעמים לומר "אוקיי, בואו ננחש שהפתרון הוא מהצורה כך וכך..." הוא לגיטימי, אבל עבור המשוואה שלעיל דווקא יש שיטת פתרון כללית, פחות או יותר, בעזרת מה שנקרא <strong>התמרת לפלס</strong>. להיכנס לזה לוקח אותי רחוק מדי ממה שאפשר לדבר עליו במרוכז כאן, אז בואו ננקוט בגישה השניה: נתחיל עם ההגדרה הידועה של <span class="math">\(f\left(z\right)\)</span> עבור התפלגות נורמלית ונראה שאנחנו מקבלים את השוויון למעלה. החישובים הספציפיים שנצטרך לבצע הם דומים למדי לחישובים שצריך לעשות אם פותרים את המשוואה האינטגרלית.</p>
<p>אם כן, <span class="math">\(f\left(z\right)=\frac{1}{\sqrt{2\pi}}e^{-z^{2}/2}\)</span>, ולכן אנחנו מחשבים את האינטגרל</p>
<p><span class="math">\(\frac{1}{\sqrt{2\pi}}\int_{-\infty}^{\infty}e^{tz}e^{-z^{2}/2}dz\)</span></p>
<p>לב העניין הוא מה שהולך בחזקה של <span class="math">\(e\)</span>. בהתחלה כתוב שם</p>
<p><span class="math">\(tz-\frac{z^{2}}{2}\)</span></p>
<p>לב הרעיון הטכני (גם פה וגם בגישת המשוואה האינטגרלית) הוא <strong>להשלים לריבוע</strong> את הביטוי הזה; להכניס את ה-<span class="math">\(z\)</span>-ים בצורה יפה לסוגריים שאותם מעלים בריבוע, ואולי להוציא החוצה איזה קבוע שקשור ל-<span class="math">\(t\)</span>. זו בדיוק אותה השלמה לריבוע שאיתה גם פותרים משוואה ריבועית, <a href="https://gadial.net/2023/12/16/quadratic_equations/">כמו שהראיתי</a> פעם בבלוג.</p>
<p>אז ראשית, בואו נעשה חישובון:</p>
<p><span class="math">\(tz-\frac{z^{2}}{2}=-\frac{1}{2}\left(z^{2}-2tz\right)\)</span></p>
<p>מה שבתוך הסוגריים כבר די קרוב למשהו ריבועי! רק צריך להוסיף ולחסר <span class="math">\(t^{2}\)</span>:</p>
<p><span class="math">\(-\frac{1}{2}\left(z^{2}-2tz\right)=-\frac{1}{2}\left(z^{2}-2tz+t^{2}-t^{2}\right)=\frac{t^{2}}{2}-\frac{1}{2}\left(z-t\right)^{2}\)</span></p>
<p>בום! ה-<span class="math">\(\frac{t^{2}}{2}\)</span> שקיבלנו יהיה בדיוק אותו <span class="math">\(\frac{t^{2}}{2}\)</span> ב-<span class="math">\(e^{t^{2}/2}\)</span> שאנחנו מצפים לקבל בסוף הדרך. בואו נחזור אל האינטגרל:</p>
<p><span class="math">\(\frac{1}{\sqrt{2\pi}}\int_{-\infty}^{\infty}e^{tz}e^{-z^{2}/2}dz=\frac{1}{\sqrt{2\pi}}\int_{-\infty}^{\infty}e^{t^{2}/2-\left(z-t\right)^{2}/2}dz\)</span></p>
<p>עכשיו אפשר להוציא את הקבוע החוצה, תוך שימוש בכך ש-<span class="math">\(e^{a-b}=e^{a}e^{-b}\)</span>:</p>
<p><span class="math">\(\frac{1}{\sqrt{2\pi}}\int_{-\infty}^{\infty}e^{t^{2}/2-\left(z-t\right)^{2}/2}dz=e^{t^{2}/2}\frac{1}{\sqrt{2\pi}}\int_{-\infty}^{\infty}e^{-\left(z-t\right)^{2}/2}dz\)</span></p>
<p>את האינטגרל <span class="math">\(\frac{1}{\sqrt{2\pi}}\int_{-\infty}^{\infty}e^{-\left(z-t\right)^{2}/2}dz\)</span> אנחנו כבר יודעים לחשב; שברנו עליו את הראש כשרצינו להוכיח שפונקציית הצפיפות של ההתפלגות הנורמלית מסתכמת ל-1. העובדה שאנחנו צריכים לעבור דרכו היא "חוק שימור הקושי" - גם אם הייתי מנסה ללכת דרך משוואות אינטגרליות הייתי צריך לצלול בים טכני של טענות כלליות על הלהטוטים שאנחנו יכולים לעשות במסגרת חדו"א; למזלי בגישה הנוכחית אני יכול פשוט לומר שכבר עשינו את זה. מה שראינו היה <span class="math">\(\frac{1}{\sqrt{2\pi}}\int_{-\infty}^{\infty}e^{-\frac{x^{2}}{2}}dx=1\)</span>, וזה בדיוק אותו הדבר כמו אצלנו עד כדי החלפת המשתנה <span class="math">\(x=z-t\)</span> שלא משפיעה על האינטגרל כי גבולות האינטגרציה הם ממילא מ-<span class="math">\(-\infty\)</span> עד <span class="math">\(\infty\)</span> והיעקוביאן של ההחלפה (שהוא במקרה הזה פשוט נגזרת) יוצא 1.</p>
<h2>ולסיום - אז למה הדברים הם כמו שהם?</h2>

<p>לסיום סדרת הפוסטים הזו, בואו נחזור אל הפונקציה שאותה רצינו להבין: <span class="math">\(f\left(x\right)=\frac{1}{\sqrt{2\pi}\sigma}e^{-\left(x-\mu\right)^{2}/2\sigma^{2}}\)</span>, פונקציית הצפיפות של התפלגות נורמלית. בשלב הזה אנחנו כבר יודעים ש-<span class="math">\(\pi\)</span> כאן כדי להבטיח שהכל יסתכם ל-1, שה-<span class="math">\(\mu\)</span> וה-<span class="math">\(\sigma\)</span> מייצגים את התוחלת וסטיית התקן ואפשר לנרמל אותם החוצה ושהאקספוננט מגיע, בגדול, מזה שהפונקציה שמתארת התנהלות של סכום משתנים מקריים בלתי תלויים ומפולגים אחיד נראית כמו<span class="math">\(\lim_{n\to\infty}\left[M\left(\frac{t}{\sqrt{n}}\right)\right]^{n}\)</span>. וזה בעצם מגיע אל מה שהטריד <strong>אותי</strong> עם משפט הגבול המרכזי: מה זה ה-<span class="math">\(\frac{1}{\sqrt{n}}\)</span> הזה? למה כדי לנרמל מחלקים דווקא בו? מה קרה ל-<span class="math">\(\frac{1}{n}\)</span> הישן והטוב? ולמה לחלק בכלל? בתחילת הפוסט הזכרתי את השימוש שעשיתי במשפט הגבול המרכזי - פשוט חיברתי את ה-<span class="math">\(X_{i}\)</span>-ים שלי וקירבתי את התוצאה הזו עם עקומה נורמלית; בשביל לעשות את זה לא הספיק לדעת רק את <span class="math">\(\mu,\sigma\)</span> אלא הייתי צריך להכניס גם את <span class="math">\(n\)</span> למשוואה: כפלתי ב-<span class="math">\(n\)</span> גם את <span class="math">\(\mu\)</span> וגם את <span class="math">\(\sigma^{2}\)</span> (כלומר, בפועל כפלתי את <span class="math">\(\sigma\)</span> ב-<span class="math">\(\sqrt{n}\)</span> והנה השורש צץ שוב).</p>
<p>אבל מה היה קורה אם מלכתחילה הייתי מנרמל על ידי חלוקה ב-<span class="math">\(n\)</span> ולכן מגיע אל חישוב של <span class="math">\(\lim_{n\to\infty}\left[M\left(\frac{t}{n}\right)\right]^{n}\)</span>? התשובה, כמובן, היא ששום דבר לא היה עובד. כזכור, כדי להתמודד עם הגבול הזה הגדרתי <span class="math">\(L\left(t\right)=\log M\left(t\right)\)</span> ואז חישבתי את הגבול <span class="math">\(\lim_{n\to\infty}nL\left(\frac{t}{\sqrt{n}}\right)\)</span> באמצעות כלל לופיטל. עוד לפני שאומרים לופיטל, כבר ברור שהגבול <span class="math">\(\lim_{n\to\infty}nL\left(\frac{t}{\sqrt{n}}\right)\)</span> קיים בכלל רק בזכות זה שיש פה שני כוחות שונים וסותרים שמאזנים אחד את השני. ה-<span class="math">\(n\)</span> שבו כופלים שואף לאינסוף, בעוד שה-<span class="math">\(L\left(\frac{t}{\sqrt{n}}\right)\)</span> שואף לאפס. בגבולות מהצורה "משהו ששואף לאינסוף כפול משהו ששואף לאפס" פחות או יותר הכל יכול לקרות, והסיכוי שנקבל תוצאה סופית תלוי ביחסים העדינים בין שתי הפונקציות שאותם כופלים. כלל לופיטל הוא בדיוק דרך "לקלף" מעל שתי הפונקציות המעורבות שכבה אחר שכבה של סיבוכיות עד שמגיעים אל הגרעין העדין שלהן שאנחנו יודעים להשוות. ועכשיו חדל פילוסופיה ובואו נדבר תכל'ס. מה היה קורה אם היינו מחלקים ב-<span class="math">\(n\)</span> ולא ב-<span class="math">\(\sqrt{n}\)</span>? (אם לא היינו מחלקים <strong>בכלל</strong> ב-<span class="math">\(n\)</span> אז היינו מקבלים <span class="math">\(\lim_{n\to\infty}L\left(t\right)=L\left(t\right)\)</span> וקבוע כפול אינסוף הוא אינסוף).</p>
<p>בואו נעשה קופי-פייסט מההוכחה שכתבתי קודם ונחליף כל מופע של -<span class="math">\(\sqrt{n}\)</span> ב-<span class="math">\(n\)</span>, עם ההשלכות המתאימות:</p>
<p>הנגזרת של <span class="math">\(L\left(\frac{t}{n}\right)\)</span> על פי כלל השרשרת היא <span class="math">\(\left(\frac{t}{n}\right)^{\prime}L^{\prime}\left(\frac{t}{n}\right)=-tn^{-2}L^{\prime}\left(\frac{t}{n}\right)\)</span> , ולכן מכלל לופיטל אנחנו מקבלים</p>
<p><span class="math">\(\lim_{n\to\infty}\frac{L\left(\frac{t}{n}\right)}{n^{-1}}=\lim_{n\to\infty}\frac{-tn^{-2}L^{\prime}\left(\frac{t}{n}\right)}{-n^{-2}}=\lim_{n\to\infty}tL^{\prime}\left(\frac{t}{n}\right)\)</span></p>
<p>וזה... טוב? נפטרנו לגמרי מהגורם שבמכנה! אבל ראינו קודם ש-<span class="math">\(L^{\prime}\left(0\right)=0\)</span>, כלומר <span class="math">\(\lim_{n\to\infty}tL^{\prime}\left(\frac{t}{n}\right)=0\)</span>, וזה ממש לא טוב לנו. זה אומר שעבור המשתנה המקרי <span class="math">\(Z_{n}=\frac{X_{1}+\ldots+X_{n}}{n}\)</span> מתקיים <span class="math">\(M_{Z}=e^{0}=1\)</span>, ובמילים אחרות - קיבלנו משתנה מקרי שכל המומנטים שלו הם 0. או, בניסוח שקצת יותר קל להבין - קיבלנו אפס. וזה לא אמור להיות מפתיע שקיבלנו אפס כי זה בדיוק מה שאומר <strong>אי-שוויון צ'בישב</strong> עבור התפלגויות שסטיית התקן שלהן היא אפס. כזכור, הוא אומר באופן כללי ש-</p>
<p><span class="math">\(P\left(\left|X-\mu\right|\ge k\right)\le\frac{\sigma^{2}}{k^{2}}\)</span></p>
<p>ואם סטיית התקן <span class="math">\(\sigma=0\)</span> זה אומר שלכל <span class="math">\(k&gt;0\)</span>, ההסתברות ש-<span class="math">\(X\)</span> יקבל ערך שסוטה מהתוחלת ולו ב-<span class="math">\(k\)</span> היא פשוט 0. עגול. לא קירוב ולא כלום. עכשיו שוב, צריך להזכיר שזה <strong>לא</strong> אומר שהמשתנה המקרי הוא זהותית אפס; כשאנחנו עוסקים במשתנים מקריים רציפים כל מה שזה יכול לומר הוא שמידת ההסתברות של קבוצת כל התוצאות ששונות מ-<span class="math">\(\mu\)</span> היא אפס.</p>
<p>את מה שראינו עכשיו אפשר לקחת טיפה יותר רחוק. בפוסט הקודם הגדרתי <span class="math">\(\overline{X}_{n}=\frac{X_{1}+X_{2}\ldots+X_{n}}{n}\)</span> (שזה בדיוק מה שקראתי לו כאן <span class="math">\(Z_{n}\)</span>) ואז הוכחתי שבהסתברות 1 מתקיים <span class="math">\(\overline{X}_{n}\to\mu\)</span>. התוצאה הזו, שנקראה <strong>החוק החזק של המספרים הגדולים</strong>, דיברה על ההתנהגות של כל הסדרה <span class="math">\(\overline{X}_{n}\)</span> "בבת אחת". אפשר לדבר על זה גם מזווית טיפה שונה. הרי אנחנו יודעים ש-<span class="math">\(\overline{X}_{n}\)</span> לא בהכרח יהיה <strong>שווה</strong> לתוחלת - אנחנו צריכים לקחת עוד ועוד איברים ולהגדיל את <span class="math">\(n\)</span> כדי שהממוצע יתקרב לתוחלת וגם אז הסיכוי שהוא יהיה שווה לה הוא לא בהכרח גדול. אבל אפשר להעריך בצורה גסה מה יהיה גודל הטעות, בעזרת צ'בישב. </p>
<p>אז נניח שיש לי משתנה <span class="math">\(X\)</span> כך ש-<span class="math">\(\text{E}\left[X\right]=\mu\)</span> ו-<span class="math">\(\text{Var}\left(X\right)=\sigma^{2}\)</span>. עכשיו בניתי משתנה חדש, <span class="math">\(\overline{X}_{n}=\frac{X_{1}+\ldots+X_{n}}{n}\)</span>. מה התוחלת שלו? לינאריות התוחלת נותנת לנו</p>
<p><span class="math">\(\text{E}\left[\overline{X}_{n}\right]=\text{E}\left[\frac{X_{1}+\ldots+X_{n}}{n}\right]=\frac{\text{E}\left[X_{1}\right]+\ldots+\text{E}\left[X_{n}\right]}{n}=\frac{\mu+\ldots+\mu}{n}=\mu\)</span></p>
<p>עכשיו, שונות של משתנים מקריים לא מקיימת לינאריות באופן כללי, אבל היא <strong>כן</strong> משמרת חיבור של משתנים מקריים <strong>בלתי תלויים</strong> (די בדומה לאיך שתוחלת של מכפלה של משתנים בלתי תלויים מתפרקת למכפלת תוחלות). בפוסט הקודם גם הזכרתי ש-<span class="math">\(\text{Var}\left(\alpha X\right)=\alpha^{2}X\)</span>. לכן אפשר לחשב:</p>
<p><span class="math">\(\text{Var}\left(\overline{X}_{n}\right)=\text{Var}\left(\frac{X_{1}+\ldots+X_{n}}{n}\right)=\frac{\text{Var}\left(X_{1}\right)+\ldots+\text{Var}\left(X_{n}\right)}{n^{2}}=\frac{\sigma^{2}+\ldots\sigma^{2}}{n^{2}}=\frac{\sigma^{2}}{n}\)</span></p>
<p>ולכן מאי-שוויון צ'בישב:</p>
<p><span class="math">\(P\left(\left|\overline{X}_{n}-\mu\right|\ge\varepsilon\right)\le\frac{\sigma^{2}}{n\varepsilon^{2}}\)</span></p>
<p>המספר המעניין פה הוא ה-<span class="math">\(n\)</span> שנשאר במכנה. בזכותו, אם משאיפים את <span class="math">\(n\)</span> לאינסוף, מקבלים</p>
<p><span class="math">\(\lim_{n\to\infty}P\left(\left|\overline{X}_{n}-\mu\right|\ge\varepsilon\right)=0\)</span></p>
<p>זה מה שנקרא <strong>החוק החלש של המספרים הגדולים</strong> (כי החוק החזק של המספרים הגדולים גורר אותו - ה"התכנסות" שלו היא חזקה יותר מההתכנסות שיש בחוק החלש) וזו דרך קצת יותר פשוטה לראות את "חוסר הטעם" שבהסתכלות על הממוצעים <span class="math">\(\overline{X}_{n}\)</span> אם אנחנו רוצים לקבל משתנה מקרי שמדמה את ההתפלגות של <span class="math">\(X_{1}+\ldots+X_{n}\)</span> כש-<span class="math">\(n\)</span> גדול. המיצוע שאנחנו עושים הוא "טוב מדי" - הוא משמר את המידע על ההתפלגות שבא לידי ביטוי בתוחלת <span class="math">\(\mu\)</span> אבל מוחק את המידע על ההתפלגות שבא לידי ביטוי בסטיית התקן <span class="math">\(\sigma\)</span>. המיצוע שבו מחלקים ב-<span class="math">\(\sqrt{n}\)</span> הוא "עדין" יותר ומשמר גם את המידע הזה, והוכחת החוק החלש של המספרים הגדולים נותנת עוד דרך לראות את זה - אם היינו מחלקים ב-<span class="math">\(\sqrt{n}\)</span> ומנסים להשתמש בצ'בישב, היינו מקבלים רק <span class="math">\(P\left(\left|\frac{X_{1}+\ldots+X_{n}}{\sqrt{n}}-\mu\right|\ge\varepsilon\right)\le\frac{\sigma^{2}}{\varepsilon^{2}}\)</span> שזו תוצאה מעניינת טיפה בפני עצמה אבל אין בה שאיפה לאפס של ההסתברות אלא רק חסם אחיד לכל הממוצעים, לא משנה כמה רחוק ניקח אותם.</p>
<p>הקסם הגדול של משפט הגבול המרכזי בעיני, כמו שאמרתי כבר לפני כמה פוסטים, הוא שלא משנה כמה המשתנה <span class="math">\(X\)</span> שאנחנו מתחילים איתו הוא מורכב ומתוסבך - ההתנהגות של <span class="math">\(X_{1}+\ldots+X_{n}\)</span> תהיה ניתנת לקירוב מצוין רק עם שני הפרמטרים המספריים <span class="math">\(\mu,\sigma\)</span>. ראינו את זה בתוך ההוכחה של משפט הגבול המרכזי עצמו (היינו צריכים רק לדעת את <span class="math">\(L^{\prime}\left(0\right)\)</span> ואת <span class="math">\(L^{\prime\prime}\left(0\right)\)</span> כדי לקבל אותו ולא משהו שתלוי במומנטים מתקדמים יותר) וראינו את זה גם עם החוק החלש של המספרים הגדולים עכשיו (אם המומנט השני הוא אפס גורלה של ההתפלגות נחרץ להיות קבועה בהסתברות 1), אבל למרות שראינו את זה אני עדיין מתקשה להאמין לזה. אולי כי זו לא סתם תוצאה מספרית - זה משהו שבאמת בא לידי ביטוי אמפירית, במציאות, בעולם שלנו, ומשפיע עלינו בשלל דרכים שונות. גם זה אחד מהקסמים של המתמטיקה.</p>
        </article>
        
        <footer>
            <p>© כל הזכויות שמורות לגדי אלכסנדרוביץ'</p>
        </footer>
    </div>

    
    <script>
        function searchPosts() {
            const searchTerm = document.getElementById('searchInput').value;
            if (searchTerm.trim()) {
                window.location.href = '/new_blog/post_list.html?search=' + encodeURIComponent(searchTerm);
            }
        }
        
        document.getElementById('searchInput').addEventListener('keypress', function(e) {
            if (e.key === 'Enter') {
                searchPosts();
            }
        });
    </script>
    
    
    <!-- Auto-render KaTeX math -->
    <script>
        document.addEventListener("DOMContentLoaded", function() {
            renderMathInElement(document.body, {
                delimiters: [
                    {left: "\\[", right: "\\]", display: true},
                    {left: "\\(", right: "\\)", display: false}
                ],
                throwOnError: false
            });
        });
    </script>

</body>
</html>